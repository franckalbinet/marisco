"""Various utilities to decode MARIS dataset from `NetCDF`."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/decoders.ipynb.

# %% auto 0
__all__ = ['nc_to_dfs', 'get_netcdf_properties', 'get_netcdf_group_properties', 'get_netcdf_variable_properties', 'get_enum_dict',
           'NetCDFDecoder']

# %% ../nbs/api/decoders.ipynb 3
from pathlib import Path
from netCDF4 import Dataset
import pandas as pd
import numpy as np
from fastcore.basics import patch, store_attr
import fastcore.all as fc
from typing import Dict, Callable

from marisco.configs import (
    NC_DTYPES, 
    NC_VARS, 
    OR_VARS,
    NC_DIM,
    NC_GROUPS,
    SMP_TYPE_LUT,
    lut_path, 
    Enums,
    nc_tpl_path,
    get_time_units
)

from marisco.callbacks import (
    DecodeTimeCB
    )

# %% ../nbs/api/decoders.ipynb 6
def nc_to_dfs(
    fname: str # Path to NetCDF file
    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values
    "Convert a NetCDF (with groups) file to a dictionary of dataframes."
    dfs = {}
    
    with Dataset(fname, 'r') as nc:
        # Process each group in the NetCDF file
        for group_name in nc.groups:
            group = nc.groups[group_name]
            
            # Get all variables in the group
            data = {}
            for var_name in group.variables:
                # Skip dimension variables (like 'id')
                if var_name not in group.dimensions:
                    data[var_name] = group.variables[var_name][:]
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Convert time from seconds since epoch if present
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'], unit='s')
                
            dfs[group_name.upper()] = df
    
    return dfs

# %% ../nbs/api/decoders.ipynb 10
def get_netcdf_properties(file_path: str) -> dict:
    """
    Retrieve general properties of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing file properties such as size, format, and dimensions.
    """
    properties = {}
    
    file = Path(file_path)
    
    if not file.exists():
        print(f'File not found: {file_path}')
        return properties

    # Get file size
    properties['file_size_bytes'] = file.stat().st_size
    
    # Open the NetCDF file
    with Dataset(file_path, 'r') as nc:
        # Get file format
        properties['file_format'] = nc.file_format

        # Get groups
        properties['groups'] = list(nc.groups.keys())
        
        # Get global attributes
        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}
    
    return properties

# %% ../nbs/api/decoders.ipynb 14
def get_netcdf_group_properties(file_path: str) -> dict:
    """
    Retrieve properties of each group in a NetCDF file, including dimension sizes.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing properties of each group such as variables, dimensions with sizes, and attributes.
    """
    group_properties = {}

    file = Path(file_path)

    if not file.exists():
        print(f'File not found: {file_path}')
        return group_properties

    with Dataset(file_path, 'r') as nc:
        # Iterate over each group in the NetCDF file
        for group_name, group in nc.groups.items():
            # Get dimensions with their sizes
            dimensions = {dim_name: len(dim) for dim_name, dim in group.dimensions.items()}
            
            group_info = {
                'variables': list(group.variables.keys()),
                'dimensions': dimensions,
                'attributes': {attr: group.getncattr(attr) for attr in group.ncattrs()}
            }
            group_properties[group_name] = group_info

    return group_properties


# %% ../nbs/api/decoders.ipynb 17
def get_netcdf_variable_properties(file_path: str, as_df: bool = False) -> dict | pd.DataFrame:
    """
    Retrieve properties of variables in each group of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file
    as_df (bool): If True, returns a pandas DataFrame; if False, returns nested dictionary

    Returns:
    Union[dict, pd.DataFrame]: Properties of variables either as nested dictionary or DataFrame
    """
    var_properties = {}
    
    file = Path(file_path)
    if not file.exists():
        print(f'File not found: {file_path}')
        return var_properties

    with Dataset(file_path, 'r') as nc:
        for group_name, group in nc.groups.items():
            group_vars = {}
            for var_name, var in group.variables.items():
                var_info = {
                    'group': group_name,
                    'variable': var_name,
                    'data_type': var.dtype.str,
                    'dimensions_id': str(var.dimensions),
                    'dimensions_size': str(var.shape),
                }
                # Add variable attributes
                for attr in var.ncattrs():
                    var_info[f'attr_{attr}'] = str(getattr(var, attr))
                    
                group_vars[var_name] = var_info
            var_properties[group_name] = group_vars

    if not as_df:
        return var_properties
    
    # Convert to DataFrame
    rows = []
    for group_name, group_vars in var_properties.items():
        for var_name, var_info in group_vars.items():
            rows.append(var_info)
    
    df = pd.DataFrame(rows)
    
    # Reorder columns to put key information first
    first_cols = ['group', 'variable', 'dimensions_id', 'dimensions_size']
    other_cols = [col for col in df.columns if col not in first_cols]
    df = df[first_cols + other_cols]
    
    return df

# %% ../nbs/api/decoders.ipynb 20
def get_enum_dict(file_path: str, var_name: str) -> dict:
    """
    Get the enum dictionary for a variable in a NetCDF file.
    
    Parameters:
    file_path (str): Path to the NetCDF file
    var_name (str): Name of the variable to get enum for
    
    Returns:
    dict: Dictionary mapping enum names to values, or empty dict if not found
    """
    with Dataset(file_path, 'r') as nc:
        # Look for the variable in all groups
        enum_dict = {}
        for group_name in nc.groups:
            group = nc.groups[group_name]
            if var_name in group.variables:
                var = group.variables[var_name]
                if hasattr(var.datatype, 'enum_dict'):
                    nc_enum_dict = var.datatype.enum_dict       
                    # Store group info and enum dict
                    enum_dict[group_name] = {
                        'variable': var_name,
                        'enum_dict': nc_enum_dict
                    }
                    
        return enum_dict

# %% ../nbs/api/decoders.ipynb 26
class NetCDFDecoder:
    """Decode MARIS NetCDF files to human readable formats."""
    def __init__(self, 
                 dfs: Dict[str, pd.DataFrame], 
                 fname_in: str,  # Path to NetCDF file
                 dest_out: str, 
                 output_format:str, 
                 remap_vars: Dict[str, str],
                 verbose: bool=False
                ):
        fc.store_attr()        

# %% ../nbs/api/decoders.ipynb 29
@patch
def decode(self: NetCDFDecoder):
    "  Decode NetCDF to Human readable files."
    # Funvtion to rename the columns. 
    save_dataframes()
    
    return self.dfs
    

# %% ../nbs/api/decoders.ipynb 30
@patch
def save_dataframes(self: NetCDFDecoder):
    """
    Save DataFrames to files in the specified format.
    
    Parameters:
        dest_path (str, optional): Base path for output files, without extension.
            If None, uses self.dest_fname's path without extension.
        output_format (str): Format to save files in. Options:
            - 'csv': Comma-separated values
            - 'excel': Excel spreadsheet (one sheet per group)
            - 'json': JSON format
            - 'parquet': Apache Parquet format
            - 'hdf': HDF5 format
            - 'pickle': Python pickle format
            - 'feather': Feather format
            - 'stata': Stata format
    """
    # Get base path without extension
    if self.dest_out is None:
            raise ValueError("No destination path provided")
    else:
        base_path = str(Path(self.dest_path).with_suffix(''))
    
    # Handle formats that combine all groups in one file
    if self.output_format == 'excel':
        output_path = f"{base_path}.xlsx"
        with pd.ExcelWriter(output_path) as writer:
            for group_name, df in self.dfs.items():
                df.to_excel(writer, sheet_name=group_name, index=False)
                if self.verbose:
                    print(f"Saved {group_name} to sheet in {output_path}")
    
    elif self.output_format == 'hdf':
        output_path = f"{base_path}.h5"
        with pd.HDFStore(output_path) as store:
            for group_name, df in self.dfs.items():
                store[group_name] = df
                if self.verbose:
                    print(f"Saved {group_name} to group in {output_path}")
    
    # Handle formats that create separate files for each group
    else:
        format_extensions = {
            'csv': '.csv',
            'json': '.json',
            'parquet': '.parquet',
            'pickle': '.pkl',
            'feather': '.feather',
            'stata': '.dta'
        }
        
        if self.output_format not in format_extensions:
            raise ValueError(f"Unsupported output format: {output_format}. Supported formats: {format_extensions.keys()}")
            
        extension = format_extensions[output_format]
        save_methods = {
            'csv': lambda df, path: df.to_csv(path, index=False),
            'json': lambda df, path: df.to_json(path),
            'parquet': lambda df, path: df.to_parquet(path),
            'pickle': lambda df, path: df.to_pickle(path),
            'feather': lambda df, path: df.to_feather(path),
            'stata': lambda df, path: df.to_stata(path)
        }
        
        for group_name, df in self.dfs.items():
            output_path = f"{base_path}_{group_name}{extension}"
            save_methods[self.output_format](df, output_path)
            
            if self.verbose:
                print(f"Saved {group_name} to {output_path}")

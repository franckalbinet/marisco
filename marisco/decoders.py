"""Various utilities to decode MARIS dataset from `NetCDF`."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/decoders.ipynb.

# %% auto 0
__all__ = ['OR_VARS', 'OR_DTYPES', 'OR_GROUPS', 'nc_to_dfs', 'get_netcdf_properties', 'get_netcdf_group_properties',
           'get_netcdf_variable_properties', 'get_enum_dict', 'NetCDFDecoder']

# %% ../nbs/api/decoders.ipynb 3
from pathlib import Path
from netCDF4 import Dataset
import pandas as pd
import numpy as np
from fastcore.basics import patch, store_attr
import fastcore.all as fc

from marisco.configs import (
    NC_DTYPES, 
    NC_VARS, 
    NC_DIM,
    NC_GROUPS,
    lut_path, 
    Enums,
    nc_tpl_path,
    get_time_units
)

# %% ../nbs/api/decoders.ipynb 6
def nc_to_dfs(
    fname: str # Path to NetCDF file
    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values
    "Convert a NetCDF (with groups) file to a dictionary of dataframes."
    dfs = {}
    
    with Dataset(fname, 'r') as nc:
        # Process each group in the NetCDF file
        for group_name in nc.groups:
            group = nc.groups[group_name]
            
            # Get all variables in the group
            data = {}
            for var_name in group.variables:
                # Skip dimension variables (like 'id')
                if var_name not in group.dimensions:
                    data[var_name] = group.variables[var_name][:]
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Convert time from seconds since epoch if present
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'], unit='s')
                
            dfs[group_name.upper()] = df
    
    return dfs

# %% ../nbs/api/decoders.ipynb 11
def get_netcdf_properties(file_path: str) -> dict:
    """
    Retrieve general properties of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing file properties such as size, format, and dimensions.
    """
    properties = {}
    
    file = Path(file_path)
    
    if not file.exists():
        print(f'File not found: {file_path}')
        return properties

    # Get file size
    properties['file_size_bytes'] = file.stat().st_size
    
    # Open the NetCDF file
    with Dataset(file_path, 'r') as nc:
        # Get file format
        properties['file_format'] = nc.file_format

        # Get groups
        properties['groups'] = list(nc.groups.keys())
        
        # Get global attributes
        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}
    
    return properties

# %% ../nbs/api/decoders.ipynb 15
def get_netcdf_group_properties(file_path: str) -> dict:
    """
    Retrieve properties of each group in a NetCDF file, including dimension sizes.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing properties of each group such as variables, dimensions with sizes, and attributes.
    """
    group_properties = {}

    file = Path(file_path)

    if not file.exists():
        print(f'File not found: {file_path}')
        return group_properties

    with Dataset(file_path, 'r') as nc:
        # Iterate over each group in the NetCDF file
        for group_name, group in nc.groups.items():
            # Get dimensions with their sizes
            dimensions = {dim_name: len(dim) for dim_name, dim in group.dimensions.items()}
            
            group_info = {
                'variables': list(group.variables.keys()),
                'dimensions': dimensions,
                'attributes': {attr: group.getncattr(attr) for attr in group.ncattrs()}
            }
            group_properties[group_name] = group_info

    return group_properties


# %% ../nbs/api/decoders.ipynb 18
def get_netcdf_variable_properties(file_path: str, as_df: bool = False) -> dict | pd.DataFrame:
    """
    Retrieve properties of variables in each group of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file
    as_df (bool): If True, returns a pandas DataFrame; if False, returns nested dictionary

    Returns:
    Union[dict, pd.DataFrame]: Properties of variables either as nested dictionary or DataFrame
    """
    var_properties = {}
    
    file = Path(file_path)
    if not file.exists():
        print(f'File not found: {file_path}')
        return var_properties

    with Dataset(file_path, 'r') as nc:
        for group_name, group in nc.groups.items():
            group_vars = {}
            for var_name, var in group.variables.items():
                var_info = {
                    'group': group_name,
                    'variable': var_name,
                    'data_type': var.dtype.str,
                    'dimensions_id': str(var.dimensions),
                    'dimensions_size': str(var.shape),
                }
                # Add variable attributes
                for attr in var.ncattrs():
                    var_info[f'attr_{attr}'] = str(getattr(var, attr))
                    
                group_vars[var_name] = var_info
            var_properties[group_name] = group_vars

    if not as_df:
        return var_properties
    
    # Convert to DataFrame
    rows = []
    for group_name, group_vars in var_properties.items():
        for var_name, var_info in group_vars.items():
            rows.append(var_info)
    
    df = pd.DataFrame(rows)
    
    # Reorder columns to put key information first
    first_cols = ['group', 'variable', 'dimensions_id', 'dimensions_size']
    other_cols = [col for col in df.columns if col not in first_cols]
    df = df[first_cols + other_cols]
    
    return df

# %% ../nbs/api/decoders.ipynb 21
def get_enum_dict(file_path: str, variable_name: str) -> dict:
    """
    Get the enum dictionary for a variable in a NetCDF file.
    
    Parameters:
    file_path (str): Path to the NetCDF file
    variable_name (str): Name of the variable to get enum for
    
    Returns:
    dict: Dictionary mapping enum names to values
    """
    enum_dict = {}
    
    with Dataset(file_path, 'r') as nc:
        # Look for the variable in all groups
        for group_name in nc.groups:
            group = nc.groups[group_name]
            if variable_name in group.variables:
                var = group.variables[variable_name]
                
                # Check if variable has an enum type
                if hasattr(var, 'enum_dict'):
                    enum_dict = var.enum_dict
    
    return enum_dict

# %% ../nbs/api/decoders.ipynb 27
class NetCDFDecoder:
    """Decode MARIS NetCDF files to OpenRefine-compatible CSV format."""
    def __init__(self, 
                 src_fname: str,  # Path to source NetCDF file
                 dest_fname: str, # Base name for output CSV files
                 encoding_type: str,
                 verbose: bool=False
                ):
        store_attr()
        self.enums = Enums(lut_src_dir=lut_path())
        

# %% ../nbs/api/decoders.ipynb 28
@patch 
def validate_enum_mappings(self: NetCDFDecoder):
    """Validate that enum mappings in NetCDF match lookup tables."""
    with Dataset(self.src_fname, 'r') as nc:
        for group_name in nc.groups:
            self._validate_group_enums(nc.groups[group_name], group_name)

# %% ../nbs/api/decoders.ipynb 29
@patch
def _validate_group_enums(self: NetCDFDecoder, group, group_name):
    """Validate enum mappings for a specific group."""
    for var_name, var in group.variables.items():
        if not hasattr(var.datatype, 'enum_dict'): continue
        
        nc_enum_dict = var.datatype.enum_dict
        if self.verbose:
            print(f'nc_enum_dict [{var_name}]:', nc_enum_dict)

        original_col = next((col for col, nc_var in NC_VARS.items() 
                           if nc_var == var_name), None)
        if not original_col: continue

        self._compare_enum_mappings(
            nc_enum_dict, 
            self.enums.types[original_col],
            group_name, 
            var_name,
            original_col
        )

# %% ../nbs/api/decoders.ipynb 30
@patch
def _compare_enum_mappings(self: NetCDFDecoder, nc_enum_dict, lut_enum, 
                          group_name, var_name, original_col):
    """Compare NetCDF enum mappings against lookup table values."""
    if self.verbose:
        print(f'lut_enum [{original_col}]:', lut_enum)
        
    for enum_name, enum_val in nc_enum_dict.items():
        if enum_name not in lut_enum:
            raise ValueError(
                f"Enum value '{enum_name}' in NetCDF not found in lookup table "
                f"for {group_name}/{var_name}"
            )
        if enum_val != lut_enum[enum_name]:
            raise ValueError(
                f"Enum value mismatch for '{enum_name}' in {group_name}/{var_name}: "
                f"NetCDF={enum_val}, LookupTable={lut_enum[enum_name]}"
            )

# %% ../nbs/api/decoders.ipynb 31
@patch
def load_to_dataframes(self: NetCDFDecoder):
    """Load NetCDF groups into DataFrames with standardized column names."""
    dfs = {}
    with Dataset(self.src_fname, 'r') as nc:
        for group_name in nc.groups:
            group = nc.groups[group_name]
            # Get all variables in the group
            data = {}
            for var_name, var in group.variables.items():
                if var_name not in group.dimensions:  # Skip dimension variables
                    data[var_name] = var[:]
            # Convert to DataFrame
            df = pd.DataFrame(data)
            # Rename columns using NC_VARS mapping
            rename_map = {nc_var: col for col, nc_var in NC_VARS.items() 
                         if nc_var in df.columns}
            df = df.rename(columns=rename_map)
            dfs[group_name.upper()] = df
            if self.verbose:
                print(f"Loaded group {group_name} with columns: {df.columns.tolist()}")
    
    return dfs

# %% ../nbs/api/decoders.ipynb 32
OR_VARS = {
    'LON': 'longitude', 
    'LAT': 'latitude',
    'SMP_DEPTH': 'sampdepth',
    'TOT_DEPTH': 'totdepth',
    'TIME': 'begperiod',
    'AREA': 'area',
    'NUCLIDE': 'nuclide_id',
    'VALUE': 'activity',
    'UNIT': 'unit_id',
    'UNC': 'uncertaint',
    'DL': 'detection',
    'FILT': 'filtered',
    'COUNT_MET': 'counmet_id',
    'SAMP_MET': 'sampmet_id', 
    'PREP_MET': 'prepmet_id',
    'VOL': 'volume',
    'SAL': 'salinity',
    'TEMP': 'temperatur',
    'SPECIES': 'species_id',
    'BODY_PART': 'bodypar_id',
    'SED_TYPE': 'sedtype_id',
    'TOP': 'sliceup',
    'BOTTOM': 'slicedown',
    'DRYWT': 'drywt',
    'WETWT': 'wetwt',
    'LAB': 'lab_id'
}

# %% ../nbs/api/decoders.ipynb 34
OR_DTYPES = {
    'AREA': {
        'or_value':'displayName', 
    },
    #'BIO_GROUP': { 
    #    'or_value': 'biogroup', 
    #},
    'BODY_PART': {
        'or_value': 'bodypar_id', 
    },
    'COUNT_MET': {
        'or_value':'counmet_id'
    },
    'DL': {
        'or_value':'name'
    },
    'FILT': {
        'name': 'filt_t', 
        'fname': 'dbo_filtered.xlsx',
        'key': 'name',
        'value':'id'
    },
    'NUCLIDE': {
        'name': 'nuclide_t', 
        'fname': 'dbo_nuclide.xlsx',
        'key': 'nc_name',
        'value':'nuclide_id'
    },
    'PREP_MET': {
        'name': 'prep_met_t', 
        'fname': 'dbo_prepmet.xlsx', 
        'key': 'prepmet',
        'value':'prepmet_id'
    },
    'SAMP_MET': {
        'name': 'samp_met_t', 
        'fname': 'dbo_sampmet.xlsx', 
        'key': 'sampmet',
        'value':'sampmet_id'
    },
    'SED_TYPE': {
        'name': 'sed_type_t', 
        'fname': 'dbo_sedtype.xlsx', 
        'key': 'sedtype', 
        'value':'sedtype_id'
    },
    'SPECIES': {
        'name': 'species_t', 
        # 'fname': 'dbo_species_cleaned.xlsx',
        'fname': 'dbo_species_2024_11_19.xlsx',
        'key': 'species', 
        'value':'species_id'
    },
    'UNIT': {
        'name': 'unit_t', 
        'fname': 'dbo_unit.xlsx', 
        'key': 'unit_sanitized', 
        'value':'unit_id'
    },
    'LAB': {
        'name': 'lab_t', 
        #'fname': 'dbo_lab.xlsx', 
        'fname': 'dbo_lab_cleaned.xlsx', 
        'key': 'lab', 
        'value':'lab_id'
    }
}



# %% ../nbs/api/decoders.ipynb 35
OR_GROUPS = {
    'SEAWATER': '1',
    'BIOTA': '2',
    'SEDIMENT': '3',
    'SUSPENDED': '4',
}

# %% ../nbs/api/decoders.ipynb 36
@patch
def decode(self:NetCDFDecoder):
    """Decode NetCDF to OpenRefine CSV files."""
    # First validate enum mappings. Ensure that the enum values in the netcdf file
    # match the lookup table values.
    self.validate_enum_mappings() 
    self.dfs = self.load_to_dataframes()
    if self.encoding_type == 'openrefine':
        print('OpenRefine encoding type selected.')

     #here going to load the netcdf file to dataframes and standardise the column names.
    
    
    

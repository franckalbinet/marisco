"""Various utilities to decode MARIS dataset from `NetCDF`."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/decoders.ipynb.

# %% auto 0
__all__ = ['nc_to_dfs', 'get_netcdf_properties', 'get_netcdf_group_properties', 'get_netcdf_variable_properties', 'get_enum_dict',
           'NetCDFOpenRefineDecoder']

# %% ../nbs/api/decoders.ipynb 3
from pathlib import Path
from netCDF4 import Dataset
import pandas as pd
import numpy as np
from fastcore.basics import patch, store_attr
import fastcore.all as fc

from marisco.configs import (
    NC_DTYPES, 
    NC_VARS, 
    NC_DIM,
    NC_GROUPS,
    lut_path, 
    Enums,
    nc_tpl_path,
    get_time_units
)

# %% ../nbs/api/decoders.ipynb 6
def nc_to_dfs(
    fname: str # Path to NetCDF file
    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values
    "Convert a NetCDF (with groups) file to a dictionary of dataframes."
    dfs = {}
    
    with Dataset(fname, 'r') as nc:
        # Process each group in the NetCDF file
        for group_name in nc.groups:
            group = nc.groups[group_name]
            
            # Get all variables in the group
            data = {}
            for var_name in group.variables:
                # Skip dimension variables (like 'id')
                if var_name not in group.dimensions:
                    data[var_name] = group.variables[var_name][:]
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Convert time from seconds since epoch if present
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'], unit='s')
                
            dfs[group_name.upper()] = df
    
    return dfs

# %% ../nbs/api/decoders.ipynb 11
def get_netcdf_properties(file_path: str) -> dict:
    """
    Retrieve general properties of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing file properties such as size, format, and dimensions.
    """
    properties = {}
    
    file = Path(file_path)
    
    if not file.exists():
        print(f'File not found: {file_path}')
        return properties

    # Get file size
    properties['file_size_bytes'] = file.stat().st_size
    
    # Open the NetCDF file
    with Dataset(file_path, 'r') as nc:
        # Get file format
        properties['file_format'] = nc.file_format

        # Get groups
        properties['groups'] = list(nc.groups.keys())
        
        # Get global attributes
        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}
    
    return properties

# %% ../nbs/api/decoders.ipynb 15
def get_netcdf_group_properties(file_path: str) -> dict:
    """
    Retrieve properties of each group in a NetCDF file, including dimension sizes.

    Parameters:
    file_path (str): Path to the NetCDF file.

    Returns:
    dict: A dictionary containing properties of each group such as variables, dimensions with sizes, and attributes.
    """
    group_properties = {}

    file = Path(file_path)

    if not file.exists():
        print(f'File not found: {file_path}')
        return group_properties

    with Dataset(file_path, 'r') as nc:
        # Iterate over each group in the NetCDF file
        for group_name, group in nc.groups.items():
            # Get dimensions with their sizes
            dimensions = {dim_name: len(dim) for dim_name, dim in group.dimensions.items()}
            
            group_info = {
                'variables': list(group.variables.keys()),
                'dimensions': dimensions,
                'attributes': {attr: group.getncattr(attr) for attr in group.ncattrs()}
            }
            group_properties[group_name] = group_info

    return group_properties


# %% ../nbs/api/decoders.ipynb 18
def get_netcdf_variable_properties(file_path: str, as_df: bool = False) -> dict | pd.DataFrame:
    """
    Retrieve properties of variables in each group of a NetCDF file.

    Parameters:
    file_path (str): Path to the NetCDF file
    as_df (bool): If True, returns a pandas DataFrame; if False, returns nested dictionary

    Returns:
    Union[dict, pd.DataFrame]: Properties of variables either as nested dictionary or DataFrame
    """
    var_properties = {}
    
    file = Path(file_path)
    if not file.exists():
        print(f'File not found: {file_path}')
        return var_properties

    with Dataset(file_path, 'r') as nc:
        for group_name, group in nc.groups.items():
            group_vars = {}
            for var_name, var in group.variables.items():
                var_info = {
                    'group': group_name,
                    'variable': var_name,
                    'data_type': var.dtype.str,
                    'dimensions_id': str(var.dimensions),
                    'dimensions_size': str(var.shape),
                }
                # Add variable attributes
                for attr in var.ncattrs():
                    var_info[f'attr_{attr}'] = str(getattr(var, attr))
                    
                group_vars[var_name] = var_info
            var_properties[group_name] = group_vars

    if not as_df:
        return var_properties
    
    # Convert to DataFrame
    rows = []
    for group_name, group_vars in var_properties.items():
        for var_name, var_info in group_vars.items():
            rows.append(var_info)
    
    df = pd.DataFrame(rows)
    
    # Reorder columns to put key information first
    first_cols = ['group', 'variable', 'dimensions_id', 'dimensions_size']
    other_cols = [col for col in df.columns if col not in first_cols]
    df = df[first_cols + other_cols]
    
    return df

# %% ../nbs/api/decoders.ipynb 21
def get_enum_dict(file_path: str, variable_name: str) -> dict:
    """
    Get the enum dictionary for a variable in a NetCDF file.
    
    Parameters:
    file_path (str): Path to the NetCDF file
    variable_name (str): Name of the variable to get enum for
    
    Returns:
    dict: Dictionary mapping enum names to values
    """
    enum_dict = {}
    
    with Dataset(file_path, 'r') as nc:
        # Look for the variable in all groups
        for group_name in nc.groups:
            group = nc.groups[group_name]
            if variable_name in group.variables:
                var = group.variables[variable_name]
                
                # Check if variable has an enum type
                if hasattr(var, 'enum_dict'):
                    enum_dict = var.enum_dict
    
    return enum_dict

# %% ../nbs/api/decoders.ipynb 27
class NetCDFOpenRefineDecoder:
    """Decode MARIS NetCDF files to OpenRefine-compatible CSV format."""
    def __init__(self, 
                 src_fname: str,  # Path to source NetCDF file
                 dest_fname: str, # Base name for output CSV files
                 verbose: bool=False
                ):
        store_attr()
        self.enums = Enums(lut_src_dir=lut_path())
        

# %% ../nbs/api/decoders.ipynb 28
@patch 
def validate_enum_mappings(self: NetCDFOpenRefineDecoder):
    """Validate that enum mappings in NetCDF match lookup tables."""
    with Dataset(self.src_fname, 'r') as nc:
        for group_name in nc.groups:
            self._validate_group_enums(nc.groups[group_name], group_name)

# %% ../nbs/api/decoders.ipynb 29
@patch
def _validate_group_enums(self: NetCDFOpenRefineDecoder, group, group_name):
    """Validate enum mappings for a specific group."""
    for var_name, var in group.variables.items():
        if not hasattr(var.datatype, 'enum_dict'): continue
            
        nc_enum_dict = var.datatype.enum_dict
        if self.verbose:
            print(f'nc_enum_dict [{var_name}]:', nc_enum_dict)

        original_col = next((col for col, nc_var in NC_VARS.items() 
                           if nc_var == var_name), None)
        if not original_col: continue

        self._compare_enum_mappings(
            nc_enum_dict, 
            self.enums.types[original_col],
            group_name, 
            var_name,
            original_col
        )

# %% ../nbs/api/decoders.ipynb 30
@patch
def _compare_enum_mappings(self: NetCDFOpenRefineDecoder, nc_enum_dict, lut_enum, 
                          group_name, var_name, original_col):
    """Compare NetCDF enum mappings against lookup table values."""
    if self.verbose:
        print(f'lut_enum [{original_col}]:', lut_enum)
        
    for enum_name, enum_val in nc_enum_dict.items():
        if enum_name not in lut_enum:
            raise ValueError(
                f"Enum value '{enum_name}' in NetCDF not found in lookup table "
                f"for {group_name}/{var_name}"
            )
        if enum_val != lut_enum[enum_name]:
            raise ValueError(
                f"Enum value mismatch for '{enum_name}' in {group_name}/{var_name}: "
                f"NetCDF={enum_val}, LookupTable={lut_enum[enum_name]}"
            )

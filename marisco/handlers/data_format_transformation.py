# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/handlers/data_format_transformation.ipynb.

# %% auto 0
__all__ = ['TAXON_KEY_MAP', 'lut_taxon', 'or_mappings', 'load_data', 'ValidateEnumsCB', 'RemoveNonORVarsCB', 'get_taxon_info_lut',
           'AddTaxonInformationCB', 'RemapToORMappingsCB', 'RemapToHumanReadableCB', 'AddZoteroArchiveLocationCB',
           'decode']

# %% ../../nbs/handlers/data_format_transformation.ipynb 5
from pathlib import Path
from netCDF4 import Dataset
import pandas as pd
import fastcore.all as fc
from typing import Dict, Callable

from marisco.configs import (
    NC_VARS,
    OR_VARS,
    NC_GROUPS,
    OR_DTYPES,
    Enums,
    lut_path,
    species_lut_path,
    cfg
)

from marisco.utils import (
    get_netcdf_properties
)

from marisco.callbacks import (
    Callback,
    Transformer,
    DecodeTimeCB,
    AddSampleTypeIdColumnCB
)  
    
from marisco.decoders import (
        NetCDFDecoder
    )
from marisco.metadata import (
    ZoteroItem
)

# %% ../../nbs/handlers/data_format_transformation.ipynb 10
def load_data(fname:str, verbose: bool = False):
    """Load NetCDF groups into DataFrames with standardized column names."""
    dfs = {}
    with Dataset(fname, 'r') as nc:
        for group_name in nc.groups:
            group = nc.groups[group_name]
            # Get all variables in the group
            data = {var_name: var[:] for var_name, var in group.variables.items() if var_name not in group.dimensions}
            # Convert to DataFrame
            df = pd.DataFrame(data)
            # Rename columns using NC_VARS mapping
            rename_map = {nc_var: col for col, nc_var in NC_VARS.items() 
                         if nc_var in df.columns}
            # here update to infrom if df.columns includes names that are not included in NC_VARS. Just print 
            
            
            df = df.rename(columns=rename_map)
            dfs[group_name.upper()] = df
            if verbose:
                print(f"Loaded group {group_name} with columns: {df.columns.tolist()}")
        
        # herer extract enum_dicts 
        
        #here get global attibutes 
        
        
    
    return dfs, enum_dicts, globattrs

# %% ../../nbs/handlers/data_format_transformation.ipynb 15
class ValidateEnumsCB(Callback):
    "Validate enumeration mappings between NetCDF file and MARIS lookup tables."
    def __init__(self, 
                src_fname: str,  # Path to NetCDF file
                enums: Enums,    # MARIS lookup table enums
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Process each group in the NetCDF file and validate its enums."""
        with Dataset(self.src_fname, 'r') as nc:
            for group_name in nc.groups:
                group = nc.groups[group_name]
                self._validate_group(group, group_name)
    
    def _validate_group(self, group, group_name: str):
        """Validate enum mappings for a specific group."""
        for var_name, var in group.variables.items():
            if not hasattr(var.datatype, 'enum_dict'): 
                continue
            
            nc_enum_dict = var.datatype.enum_dict
            if self.verbose:
                print(f"nc_enum_dict [{var_name}]:", nc_enum_dict)

            # Get original column name from NC_VARS mapping
            original_col = next((col for col, nc_var in NC_VARS.items() 
                               if nc_var == var_name), None)
            if not original_col: 
                continue

            # Compare enum mappings
            self._compare_mappings(
                nc_enum_dict,
                self.enums.types[original_col],
                group_name,
                var_name,
                original_col
            )
    
    def _compare_mappings(self, nc_dict: dict, lut_dict: dict, 
                         group_name: str, var_name: str, col_name: str):
        """Compare NetCDF enum dictionary with lookup table dictionary."""
        if self.verbose:
            print(f"lut_enum [{col_name}]:", lut_dict)
            
        # Check for mismatches between NetCDF and lookup table
        for key, value in nc_dict.items():
            if key not in lut_dict or lut_dict[key] != value:
                print(f"\nWarning: Enum mismatch in {group_name}/{var_name}")
                print(f"NetCDF value: {key} -> {value}")
                print(f"Lookup value: {key} -> {lut_dict.get(key, 'Not found')}")        

# %% ../../nbs/handlers/data_format_transformation.ipynb 19
class RemoveNonORVarsCB(Callback):
    "Remove variables not defined in OR_VARS configuration."
    def __init__(self, 
                or_vars: Dict[str, str] = OR_VARS,  # Dictionary mapping OR vars to NC vars
                verbose: bool = False,
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Remove non-OR variables from all dataframes."""
        for group_name in tfm.dfs:
            tfm.dfs[group_name] = self._remove_non_or_vars(tfm.dfs[group_name], group_name)
            
    def _remove_non_or_vars(self, df: pd.DataFrame, group_name:str ) -> pd.DataFrame:
        """Remove columns not in OR_VARS and print removed columns if verbose."""
        current_cols = set(df.columns)
        or_cols = set(self.or_vars.keys())
        cols_to_remove = current_cols - or_cols
        
        if self.verbose and cols_to_remove:
            print(f"Removing variables that are not compatible with MARIS's OpenRefine processing. \nRemoving {', '.join(cols_to_remove)} from {group_name} dataset.")
                        
        return df.drop(columns=cols_to_remove)


# %% ../../nbs/handlers/data_format_transformation.ipynb 22
TAXON_KEY_MAP = {
    'Taxonname': 'TAXONNAME',
    'Taxonrank': 'TAXONRANK',
    'TaxonDB': 'TAXONDB',
    'TaxonDBID': 'TAXONDBID',
    'TaxonDBURL': 'TAXONDBURL'
}

# %% ../../nbs/handlers/data_format_transformation.ipynb 23
def get_taxon_info_lut(maris_lut: str, key_names: dict = TAXON_KEY_MAP) -> dict:
    "Create lookup dictionary for taxon information from MARIS species lookup table."
    species = pd.read_excel(maris_lut)
    # Select columns and rename them to standardized format
    columns = ['species_id'] + list(key_names.keys())
    df = species[columns].rename(columns=key_names)
    return df.set_index('species_id').to_dict()

lut_taxon = lambda: get_taxon_info_lut(maris_lut=species_lut_path(), key_names=TAXON_KEY_MAP)

# %% ../../nbs/handlers/data_format_transformation.ipynb 24
class AddTaxonInformationCB(Callback):
    """Add taxon information to BIOTA group based on species lookup table."""
    
    def __init__(self, 
                fn_lut: Callable = lut_taxon,  # Function that returns taxon lookup dictionary
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Delegate tasks to add taxon information to the BIOTA group."""
        if not self.check_biota_group_exists(tfm):
            return
        
        df = tfm.dfs['BIOTA']
        if not self.check_species_column_exists(df):
            return
        
        self.add_taxon_columns(df)

    def check_biota_group_exists(self, tfm: Transformer) -> bool:
        """Check if 'BIOTA' group exists in the dataframes."""
        if 'BIOTA' not in tfm.dfs:
            if self.verbose:
                print("No BIOTA group found, skipping taxon information")
            return False
        return True

    def check_species_column_exists(self, df: pd.DataFrame) -> bool:
        """Check if 'SPECIES' column exists in the BIOTA dataframe."""
        if 'SPECIES' not in df.columns:
            if self.verbose:
                print("No SPECIES column found in BIOTA dataframe, skipping taxon information")
            return False
        return True

    def add_taxon_columns(self, df: pd.DataFrame):
        """Add taxon information columns to the BIOTA dataframe."""
        lut = self.fn_lut()
        
        # Add each column from the lookup table
        for col in lut.keys():
            df[col] = df['SPECIES'].map(lut[col]).fillna('Unknown')
        
        self.report_unmatched_species(df)

    def report_unmatched_species(self, df: pd.DataFrame):
        """Report any species IDs not found in the lookup table."""
        unmatched = df[df['TAXONNAME'] == 'Unknown']['SPECIES'].unique()
        if self.verbose and len(unmatched) > 0:
            print(f"Warning: Species IDs not found in lookup table: {', '.join(map(str, unmatched))}")

# %% ../../nbs/handlers/data_format_transformation.ipynb 28
or_mappings={'DL':
                {0:'ND',1:'=',2:'<'},
            'FILT':
                {0:'NA',1:'Y',2:'N'},
            }

# %% ../../nbs/handlers/data_format_transformation.ipynb 29
class RemapToORMappingsCB(Callback):
    "Convert values using OR mappings if columns exist in dataframe."
    def __init__(self, 
                or_mappings: Dict[str, Dict] = or_mappings,  # Dictionary of column mappings, 
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Apply OR mappings to all dataframes."""
        for group_name in tfm.dfs:
            if self.verbose:
                print(f"\nProcessing {group_name} group...")
            tfm.dfs[group_name] = self._apply_mappings(tfm.dfs[group_name])
            
    def _apply_mappings(self, df: pd.DataFrame) -> pd.DataFrame:
        """Apply OR mappings to columns that exist in the dataframe."""
        for col, mapping in self.or_mappings.items():
            if col in df.columns:
                if self.verbose:
                    print(f"    Mapping values for column: {col}")
                df[col] = df[col].map(mapping)
        return df


# %% ../../nbs/handlers/data_format_transformation.ipynb 33
class RemapToHumanReadableCB(Callback):
    """Convert enum values in DataFrames to their human-readable format, but only for variables defined as 'human_readable' in OR_DTYPES and not present in or_mappings."""
    
    def __init__(self, 
                 or_dtypes: Dict = OR_DTYPES,  # Dictionary defining variable types
                 or_mappings: Dict = or_mappings,  # Dictionary of value mappings
                 output_format: str = 'openrefine_csv',
                 verbose: bool = False
                ):
        fc.store_attr()

    def __call__(self, tfm: Transformer):
        """Delegate the conversion of numeric enum values to human-readable strings for specified variables."""
        if self.output_format != 'openrefine_csv':
            self.or_mappings = {}
        
        for group_name, df in tfm.dfs.items():
            self.process_group(group_name, df)

    def process_group(self, group_name, df):
        """Process each group to convert enums to human-readable format."""
        if self.verbose:
            print(f'Processing {group_name} enums ...')
        
        self.convert_variables(group_name, df)

    def convert_variables(self, group_name, df):
        """Convert variables within a group to their human-readable format if applicable."""
        for col_name in df.columns:
            if col_name in self.or_dtypes and self.or_dtypes[col_name]['type'] == 'human_readable':
                self.convert_variable(col_name, group_name, df)

    def convert_variable(self, col_name, group_name, df):
        """Convert a single variable to human-readable format based on conditions."""
        if col_name not in self.or_mappings and self.output_format == 'openrefine_csv':
            if self.verbose:
                print(f"Converting '{col_name}' to human readable format")
            
            # Assuming enum_dict is somehow accessible here, possibly through a modified approach or additional data structure
            enum_dict = self.get_enum_dict(col_name)
            df[col_name] = df[col_name].map(enum_dict).fillna('Unknown')
            
            if self.verbose:
                print(f"Converted {col_name} in {group_name}")
                print("-" * 80)
                
            
    def get_enum_dict(self, col_name):
        """Retrieve or simulate the enum dictionary for a column."""
        # Placeholder for actual enum dictionary retrieval logic
        return {1: 'Type A', 2: 'Type B', 3: 'Type C'}  # Example mapping

# %% ../../nbs/handlers/data_format_transformation.ipynb 41
class AddZoteroArchiveLocationCB(Callback):
    "Fetch and append 'Loc. in Archive' from Zotero to DataFrame."
    def __init__(self, src_fname: str, cfg: dict):
        self.src_fname = src_fname
        self.cfg = cfg

    def __call__(self, tfm):
        
        zotero_key = get_netcdf_properties(self.src_fname)['global_attributes']['id']
        item = ZoteroItem(zotero_key, self.cfg['zotero'])
        if item.exist():
            loc_in_archive = item.item['data']['archiveLocation'] 
            for grp, df in tfm.dfs.items():
                df['REF_ID'] = int(loc_in_archive)
        else:
            print(f"Warning: Zotero item {self.item_id} does not exist.")

# %% ../../nbs/handlers/data_format_transformation.ipynb 47
def decode(
    fname_in: str, # Input file name
    dest_out: str | None = None, # Output file name (optional)
    output_format: str = 'openrefine_csv',
    remap_vars: Dict[str, str] = OR_VARS,
    verbose: bool = False,
    **kwargs # Additional arguments
    ) -> None:
    "Decode data from NetCDF."
    dfs = load_to_dataframes(fname_in)

    valid_output_formats=['openrefine_csv', 'csv']
    if output_format not in valid_output_formats:
        print (f'Invalid output format. Allowed formats: {valid_output_formats}')
        return 
    
    tfm = Transformer(
        dfs,
        cbs=[
            RemoveNonORVarsCB(
                output_format=output_format
                ),
            ValidateEnumsCB(
                src_fname=fname_in,
                enums=Enums(lut_src_dir=lut_path())
                ),
            ValidateNetCDFVarsCB(
                src_fname=fname_in
                ),
            
            AddTaxonInformationCB(
                fn_lut=lut_taxon
                ),  
            RemapToORMappingsCB(
                or_mappings=or_mappings,
                output_format=output_format
                ),            
            RemapToHumanReadableCB(
                src_fname=fname_in, 
                output_format=output_format
                ),
            DecodeTimeCB(),
            AddSampleTypeIdColumnCB(),
            AddZoteroArchiveLocationCB(src_fname=fname_in, cfg=cfg())
        ]
    )    
    
    tfm()
    decoder = NetCDFDecoder( 
                            dfs=tfm.dfs,
                            fname_in=fname_in,  
                            dest_out=dest_out,                           
                            output_format='csv',
                            remap_vars=OR_VARS,
                            verbose=verbose
                    )
    decoder.decode()

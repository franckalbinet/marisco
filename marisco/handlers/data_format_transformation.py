# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/handlers/data_format_transformation.ipynb.

# %% auto 0
__all__ = ['TAXON_KEY_MAP', 'lut_taxon', 'or_mappings', 'load_to_dataframes', 'RemoveNonORVarsCB', 'ValidateEnumsCB',
           'ValidateNetCDFVarsCB', 'get_taxon_info_lut', 'AddTaxonInformationCB', 'RemapToORMappingsCB',
           'RemapToHumanReadableCB', 'decode']

# %% ../../nbs/handlers/data_format_transformation.ipynb 5
from pathlib import Path
from netCDF4 import Dataset
import pandas as pd
from fastcore.basics import patch, store_attr
import fastcore.all as fc
from typing import Dict, Callable

from marisco.configs import (
    NC_VARS,
    OR_VARS,
    NC_GROUPS,
    OR_DTYPES,
    Enums,
    lut_path,
    species_lut_path
)

from marisco.callbacks import (
    Callback,
    Transformer,
    DecodeTimeCB,
    RemapCB
)  
    
from marisco.decoders import (
        NetCDFDecoder
    )


# %% ../../nbs/handlers/data_format_transformation.ipynb 10
def load_to_dataframes(fname:str, verbose: bool = False):
    """Load NetCDF groups into DataFrames with standardized column names."""
    dfs = {}
    with Dataset(fname, 'r') as nc:
        for group_name in nc.groups:
            group = nc.groups[group_name]
            # Get all variables in the group
            data = {}
            for var_name, var in group.variables.items():
                if var_name not in group.dimensions:  # Skip dimension variables
                    data[var_name] = var[:]
            # Convert to DataFrame
            df = pd.DataFrame(data)
            # Rename columns using NC_VARS mapping
            rename_map = {nc_var: col for col, nc_var in NC_VARS.items() 
                         if nc_var in df.columns}
            df = df.rename(columns=rename_map)
            dfs[group_name.upper()] = df
            if verbose:
                print(f"Loaded group {group_name} with columns: {df.columns.tolist()}")
    
    return dfs

# %% ../../nbs/handlers/data_format_transformation.ipynb 13
class RemoveNonORVarsCB(Callback):
    "Remove variables not defined in OR_VARS configuration."
    def __init__(self, 
                or_vars: Dict[str, str] = OR_VARS,  # Dictionary mapping OR vars to NC vars
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Remove non-OR variables from all dataframes."""
        for group_name in tfm.dfs:
            if self.verbose:
                print(f"\nProcessing {group_name} group...")
            tfm.dfs[group_name] = self._remove_non_or_vars(tfm.dfs[group_name])
            
    def _remove_non_or_vars(self, df: pd.DataFrame) -> pd.DataFrame:
        """Remove columns not in OR_VARS and print removed columns if verbose."""
        current_cols = set(df.columns)
        or_cols = set(self.or_vars.keys())
        cols_to_remove = current_cols - or_cols
        
        if self.verbose and cols_to_remove:
            print(f"    Removing columns: {', '.join(cols_to_remove)}")
            
        return df.drop(columns=cols_to_remove)


# %% ../../nbs/handlers/data_format_transformation.ipynb 18
class ValidateEnumsCB(Callback):
    "Validate enumeration mappings between NetCDF file and MARIS lookup tables."
    def __init__(self, 
                src_fname: str,  # Path to NetCDF file
                enums: Enums,    # MARIS lookup table enums
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Process each group in the NetCDF file and validate its enums."""
        with Dataset(self.src_fname, 'r') as nc:
            for group_name in nc.groups:
                group = nc.groups[group_name]
                self._validate_group(group, group_name)
    
    def _validate_group(self, group, group_name: str):
        """Validate enum mappings for a specific group."""
        for var_name, var in group.variables.items():
            if not hasattr(var.datatype, 'enum_dict'): 
                continue
            
            nc_enum_dict = var.datatype.enum_dict
            if self.verbose:
                print(f"nc_enum_dict [{var_name}]:", nc_enum_dict)

            # Get original column name from NC_VARS mapping
            original_col = next((col for col, nc_var in NC_VARS.items() 
                               if nc_var == var_name), None)
            if not original_col: 
                continue

            # Compare enum mappings
            self._compare_mappings(
                nc_enum_dict,
                self.enums.types[original_col],
                group_name,
                var_name,
                original_col
            )
    
    def _compare_mappings(self, nc_dict: dict, lut_dict: dict, 
                         group_name: str, var_name: str, col_name: str):
        """Compare NetCDF enum dictionary with lookup table dictionary."""
        if self.verbose:
            print(f"lut_enum [{col_name}]:", lut_dict)
            
        # Check for mismatches between NetCDF and lookup table
        for key, value in nc_dict.items():
            if key not in lut_dict or lut_dict[key] != value:
                print(f"\nWarning: Enum mismatch in {group_name}/{var_name}")
                print(f"NetCDF value: {key} -> {value}")
                print(f"Lookup value: {key} -> {lut_dict.get(key, 'Not found')}")        

# %% ../../nbs/handlers/data_format_transformation.ipynb 22
class ValidateNetCDFVarsCB(Callback):
    " Validate that all variables in the NetCDF file are included in NC_VARS mapping. Identifies and reports any unmapped variables."
    def __init__(self, 
                src_fname: str,  # Path to NetCDF file
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Check each group's variables against NC_VARS mapping."""
        unmapped_vars = {}
        
        with Dataset(self.src_fname, 'r') as nc:
            for group_name in nc.groups:
                group = nc.groups[group_name]
                group_vars = set(group.variables.keys())
                mapped_vars = {v for k, v in NC_VARS.items()}
                unmapped = group_vars - mapped_vars - {'id'}  # Exclude dimension variables
                
                if unmapped:
                    unmapped_vars[group_name] = unmapped
                    if self.verbose:
                        print(f"\nWarning: Unmapped variables in group {group_name}:")
                        print(f"Variables: {unmapped}")
        

# %% ../../nbs/handlers/data_format_transformation.ipynb 25
TAXON_KEY_MAP = {
    'Taxonname': 'TAXONNAME',
    'Taxonrank': 'TAXONRANK',
    'TaxonDB': 'TAXONDB',
    'TaxonDBID': 'TAXONDBID',
    'TaxonDBURL': 'TAXONDBURL'
}

# %% ../../nbs/handlers/data_format_transformation.ipynb 26
def get_taxon_info_lut(maris_lut: str, key_names: dict = TAXON_KEY_MAP) -> dict:
    "Create lookup dictionary for taxon information from MARIS species lookup table."
    species = pd.read_excel(maris_lut)
    # Select columns and rename them to standardized format
    columns = ['species_id'] + list(key_names.keys())
    df = species[columns].rename(columns=key_names)
    return df.set_index('species_id').to_dict()

lut_taxon = lambda: get_taxon_info_lut(maris_lut=species_lut_path(), key_names=TAXON_KEY_MAP)

# %% ../../nbs/handlers/data_format_transformation.ipynb 27
class AddTaxonInformationCB(Callback):
    "Add taxon information to BIOTA group based on species lookup table."
    def __init__(self, 
                fn_lut: Callable = lut_taxon,  # Function that returns taxon lookup dictionary
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Add taxon information columns to BIOTA group."""
        if 'BIOTA' not in tfm.dfs:
            if self.verbose:
                print("No BIOTA group found, skipping taxon information")
            return
            
        df = tfm.dfs['BIOTA']
        if 'SPECIES' not in df.columns:
            if self.verbose:
                print("No SPECIES column found in BIOTA dataframe, skipping taxon information")
            return
        
        lut = self.fn_lut()
        
        # Add each column from the lookup table
        for col in lut.keys():
            df[col] = df['SPECIES'].map(lut[col]).fillna('Unknown')
            
        if self.verbose:
            unmatched = df[df['TAXONNAME'] == 'Unknown']['SPECIES'].unique()
            if len(unmatched) > 0:
                print(f"Warning: Species IDs not found in lookup table: {', '.join(map(str, unmatched))}")

# %% ../../nbs/handlers/data_format_transformation.ipynb 31
or_mappings={'DL':
                {0:'ND',1:'=',2:'<'},
            'FILT':
                {0:'NA',1:'Y',2:'N'},
            }

# %% ../../nbs/handlers/data_format_transformation.ipynb 32
class RemapToORMappingsCB(Callback):
    "Convert values using OR mappings if columns exist in dataframe."
    def __init__(self, 
                or_mappings: Dict[str, Dict] = or_mappings,  # Dictionary of column mappings
                verbose: bool = False
                ):
        fc.store_attr()
        
    def _apply_mappings(self, df: pd.DataFrame) -> pd.DataFrame:
        """Apply OR mappings to columns that exist in the dataframe."""
        for col, mapping in self.or_mappings.items():
            if col in df.columns:
                if self.verbose:
                    print(f"    Mapping values for column: {col}")
                df[col] = df[col].map(mapping)
        return df
    
    def __call__(self, tfm: Transformer):
        """Apply OR mappings to all dataframes."""
        for group_name in tfm.dfs:
            if self.verbose:
                print(f"\nProcessing {group_name} group...")
            tfm.dfs[group_name] = self._apply_mappings(tfm.dfs[group_name])

# %% ../../nbs/handlers/data_format_transformation.ipynb 35
class RemapToHumanReadableCB(Callback):
    "Convert enum values in DataFrames to their human-readable format,but only for variables defined as 'human_readable' in OR_DTYPES and not present in or_mappings."
    def __init__(self, 
                src_fname: str,  # Path to NetCDF file
                or_dtypes: Dict = OR_DTYPES,  # Dictionary defining variable types
                or_mappings: Dict = or_mappings,  # Dictionary of value mappings
                verbose: bool = False
                ):
        fc.store_attr()
        
    def __call__(self, tfm: Transformer):
        """Convert numeric enum values to human-readable strings for specified variables."""
        with Dataset(self.src_fname, 'r') as nc:
            for group_name, df in tfm.dfs.items():
                nc_group_name = NC_GROUPS[group_name]
                group = nc.groups[nc_group_name]
                
                if self.verbose:
                    print(f'Processing {group_name} enums ...')
                
                # Process each variable that has an enum
                for var_name, var in group.variables.items():
                    if hasattr(var.datatype, 'enum_dict'):
                        # Get the original column name from NC_VARS mapping
                        original_col = next((col for col, nc_var in NC_VARS.items() 
                                          if nc_var == var_name), None)
                        
                        # Only convert if variable is human_readable and not in or_mappings
                        if (original_col and 
                            original_col in df.columns and 
                            original_col not in self.or_mappings and
                            self.or_dtypes[original_col]['type'] == 'human_readable'):
                            
                            if self.verbose:
                                print(f"Converting '{original_col}' to human readable format")
                                print(f"Enum values: {var.datatype.enum_dict}")
                            
                            enum_dict = {v: k for k, v in var.datatype.enum_dict.items()}
                            tfm.dfs[group_name][original_col] = df[original_col].map(enum_dict)
                            
                            if self.verbose:
                                print(f"Converted {original_col} in {group_name}")
                                print("-" * 80)

# %% ../../nbs/handlers/data_format_transformation.ipynb 42
def decode(
    fname_in: str, # Input file name
    dest_out: str | None = None, # Output file name (optional)
    output_format: str = 'csv',
    remap_vars: Dict[str, str] = OR_VARS,
    verbose: bool = False,
    **kwargs # Additional arguments
    ) -> None:
    "Decode data from NetCDF."
    dfs = load_to_dataframes(fname_in)
    print (dfs)
    tfm = Transformer(
        dfs,
        cbs=[
            RemoveNonORVarsCB(),
            ValidateEnumsCB(
                src_fname=fname_in,
                enums=Enums(lut_src_dir=lut_path())
                ),
            ValidateNetCDFVarsCB(
                src_fname=fname_in
                ),
            AddTaxonInformationCB(
                fn_lut=lut_taxon
                ),  
            RemapToORMappingsCB(or_mappings),            
            RemapToHumanReadableCB(
                src_fname=fname_in),
            DecodeTimeCB(),
        ]
    )    
    
    tfm()
    decoder = NetCDFDecoder( 
                            dfs=tfm.dfs,
                            fname_in=fname_in,  
                            dest_out=dest_out,                           
                            output_format='csv',
                            remap_vars=OR_VARS,
                            verbose=verbose
                    )
    decoder.decode()

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/handlers/helcom.ipynb.

# %% auto 0
__all__ = ['fname_in', 'fname_out_nc', 'fname_out_csv', 'zotero_key', 'ref_id', 'varnames_lut_updates', 'coi_units_unc',
           'unmatched_fixes_biota_species', 'get_maris_species', 'unmatched_fixes_biota_tissues', 'get_maris_bodypart',
           'unmatched_fixes_sediments', 'get_maris_sediments', 'renaming_unit_rules', 'coi_dl', 'coi_coordinates',
           'coi_val', 'kw', 'load_data', 'CompareDfsAndTfm', 'LowerStripRdnNameCB', 'get_unique_nuclides',
           'get_varnames_lut', 'RemapRdnNameCB', 'ParseTimeCB', 'unc_rel2stan', 'NormalizeUncUnitCB', 'get_maris_lut',
           'LookupBiotaSpeciesCB', 'LookupBiotaBodyPartCB', 'get_biogroup_lut', 'LookupBiogroupCB', 'LookupSedimentCB',
           'LookupUnitCB', 'get_detectionlimit_lut', 'LookupDetectionLimitCB', 'RemapDataProviderSampleIdCB',
           'get_filtered_lut', 'LookupFiltCB', 'RemapStationIdCB', 'RemapProfileIdCB', 'RemapSedSliceTopBottomCB',
           'LookupDryWetRatio', 'ddmmmm2dddddd', 'FormatCoordinates', 'SanitizeValue', 'get_renaming_rules_netcdf',
           'get_renaming_rules_openrefine', 'SelectAndRenameColumnCB', 'ReshapeLongToWide', 'get_attrs', 'enums_xtra',
           'encode', 'get_renaming_rules_netcdf2OpenRefine', 'encode_open_refine_csv']

# %% ../../nbs/handlers/helcom.ipynb 7
import pandas as pd # Python package that provides fast, flexible, and expressive data structures.
import numpy as np
from tqdm import tqdm # Python Progress Bar Library
from functools import partial # Function which Return a new partial object which when called will behave like func called with the positional arguments args and keyword arguments keywords
import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.
from pathlib import Path # This module offers classes representing filesystem paths
from dataclasses import asdict

from ..utils import (has_valid_varname, match_worms, match_maris_lut, Match)
from ..callbacks import (Callback, Transformer, EncodeTimeCB, SanitizeLonLatCB)
from ..metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, TimeRangeCB, ZoteroCB, KeyValuePairCB)
from ..configs import (base_path, nc_tpl_path, cfg, cache_path, cdl_cfg, Enums, lut_path,
                             species_lut_path, sediments_lut_path, bodyparts_lut_path, 
                             detection_limit_lut_path, filtered_lut_path, area_lut_path)
from ..serializers import NetCDFEncoder
from collections.abc import Callable
from math import modf
import warnings
from ..netcdf_to_csv import (LookupTimeFromEncodedTime, GetSampleTypeCB,
                                   LookupNuclideByIdCB, ConvertLonLatCB, LookupUnitByIdCB,
                                   LookupValueTypeByIdCB, LookupSpeciesByIdCB, 
                                   LookupBodypartByIdCB, LookupSedimentTypeByIdCB)                                  
from ..serializers import OpenRefineCsvEncoder

# %% ../../nbs/handlers/helcom.ipynb 26
fname_in = '../../_data/accdb/mors/csv'
fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'
fname_out_csv = '../../_data/output/100-HELCOM-MORS-2024.csv'
zotero_key ='26VMZZ2Q'
ref_id = 100

# %% ../../nbs/handlers/helcom.ipynb 29
def load_data(src_dir,
                smp_types=['SEA', 'SED', 'BIO']):
    "Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type"
    dfs = {}
    lut_smp_type = {'SEA': 'seawater', 'SED': 'sediment', 'BIO': 'biota'}
    for smp_type in smp_types:
        fname_meas = smp_type + '02.csv' # measurement (i.e. radioactivity) information.
        fname_smp = smp_type + '01.csv' # sample information 
        df = pd.merge(pd.read_csv(Path(src_dir)/fname_meas),  # measurements
                      pd.read_csv(Path(src_dir)/fname_smp),  # sample
                      on='KEY', how='left')
        dfs[lut_smp_type[smp_type]] = df
    return dfs

# %% ../../nbs/handlers/helcom.ipynb 44
class CompareDfsAndTfm(Callback):
    "Create a dfs of dropped data. Data included in the DFS not in the TFM"
    def __init__(self, dfs_compare):
        fc.store_attr()

    def __call__(self, tfm):
        tfm.dfs_dropped={}
        tfm.compare_stats={}
        for grp in tfm.dfs.keys():
           
            # get the index values in dfs (i.e. dfs_compare) not in tfm.dfs. 
            index_diff=self.dfs_compare[grp].index.difference(tfm.dfs[grp].index)
            tfm.dfs_dropped[grp] = self.dfs_compare[grp].loc[index_diff]

            tfm.compare_stats[grp]= {'Number of rows in dfs :' : len(self.dfs_compare[grp].index),
                                     'Number of rows in tfm.dfs:' : len(tfm.dfs[grp].index),
                                     'Number of dropped rows:' : len(tfm.dfs_dropped[grp].index),
                                     'Number of rows in tfm.dfs + Number of dropped rows:' : len(tfm.dfs[grp].index) + len(tfm.dfs_dropped[grp].index)
                                    }

# %% ../../nbs/handlers/helcom.ipynb 49
class LowerStripRdnNameCB(Callback):
    "Convert nuclide names to lowercase & strip any trailing space(s)"
    def __call__(self, tfm):
        for k in tfm.dfs.keys():
            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].apply(
                lambda x: x.lower().strip())

# %% ../../nbs/handlers/helcom.ipynb 54
def get_unique_nuclides(dfs):
    "Get list of unique radionuclide types measured across samples."
    nuclides = []
    for k in dfs.keys():
        nuclides += dfs[k]['NUCLIDE'].unique().tolist()
    # remove duplicates from nuclides list.
    nuclides=list(set(nuclides))
    return nuclides

# %% ../../nbs/handlers/helcom.ipynb 57
varnames_lut_updates = {
    'k-40': 'k40',
    'cm243244': 'cm243_244_tot',
    'cs134137': 'cs134_137_tot',
    'pu239240': 'pu239_240_tot',
    'pu238240': 'pu238_240_tot',
    'cs138': 'cs137',
    'cs139': 'cs137',
    'cs140': 'cs137',
    'cs141': 'cs137',
    'cs142': 'cs137',
    'cs143': 'cs137',
    'cs144': 'cs137',
    'cs145': 'cs137',
    'cs146': 'cs137'}

# %% ../../nbs/handlers/helcom.ipynb 59
def get_varnames_lut(dfs, lut=varnames_lut_updates):
    lut = {n: n for n in set(get_unique_nuclides(dfs))}
    lut.update(varnames_lut_updates)
    return lut

# %% ../../nbs/handlers/helcom.ipynb 61
class RemapRdnNameCB(Callback):
    "Remap to MARIS radionuclide names."
    def __init__(self,
                 fn_lut=partial(get_varnames_lut, lut=varnames_lut_updates)):
        fc.store_attr()

    def __call__(self, tfm):
        lut = self.fn_lut(tfm.dfs)
        for grp in tfm.dfs.keys():
            tfm.dfs[grp]['NUCLIDE'].replace(lut, inplace=True)

# %% ../../nbs/handlers/helcom.ipynb 71
class ParseTimeCB(Callback):
    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            # get 'time' from 'DATE' column
            tfm.dfs[grp]['time'] = pd.to_datetime(tfm.dfs[grp]['DATE'], format='%m/%d/%y %H:%M:%S')
            # if 'DATE' column is nan, get 'time' from 'YEAR','MONTH' and 'DAY' column. 
            # if 'DAY' or 'MONTH' is 0 then set it to 1. 
            tfm.dfs[grp].loc[tfm.dfs[grp]["DAY"] == 0, "DAY"] = 1
            tfm.dfs[grp].loc[tfm.dfs[grp]["MONTH"] == 0, "MONTH"] = 1
            
            # if 'DAY' and 'MONTH' is nan but YEAR is not nan then set 'DAY' and 'MONTH' both to 1. 
            condition = (tfm.dfs[grp]["DAY"].isna()) & (tfm.dfs[grp]["MONTH"].isna()) & (tfm.dfs[grp]["YEAR"].notna())
            tfm.dfs[grp].loc[condition, "DAY"] = 1
            tfm.dfs[grp].loc[condition, "MONTH"] = 1
            
            
            condition = tfm.dfs[grp]['DATE'].isna() # if 'DATE' is nan. 
            tfm.dfs[grp]['time']  = np.where(condition,
                                             # 'coerce', then invalid parsing will be set as NaT. NaT will result if the number of days are not valid for the month.
                                            pd.to_datetime(tfm.dfs[grp][['YEAR', 'MONTH', 'DAY']], format='%y%m%d', errors='coerce'),  
                                            pd.to_datetime(tfm.dfs[grp]['DATE'], format='%m/%d/%y %H:%M:%S'))


# %% ../../nbs/handlers/helcom.ipynb 86
# Make measurement and uncertainty units consistent
def unc_rel2stan(df, meas_col, unc_col):
    return df.apply(lambda row: row[unc_col] * row[meas_col]/100, axis=1)

# %% ../../nbs/handlers/helcom.ipynb 88
# Columns of interest
coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),
                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),
                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]

# %% ../../nbs/handlers/helcom.ipynb 90
class NormalizeUncUnitCB(Callback):
    "Convert from relative error % to uncertainty of activity unit"
    def __init__(self, 
                 fn_convert_unc=unc_rel2stan,
                 coi=coi_units_unc):
        fc.store_attr()

    def __call__(self, tfm):
        for grp, val, unc in self.coi:
            tfm.dfs[grp][unc] = self.fn_convert_unc(tfm.dfs[grp], val, unc)

# %% ../../nbs/handlers/helcom.ipynb 97
def get_maris_lut(fname_in, 
                  fname_cache, # For instance 'species_helcom.pkl'
                  data_provider_lut:str, # Data provider lookup table name
                  data_provider_id_col:str, # Data provider lookup column id of interest
                  data_provider_name_col:str, # Data provider lookup column name of interest
                  maris_lut:Callable, # Function retrieving MARIS source lookup table
                  maris_id: str, # Id of MARIS lookup table nomenclature item to match
                  maris_name: str, # Name of MARIS lookup table nomenclature item to match
                  unmatched_fixes={},
                  as_dataframe=False,
                  overwrite=False
                 ):
    fname_cache = cache_path() / fname_cache
    lut = {}
    maris_lut = maris_lut()
    df = pd.read_csv(Path(fname_in) / data_provider_lut)
    if overwrite or (not fname_cache.exists()):
        for _, row in tqdm(df.iterrows(), total=len(df)):

            # Fix if unmatched
            has_to_be_fixed = row[data_provider_id_col] in unmatched_fixes            
            name_to_match = unmatched_fixes[row[data_provider_id_col]] if has_to_be_fixed else row[data_provider_name_col]

            # Match
            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)
            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], 
                          row[data_provider_name_col], result.iloc[0]['score'])
            
            lut[row[data_provider_id_col]] = match
        fc.save_pickle(fname_cache, lut)
    else:
        lut = fc.load_pickle(fname_cache)

    if as_dataframe:
        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()
        df_lut.index.name = 'source_id'
        return df_lut.sort_values(by='match_score', ascending=False)
    else:
        return lut

# %% ../../nbs/handlers/helcom.ipynb 104
unmatched_fixes_biota_species = {
    'CARD EDU': 'Cerastoderma edule',
    'LAMI SAC': 'Saccharina latissima',
    'PSET MAX': 'Scophthalmus maximus',
    'STIZ LUC': 'Sander luciopercas'}

# %% ../../nbs/handlers/helcom.ipynb 111
class LookupBiotaSpeciesCB(Callback):
    """
    Biota species remapped to MARIS db:
        CARD EDU: Cerastoderma edule
        LAMI SAC: Saccharina latissima
        PSET MAX: Scophthalmus maximus
        STIZ LUC: Sander luciopercas
    """
    def __init__(self, fn_lut): fc.store_attr()
    def __call__(self, tfm):
        lut = self.fn_lut()
        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: lut[x.strip()].matched_id)

# %% ../../nbs/handlers/helcom.ipynb 113
get_maris_species = partial(get_maris_lut,
                            fname_in, fname_cache='species_helcom.pkl', 
                            data_provider_lut='RUBIN_NAME.csv',
                            data_provider_id_col='RUBIN',
                            data_provider_name_col='SCIENTIFIC NAME',
                            maris_lut=species_lut_path,
                            maris_id='species_id',
                            maris_name='species',
                            unmatched_fixes=unmatched_fixes_biota_species,
                            as_dataframe=False,
                            overwrite=False)

# %% ../../nbs/handlers/helcom.ipynb 123
unmatched_fixes_biota_tissues = {
    3: 'Whole animal eviscerated without head',
    12: 'Viscera',
    8: 'Skin'}

# %% ../../nbs/handlers/helcom.ipynb 127
class LookupBiotaBodyPartCB(Callback):
    """
    Update bodypart id based on MARIS dbo_bodypar.xlsx:
        - 3: 'Whole animal eviscerated without head',
        - 12: 'Viscera',
        - 8: 'Skin'
    """
    def __init__(self, fn_lut): fc.store_attr()
    def __call__(self, tfm):
        lut = self.fn_lut()
        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: lut[x].matched_id)

# %% ../../nbs/handlers/helcom.ipynb 129
get_maris_bodypart = partial(get_maris_lut,
                             fname_in,
                             fname_cache='tissues_helcom.pkl', 
                             data_provider_lut='TISSUE.csv',
                             data_provider_id_col='TISSUE',
                             data_provider_name_col='TISSUE_DESCRIPTION',
                             maris_lut=bodyparts_lut_path,
                             maris_id='bodypar_id',
                             maris_name='bodypar',
                             unmatched_fixes=unmatched_fixes_biota_tissues)

# %% ../../nbs/handlers/helcom.ipynb 137
def get_biogroup_lut(maris_lut):
    species = pd.read_excel(maris_lut)
    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']

# %% ../../nbs/handlers/helcom.ipynb 139
class LookupBiogroupCB(Callback):
    """
    Update biogroup id  based on MARIS dbo_species.xlsx
    """
    def __init__(self, fn_lut): fc.store_attr()
    def __call__(self, tfm):
        lut = self.fn_lut()
        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: lut[x])

# %% ../../nbs/handlers/helcom.ipynb 149
unmatched_fixes_sediments = {
    #np.nan: 'Not applicable',
    -99: '(Not available)'
}

# %% ../../nbs/handlers/helcom.ipynb 152
get_maris_sediments = partial(
    get_maris_lut,
    fname_in, 
    fname_cache='sediments_helcom.pkl', 
    data_provider_lut='SEDIMENT_TYPE.csv',
    data_provider_id_col='SEDI',
    data_provider_name_col='SEDIMENT TYPE',
    maris_lut=sediments_lut_path,
    maris_id='sedtype_id',
    maris_name='sedtype',
    unmatched_fixes=unmatched_fixes_sediments)

# %% ../../nbs/handlers/helcom.ipynb 154
class LookupSedimentCB(Callback):
    """
    Update sediment id  based on MARIS dbo_sedtype.xlsx
        -99: '(Not available)'
        - na: '(Not available)'
        - 56: '(Not available)'
        - 73: '(Not available)'
    """
    def __init__(self, fn_lut): fc.store_attr()
    def __call__(self, tfm):
        lut = self.fn_lut()

        # To check with Helcom
        tfm.dfs['sediment']['SEDI'] = dfs['sediment']['SEDI'].fillna(-99).astype('int')
        tfm.dfs['sediment']['SEDI'].replace(56, -99, inplace=True)
        tfm.dfs['sediment']['SEDI'].replace(73, -99, inplace=True)
        
        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: lut[x].matched_id)

# %% ../../nbs/handlers/helcom.ipynb 162
# Define unit names renaming rules
renaming_unit_rules = {'seawater' : 1, #  'Bq/m3'
                       'sediment' : 4, # 'Bq/kgd' for sediment (see https://maps.helcom.fi/website/download/MORS_ENVIRONMENT_Reporting_form.xlsx)
                       'biota': {'D' : 4, # 'Bq/kgd'
                                 'W' : 5, # 'Bq/kgw'
                                 'F' : 5 # 'Bq/kgw' !assumed to be 'Fresh' so set to wet. .  
                                 } } 


# %% ../../nbs/handlers/helcom.ipynb 164
class LookupUnitCB(Callback):
    def __init__(self,
                 renaming_unit_rules=renaming_unit_rules):
        fc.store_attr()
    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            
            if grp == 'biota':
                lut=renaming_unit_rules[grp]
                # lookup value in the 'BASIS' column to determine the unit. 
                tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut[x] if x in lut.keys() else 0 )
            else:                 
                tfm.dfs[grp]['unit'] = renaming_unit_rules[grp]

# %% ../../nbs/handlers/helcom.ipynb 172
# Columns of interest
coi_dl = {'seawater' : { 'val' : 'VALUE_Bq/m³',
                        'unc' : 'ERROR%_m³',
                        'dl' : '< VALUE_Bq/m³'},
                 'biota':  {'val' : 'VALUE_Bq/kg',
                            'unc' : 'ERROR%',
                            'dl' : '< VALUE_Bq/kg'},
                 'sediment': { 'val' : 'VALUE_Bq/kg',
                              'unc' : 'ERROR%_kg',
                              'dl' : '< VALUE_Bq/kg'}}

# %% ../../nbs/handlers/helcom.ipynb 174
def get_detectionlimit_lut():
    df = pd.read_excel(detection_limit_lut_path(), usecols=['name','id'])
    return df.set_index('name').to_dict()['id']

# %% ../../nbs/handlers/helcom.ipynb 176
class LookupDetectionLimitCB(Callback):
    "Remap value type to MARIS format."
    def __init__(self ,
                 coi=coi_dl,
                 fn_lut=get_detectionlimit_lut
                 ):
        fc.store_attr()

    def __call__(self, tfm):
        lut = self.fn_lut()
        for grp in tfm.dfs.keys():
            # Copy dl col 
            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp][self.coi[grp]['dl']]
            # Fill values with '=' if both a value and uncertainty are not nan and detection_limit is not in the list of keys returned from lut.
            condition = ((tfm.dfs[grp][self.coi[grp]['val']].notna()) & (tfm.dfs[grp][self.coi[grp]['unc']].notna())) & (~tfm.dfs[grp]["detection_limit"].isin(list(lut.keys())))
            tfm.dfs[grp].loc[condition, 'detection_limit']= '='
            # Fill values that are not in the lut with 'Not Available'.
            tfm.dfs[grp].loc[~tfm.dfs[grp]["detection_limit"].isin(list(lut.keys())), "detection_limit"] = 'Not Available'
            # Perform lookup
            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp]['detection_limit'].apply(lambda x: lut[x])
            

# %% ../../nbs/handlers/helcom.ipynb 189
class RemapDataProviderSampleIdCB(Callback):
    "Remap key to MARIS data_provider_sample_id format."
    def __init__(self):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            # data_provider_sample_id
            tfm.dfs[grp]['data_provider_sample_id'] = tfm.dfs[grp]['KEY']


# %% ../../nbs/handlers/helcom.ipynb 196
def get_filtered_lut():
    df = pd.read_excel(filtered_lut_path(), usecols=['name','id'])
    return df.set_index('name').to_dict()['id']

# %% ../../nbs/handlers/helcom.ipynb 201
class LookupFiltCB(Callback):
    "Lookup FILT value."
    def __init__(self ,
                 rules=renaming_rules,
                 fn_lut=get_filtered_lut
                 ):
        fc.store_attr()

    def __call__(self, tfm):
        lut = self.fn_lut()
        rules = self.rules
        for grp in tfm.dfs.keys():
            if "FILT" in tfm.dfs[grp].columns:
                # Fill values that are not in the renaming rules with 'Not Available'.
                tfm.dfs[grp].loc[~tfm.dfs[grp]["FILT"].isin(list(rules.keys())), "FILT"] = 'Not available'
                # Rename HELCOM format with MARIS format. 
                tfm.dfs[grp]['FILT'] = tfm.dfs[grp]['FILT'].apply(lambda x : rules[x] if x != 'Not available' else 'Not available')
                # Perform lookup
                tfm.dfs[grp]['FILT'] = tfm.dfs[grp]['FILT'].apply(lambda x : lut[x])                

# %% ../../nbs/handlers/helcom.ipynb 225
class RemapStationIdCB(Callback):
    "Remap Station ID to MARIS format."
    def __init__(self):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            tfm.dfs[grp]['station_id'] = tfm.dfs[grp]['STATION']


# %% ../../nbs/handlers/helcom.ipynb 232
class RemapProfileIdCB(Callback):
    "Remap Profile ID to MARIS format."
    def __init__(self):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            tfm.dfs[grp]['profile_or_transect_id'] = tfm.dfs[grp]['SEQUENCE']


# %% ../../nbs/handlers/helcom.ipynb 239
class RemapSedSliceTopBottomCB(Callback):
    "Remap Sediment slice top and bottom to MARIS format."
    def __init__(self):
        fc.store_attr()

    def __call__(self, tfm):
        tfm.dfs['sediment']['bottom'] = tfm.dfs['sediment']['LOWSLI']
        tfm.dfs['sediment']['top'] = tfm.dfs['sediment']['UPPSLI']

# %% ../../nbs/handlers/helcom.ipynb 246
class LookupDryWetRatio(Callback):
    "Lookup dry wet ratio and format for MARIS."
    def __init__(self):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            if 'DW%' in tfm.dfs[grp].columns:
                tfm.dfs[grp]['dry_wet_ratio'] = tfm.dfs[grp]['DW%']
                # Convert 'Dw%' = 0% to 'nan'.
                tfm.dfs[grp].loc[tfm.dfs[grp]['dry_wet_ratio'] == 0, 'dry_wet_ratio'] = np.NaN

# %% ../../nbs/handlers/helcom.ipynb 253
# Columns of interest coordinates
coi_coordinates = {'seawater' : { 'lon_d' : 'LONGITUDE (dddddd)', 'lat_d':'LATITUDE (dddddd)',
                                 'lon_m' : 'LONGITUDE (ddmmmm)', 'lat_m':'LATITUDE (ddmmmm)'},
                 'biota' : { 'lon_d' : 'LONGITUDE dddddd', 'lat_d':'LATITUDE dddddd',
                                 'lon_m' : 'LONGITUDE ddmmmm', 'lat_m':'LATITUDE ddmmmm'},
                 'sediment': { 'lon_d' : 'LONGITUDE (dddddd)', 'lat_d':'LATITUDE (dddddd)',
                                 'lon_m' : 'LONGITUDE (ddmmmm)', 'lat_m':'LATITUDE (ddmmmm)'}
                 }

# %% ../../nbs/handlers/helcom.ipynb 254
def ddmmmm2dddddd(ddmmmm):
    mins, degs = modf(ddmmmm)
    # move 2 decimal place
    mins = mins*100
    return round((int(degs)+(float(mins)/60)), 4)

# %% ../../nbs/handlers/helcom.ipynb 255
class FormatCoordinates(Callback):
    "Format coordinates for MARIS."
    def __init__(self, 
                 coi: dict,
                 fn_convert_cor
                 ):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            # If coordinates with format dddddd (e.g. )
            # Get coordinates from dddddd unless dddddd equals 0 or nan. 
            condition = ((tfm.dfs[grp][self.coi[grp]['lon_d']].isna()) | (tfm.dfs[grp][self.coi[grp]['lon_d']] == 0 )) | ((tfm.dfs[grp][self.coi[grp]['lat_d']].isna()) | (tfm.dfs[grp][self.coi[grp]['lat_d']] == 0 ))            
            
            
            tfm.dfs[grp]['lon']  = np.where(condition,
                                            tfm.dfs[grp][self.coi[grp]['lon_m']].apply(lambda x: self.fn_convert_cor(x)),
                                            tfm.dfs[grp][self.coi[grp]['lon_d']])
            
            tfm.dfs[grp]['lat']  = np.where(condition,
                                            tfm.dfs[grp][self.coi[grp]['lat_m']].apply(lambda x: self.fn_convert_cor(x)),
                                            tfm.dfs[grp][self.coi[grp]['lat_d']])      
              

# %% ../../nbs/handlers/helcom.ipynb 267
# Columns of interest
coi_val = {'seawater' : { 'val' : 'VALUE_Bq/m³'},
                 'biota':  {'val' : 'VALUE_Bq/kg'},
                 'sediment': { 'val' : 'VALUE_Bq/kg'}}

# %% ../../nbs/handlers/helcom.ipynb 268
class SanitizeValue(Callback):
    "Sanitize value. Remove blank entries."
    def __init__(self,
                coi: dict):
        fc.store_attr()

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            val = self.coi[grp]['val']
            # Keep rows where either value (i.e. VALUE_Bq/m³ or VALUE_Bq/kg ) is not 'nan'
            tfm.dfs[grp] = tfm.dfs[grp][tfm.dfs[grp][[val]].notna().any(axis=1)]


# %% ../../nbs/handlers/helcom.ipynb 277
# Define columns of interest (keys) and renaming rules (values).
def get_renaming_rules_netcdf():
    vars = cdl_cfg()['vars']
    return {('seawater','biota', 'sediment') : {    
                                                        ## DEFAULT
                                                        'lat' : vars['defaults']['lat']['name'] ,
                                                        'lon' : vars['defaults']['lon']['name'] ,
                                                        'time' : vars['defaults']['time']['name'],
                                                        'NUCLIDE' : 'nuclide',
                                                        'unit' : vars['suffixes']['unit']['name'],
                                                        #'station_id' : 'data_provider_station_id',
                                                        #'data_provider_sample_id' : vars['defaults']['data_provider_sample_id']['name'],
                                                        #'profile_or_transect_id' : 'profile_id',
                                                        'detection_limit' : vars['suffixes']['detection_limit']['name']
                                                        #'Sampling method' : 'sampling_method'
                                                        #'Preparation method' : 'preparation_method'
                                                        #'Counting method' : 'counting_method'
                                                        #'Sample notes' : 'sample_notes'
                                                        #'Measurement notes' : 'measurement_notes'
                                                    },
                  ('seawater',) : {
                                ## SEAWATER
                                'VALUE_Bq/m³': 'value',
                                'ERROR%_m³': vars['suffixes']['uncertainty']['name'],
                                'TDEPTH': vars['defaults']['tot_depth']['name'],
                                'SDEPTH': vars['defaults']['smp_depth']['name'],
                                'SALIN' : vars['suffixes']['salinity']['name'],
                                'TTEMP' : vars['suffixes']['temperature']['name'],
                                #'FILT' : vars['suffixes']['filtered']['name']
                                },
                  ('biota',) : { 
                                ## BIOTA
                                'VALUE_Bq/kg': 'value',
                                'ERROR%' : vars['suffixes']['uncertainty']['name'],
                                'species' : vars['bio']['species']['name'],
                                'body_part' : vars['bio']['body_part']['name'],
                                'bio_group' : vars['bio']['bio_group']['name'],
                                'SDEPTH' : vars['defaults']['smp_depth']['name'],
                                #'DW%' : 'dry_wet_ratio'
                                #'Drying Method' : drying_method
                                
                                },
                  ('sediment',) : {
                                ## SEDIMENT
                                'VALUE_Bq/kg': 'value',
                                'ERROR%_kg' : vars['suffixes']['uncertainty']['name'],
                                'TDEPTH' : vars['defaults']['tot_depth']['name'],
                                'sed_type' : vars['sed']['sed_type']['name'],
                                #'top' : 'top',
                                #'bottom' : 'bottom', 
                                #'DW%' : 'dry_wet_ratio'
                                #'Drying Method' : drying_method
                                }
                    }

# %% ../../nbs/handlers/helcom.ipynb 280
# Define columns of interest (keys) and renaming rules (values) for encoding to open refine csv. .
def get_renaming_rules_openrefine():
    vars = cdl_cfg()['vars']
    return {('seawater','biota', 'sediment') : {    
                                                        ## DEFAULT
                                                        'lat' : vars['defaults']['lat']['name'] ,
                                                        'lon' : vars['defaults']['lon']['name'] ,
                                                        'time' : vars['defaults']['time']['name'],
                                                        'NUCLIDE' : 'nuclide',
                                                        'unit' : vars['suffixes']['unit']['name'],
                                                        'station_id' : 'data_provider_station_id',
                                                        'data_provider_sample_id' : vars['defaults']['data_provider_sample_id']['name'],
                                                        'profile_or_transect_id' : 'profile_id',
                                                        'detection_limit' : vars['suffixes']['detection_limit']['name']
                                                        #'Sampling method' : 'sampling_method'
                                                        #'Preparation method' : 'preparation_method'
                                                        #'Counting method' : 'counting_method'
                                                        #'Sample notes' : 'sample_notes'
                                                        #'Measurement notes' : 'measurement_notes'
                                                    },
                  ('seawater',) : {
                                ## SEAWATER
                                'VALUE_Bq/m³': 'value',
                                'ERROR%_m³': vars['suffixes']['uncertainty']['name'],
                                'TDEPTH': vars['defaults']['tot_depth']['name'],
                                'SDEPTH': vars['defaults']['smp_depth']['name'],
                                'SALIN' : vars['suffixes']['salinity']['name'],
                                'TTEMP' : vars['suffixes']['temperature']['name'],
                                'FILT' : vars['suffixes']['filtered']['name']
                                },
                  ('biota',) : { 
                                ## BIOTA
                                'VALUE_Bq/kg': 'value',
                                'ERROR%' : vars['suffixes']['uncertainty']['name'],
                                'species' : vars['bio']['species']['name'],
                                'body_part' : vars['bio']['body_part']['name'],
                                'bio_group' : vars['bio']['bio_group']['name'],
                                'SDEPTH' : vars['defaults']['smp_depth']['name'],
                                'DW%' : 'dry_wet_ratio'
                                #'Drying Method' : drying_method
                                
                                },
                  ('sediment',) : {
                                ## SEDIMENT
                                'VALUE_Bq/kg': 'value',
                                'ERROR%_kg' : vars['suffixes']['uncertainty']['name'],
                                'TDEPTH' : vars['defaults']['tot_depth']['name'],
                                'sed_type' : vars['sed']['sed_type']['name'],
                                'top' : 'top',
                                'bottom' : 'bottom', 
                                'DW%' : 'dry_wet_ratio'
                                #'Drying Method' : drying_method
                                }
                    }

# %% ../../nbs/handlers/helcom.ipynb 281
class SelectAndRenameColumnCB(Callback):
    def __init__(self,
                 fn_renaming_rules,
                ):
        fc.store_attr()
    def __call__(self, tfm):
        renaming = self.fn_renaming_rules()
        for grp in tfm.dfs.keys():            
            # get columns related to the grp (e.g. 'biota').
            coi = [v for k, v in renaming.items() if grp in k]
            # Join cols of interest
            coi_rename = {}
            for d in coi:
                for k, v in d.items(): 
                    coi_rename[k]=v
            # list cols
            cols = list(coi_rename.keys()) 
            # select cols in df 
            tfm.dfs[grp] = tfm.dfs[grp].loc[:, cols]
            # Rename cols
            tfm.dfs[grp].rename(columns=coi_rename, inplace=True)
            

# %% ../../nbs/handlers/helcom.ipynb 286
class ReshapeLongToWide(Callback):
    "Convert data from long to wide with renamed columns."
    def __init__(self, columns=['nuclide'], values=['value']):
        fc.store_attr()
        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs
        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]
    
    def renamed_cols(self, cols):
        "Flatten columns name"
        return [inner if outer == "value" else f'{inner}{outer}'
                if inner else outer
                for outer, inner in cols]

    def pivot(self, df):
        # Among all possible 'derived cols' select the ones present in df
        derived_coi = [col for col in self.derived_cols if col in df.columns]
        
        df=df.reset_index()
        
        idx = list(set(df.columns) - set(self.columns + derived_coi + self.values))
        
        # Create a fill_value to replace NaN values in the columns used as the index in the pivot table.
        # Check if num_fill_value is already in the dataframe index values. If num_fill_value already exists
        # then increase num_fill_value by 1 until a value is found for num_fill_value that is not in the dataframe. 
        num_fill_value = 99999999999999
        while (df[idx] == num_fill_value).any().any():
            num_fill_value += 1
        # Fill in nan values for each col found in idx. 
        for col in idx:   
            if pd.api.types.is_numeric_dtype(df[col]):
                fill_value = num_fill_value
            if pd.api.types.is_string_dtype(df[col]):
                fill_value = 'NOT AVAILABLE'
                
            df[col]=df[col].fillna(fill_value)

        pivot_df=df.pivot_table(index=idx,
                              columns=self.columns,
                              values=self.values + derived_coi,
                              fill_value=np.nan,
                              aggfunc=lambda x: x
                              ).reset_index()
        
        pivot_df.index.name = 'sample'
        pivot_df=pivot_df.reset_index('sample')
        
        # Replace fill_value  with  np.nan
        pivot_df[idx]=pivot_df[idx].replace({'NOT AVAILABLE': np.nan,
                                             num_fill_value : np.nan})
        return (pivot_df)

    def __call__(self, tfm):
        for grp in tfm.dfs.keys():
            tfm.dfs[grp] = self.pivot(tfm.dfs[grp])
            tfm.dfs[grp].columns = self.renamed_cols(tfm.dfs[grp].columns)

# %% ../../nbs/handlers/helcom.ipynb 293
kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',
      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',
      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',
      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',
      'Earth Science > Oceans > Water Quality > Ocean Contaminants',
      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',
      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',
      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',
      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',
      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']


# %% ../../nbs/handlers/helcom.ipynb 294
def get_attrs(tfm, zotero_key, kw=kw):
    return GlobAttrsFeeder(tfm.dfs, cbs=[
        BboxCB(),
        DepthRangeCB(),
        TimeRangeCB(cfg()),
        ZoteroCB(zotero_key, cfg=cfg()),
        KeyValuePairCB('keywords', ', '.join(kw)),
        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))
        ])()

# %% ../../nbs/handlers/helcom.ipynb 296
def enums_xtra(tfm, vars):
    "Retrieve a subset of the lengthy enum as 'species_t' for instance"
    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])
    xtras = {}
    for var in vars:
        unique_vals = tfm.unique(var)
        if unique_vals.any():
            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)
    return xtras

# %% ../../nbs/handlers/helcom.ipynb 298
def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):
    dfs = load_data(fname_in)
    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),
                                RemapRdnNameCB(),
                                ParseTimeCB(),
                                EncodeTimeCB(cfg()),                             
                                NormalizeUncUnitCB(),
                                LookupBiotaSpeciesCB(get_maris_species),
                                LookupBiotaBodyPartCB(get_maris_bodypart), 
                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),
                                LookupSedimentCB(get_maris_sediments),
                                LookupUnitCB(),
                                LookupDetectionLimitCB(),
                                RemapDataProviderSampleIdCB(),
                                RemapStationIdCB(),
                                RemapProfileIdCB(), 
                                RemapSedSliceTopBottomCB(),
                                LookupDryWetRatio(),
                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),
                                SanitizeLonLatCB(),
                                SanitizeValue(coi_val),
                                SelectAndRenameColumnCB(get_renaming_rules_netcdf),
                                ReshapeLongToWide()
                                ])
    tfm()
    encoder = NetCDFEncoder(tfm.dfs, 
                            src_fname=nc_tpl_path,
                            dest_fname=fname_out_nc, 
                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),
                            verbose=kwargs.get('verbose', False),
                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])
                           )
    encoder.encode()

# %% ../../nbs/handlers/helcom.ipynb 304
# Define columns of interest (keys) and renaming rules (values).
def get_renaming_rules_netcdf2OpenRefine():
    vars = cdl_cfg()['vars']
    return {('seawater','biota', 'sediment') : {    
                                                        ## DEFAULT
                                                        'Sample type' : 'Sample type',
                                                        'Latitude degrees' : 'Latitude degrees',
                                                        'Latitude minutes' : 'Latitude minutes',
                                                        'Latitude seconds' : 'Latitude seconds',
                                                        'Latitude direction' : 'Latitude direction',
                                                        'Longitude degrees' : 'Longitude degrees',
                                                        'Longitude minutes' : 'Longitude minutes',
                                                        'Longitude seconds' : 'Longitude seconds', 
                                                        'Longitude direction' : 'Longitude direction', 
                                                        vars['defaults']['lat']['name'] : 'Latitude decimal',
                                                        vars['defaults']['lon']['name'] : 'Longitude decimal',
                                                        'Sampling start date' : 'Sampling start date',
                                                        'Sampling start time' : 'Sampling start time',
                                                        'Nuclide' : 'Nuclide',
                                                        'Value type': 'Value type',
                                                        'Unit' : 'Unit',
                                                        'value' : 'Activity or MDA',
                                                        vars['suffixes']['uncertainty']['name'] : 'Uncertainty',
                                                        'data_provider_station_id' : 'Station ID',
                                                        vars['defaults']['data_provider_sample_id']['name'] :'Sample ID',
                                                        'profile_id' : 'Profile or transect ID',                                                        
                                                        #'Sampling method' : 'sampling_method'
                                                        #'Preparation method' : 'preparation_method'
                                                        #'Counting method' : 'counting_method'
                                                        #'Sample notes' : 'sample_notes'
                                                        #'Measurement notes' : 'measurement_notes'
                                                    },
                  ('seawater',) : {
                                ## SEAWATER
                                vars['defaults']['tot_depth']['name'] : 'Total depth',
                                vars['defaults']['smp_depth']['name'] : 'Sampling depth' ,
                                vars['suffixes']['salinity']['name'] : 'Salinity',
                                vars['suffixes']['temperature']['name'] : 'Temperature',
                                vars['suffixes']['filtered']['name'] : 'Filtered'
                                },
                  ('biota',) : { 
                                ## BIOTA
                                'Species' : 'Species',
                                'Body part' : 'Body part',
                                #'bio_group' : vars['bio']['bio_group']['name'],
                                #'SDEPTH' : vars['defaults']['smp_depth']['name'],
                                'dry_wet_ratio' : 'Dry/wet ratio'
                                #'Drying Method' : drying_method
                                
                                },
                  ('sediment',) : {
                                ## SEDIMENT
                                vars['defaults']['tot_depth']['name'] : 'Total depth',
                                'Sediment type' : 'Sediment type',
                                'top' : 'Top',
                                'bottom' : 'Bottom', 
                                'dry_wet_ratio' : 'Dry/wet ratio'
                                #'Drying Method' : drying_method
                                }
                    }

# %% ../../nbs/handlers/helcom.ipynb 308
def encode_open_refine_csv(fname_in, fname_out, ref_id=-1, **kwargs):
    dfs = load_data(fname_in)
    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),
                                RemapRdnNameCB(),
                                ParseTimeCB(),
                                EncodeTimeCB(cfg()),                             
                                NormalizeUncUnitCB(),
                                LookupBiotaSpeciesCB(get_maris_species),
                                LookupBiotaBodyPartCB(get_maris_bodypart), 
                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),
                                LookupSedimentCB(get_maris_sediments),
                                LookupUnitCB(),
                                LookupDetectionLimitCB(),
                                RemapDataProviderSampleIdCB(),
                                RemapStationIdCB(),
                                RemapProfileIdCB(), 
                                RemapSedSliceTopBottomCB(),
                                LookupDryWetRatio(),
                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),
                                SanitizeLonLatCB(),
                                SanitizeValue(coi_val),
                                SelectAndRenameColumnCB(get_renaming_rules_openrefine), 
                                LookupTimeFromEncodedTime(cfg()),
                                GetSampleTypeCB(), 
                                LookupNuclideByIdCB(),
                                ConvertLonLatCB(), 
                                LookupUnitByIdCB(), 
                                LookupValueTypeByIdCB(), 
                                LookupSpeciesByIdCB(),
                                LookupBodypartByIdCB(), 
                                LookupSedimentTypeByIdCB(),
                                SelectAndRenameColumnCB(get_renaming_rules_netcdf2OpenRefine)
                                ])
    
    encoder = OpenRefineCsvEncoder(tfm(), 
                            dest_fname=fname_out,
                            ref_id = ref_id,
                            **kwargs)
    encoder.encode()

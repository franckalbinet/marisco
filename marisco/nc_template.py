# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/nc_template.ipynb.

# %% auto 0
__all__ = ['enum_bio_group', 'enum_body_par', 'enum_species', 'enum_sed_type', 'enum_type_lut', 'sanitize', 'get_lut',
           'NCTemplate', 'derive']

# %% ../nbs/api/nc_template.ipynb 3
from typing import Dict, Union
from copy import deepcopy
from functools import partial
import re

from netCDF4 import Dataset
import numpy as np
import pandas as pd
from pathlib import Path
from fastcore.basics import patch, store_attr
from fastcore.test import *

from .utils import read_toml
from .configs import name2grp, get_cfgs

# %% ../nbs/api/nc_template.ipynb 5
def sanitize(s):
    """Sanitize dictionary key to comply with NetCDF enumeration type"""
    s = re.sub(r'[()]', '', s)
    return re.sub(r'[./-]', ' ', s).strip() 

def get_lut(fname, name, idx):
    """Convert MARIS db lookup table excel file to dictionary {'name': id, ...}"""
    fname = Path(get_cfgs(key='dirs')['lut']) / fname
    lut = pd.read_excel(fname, index_col=name, usecols=[name, idx])[idx].to_dict()
    lut = {sanitize(key): value for key, value in lut.items()}
    return lut

# %% ../nbs/api/nc_template.ipynb 6
enum_bio_group = get_lut('dbo_biogroup.xlsx', name='biogroup', idx='biogroup_id') # ok
enum_body_par = get_lut('dbo_bodypar.xlsx', name='bodypar', idx='bodypar_id') # ok
enum_species = get_lut('dbo_species.xlsx', name='species', idx='species_id')
enum_sed_type = get_lut('dbo_sedtype.xlsx', name='sedtype', idx='sedtype_id')

enum_type_lut = {'bio_group_t': enum_bio_group,
                 'body_part_t': enum_body_par,
                 'species_t': enum_species,
                 'sed_type_t': enum_sed_type}

# %% ../nbs/api/nc_template.ipynb 8
class NCTemplate:
    "MARIS NetCDF templater"
    def __init__(self, 
                 tpl_fname:str, # CDL file name
                 vars_fname:str, # File name and path of MARIS nuclide look up table
                 dest_dir:str, # Destination directory for generated NetCDF template files
                 cdl:Dict, # Pseudo CDL (`.toml`)
                ):
        store_attr()
        self.dim = self.cdl['dim']
        self.enum_types = {}

# %% ../nbs/api/nc_template.ipynb 11
@patch
def get_analytes(self:NCTemplate,
                 col_varnames:str='nc_name', # Column name containing the NetCDF variable names
                 col_stdnames:str='nusymbol', # Column name containing the NetCDF standard names
                 dtype:str='f4', # Default type
                ):
    "Return the name of the variables analysed"
    df = pd.read_excel(self.vars_fname, index_col=0)
    df = df[df.nuclide != 'NOT AVAILABLE']
    var_names = df[col_varnames].tolist()
    std_names = df[col_stdnames].tolist()
    long_names = df[['nuclide', 'massnb']].apply(lambda row: ' '.join(row.values.astype(str)), 
                                                 axis=1).tolist()
    long_names = [name.capitalize() for name in long_names]

    return [{'name': n,
             'attrs': {
                 'long_name': ln,
                 'standard_name': sn
             },
             'dtype': dtype
            } for n, ln, sn in zip(*(var_names, long_names, std_names))]

# %% ../nbs/api/nc_template.ipynb 13
def derive(
    analyte:dict, # Analyte/nuclide/var name and associated netcdf attributes
    suffix:dict,  # Naming rules as described in CDL
):
    "Derive NetCDf var name & attributes as defined in CDL" 
    # TBD: refactor using recursion?
    derived = deepcopy(analyte)
    for k1, v1 in suffix.items():
        if k1 == 'attrs':
            for k2, v2 in suffix['attrs'].items():
                derived['attrs'][k2] += v2
        else:
            derived[k1] += v1
    return derived

# %% ../nbs/api/nc_template.ipynb 18
# if contains _t
# {'biogroup_t': enum_biogroup}
# enum_biogroup
 
# nc.createEnumType(np.uint8, 'biogroup_t', enum_biogroup)

# %% ../nbs/api/nc_template.ipynb 19
# @patch
# def get_type(self:NCTemplate, 
#              dtype:str, # dtype as specified in the toml config file
#            ):
#     return self.enum_types.keys().get(dtype) or dtype 
    

# %% ../nbs/api/nc_template.ipynb 20
@patch
def create_variable(self:NCTemplate, 
               nc, # NetCDF file
               var:Dict, # Variable
               dtype:Union[str, None]=None, # Type of the variable
           ):
    name = var['name']
    # dtype = self.get_type(var['dtype'])
    dtype = self.enum_types.get(dtype) or dtype
    # dtype = None or var['dtype']
    # if enum_type then create enumtype and assign
    # print(dtype)
    attrs = var['attrs'].copy()
    nc_var = nc.createVariable(name, dtype, self.dim['name'])
    nc_var.setncatts(attrs)    
    return nc

# %% ../nbs/api/nc_template.ipynb 22
@patch
def generate(self:NCTemplate,
             common_vars:list=['lon', 'lat', 'depth', 'time'], # Common variables
            ):
    "Generate CDL"
    fname = Path(self.dest_dir)/self.tpl_fname
    
    common_vars = self.cdl['vars']['defaults'].keys()
    
    with Dataset(fname, 'w', format='NETCDF4') as nc:
        # Create dataset attributes
        nc.setncatts(self.cdl['global_attrs']) 
        
        # Create Enum type    
        for name, enum in enum_type_lut.items(): 
            self.enum_types[name] = nc.createEnumType(np.uint16, name, enum)
        
        # Create shared `sample` dimension
        nc.createDimension(self.dim['name'], None)
        
        # Create grps
        grp_names = [v['name'] for k, v in self.cdl['grps'].items()]
        for grp_name in grp_names:
            grp = nc.createGroup(grp_name)

            # Create 'dim' variable
            #self.create_variable(grp, self.dim, 'i4')
            self.create_variable(grp, self.dim)
            
            # Create default variables
            for var in self.cdl['vars']['defaults'].values(): 
                self.create_variable(grp, var)

            # Create group-specific variables
            if name2grp(grp_name) in self.cdl['vars']:
                for var in self.cdl['vars'][name2grp(grp_name)].values(): 
                    self.create_variable(grp, var)
            
            # Create analyte variables
            for analyte in self.get_analytes():
                analyte['units'] = self.cdl['placeholder']
                self.create_variable(grp, analyte)
            
                # Derived uncertainty and detection limit variables
                for k, v in self.cdl['vars']['suffixes'].items():
                    self.create_variable(grp, derive(analyte, v))

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/nc_template.ipynb.

# %% auto 0
__all__ = ['NCTemplate', 'derive']

# %% ../nbs/api/nc_template.ipynb 3
from netCDF4 import Dataset
import numpy as np
import pandas as pd
from pathlib import Path
from fastcore.basics import patch, store_attr
from fastcore.test import *
from typing import Dict, Union, List
from copy import deepcopy

from .utils import read_toml
from .configs import BASE_PATH, name2grp

# %% ../nbs/api/nc_template.ipynb 4
# from each lut provided, create netcdf enumtype
#enum_dict = {'Altocumulus': 7, 'Missing': 255,
#             'Stratus': 2, 'Clear': 0,
#             'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 
#             'Cumulonimbus': 1, 'Stratocumulus': 3}
#df = pd.read_excel(self.vars_fname, index_col=0)

# %% ../nbs/api/nc_template.ipynb 9
class NCTemplate:
    "MARIS NetCDF templater"
    def __init__(self, 
                 tpl_fname:str, # CDL file name
                 vars_fname:str, # File name and path of MARIS nuclide look up table
                 dest_dir:str, # Destination directory for generated NetCDF template files
                 cdl:Dict, # Pseudo CDL (`.toml`)
                ):
        store_attr()
        self.dim = self.cdl['dim']

# %% ../nbs/api/nc_template.ipynb 12
@patch
def get_analytes(self:NCTemplate,
                 col_varnames:str='nc_name', # Column name containing the NetCDF variable names
                 col_stdnames:str='nusymbol', # Column name containing the NetCDF standard names
                 dtype:str='f4', # Default type
                ):
    "Return the name of the variables analysed"
    df = pd.read_excel(self.vars_fname, index_col=0)
    df = df[df.nuclide != 'NOT AVAILABLE']
    var_names = df[col_varnames].tolist()
    std_names = df[col_stdnames].tolist()
    long_names = df[['nuclide', 'massnb']].apply(lambda row: ' '.join(row.values.astype(str)), 
                                                 axis=1).tolist()
    long_names = [name.capitalize() for name in long_names]

    return [{'name': n,
             'attrs': {
                 'long_name': ln,
                 'standard_name': sn
             },
             'dtype': dtype
            } for n, ln, sn in zip(*(var_names, long_names, std_names))]

# %% ../nbs/api/nc_template.ipynb 14
def derive(
    analyte:dict, # Analyte/nuclide/var name and associated netcdf attributes
    suffix:dict,  # Naming rules as described in CDL
):
    "Derive NetCDf var name & attributes as defined in CDL" 
    # TBD: refactor using recursion?
    derived = deepcopy(analyte)
    for k1, v1 in suffix.items():
        if k1 == 'attrs':
            for k2, v2 in suffix['attrs'].items():
                derived['attrs'][k2] += v2
        else:
            derived[k1] += v1
    return derived

# %% ../nbs/api/nc_template.ipynb 20
@patch
def create_variable(self:NCTemplate, 
               nc, # NetCDF file
               var:Dict, # Variable
               dtype:Union[str, None]=None, # Type of the variable
           ):
    name = var['name']
    dtype = None or var['dtype']
    attrs = var['attrs'].copy()
    nc_var = nc.createVariable(name, dtype, self.dim['name'])
    nc_var.setncatts(attrs)    
    return nc

# %% ../nbs/api/nc_template.ipynb 22
@patch
def generate(self:NCTemplate,
             common_vars:list=['lon', 'lat', 'depth', 'time'], # Common variables
            ):
    "Generate CDL"
    fname = Path(self.dest_dir)/self.tpl_fname
    
    common_vars = self.cdl['vars']['defaults'].keys()
    
    with Dataset(fname, 'w', format='NETCDF4') as nc:
        # Create dataset attributes
        nc.setncatts(self.cdl['global_attrs']) 
        
        # Create Enum type
        #biogroup_type = nc.createEnumType(np.uint8, 'biogroup_t', enum_bio_group)
        
        # Create shared `sample` dimension
        nc.createDimension(self.dim['name'], None)
        
        # Create grps
        grp_names = [v['name'] for k, v in self.cdl['grps'].items()]
        for grp_name in grp_names:
            grp = nc.createGroup(grp_name)

            # Create 'dim' variable
            #self.create_variable(grp, self.dim, 'i4')
            self.create_variable(grp, self.dim)
            
            # Create default variables
            for var in self.cdl['vars']['defaults'].values(): 
                self.create_variable(grp, var)

            # Create group-specific variables
            if name2grp(grp_name) in self.cdl['vars']:
                for var in self.cdl['vars'][name2grp(grp_name)].values(): 
                    self.create_variable(grp, var)
            
            # Create analyte variables
            for analyte in self.get_analytes():
                analyte['units'] = self.cdl['placeholder']
                self.create_variable(grp, analyte)
            
                # Derived uncertainty and detection limit variables
                for k, v in self.cdl['vars']['suffixes'].items():
                    self.create_variable(grp, derive(analyte, v))

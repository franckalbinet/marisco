{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272420d3",
   "metadata": {},
   "source": [
    "# Data core\n",
    "\n",
    "> Core functionality to transform and gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from fastcore.basics import store_attr\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6db8e",
   "metadata": {},
   "source": [
    "## DumpExploder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DumpExploder():\n",
    "    \"\"\"Exploding MARIS global .csv dump into distinct dataset-specific ones...\"\"\"\n",
    "    def __init__(self, \n",
    "                 fname:str, # File name path and name\n",
    "                 dst:str, # Path of folder that will receive created .csv\n",
    "                 col_id:str='ref_id', # Name of the unique id column in loaded .csv\n",
    "                 #cols_name:List[str]=['displaytext'] # Columns name as part of file name generated\n",
    "                cols_name=['displaytext'] # Columns name as part of file name generated\n",
    "                ):\n",
    "        store_attr()\n",
    "        self.df = self.load_data()\n",
    "        self.dst = Path(dst)\n",
    "        self.cols = [col_id] + cols_name\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.df = pd.read_csv(Path(self.fname))   \n",
    "        return self.df\n",
    "    \n",
    "    def num_ds(self, verbose:Bool=False):\n",
    "        if self.df is None:\n",
    "            raise Exception('Run `.loadData() first: no data loaded yet')\n",
    "        print(f'Number of distinct datasets: {len(self.df[self.col_id].unique())}')\n",
    "        if verbose:\n",
    "            print(self.df.drop_duplicates(subset=[self.col_id])[self.cols])     \n",
    "    \n",
    "    def explode(self):\n",
    "        if self.df is None:\n",
    "            self.loadData()\n",
    "        grouped = self.df.groupby(self.col_id)\n",
    "        print('Exploding MARIS global csv dump into distinct dataset-specific ones...')\n",
    "        for _, group in tqdm(grouped):\n",
    "            name = self._namer(group)\n",
    "            group.to_csv(self.dst/name, index=False)\n",
    "\n",
    "    def _namer(self, group):\n",
    "        cols_name = group[self.cols].drop_duplicates().values[0]\n",
    "        cols_name = [str(s) for s in cols_name]\n",
    "        name = '-'.join(cols_name)\n",
    "        return re.sub(r'\\W+', '-', name).lower() + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e11d0",
   "metadata": {},
   "source": [
    "A bit of description ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../files/csv/maris-dump-test.csv'\n",
    "dst = 'files/exploded'\n",
    "\n",
    "exploder = DumpExploder(fname, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a96920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (100, 79)\n",
      "Columns list Index(['sample_id', 'area_id', 'areaname', 'samptype_id', 'samptype', 'ref_id',\n",
      "       'displaytext', 'zoterourl', 'ref_note', 'datbase', 'lab_id', 'lab',\n",
      "       'latitude', 'longitude', 'begperiod', 'endperiod', 'samplingyear',\n",
      "       'totdepth', 'sampdepth', 'station', 'samplabcode', 'species_id',\n",
      "       'taxonname', 'taxonrank', 'biogroup', 'taxondb', 'taxondbid',\n",
      "       'taxondburl', 'taxonrepname', 'bodypar_id', 'bodypar', 'sliceup',\n",
      "       'slicedown', 'sedtype_id', 'sedtype', 'sedrepname', 'nuclide_id',\n",
      "       'nusymbol', 'volume', 'salinity', 'temperatur', 'filtered', 'filtpore',\n",
      "       'samparea', 'drywt', 'wetwt', 'percentwt', 'sampmet_id', 'sampmet',\n",
      "       'prepmet_id', 'prepmet', 'drymet_id', 'drymet', 'counmet_id', 'counmet',\n",
      "       'decayedto', 'detection', 'activity', 'uncertaint', 'unit_id', 'unit',\n",
      "       'vartype', 'freq', 'rangelow', 'rangeupp', 'profile', 'transect_id',\n",
      "       'measure_note', 'shapetype_id', 'profile_id', 'sampnote',\n",
      "       'ref_fulltext', 'ref_yearpub', 'ref_sampleTypes', 'LongLat',\n",
      "       'displaycoordinates', 'DisplayLong', 'DisplayLat', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = exploder.load_data()\n",
    "print('Dataframe shape: ', df.shape)\n",
    "print('Columns list', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct datasets: 28\n",
      "    ref_id                                        displaytext\n",
      "0      237                                Takata et al., 2018\n",
      "1      682           NRA - Nuclear Regulation Authority, 2021\n",
      "2      103                                       RADNOR, 2010\n",
      "3      126                         Fukushima Prefecture, 2011\n",
      "4      395                        Bailly du Bois et al., 2020\n",
      "5      402                                        CCHDO, 2018\n",
      "6      100                                  HELCOM MORS, 2018\n",
      "9      681           NRA - Nuclear Regulation Authority, 2021\n",
      "11      84                             MAFF (now Cefas), 2004\n",
      "12     190                             Schlitzer et al., 2018\n",
      "13     679         TEPCO - Tokyo Electric Power Company, 2021\n",
      "15     400                                 Boyer et al., n.d.\n",
      "16     121         TEPCO - Tokyo Electric Power Company, 2011\n",
      "18     234                                Aoyama et al., 2013\n",
      "28     680         TEPCO - Tokyo Electric Power Company, 2021\n",
      "33     191  OSPAR Comission’s Radioactive Substances Commi...\n",
      "35      95                         IPSN, CEA (now IRSN), 2004\n",
      "41     156                               Yoshida et al., 2015\n",
      "42      99                            Aoyama and Hirose, 2004\n",
      "46      97                                     ASPAMARD, 2004\n",
      "48     117                                Oikawa et al., 2013\n",
      "51     374                               Ostlund et al., 1987\n",
      "58     155                             Buesseler et al., 2012\n",
      "61     119  MEXT - Ministry of Education, Culture, Sports,...\n",
      "84     203                                         MERI, 2016\n",
      "85     120           NRA - Nuclear Regulation Authority, 2013\n",
      "87     401                                 Olsen et al., 2016\n",
      "93     206                                         MERI, 2019\n"
     ]
    }
   ],
   "source": [
    "exploder.num_ds(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa230957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploding MARIS global csv dump into distinct dataset-specific ones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 598.15it/s]\n"
     ]
    }
   ],
   "source": [
    "exploder.explode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6b7be",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54978967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

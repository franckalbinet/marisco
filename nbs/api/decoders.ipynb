{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp decoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Decoders\n",
    "> Various utilities to decode MARIS dataset from `NetCDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_DTYPES, \n",
    "    NC_VARS, \n",
    "    NC_DIM,\n",
    "    NC_GROUPS,\n",
    "    lut_path, \n",
    "    Enums,\n",
    "    nc_tpl_path,\n",
    "    get_time_units\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78441e",
   "metadata": {},
   "source": [
    "Convert NetCDF file to a dictionary of dataframes (dfs). Convert `time` from seconds since epoch to a date-time format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762673eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def nc_to_dfs(\n",
    "    fname: str # Path to NetCDF file\n",
    "    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values\n",
    "    \"Convert a NetCDF (with groups) file to a dictionary of dataframes.\"\n",
    "    dfs = {}\n",
    "    \n",
    "    with Dataset(fname, 'r') as nc:\n",
    "        # Process each group in the NetCDF file\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            \n",
    "            # Get all variables in the group\n",
    "            data = {}\n",
    "            for var_name in group.variables:\n",
    "                # Skip dimension variables (like 'id')\n",
    "                if var_name not in group.dimensions:\n",
    "                    data[var_name] = group.variables[var_name][:]\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Convert time from seconds since epoch if present\n",
    "            if 'time' in df.columns:\n",
    "                df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "                \n",
    "            dfs[group_name.upper()] = df\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeef801",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05c670",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../_data/output/190-geotraces-2021.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| eval: false\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# fname = Path('../files/nc/encoding-test.nc')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fname \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../_data/output/190-geotraces-2021.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m dfs \u001b[38;5;241m=\u001b[39m \u001b[43mnc_to_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grp, df \u001b[38;5;129;01min\u001b[39;00m dfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup:\u001b[39m\u001b[38;5;124m'\u001b[39m, grp)\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mnc_to_dfs\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert a NetCDF (with groups) file to a dictionary of dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m dfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m nc:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Process each group in the NetCDF file\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group_name \u001b[38;5;129;01min\u001b[39;00m nc\u001b[38;5;241m.\u001b[39mgroups:\n\u001b[1;32m     11\u001b[0m         group \u001b[38;5;241m=\u001b[39m nc\u001b[38;5;241m.\u001b[39mgroups[group_name]\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../_data/output/190-geotraces-2021.nc'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "\n",
    "dfs = nc_to_dfs(fname)\n",
    "\n",
    "for grp, df in dfs.items():\n",
    "    print('group:', grp)\n",
    "    print(f'shape: {df.shape}')\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a6efd2",
   "metadata": {},
   "source": [
    "Return properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_properties(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve general properties of a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing file properties such as size, format, and dimensions.\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    \n",
    "    file = Path(file_path)\n",
    "    \n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return properties\n",
    "\n",
    "    # Get file size\n",
    "    properties['file_size_bytes'] = file.stat().st_size\n",
    "    \n",
    "    # Open the NetCDF file\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Get file format\n",
    "        properties['file_format'] = nc.file_format\n",
    "\n",
    "        # Get groups\n",
    "        properties['groups'] = list(nc.groups.keys())\n",
    "        \n",
    "        # Get global attributes\n",
    "        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}\n",
    "    \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dfe0e",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 669446\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: TBD\n",
      "  geospatial_vertical_max: TBD\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \n",
      "    Get geographical coordinates from columns expressed in degrees decimal format \n",
      "    or from columns in degrees/minutes decimal format where degrees decimal format is missing.\n",
      "    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "properties = get_netcdf_properties(fname)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp decoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Decoders\n",
    "> Various utilities to decode MARIS dataset from `NetCDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "from typing import Dict, Callable\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_DTYPES, \n",
    "    NC_VARS, \n",
    "    OR_VARS,\n",
    "    NC_DIM,\n",
    "    NC_GROUPS,\n",
    "    SMP_TYPE_LUT,\n",
    "    lut_path, \n",
    "    Enums,\n",
    "    nc_tpl_path,\n",
    "    get_time_units\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    DecodeTimeCB\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82c9bc",
   "metadata": {},
   "source": [
    "## Convert NetCDF to OpenRefine CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d38d1",
   "metadata": {},
   "source": [
    "Maris NetCDF files can be converted to OpenRefine CSV files. The OpenRefine CSV files are compatible with the [OpenRefine](https://openrefine.org/) data cleaning tool which are used during the MARIS data cleaning process before loading into the MARIS database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NetCDFDecoder:\n",
    "    \"\"\"Decode MARIS NetCDF files to human readable formats.\"\"\"\n",
    "    def __init__(self, \n",
    "                 dfs: Dict[str, pd.DataFrame], \n",
    "                 fname_in: str,  # Path to NetCDF file\n",
    "                 dest_out: str, \n",
    "                 output_format:str, \n",
    "                 remap_vars: Dict[str, str],\n",
    "                 verbose: bool=False\n",
    "                ):\n",
    "        fc.store_attr()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_groups(self: NetCDFDecoder):\n",
    "    \"\"\"Process all groups in the dataset.\"\"\"\n",
    "    for group_name, df in self.dfs.items():\n",
    "        self.process_group(group_name, df, self.remap_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_group(self: NetCDFDecoder, group_name: str, df: pd.DataFrame, remap_vars: Dict[str, str]):\n",
    "    \"\"\"Process a single group, mapping column names using remap_vars.\"\"\"\n",
    "    # Map column names using remap_vars\n",
    "    df.columns = [remap_vars.get(col, col) for col in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c883f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def save_dataframes(self: NetCDFDecoder):\n",
    "    \"\"\"\n",
    "    Save DataFrames to files in the specified format.\n",
    "    \n",
    "    Parameters:\n",
    "        dest_path (str, optional): Base path for output files, without extension.\n",
    "            If None, uses self.dest_fname's path without extension.\n",
    "        output_format (str): Format to save files in. Options:\n",
    "            - 'csv': Comma-separated values\n",
    "            - 'excel': Excel spreadsheet (one sheet per group)\n",
    "            - 'json': JSON format\n",
    "            - 'parquet': Apache Parquet format\n",
    "            - 'hdf': HDF5 format\n",
    "            - 'pickle': Python pickle format\n",
    "            - 'feather': Feather format\n",
    "            - 'stata': Stata format\n",
    "    \"\"\"\n",
    "    # Get base path without extension\n",
    "    if self.dest_out is None:\n",
    "            raise ValueError(\"No destination path provided\")\n",
    "    else:\n",
    "        base_path = str(Path(self.dest_out).with_suffix(''))\n",
    "    \n",
    "    # Handle formats that combine all groups in one file\n",
    "    if self.output_format == 'excel':\n",
    "        output_path = f\"{base_path}.xlsx\"\n",
    "        with pd.ExcelWriter(output_path) as writer:\n",
    "            for group_name, df in self.dfs.items():\n",
    "                df.to_excel(writer, sheet_name=group_name, index=False)\n",
    "                if self.verbose:\n",
    "                    print(f\"Saved {group_name} to sheet in {output_path}\")\n",
    "    \n",
    "    elif self.output_format == 'hdf':\n",
    "        output_path = f\"{base_path}.h5\"\n",
    "        with pd.HDFStore(output_path) as store:\n",
    "            for group_name, df in self.dfs.items():\n",
    "                store[group_name] = df\n",
    "                if self.verbose:\n",
    "                    print(f\"Saved {group_name} to group in {output_path}\")\n",
    "    \n",
    "    # Handle formats that create separate files for each group\n",
    "    else:\n",
    "        format_extensions = {\n",
    "            'csv': '.csv',\n",
    "            'json': '.json',\n",
    "            'parquet': '.parquet',\n",
    "            'pickle': '.pkl',\n",
    "            'feather': '.feather',\n",
    "            'stata': '.dta'\n",
    "        }\n",
    "        \n",
    "        if self.output_format not in format_extensions:\n",
    "            raise ValueError(f\"Unsupported output format: {self.output_format}. Supported formats: {format_extensions.keys()}\")\n",
    "            \n",
    "        extension = format_extensions[self.output_format]\n",
    "        save_methods = {\n",
    "            'csv': lambda df, path: df.to_csv(path, index=False),\n",
    "            'json': lambda df, path: df.to_json(path),\n",
    "            'parquet': lambda df, path: df.to_parquet(path),\n",
    "            'pickle': lambda df, path: df.to_pickle(path),\n",
    "            'feather': lambda df, path: df.to_feather(path),\n",
    "            'stata': lambda df, path: df.to_stata(path)\n",
    "        }\n",
    "        \n",
    "        for group_name, df in self.dfs.items():\n",
    "            output_path = f\"{base_path}_{group_name}{extension}\"\n",
    "            save_methods[self.output_format](df, output_path)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Saved {group_name} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1774dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def decode(self: NetCDFDecoder):\n",
    "    \"  Decode NetCDF to Human readable files.\"\n",
    "    # Funvtion to rename the columns. \n",
    "    self.process_groups()\n",
    "    self.save_dataframes()\n",
    "    \n",
    "    return self.dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "\n",
    "df_seawater = pd.DataFrame({\n",
    "    'ID': [0, 1, 2], \n",
    "    'LON': [141, 142, 143], \n",
    "    'LAT': [37.3, 38.3, 39.3], \n",
    "    'TIME': [1234, 1235, 1236], \n",
    "    'NUCLIDE': [1, 2, 3],\n",
    "    'VALUE': [0.1, 1.1, 2.1], \n",
    "    'AREA': [2374, 2379, 2401],\n",
    "    })\n",
    "\n",
    "df_biota = pd.DataFrame({\n",
    "    'ID': [0, 1, 2, 3], \n",
    "    'LON': [141, 142, 143, 144], \n",
    "    'LAT': [37.3, 38.3, 39.3, 40.3], \n",
    "    'TIME': [1234, 1235, 1236, 1237], \n",
    "    'NUCLIDE': [1, 2, 3, 3],\n",
    "    'VALUE': [0.1, 1.1, 2.1, 3.1], \n",
    "    'SPECIES': [1, 2, 3, 3]\n",
    "    })\n",
    "dfs = {'SEAWATER': df_seawater, 'BIOTA': df_biota}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SEAWATER to ../../_data/output/100-HELCOM-MORS-2024_SEAWATER.csv\n",
      "Saved BIOTA to ../../_data/output/100-HELCOM-MORS-2024_BIOTA.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SEAWATER':    ID  longitude  latitude  begperiod  nuclide_id  activity  area\n",
       " 0   0        141      37.3       1234           1       0.1  2374\n",
       " 1   1        142      38.3       1235           2       1.1  2379\n",
       " 2   2        143      39.3       1236           3       2.1  2401,\n",
       " 'BIOTA':    ID  longitude  latitude  begperiod  nuclide_id  activity  species_id\n",
       " 0   0        141      37.3       1234           1       0.1           1\n",
       " 1   1        142      38.3       1235           2       1.1           2\n",
       " 2   2        143      39.3       1236           3       2.1           3\n",
       " 3   3        144      40.3       1237           3       3.1           3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "decoder = NetCDFDecoder( \n",
    "                        dfs=dfs,\n",
    "                        fname_in=fname,  \n",
    "                        dest_out=fname.with_suffix(''),\n",
    "                        output_format='csv',\n",
    "                        remap_vars=OR_VARS,\n",
    "                        verbose=True\n",
    "                 )\n",
    "decoder.decode()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

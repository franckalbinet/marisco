{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp decoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Decoders\n",
    "> Various utilities to decode MARIS dataset from `NetCDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_DTYPES, \n",
    "    NC_VARS, \n",
    "    NC_DIM,\n",
    "    NC_GROUPS,\n",
    "    lut_path, \n",
    "    Enums,\n",
    "    nc_tpl_path,\n",
    "    get_time_units\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5f459",
   "metadata": {},
   "source": [
    "## NetCDF to a dictionary of Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78441e",
   "metadata": {},
   "source": [
    "Convert NetCDF file to a dictionary of dataframes (dfs). Convert `time` from seconds since epoch to a date-time format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762673eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def nc_to_dfs(\n",
    "    fname: str # Path to NetCDF file\n",
    "    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values\n",
    "    \"Convert a NetCDF (with groups) file to a dictionary of dataframes.\"\n",
    "    dfs = {}\n",
    "    \n",
    "    with Dataset(fname, 'r') as nc:\n",
    "        # Process each group in the NetCDF file\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            \n",
    "            # Get all variables in the group\n",
    "            data = {}\n",
    "            for var_name in group.variables:\n",
    "                # Skip dimension variables (like 'id')\n",
    "                if var_name not in group.dimensions:\n",
    "                    data[var_name] = group.variables[var_name][:]\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Convert time from seconds since epoch if present\n",
    "            if 'time' in df.columns:\n",
    "                df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "                \n",
    "            dfs[group_name.upper()] = df\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeef801",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group: SEAWATER\n",
      "shape: (21477, 49)\n",
      "   sample         lon    lat                time  h3  h3_dl  mn54  mn54_dl  \\\n",
      "0       0  141.029999  37.32 2011-03-21 23:15:00 NaN    NaN   NaN      NaN   \n",
      "1       1  141.029999  37.32 2011-03-22 14:28:00 NaN    NaN   NaN      NaN   \n",
      "2       2  141.029999  37.32 2011-03-23 13:51:00 NaN    NaN   NaN      NaN   \n",
      "3       3  141.029999  37.32 2011-03-24 09:30:00 NaN    NaN   NaN      NaN   \n",
      "4       4  141.029999  37.32 2011-03-25 10:00:00 NaN    NaN   NaN      NaN   \n",
      "\n",
      "   co58  co58_dl  ...  te132  te132_dl   i132  i132_dl  cs136  cs136_dl  \\\n",
      "0   5.7      7.6  ...    NaN       NaN  160.0     44.0    6.7       4.7   \n",
      "1   NaN     15.0  ...    NaN       NaN    NaN     88.0    NaN       7.8   \n",
      "2   NaN      NaN  ...    NaN       NaN  200.0     58.0    NaN       NaN   \n",
      "3   NaN      NaN  ...    NaN       NaN  120.0     88.0   68.0      49.0   \n",
      "4   NaN      NaN  ...   13.0       7.4   58.0     22.0    4.4       3.2   \n",
      "\n",
      "   tbeta  tbeta_dl  talpha  talpha_dl  \n",
      "0    NaN       NaN     NaN        NaN  \n",
      "1    NaN       NaN     NaN        NaN  \n",
      "2    NaN       NaN     NaN        NaN  \n",
      "3    NaN       NaN     NaN        NaN  \n",
      "4    NaN       NaN     NaN        NaN  \n",
      "\n",
      "[5 rows x 49 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/tepco.nc')\n",
    "\n",
    "dfs = nc_to_dfs(fname)\n",
    "\n",
    "for grp, df in dfs.items():\n",
    "    print('group:', grp)\n",
    "    print(f'shape: {df.shape}')\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f464c",
   "metadata": {},
   "source": [
    "## NetCDF Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a6efd2",
   "metadata": {},
   "source": [
    "Return properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_properties(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve general properties of a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing file properties such as size, format, and dimensions.\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    \n",
    "    file = Path(file_path)\n",
    "    \n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return properties\n",
    "\n",
    "    # Get file size\n",
    "    properties['file_size_bytes'] = file.stat().st_size\n",
    "    \n",
    "    # Open the NetCDF file\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Get file format\n",
    "        properties['file_format'] = nc.file_format\n",
    "\n",
    "        # Get groups\n",
    "        properties['groups'] = list(nc.groups.keys())\n",
    "        \n",
    "        # Get global attributes\n",
    "        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}\n",
    "    \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dfe0e",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 864768\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: 0.0\n",
      "  geospatial_vertical_max: 437.0\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error ( % ) to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA., Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Lookup FILT value in dataframe using the lookup table., Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "properties = get_netcdf_properties(fname)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc36997",
   "metadata": {},
   "source": [
    "Return group properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_group_properties(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve properties of each group in a NetCDF file, including dimension sizes.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing properties of each group such as variables, dimensions with sizes, and attributes.\n",
    "    \"\"\"\n",
    "    group_properties = {}\n",
    "\n",
    "    file = Path(file_path)\n",
    "\n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return group_properties\n",
    "\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Iterate over each group in the NetCDF file\n",
    "        for group_name, group in nc.groups.items():\n",
    "            # Get dimensions with their sizes\n",
    "            dimensions = {dim_name: len(dim) for dim_name, dim in group.dimensions.items()}\n",
    "            \n",
    "            group_info = {\n",
    "                'variables': list(group.variables.keys()),\n",
    "                'dimensions': dimensions,\n",
    "                'attributes': {attr: group.getncattr(attr) for attr in group.ncattrs()}\n",
    "            }\n",
    "            group_properties[group_name] = group_info\n",
    "\n",
    "    return group_properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota:\n",
      "  variables: ['lon', 'lat', 'smp_depth', 'time', 'nuclide', 'value', 'unit', 'dl', 'bio_group', 'species', 'body_part', 'drywt', 'wetwt']\n",
      "  dimensions: {'id': 14873}\n",
      "  attributes: {}\n",
      "seawater:\n",
      "  variables: ['lon', 'lat', 'smp_depth', 'tot_depth', 'time', 'nuclide', 'value', 'unit', 'dl', 'filt']\n",
      "  dimensions: {'id': 20242}\n",
      "  attributes: {}\n",
      "sediment:\n",
      "  variables: ['lon', 'lat', 'tot_depth', 'time', 'area', 'nuclide', 'value', 'unit', 'dl', 'sed_type', 'top', 'bottom']\n",
      "  dimensions: {'id': 63868}\n",
      "  attributes: {}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "properties = get_netcdf_group_properties(fname)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b3452",
   "metadata": {},
   "source": [
    "Return variable properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_variable_properties(file_path: str, as_df: bool = False) -> dict | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve properties of variables in each group of a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file\n",
    "    as_df (bool): If True, returns a pandas DataFrame; if False, returns nested dictionary\n",
    "\n",
    "    Returns:\n",
    "    Union[dict, pd.DataFrame]: Properties of variables either as nested dictionary or DataFrame\n",
    "    \"\"\"\n",
    "    var_properties = {}\n",
    "    \n",
    "    file = Path(file_path)\n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return var_properties\n",
    "\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        for group_name, group in nc.groups.items():\n",
    "            group_vars = {}\n",
    "            for var_name, var in group.variables.items():\n",
    "                var_info = {\n",
    "                    'group': group_name,\n",
    "                    'variable': var_name,\n",
    "                    'data_type': var.dtype.str,\n",
    "                    'dimensions_id': str(var.dimensions),\n",
    "                    'dimensions_size': str(var.shape),\n",
    "                }\n",
    "                # Add variable attributes\n",
    "                for attr in var.ncattrs():\n",
    "                    var_info[f'attr_{attr}'] = str(getattr(var, attr))\n",
    "                    \n",
    "                group_vars[var_name] = var_info\n",
    "            var_properties[group_name] = group_vars\n",
    "\n",
    "    if not as_df:\n",
    "        return var_properties\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for group_name, group_vars in var_properties.items():\n",
    "        for var_name, var_info in group_vars.items():\n",
    "            rows.append(var_info)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Reorder columns to put key information first\n",
    "    first_cols = ['group', 'variable', 'dimensions_id', 'dimensions_size']\n",
    "    other_cols = [col for col in df.columns if col not in first_cols]\n",
    "    df = df[first_cols + other_cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3c74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>...</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>lon</td>\n",
       "      <td>lat</td>\n",
       "      <td>smp_depth</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>bio_group</td>\n",
       "      <td>species</td>\n",
       "      <td>...</td>\n",
       "      <td>tot_depth</td>\n",
       "      <td>time</td>\n",
       "      <td>area</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>sed_type</td>\n",
       "      <td>top</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_id</th>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>...</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_size</th>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>...</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_long_name</th>\n",
       "      <td>Measurement longitude</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Sample depth below seal level</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Biota group</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>Total depth below seal level</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Marine area/region id</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Sediment type</td>\n",
       "      <td>Top depth of sediment layer</td>\n",
       "      <td>Bottom depth of sediment layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_standard_name</th>\n",
       "      <td>longitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>sample_depth_below_sea_floor</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>biota_group_tbd</td>\n",
       "      <td>species</td>\n",
       "      <td>...</td>\n",
       "      <td>total_depth_below_sea_floor</td>\n",
       "      <td>time</td>\n",
       "      <td>area_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>sediment_type_tbd</td>\n",
       "      <td>top_depth_of_sediment_layer_tbd</td>\n",
       "      <td>bottom_depth_of_sediment_layer_tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_units</th>\n",
       "      <td>degrees_east</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>m</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_origin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_abbreviation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_calendar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                     1   \\\n",
       "group                               biota                 biota   \n",
       "variable                              lon                   lat   \n",
       "dimensions_id                     ('id',)               ('id',)   \n",
       "dimensions_size                  (14873,)              (14873,)   \n",
       "data_type                             <f4                   <f4   \n",
       "attr_long_name      Measurement longitude  Measurement latitude   \n",
       "attr_standard_name              longitude              latitude   \n",
       "attr_units                   degrees_east         degrees_north   \n",
       "attr_axis                             NaN                   NaN   \n",
       "attr_time_origin                      NaN                   NaN   \n",
       "attr_time_zone                        NaN                   NaN   \n",
       "attr_abbreviation                     NaN                   NaN   \n",
       "attr_calendar                         NaN                   NaN   \n",
       "\n",
       "                                               2   \\\n",
       "group                                       biota   \n",
       "variable                                smp_depth   \n",
       "dimensions_id                             ('id',)   \n",
       "dimensions_size                          (14873,)   \n",
       "data_type                                     <f4   \n",
       "attr_long_name      Sample depth below seal level   \n",
       "attr_standard_name   sample_depth_below_sea_floor   \n",
       "attr_units                                      m   \n",
       "attr_axis                                       Z   \n",
       "attr_time_origin                              NaN   \n",
       "attr_time_zone                                NaN   \n",
       "attr_abbreviation                             NaN   \n",
       "attr_calendar                                 NaN   \n",
       "\n",
       "                                                     3         4         5   \\\n",
       "group                                             biota     biota     biota   \n",
       "variable                                           time   nuclide     value   \n",
       "dimensions_id                                   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                                (14873,)  (14873,)  (14873,)   \n",
       "data_type                                           <u8       <i8       <f4   \n",
       "attr_long_name                      Time of measurement   Nuclide  Activity   \n",
       "attr_standard_name                                 time   nuclide  activity   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0       NaN       NaN   \n",
       "attr_axis                                             T       NaN       NaN   \n",
       "attr_time_origin                    1970-01-01 00:00:00       NaN       NaN   \n",
       "attr_time_zone                                      UTC       NaN       NaN   \n",
       "attr_abbreviation                             Date/Time       NaN       NaN   \n",
       "attr_calendar                                 gregorian       NaN       NaN   \n",
       "\n",
       "                          6                7                8         9   ...  \\\n",
       "group                  biota            biota            biota     biota  ...   \n",
       "variable                unit               dl        bio_group   species  ...   \n",
       "dimensions_id        ('id',)          ('id',)          ('id',)   ('id',)  ...   \n",
       "dimensions_size     (14873,)         (14873,)         (14873,)  (14873,)  ...   \n",
       "data_type                <i8              <i8              <i8       <i8  ...   \n",
       "attr_long_name          Unit  Detection limit      Biota group   Species  ...   \n",
       "attr_standard_name      unit  detection_limit  biota_group_tbd   species  ...   \n",
       "attr_units               NaN              NaN              NaN       NaN  ...   \n",
       "attr_axis                NaN              NaN              NaN       NaN  ...   \n",
       "attr_time_origin         NaN              NaN              NaN       NaN  ...   \n",
       "attr_time_zone           NaN              NaN              NaN       NaN  ...   \n",
       "attr_abbreviation        NaN              NaN              NaN       NaN  ...   \n",
       "attr_calendar            NaN              NaN              NaN       NaN  ...   \n",
       "\n",
       "                                              25  \\\n",
       "group                                   sediment   \n",
       "variable                               tot_depth   \n",
       "dimensions_id                            ('id',)   \n",
       "dimensions_size                         (63868,)   \n",
       "data_type                                    <f4   \n",
       "attr_long_name      Total depth below seal level   \n",
       "attr_standard_name   total_depth_below_sea_floor   \n",
       "attr_units                                     m   \n",
       "attr_axis                                      Z   \n",
       "attr_time_origin                             NaN   \n",
       "attr_time_zone                               NaN   \n",
       "attr_abbreviation                            NaN   \n",
       "attr_calendar                                NaN   \n",
       "\n",
       "                                                     26  \\\n",
       "group                                          sediment   \n",
       "variable                                           time   \n",
       "dimensions_id                                   ('id',)   \n",
       "dimensions_size                                (63868,)   \n",
       "data_type                                           <u8   \n",
       "attr_long_name                      Time of measurement   \n",
       "attr_standard_name                                 time   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0   \n",
       "attr_axis                                             T   \n",
       "attr_time_origin                    1970-01-01 00:00:00   \n",
       "attr_time_zone                                      UTC   \n",
       "attr_abbreviation                             Date/Time   \n",
       "attr_calendar                                 gregorian   \n",
       "\n",
       "                                       27        28        29        30  \\\n",
       "group                            sediment  sediment  sediment  sediment   \n",
       "variable                             area   nuclide     value      unit   \n",
       "dimensions_id                     ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                  (63868,)  (63868,)  (63868,)  (63868,)   \n",
       "data_type                             <i8       <i8       <f4       <i8   \n",
       "attr_long_name      Marine area/region id   Nuclide  Activity      Unit   \n",
       "attr_standard_name                area_id   nuclide  activity      unit   \n",
       "attr_units                            NaN       NaN       NaN       NaN   \n",
       "attr_axis                             NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                      NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                        NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                     NaN       NaN       NaN       NaN   \n",
       "attr_calendar                         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 31                 32  \\\n",
       "group                      sediment           sediment   \n",
       "variable                         dl           sed_type   \n",
       "dimensions_id               ('id',)            ('id',)   \n",
       "dimensions_size            (63868,)           (63868,)   \n",
       "data_type                       <i8                <i8   \n",
       "attr_long_name      Detection limit      Sediment type   \n",
       "attr_standard_name  detection_limit  sediment_type_tbd   \n",
       "attr_units                      NaN                NaN   \n",
       "attr_axis                       NaN                NaN   \n",
       "attr_time_origin                NaN                NaN   \n",
       "attr_time_zone                  NaN                NaN   \n",
       "attr_abbreviation               NaN                NaN   \n",
       "attr_calendar                   NaN                NaN   \n",
       "\n",
       "                                                 33  \\\n",
       "group                                      sediment   \n",
       "variable                                        top   \n",
       "dimensions_id                               ('id',)   \n",
       "dimensions_size                            (63868,)   \n",
       "data_type                                       <f4   \n",
       "attr_long_name          Top depth of sediment layer   \n",
       "attr_standard_name  top_depth_of_sediment_layer_tbd   \n",
       "attr_units                                      NaN   \n",
       "attr_axis                                       NaN   \n",
       "attr_time_origin                                NaN   \n",
       "attr_time_zone                                  NaN   \n",
       "attr_abbreviation                               NaN   \n",
       "attr_calendar                                   NaN   \n",
       "\n",
       "                                                    34  \n",
       "group                                         sediment  \n",
       "variable                                        bottom  \n",
       "dimensions_id                                  ('id',)  \n",
       "dimensions_size                               (63868,)  \n",
       "data_type                                          <f4  \n",
       "attr_long_name          Bottom depth of sediment layer  \n",
       "attr_standard_name  bottom_depth_of_sediment_layer_tbd  \n",
       "attr_units                                         NaN  \n",
       "attr_axis                                          NaN  \n",
       "attr_time_origin                                   NaN  \n",
       "attr_time_zone                                     NaN  \n",
       "attr_abbreviation                                  NaN  \n",
       "attr_calendar                                      NaN  \n",
       "\n",
       "[13 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "get_netcdf_variable_properties(fname, as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f546c7",
   "metadata": {},
   "source": [
    "Return the enum dictionary for a variable in a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ce353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_enum_dict(file_path: str, variable_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get the enum dictionary for a variable in a NetCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file\n",
    "    variable_name (str): Name of the variable to get enum for\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping enum names to values\n",
    "    \"\"\"\n",
    "    enum_dict = {}\n",
    "    \n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Look for the variable in all groups\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            if variable_name in group.variables:\n",
    "                var = group.variables[variable_name]\n",
    "                \n",
    "                # Check if variable has an enum type\n",
    "                if hasattr(var, 'enum_dict'):\n",
    "                    enum_dict = var.enum_dict\n",
    "    \n",
    "    return enum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOT APPLICABLE': -1,\n",
       " 'NOT AVAILABLE': 0,\n",
       " 'h3': 1,\n",
       " 'be7': 2,\n",
       " 'c14': 3,\n",
       " 'k40': 4,\n",
       " 'cr51': 5,\n",
       " 'mn54': 6,\n",
       " 'co57': 7,\n",
       " 'co58': 8,\n",
       " 'co60': 9,\n",
       " 'zn65': 10,\n",
       " 'sr89': 11,\n",
       " 'sr90': 12,\n",
       " 'zr95': 13,\n",
       " 'nb95': 14,\n",
       " 'tc99': 15,\n",
       " 'ru103': 16,\n",
       " 'ru106': 17,\n",
       " 'rh106': 18,\n",
       " 'ag106m': 19,\n",
       " 'ag108': 20,\n",
       " 'ag108m': 21,\n",
       " 'ag110m': 22,\n",
       " 'sb124': 23,\n",
       " 'sb125': 24,\n",
       " 'te129m': 25,\n",
       " 'i129': 28,\n",
       " 'i131': 29,\n",
       " 'cs127': 30,\n",
       " 'cs134': 31,\n",
       " 'cs137': 33,\n",
       " 'ba140': 34,\n",
       " 'la140': 35,\n",
       " 'ce141': 36,\n",
       " 'ce144': 37,\n",
       " 'pm147': 38,\n",
       " 'eu154': 39,\n",
       " 'eu155': 40,\n",
       " 'pb210': 41,\n",
       " 'pb212': 42,\n",
       " 'pb214': 43,\n",
       " 'bi207': 44,\n",
       " 'bi211': 45,\n",
       " 'bi214': 46,\n",
       " 'po210': 47,\n",
       " 'rn220': 48,\n",
       " 'rn222': 49,\n",
       " 'ra223': 50,\n",
       " 'ra224': 51,\n",
       " 'ra225': 52,\n",
       " 'ra226': 53,\n",
       " 'ra228': 54,\n",
       " 'ac228': 55,\n",
       " 'th227': 56,\n",
       " 'th228': 57,\n",
       " 'th232': 59,\n",
       " 'th234': 60,\n",
       " 'pa234': 61,\n",
       " 'u234': 62,\n",
       " 'u235': 63,\n",
       " 'u238': 64,\n",
       " 'np237': 65,\n",
       " 'np239': 66,\n",
       " 'pu238': 67,\n",
       " 'pu239': 68,\n",
       " 'pu240': 69,\n",
       " 'pu241': 70,\n",
       " 'am240': 71,\n",
       " 'am241': 72,\n",
       " 'cm242': 73,\n",
       " 'cm243': 74,\n",
       " 'cm244': 75,\n",
       " 'cs134_137_tot': 76,\n",
       " 'pu239_240_tot': 77,\n",
       " 'pu239_240_iii_iv_tot': 78,\n",
       " 'pu239_240_v_vi_tot': 79,\n",
       " 'cm243_244_tot': 80,\n",
       " 'pu238_pu239_240_tot_ratio': 81,\n",
       " 'am241_pu239_240_tot_ratio': 82,\n",
       " 'cs137_134_ratio': 83,\n",
       " 'cd109': 84,\n",
       " 'eu152': 85,\n",
       " 'fe59': 86,\n",
       " 'gd153': 87,\n",
       " 'ir192': 88,\n",
       " 'pu238_240_tot': 89,\n",
       " 'rb86': 90,\n",
       " 'sc46': 91,\n",
       " 'sn113': 92,\n",
       " 'sn117m': 93,\n",
       " 'tl208': 94,\n",
       " 'mo99': 95,\n",
       " 'tc99m': 96,\n",
       " 'ru105': 97,\n",
       " 'te129': 98,\n",
       " 'te132': 99,\n",
       " 'i132': 100,\n",
       " 'i135': 101,\n",
       " 'cs136': 102,\n",
       " 'tbeta': 103,\n",
       " 'talpha': 104,\n",
       " 'i133': 105,\n",
       " 'th230': 106,\n",
       " 'pa231': 107,\n",
       " 'u236': 108,\n",
       " 'ag111': 109,\n",
       " 'in116m': 110,\n",
       " 'te123m': 111,\n",
       " 'sb127': 112,\n",
       " 'ba133': 113,\n",
       " 'ce139': 114,\n",
       " 'tl201': 116,\n",
       " 'hg203': 117,\n",
       " 'na22': 122,\n",
       " 'pa234m': 123,\n",
       " 'am243': 124,\n",
       " 'se75': 126,\n",
       " 'sr85': 127,\n",
       " 'y88': 128,\n",
       " 'ce140': 129,\n",
       " 'bi212': 130,\n",
       " 'u236_238_ratio': 131,\n",
       " 'i125': 132,\n",
       " 'ba137m': 133,\n",
       " 'u232': 134,\n",
       " 'pa233': 135,\n",
       " 'ru106_rh106_tot': 136,\n",
       " 'tu': 137,\n",
       " 'tbeta40k': 138,\n",
       " 'fe55': 139,\n",
       " 'ce144_pr144_tot': 140,\n",
       " 'pu240_pu239_ratio': 141,\n",
       " 'u233': 142,\n",
       " 'pu239_242_tot': 143,\n",
       " 'ac227': 144}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "nuclide_mapping = get_enum_mapping(fname, 'biota', 'nuclide')\n",
    "nuclide_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82c9bc",
   "metadata": {},
   "source": [
    "## Convert NetCDF to OpenRefine CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d38d1",
   "metadata": {},
   "source": [
    "Maris NetCDF files can be converted to OpenRefine CSV files. The OpenRefine CSV files are compatible with the [OpenRefine](https://openrefine.org/) data cleaning tool which are used during the MARIS data cleaning process before loading into the MARIS database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd0a10",
   "metadata": {},
   "source": [
    "### WIP - TODO NetCDFOpenRefineDecoder .\n",
    "\n",
    "1. Include ENUM with NetCDF file. \n",
    "2. Can enum (alone) be used to update the netcdf data to openrefine data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ce4e6",
   "metadata": {},
   "source": [
    "Points to consider:\n",
    "1. validate_enum_mappings\n",
    "2. Generate dataframe of the netcdf file\n",
    "3. Update columns to 'MARISCO' naming standard, i.e. capitals. - this generalisation step will assist if other decoders are added.\n",
    "4. Convert column names from 'MARISCO' standard to 'CSV_VARS' standard. \n",
    "5. Convert values using CSV_DTYPES - the data standarised from the netcdf file will be considered the general standard (i.e. using enums values). - This too will assist if other decoders are added.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NetCDFDecoder:\n",
    "    \"\"\"Decode MARIS NetCDF files to OpenRefine-compatible CSV format.\"\"\"\n",
    "    def __init__(self, \n",
    "                 src_fname: str,  # Path to source NetCDF file\n",
    "                 dest_fname: str, # Base name for output CSV files\n",
    "                 encoding_type: str,\n",
    "                 verbose: bool=False\n",
    "                ):\n",
    "        store_attr()\n",
    "        self.enums = Enums(lut_src_dir=lut_path())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e38396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch \n",
    "def validate_enum_mappings(self: NetCDFDecoder):\n",
    "    \"\"\"Validate that enum mappings in NetCDF match lookup tables.\"\"\"\n",
    "    with Dataset(self.src_fname, 'r') as nc:\n",
    "        for group_name in nc.groups:\n",
    "            self._validate_group_enums(nc.groups[group_name], group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _validate_group_enums(self: NetCDFDecoder, group, group_name):\n",
    "    \"\"\"Validate enum mappings for a specific group.\"\"\"\n",
    "    for var_name, var in group.variables.items():\n",
    "        if not hasattr(var.datatype, 'enum_dict'): continue\n",
    "        \n",
    "        nc_enum_dict = var.datatype.enum_dict\n",
    "        if self.verbose:\n",
    "            print(f'nc_enum_dict [{var_name}]:', nc_enum_dict)\n",
    "\n",
    "        original_col = next((col for col, nc_var in NC_VARS.items() \n",
    "                           if nc_var == var_name), None)\n",
    "        if not original_col: continue\n",
    "\n",
    "        self._compare_enum_mappings(\n",
    "            nc_enum_dict, \n",
    "            self.enums.types[original_col],\n",
    "            group_name, \n",
    "            var_name,\n",
    "            original_col\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _compare_enum_mappings(self: NetCDFDecoder, nc_enum_dict, lut_enum, \n",
    "                          group_name, var_name, original_col):\n",
    "    \"\"\"Compare NetCDF enum mappings against lookup table values.\"\"\"\n",
    "    if self.verbose:\n",
    "        print(f'lut_enum [{original_col}]:', lut_enum)\n",
    "        \n",
    "    for enum_name, enum_val in nc_enum_dict.items():\n",
    "        if enum_name not in lut_enum:\n",
    "            raise ValueError(\n",
    "                f\"Enum value '{enum_name}' in NetCDF not found in lookup table \"\n",
    "                f\"for {group_name}/{var_name}\"\n",
    "            )\n",
    "        if enum_val != lut_enum[enum_name]:\n",
    "            raise ValueError(\n",
    "                f\"Enum value mismatch for '{enum_name}' in {group_name}/{var_name}: \"\n",
    "                f\"NetCDF={enum_val}, LookupTable={lut_enum[enum_name]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fdc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def load_to_dataframes(self: NetCDFDecoder):\n",
    "    \"\"\"Load NetCDF groups into DataFrames with standardized column names.\"\"\"\n",
    "    dfs = {}\n",
    "    with Dataset(self.src_fname, 'r') as nc:\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            # Get all variables in the group\n",
    "            data = {}\n",
    "            for var_name, var in group.variables.items():\n",
    "                if var_name not in group.dimensions:  # Skip dimension variables\n",
    "                    data[var_name] = var[:]\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            # Rename columns using NC_VARS mapping\n",
    "            rename_map = {nc_var: col for col, nc_var in NC_VARS.items() \n",
    "                         if nc_var in df.columns}\n",
    "            df = df.rename(columns=rename_map)\n",
    "            dfs[group_name.upper()] = df\n",
    "            if self.verbose:\n",
    "                print(f\"Loaded group {group_name} with columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23567eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "OR_VARS = {\n",
    "    'LON': 'longitude', \n",
    "    'LAT': 'latitude',\n",
    "    'SMP_DEPTH': 'sampdepth',\n",
    "    'TOT_DEPTH': 'totdepth',\n",
    "    'TIME': 'begperiod',\n",
    "    'AREA': 'area',\n",
    "    'NUCLIDE': 'nuclide_id',\n",
    "    'VALUE': 'activity',\n",
    "    'UNIT': 'unit_id',\n",
    "    'UNC': 'uncertaint',\n",
    "    'DL': 'detection',\n",
    "    'FILT': 'filtered',\n",
    "    'COUNT_MET': 'counmet_id',\n",
    "    'SAMP_MET': 'sampmet_id', \n",
    "    'PREP_MET': 'prepmet_id',\n",
    "    'VOL': 'volume',\n",
    "    'SAL': 'salinity',\n",
    "    'TEMP': 'temperatur',\n",
    "    'SPECIES': 'species_id',\n",
    "    'BODY_PART': 'bodypar_id',\n",
    "    'SED_TYPE': 'sedtype_id',\n",
    "    'TOP': 'sliceup',\n",
    "    'BOTTOM': 'slicedown',\n",
    "    'DRYWT': 'drywt',\n",
    "    'WETWT': 'wetwt',\n",
    "    'LAB': 'lab_id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbo_area.xlsx'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC_DTYPES['AREA']['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "OR_DTYPES = {\n",
    "    'AREA': {\n",
    "        'or_value':'displayName', \n",
    "    },\n",
    "    #'BIO_GROUP': { \n",
    "    #    'or_value': 'biogroup', \n",
    "    #},\n",
    "    'BODY_PART': {\n",
    "        'or_value': 'bodypar_id', \n",
    "    },\n",
    "    'COUNT_MET': {\n",
    "        'or_value':'counmet_id'\n",
    "    },\n",
    "    'DL': {\n",
    "        'or_value':'name'\n",
    "    },\n",
    "    'FILT': {\n",
    "        'name': 'filt_t', \n",
    "        'fname': 'dbo_filtered.xlsx',\n",
    "        'key': 'name',\n",
    "        'value':'id'\n",
    "    },\n",
    "    'NUCLIDE': {\n",
    "        'name': 'nuclide_t', \n",
    "        'fname': 'dbo_nuclide.xlsx',\n",
    "        'key': 'nc_name',\n",
    "        'value':'nuclide_id'\n",
    "    },\n",
    "    'PREP_MET': {\n",
    "        'name': 'prep_met_t', \n",
    "        'fname': 'dbo_prepmet.xlsx', \n",
    "        'key': 'prepmet',\n",
    "        'value':'prepmet_id'\n",
    "    },\n",
    "    'SAMP_MET': {\n",
    "        'name': 'samp_met_t', \n",
    "        'fname': 'dbo_sampmet.xlsx', \n",
    "        'key': 'sampmet',\n",
    "        'value':'sampmet_id'\n",
    "    },\n",
    "    'SED_TYPE': {\n",
    "        'name': 'sed_type_t', \n",
    "        'fname': 'dbo_sedtype.xlsx', \n",
    "        'key': 'sedtype', \n",
    "        'value':'sedtype_id'\n",
    "    },\n",
    "    'SPECIES': {\n",
    "        'name': 'species_t', \n",
    "        # 'fname': 'dbo_species_cleaned.xlsx',\n",
    "        'fname': 'dbo_species_2024_11_19.xlsx',\n",
    "        'key': 'species', \n",
    "        'value':'species_id'\n",
    "    },\n",
    "    'UNIT': {\n",
    "        'name': 'unit_t', \n",
    "        'fname': 'dbo_unit.xlsx', \n",
    "        'key': 'unit_sanitized', \n",
    "        'value':'unit_id'\n",
    "    },\n",
    "    'LAB': {\n",
    "        'name': 'lab_t', \n",
    "        #'fname': 'dbo_lab.xlsx', \n",
    "        'fname': 'dbo_lab_cleaned.xlsx', \n",
    "        'key': 'lab', \n",
    "        'value':'lab_id'\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "OR_GROUPS = {\n",
    "    'SEAWATER': '1',\n",
    "    'BIOTA': '2',\n",
    "    'SEDIMENT': '3',\n",
    "    'SUSPENDED': '4',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1774dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def decode(self:NetCDFDecoder):\n",
    "    \"\"\"Decode NetCDF to OpenRefine CSV files.\"\"\"\n",
    "    # First validate enum mappings. Ensure that the enum values in the netcdf file\n",
    "    # match the lookup table values.\n",
    "    self.validate_enum_mappings() \n",
    "    self.dfs = self.load_to_dataframes()\n",
    "    if self.encoding_type == 'openrefine':\n",
    "        print('OpenRefine encoding type selected.')\n",
    "\n",
    "     #here going to load the netcdf file to dataframes and standardise the column names.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRefine encoding type selected.\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "decoder = NetCDFDecoder( \n",
    "                    src_fname= fname,  # Path to source NetCDF file\n",
    "                    dest_fname=fname.with_suffix('.csv'), # Base name for output CSV files\n",
    "                    encoding_type='openrefine',\n",
    "                    verbose=False\n",
    "                 )\n",
    "decoder.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54220743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LON', 'LAT', 'SMP_DEPTH', 'TIME', 'NUCLIDE', 'VALUE', 'UNIT', 'DL',\n",
       "       'BIO_GROUP', 'SPECIES', 'BODY_PART', 'DRYWT', 'WETWT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "decoder.dfs['BIOTA'].columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

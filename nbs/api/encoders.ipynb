{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp encoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Encoders\n",
    "> Various utilities to encode MARIS dataset as `NetCDF`, `csv`, ... formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable\n",
    "import numpy as np\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "#import os\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_DTYPES, \n",
    "    NC_VARS, \n",
    "    NC_DIM,\n",
    "    NC_GROUPS,\n",
    "    lut_path, \n",
    "    Enums,\n",
    "    nc_tpl_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c33bc",
   "metadata": {},
   "source": [
    "## NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NetCDFEncoder:\n",
    "    \"MARIS NetCDF encoder.\"\n",
    "    def __init__(self, \n",
    "                 dfs: Dict[str, pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "                 dest_fname: str, # Name of output file to produce\n",
    "                 global_attrs: Dict[str, str], # Global attributes\n",
    "                 fn_src_fname: Callable=nc_tpl_path, # Function returning file name and path to the MARIS CDL template\n",
    "                 custom_maps: Dict[str, Dict[str, int]]= None,# Custom maps to encode\n",
    "                 verbose: bool=False, # Print currently written NetCDF group and variable names\n",
    "                 ):\n",
    "        store_attr()\n",
    "        self.src_fname = fn_src_fname()\n",
    "        self.enum_dtypes = {}\n",
    "        self.nc_to_cols = {v:k for k,v in NC_VARS.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "\n",
    "df_seawater = pd.DataFrame({\n",
    "    'ID': [0, 1, 2],\n",
    "    'SMP_ID': [1, 2, 3],\n",
    "    'LON': [141, 142, 143], \n",
    "    'LAT': [37.3, 38.3, 39.3], \n",
    "    'TIME': [1234, 1235, 1236], \n",
    "    'NUCLIDE': [1, 2, 3],\n",
    "    'VALUE': [0.1, 1.1, 2.1], \n",
    "    'AREA': [2374, 2379, 2401],\n",
    "    })\n",
    "\n",
    "df_biota = pd.DataFrame({\n",
    "    'ID': [0, 1, 2, 3], \n",
    "    'SMP_ID': [1, 2, 3, 4],\n",
    "    'LON': [141, 142, 143, 144], \n",
    "    'LAT': [37.3, 38.3, 39.3, 40.3], \n",
    "    'TIME': [1234, 1235, 1236, 1237], \n",
    "    'NUCLIDE': [1, 2, 3, 3],\n",
    "    'VALUE': [0.1, 1.1, 2.1, 3.1], \n",
    "    'SPECIES': [1, 2, 3, 3]\n",
    "    })\n",
    "\n",
    "# test larger map\n",
    "smp_dict = {f'SMP {x}': np.int64(x) for x in range(1, 5)}           \n",
    "custom_maps = {'SEAWATER': {'SMP_ID': smp_dict}}\n",
    "\n",
    "dfs = {'SEAWATER': df_seawater, 'BIOTA': df_biota}\n",
    "attrs = {'id': '123', 'title': 'Test title', 'summary': 'Summary test'}\n",
    "src = './files/nc/maris-template.nc'\n",
    "dest = './files/nc/encoding-test.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch \n",
    "def copy_global_attributes(self:NetCDFEncoder):\n",
    "    \"Update NetCDF template global attributes as specified by `global_attrs` argument.\"\n",
    "    self.dest.setncatts(self.src.__dict__)\n",
    "    for k, v in self.global_attrs.items(): self.dest.setncattr(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6909975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_dimensions(self:NetCDFEncoder, grp_dest):\n",
    "    \"Copy dimensions to root and all groups from template.\"\n",
    "    src_dim = self.src.groups[grp_dest.name].dimensions\n",
    "    for name, dim in src_dim.items():\n",
    "        grp_dest.createDimension(name, (len(dim) if not dim.isunlimited() else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_groups(self:NetCDFEncoder):\n",
    "    for grp_name, df in self.dfs.items():\n",
    "        self.process_group(NC_GROUPS[grp_name], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_group(self:NetCDFEncoder, grp_name, df):\n",
    "    grp_dest = self.dest.createGroup(grp_name)\n",
    "    self.copy_dimensions(grp_dest)\n",
    "    self.copy_variables(grp_name, df, grp_dest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49969ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variables(self:NetCDFEncoder, grp_name, df, grp_dest):\n",
    "    cols = [NC_VARS[col] for col in df.columns if col in NC_VARS]\n",
    "    for var_name, var_src in self.src.groups[grp_name].variables.items():\n",
    "        if var_name in cols: \n",
    "            self.copy_variable(var_name, var_src, df, grp_dest)\n",
    "        if self.custom_maps:\n",
    "            self.copy_custom_map(var_name, grp_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40561907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variable(self:NetCDFEncoder, var_name, var_src, df, grp_dest):\n",
    "    dtype_name = var_src.datatype.name\n",
    "    enums_src = self.src.enumtypes\n",
    "    if self.verbose: \n",
    "        print(80*'-')\n",
    "        print(f'Group: {grp_dest.name}, Variable: {var_name}')\n",
    "    self._create_and_copy_variable(var_name, var_src, df, grp_dest, dtype_name)\n",
    "    self.copy_variable_attributes(var_name, var_src, grp_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93792604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _create_and_copy_variable(self:NetCDFEncoder, var_name, var_src, df, grp_dest, dtype_name):\n",
    "    variable_type = self.enum_dtypes.get(dtype_name, var_src.datatype)    \n",
    "    grp_dest.createVariable(var_name, variable_type, NC_DIM, compression='zlib', complevel=9)            \n",
    "    isNotEnum = type(variable_type) != netCDF4._netCDF4.EnumType\n",
    "    values = df[self.nc_to_cols[var_name]].values\n",
    "    grp_dest[var_name][:] = values if isNotEnum else self.sanitize_if_enum_and_nan(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3042eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def sanitize_if_enum_and_nan(self:NetCDFEncoder, values, fill_value=-1):\n",
    "    values[np.isnan(values)] = int(fill_value)\n",
    "    values = values.astype(int)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd48f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#| exports - Not used in this notebook - NM/01-30-2025.\\n \\n@patch\\ndef copy_enum_type(self:NetCDFEncoder, dtype_name):\\n    # if enum type not already created\\n    if dtype_name not in self.enum_types:\\n        enum_info = self.src.enumtypes[dtype_name]\\n        # If a subset of an enum is defined in enums_xtra (typically for the lengthy species_t)\\n        if enum_info.name in self.enums_xtra:\\n            # add \"not applicable\"\\n            enum_info.enum_dict = self.enums_xtra[enum_info.name]\\n            enum_info.enum_dict[\\'Not applicable\\'] = -1 # TBD\\n        self.enum_types[dtype_name] = self.dest.createEnumType(enum_info.dtype, \\n                                                               enum_info.name, \\n                                                               enum_info.enum_dict)\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#| exports - Not used in this notebook - NM/01-30-2025.\n",
    " \n",
    "@patch\n",
    "def copy_enum_type(self:NetCDFEncoder, dtype_name):\n",
    "    # if enum type not already created\n",
    "    if dtype_name not in self.enum_types:\n",
    "        enum_info = self.src.enumtypes[dtype_name]\n",
    "        # If a subset of an enum is defined in enums_xtra (typically for the lengthy species_t)\n",
    "        if enum_info.name in self.enums_xtra:\n",
    "            # add \"not applicable\"\n",
    "            enum_info.enum_dict = self.enums_xtra[enum_info.name]\n",
    "            enum_info.enum_dict['Not applicable'] = -1 # TBD\n",
    "        self.enum_types[dtype_name] = self.dest.createEnumType(enum_info.dtype, \n",
    "                                                               enum_info.name, \n",
    "                                                               enum_info.enum_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variable_attributes(self:NetCDFEncoder, var_name, var_src, grp_dest):\n",
    "    grp_dest[var_name].setncatts(var_src.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def retrieve_all_cols(self:NetCDFEncoder, \n",
    "                      dtypes=NC_DTYPES\n",
    "                      ):\n",
    "    \"Retrieve all unique columns from the dict of dataframes.\" \n",
    "    return list(set(col for df in self.dfs.values() for col in df.columns if col in dtypes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724453b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def create_enums(self:NetCDFEncoder):\n",
    "    cols = self.retrieve_all_cols()\n",
    "    enums = Enums(lut_src_dir=lut_path())\n",
    "    for col in cols:\n",
    "        name = NC_DTYPES[col]['name']\n",
    "        if self.verbose: print(f'Creating enum for {name} with values {enums.types[col]}.')\n",
    "        dtype = self.dest.createEnumType(np.int64, name, enums.types[col])\n",
    "        self.enum_dtypes[name] = dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dddf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_custom_map(self:NetCDFEncoder, var_name, grp_dest):\n",
    "    \"\"\"Copy custom maps for variables.\"\"\"\n",
    "    custom_maps = self.custom_maps\n",
    "    # Convert group names using NC_GROUPS\n",
    "    custom_maps = {NC_GROUPS[key]: value for key, value in custom_maps.items()}\n",
    "    group_maps = custom_maps.get(grp_dest.name, {})\n",
    "    # Convert var names using NC_VARS\n",
    "    group_maps = {NC_VARS[key]: value for key, value in group_maps.items()}\n",
    "    if var_name in group_maps:\n",
    "        # Set the map as an attribute of the variable\n",
    "        grp_dest[var_name].setncatts({f\"{var_name}_map\": str(group_maps[var_name])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def encode(self:NetCDFEncoder):\n",
    "    \"Encode MARIS NetCDF based on template and dataframes.\"\n",
    "    with Dataset(self.src_fname, format='NETCDF4') as self.src, Dataset(self.dest_fname, 'w', format='NETCDF4') as self.dest:\n",
    "        self.copy_global_attributes()\n",
    "        self.create_enums()\n",
    "        self.process_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759d7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NetCDFEncoder' object has no attribute 'process_groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|eval: false\u001b[39;00m\n\u001b[1;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m NetCDFEncoder(dfs, \n\u001b[1;32m      3\u001b[0m                         dest_fname\u001b[38;5;241m=\u001b[39mdest, \n\u001b[1;32m      4\u001b[0m                         global_attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m      5\u001b[0m                         custom_maps\u001b[38;5;241m=\u001b[39mcustom_maps,\n\u001b[1;32m      6\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                         )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[160], line 8\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_global_attributes()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_enums()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_groups\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NetCDFEncoder' object has no attribute 'process_groups'"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "encoder = NetCDFEncoder(dfs, \n",
    "                        dest_fname=dest, \n",
    "                        global_attrs=attrs,\n",
    "                        custom_maps=custom_maps,\n",
    "                        verbose=False\n",
    "                        )\n",
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b830407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that global attributes are copied\n",
    "#with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#        for k, v in {'id': '123', 'title': 'Test title', 'summary': 'Summary test'}.items():\n",
    "#           fc.test_eq(getattr(nc, k), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2342f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that dimension is `sample` and unlimited\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     fc.test_eq('sample' in nc.dimensions, True)\n",
    "#     fc.test_eq(nc.dimensions['sample'].isunlimited(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that groups are created\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     fc.test_eq(nc.groups.keys(), ['seawater', 'biota'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that groups are created\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     fc.test_eq(nc.groups.keys(), ['seawater', 'biota'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that correct variables are created in groups\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     fc.test_eq(nc['biota'].variables.keys(), \n",
    "#                ['sample', 'lon', 'lat', 'time', 'species', 'i131', 'i131_dl', 'i131_unit'])\n",
    "    \n",
    "#     fc.test_eq(nc['seawater'].variables.keys(), \n",
    "#                ['sample', 'lon', 'lat', 'time', 'i131', 'i131_dl', 'i131_unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that correct variables are created in groups\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     print(nc.dimensions.items())\n",
    "#     print(nc['biota'].dimensions.items())\n",
    "#     print(nc['seawater'].dimensions.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that custom maps are copied\n",
    "# with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "#     print(nc['seawater'].variables.items())\n",
    "#     print(nc['biota'].variables.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

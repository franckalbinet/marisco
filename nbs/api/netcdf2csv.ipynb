{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp netcdf2csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF2CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A data pipeline that converts MARIS NetCDF files into MARIS Standard OpenRefine CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module converts NetCDF files into CSV files that follow the MARIS Standard [OpenRefine](https://openrefine.org/) format. While MARISCO has replaced OpenRefine in the data cleaning and preparation pipeline, the MARIS master database still requires input files to conform to this CSV format specification. The conversion is performed using the marisco library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [field definitions\n",
    "](https://github.com/franckalbinet/marisco/blob/main/nbs/metadata/field-definition.ipynb) for detailed information about Maris fields.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "> Required packages and internal modules for data format transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "# from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import fastcore.all as fc\n",
    "from typing import Dict,Callable\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_VARS,\n",
    "    CSV_VARS,\n",
    "    CSV_DTYPES,\n",
    "    Enums,\n",
    "    lut_path,\n",
    "    species_lut_path,\n",
    "    detection_limit_lut_path, # used for feedback. \n",
    "    filtered_lut_path,\n",
    "    cfg\n",
    ")\n",
    "\n",
    "from marisco.utils import (\n",
    "    ExtractNetcdfContents,\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback,\n",
    "    Transformer,\n",
    "    DecodeTimeCB,\n",
    "    AddSampleTypeIdColumnCB\n",
    ")  \n",
    "    \n",
    "from marisco.decoders import (\n",
    "    NetCDFDecoder\n",
    "    )\n",
    "from marisco.metadata import (\n",
    "    ZoteroItem\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# fname_in =  Path('../../_data/output/tepco.nc')\n",
    "fname_in =  Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "fname_out = fname_in.with_suffix('.csv')\n",
    "output_format = 'openrefine_csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from standardized MARIS NetCDF files using ExtractNetcdfContents. The NetCDF files follow CF conventions and include standardized variable names and metadata according to MARIS specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dictionary of dataframes extracted from the NetCDF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BIOTA', 'SEAWATER', 'SEDIMENT'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents.dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an example of the DataFrame extracted from the NetCDF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>FILT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337731200</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337731200</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339891200</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337817600</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337817600</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>3.996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       "0  29.333300  60.083302        0.0        NaN  1337731200       0       33   \n",
       "1  29.333300  60.083302       29.0        NaN  1337731200       1       33   \n",
       "2  23.150000  59.433300        0.0        NaN  1339891200       2       33   \n",
       "3  27.983299  60.250000        0.0        NaN  1337817600       3       33   \n",
       "4  27.983299  60.250000       39.0        NaN  1337817600       4       33   \n",
       "\n",
       "       VALUE  UNIT    UNC  DL  FILT  \n",
       "0   5.300000     1  1.696   1     0  \n",
       "1  19.900000     1  3.980   1     0  \n",
       "2  25.500000     1  5.100   1     0  \n",
       "3  17.000000     1  4.930   1     0  \n",
       "4  22.200001     1  3.996   1     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(contents.dfs['SEAWATER'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an example of the dictionary of enums extracted from the NetCDF file as a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in SEAWATER group: dict_keys(['nuclide', 'unit', 'dl', 'filt'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not applicable</th>\n",
       "      <th>Not available</th>\n",
       "      <th>Detected value</th>\n",
       "      <th>Detection limit</th>\n",
       "      <th>Not detected</th>\n",
       "      <th>Derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Not applicable Not available Detected value Detection limit Not detected  \\\n",
       "0             -1             0              1               2            3   \n",
       "\n",
       "  Derived  \n",
       "0       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='SEAWATER'\n",
    "print(f'Variables in {grp} group: {contents.enum_dicts[grp].keys()}')\n",
    "var='dl'\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pd.DataFrame.from_dict(contents.enum_dicts[grp][var], orient='index').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the global attributes extracted from the NetCDF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few attributes from global attributes: [('id', '26VMZZ2Q'), ('title', 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances'), ('summary', 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.'), ('keywords', 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)'), ('history', 'TBD')]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(\"First few attributes from global attributes:\", list(contents.global_attrs.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the custom maps extracted from the NetCDF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom maps in SEAWATER group: dict_keys([])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='SEAWATER'\n",
    "print(f'Custom maps in {grp} group: {contents.custom_maps[grp].keys()}')\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(pd.DataFrame.from_dict(contents.custom_maps[grp], orient='index'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate NetCDF Enumerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that enumerated values in the NetCDF file match current MARIS lookup tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "## FEEDBACK TO DATA PROVIDERS\n",
    "\n",
    "The enumeration validation process is a diagnostic step that identifies inconsistencies between NetCDF enumerations and MARIS lookup tables. While this validation does not modify the dataset, it generates detailed feedback about any mismatches or undefined values. \n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 'id',\n",
       " 'LON': 'lon',\n",
       " 'LAT': 'lat',\n",
       " 'SMP_DEPTH': 'smp_depth',\n",
       " 'TOT_DEPTH': 'tot_depth',\n",
       " 'TIME': 'time',\n",
       " 'AREA': 'area',\n",
       " 'SMP_ID': 'smp_id',\n",
       " 'NUCLIDE': 'nuclide',\n",
       " 'VALUE': 'value',\n",
       " 'UNIT': 'unit',\n",
       " 'UNC': 'unc',\n",
       " 'DL': 'dl',\n",
       " 'DLV': 'dlv',\n",
       " 'FILT': 'filt',\n",
       " 'COUNT_MET': 'count_met',\n",
       " 'SAMP_MET': 'samp_met',\n",
       " 'PREP_MET': 'prep_met',\n",
       " 'VOL': 'vol',\n",
       " 'SAL': 'sal',\n",
       " 'TEMP': 'temp',\n",
       " 'PH': 'ph',\n",
       " 'BIO_GROUP': 'bio_group',\n",
       " 'SPECIES': 'species',\n",
       " 'BODY_PART': 'body_part',\n",
       " 'SED_TYPE': 'sed_type',\n",
       " 'TOP': 'top',\n",
       " 'BOTTOM': 'bottom',\n",
       " 'DRYWT': 'drywt',\n",
       " 'WETWT': 'wetwt',\n",
       " 'PERCENTWT': 'percentwt',\n",
       " 'LAB': 'lab',\n",
       " 'PROFILE_ID': 'profile_id',\n",
       " 'STATION': 'station'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC_VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ValidateEnumsCB(Callback):\n",
    "    \"Validate enumeration mappings between NetCDF file and MARIS lookup tables.\"\n",
    "\n",
    "    def __init__(self, contents, maris_enums, verbose=False):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for group_name, enum_dict in self.contents.enum_dicts.items():\n",
    "            self._validate_group(group_name, enum_dict)\n",
    "\n",
    "    def _validate_group(self, group_name, enum_dict):\n",
    "        \n",
    "        for var_name, nc_enum_dict in enum_dict.items():\n",
    "            if self.verbose:\n",
    "                print(f\"Validating variable {var_name} from NetCDF group {group_name}.\")\n",
    "            var_name = self._get_original_var_name(var_name)\n",
    "            if self.verbose:\n",
    "                print(f\"Standardized variable name to MARISCO naming convention: {var_name}\")\n",
    "\n",
    "            if var_name not in self.maris_enums.types:\n",
    "                if self.verbose:\n",
    "                    print(f\"Variable {var_name} not found in MARISCO enums.\")\n",
    "                continue\n",
    "\n",
    "            self._compare_mappings(nc_enum_dict, self.maris_enums.types[var_name], group_name, var_name)\n",
    "\n",
    "    def _get_original_var_name(self, var_name):\n",
    "        return next((var for var, nc_var in NC_VARS.items() if nc_var == var_name), var_name)\n",
    "\n",
    "    def _compare_mappings(self, nc_dict, maris_enum, group_name, var_name):        \n",
    "        for key, value in nc_dict.items():\n",
    "            value=int(value)\n",
    "            if key not in maris_enum or maris_enum[key] != value:\n",
    "                print(f\"\\nWarning: Enum mismatch: {var_name} in {group_name}.\")\n",
    "                print(f\"   NetCDF value: {key} -> {value}\")\n",
    "                print(f\"   MARISCO standard enum lookup value: {key} -> {maris_enum.get(key, 'Not found')}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       0       31   \n",
       " 1      12.316667  54.283333        NaN  1348358400       0        4   \n",
       " 2      12.316667  54.283333        NaN  1348358400       0        9   \n",
       " 3      12.316667  54.283333        NaN  1348358400       0       33   \n",
       " 4      12.316667  54.283333        NaN  1348358400       1       31   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 16089  21.395000  61.241501        2.0  1652140800    4789       33   \n",
       " 16090  21.395000  61.241501        2.0  1652140800    4789        9   \n",
       " 16091  21.385000  61.343334        NaN  1663200000    4790        4   \n",
       " 16092  21.385000  61.343334        NaN  1663200000    4790       33   \n",
       " 16093  21.385000  61.343334        NaN  1663200000    4790       12   \n",
       " \n",
       "             VALUE  UNIT       UNC  DL  BIO_GROUP  SPECIES  BODY_PART  \\\n",
       " 0        0.010140     5       NaN   2          4       99         52   \n",
       " 1      135.300003     5  4.830210   1          4       99         52   \n",
       " 2        0.013980     5       NaN   2          4       99         52   \n",
       " 3        4.338000     5  0.150962   1          4       99         52   \n",
       " 4        0.009614     5       NaN   2          4       99         52   \n",
       " ...           ...   ...       ...  ..        ...      ...        ...   \n",
       " 16089   13.700000     4  0.520600   1         11       96         55   \n",
       " 16090    0.500000     4  0.045500   1         11       96         55   \n",
       " 16091   50.700001     4  4.106700   1         14      129          1   \n",
       " 16092    0.880000     4  0.140800   1         14      129          1   \n",
       " 16093    6.600000     4  0.349800   1         14      129          1   \n",
       " \n",
       "             DRYWT  WETWT  PERCENTWT  \n",
       " 0      174.934433  948.0    0.18453  \n",
       " 1      174.934433  948.0    0.18453  \n",
       " 2      174.934433  948.0    0.18453  \n",
       " 3      174.934433  948.0    0.18453  \n",
       " 4      177.935120  964.0    0.18458  \n",
       " ...           ...    ...        ...  \n",
       " 16089         NaN    NaN        NaN  \n",
       " 16090         NaN    NaN        NaN  \n",
       " 16091         NaN    NaN        NaN  \n",
       " 16092         NaN    NaN        NaN  \n",
       " 16093         NaN    NaN        NaN  \n",
       " \n",
       " [16094 rows x 16 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  SMP_ID  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       0   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       1   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       2   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       3   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       4   \n",
       " ...          ...        ...        ...        ...         ...     ...   \n",
       " 21468  13.499833  54.600334        0.0       47.0  1686441600    9724   \n",
       " 21469  13.499833  54.600334       45.0       47.0  1686441600    9725   \n",
       " 21470  14.200833  54.600334        0.0       11.0  1686614400    9731   \n",
       " 21471  14.665500  54.600334        0.0       20.0  1686614400    9732   \n",
       " 21472  14.330000  54.600334        0.0       17.0  1686614400    9734   \n",
       " \n",
       "        NUCLIDE       VALUE  UNIT        UNC  DL  FILT  \n",
       " 0           33    5.300000     1   1.696000   1     0  \n",
       " 1           33   19.900000     1   3.980000   1     0  \n",
       " 2           33   25.500000     1   5.100000   1     0  \n",
       " 3           33   17.000000     1   4.930000   1     0  \n",
       " 4           33   22.200001     1   3.996000   1     0  \n",
       " ...        ...         ...   ...        ...  ..   ...  \n",
       " 21468        1  702.838074     1  51.276207   1     0  \n",
       " 21469        1  725.855713     1  52.686260   1     0  \n",
       " 21470        1  648.992920     1  48.154419   1     0  \n",
       " 21471        1  627.178406     1  46.245316   1     0  \n",
       " 21472        1  605.715088     1  45.691143   1     0  \n",
       " \n",
       " [21473 rows x 12 columns],\n",
       " 'SEDIMENT':              LON        LAT  TOT_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      27.799999  60.466667       25.0  1337904000       0       33   \n",
       " 1      27.799999  60.466667       25.0  1337904000       1       33   \n",
       " 2      27.799999  60.466667       25.0  1337904000       2       33   \n",
       " 3      27.799999  60.466667       25.0  1337904000       3       33   \n",
       " 4      27.799999  60.466667       25.0  1337904000       4       33   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 70444  15.537800  54.617832       62.0  1654646400   14121       67   \n",
       " 70445  15.537800  54.617832       62.0  1654646400   14121       77   \n",
       " 70446  15.537800  54.617832       62.0  1654646400   14122        4   \n",
       " 70447  15.537800  54.617832       62.0  1654646400   14122       33   \n",
       " 70448  15.537800  54.617832       62.0  1654646400   14122       77   \n",
       " \n",
       "              VALUE  UNIT         UNC  DL  SED_TYPE   TOP  BOTTOM  PERCENTWT  \n",
       " 0      1200.000000     3  240.000000   1         0  15.0    20.0        NaN  \n",
       " 1       250.000000     3   50.000000   1         0  20.0    25.0        NaN  \n",
       " 2       140.000000     3   29.400000   1         0  25.0    30.0        NaN  \n",
       " 3        79.000000     3   15.800000   1         0  30.0    35.0        NaN  \n",
       " 4        29.000000     3    6.960000   1         0  35.0    40.0        NaN  \n",
       " ...            ...   ...         ...  ..       ...   ...     ...        ...  \n",
       " 70444     0.044000     2    0.015312   1        10  15.0    17.0   0.257642  \n",
       " 70445     2.500000     2    0.185000   1        10  15.0    17.0   0.257642  \n",
       " 70446  5873.000000     2  164.444000   1        10  17.0    19.0   0.263965  \n",
       " 70447    21.200001     2    2.162400   1        10  17.0    19.0   0.263965  \n",
       " 70448     0.370000     2    0.048100   1        10  17.0    19.0   0.263965  \n",
       " \n",
       " [70449 rows x 14 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data= contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        ValidateEnumsCB(\n",
    "            contents = contents,\n",
    "            maris_enums=Enums(lut_src_dir=lut_path())\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Non Compatible Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``RemoveNonCompatibleVariablesCB`` callback filters out variables from the NetCDF format that are not listed in the VARS configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemoveNonCompatibleVariablesCB(Callback):\n",
    "    \"Remove variables not listed in VARS configuration.\"\n",
    "    def __init__(self, \n",
    "                vars: Dict[str, str] = CSV_VARS,  # Dictionary mapping OR vars to NC vars\n",
    "                verbose: bool = False,\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Remove non-OR variables fro  m all dataframes.\"\"\"\n",
    "        for group_name in tfm.dfs:\n",
    "            tfm.dfs[group_name] = self._remove_non_vars(tfm.dfs[group_name], group_name)\n",
    "            \n",
    "    def _remove_non_vars(self, df: pd.DataFrame, group_name:str ) -> pd.DataFrame:\n",
    "        \"\"\"Remove variables not in vars and print removed columns if verbose.\"\"\"\n",
    "        current_cols = set(df.columns)\n",
    "        vars_cols = set(self.vars.keys())\n",
    "        cols_to_remove = current_cols - vars_cols\n",
    "        \n",
    "        if self.verbose and cols_to_remove:\n",
    "            print(f\"Removing variables that are not compatible with vars provided. \\nRemoving {', '.join(cols_to_remove)} from {group_name} dataset.\")           \n",
    "        return df.drop(columns=cols_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LON': 'longitude',\n",
       " 'LAT': 'latitude',\n",
       " 'SMP_DEPTH': 'sampdepth',\n",
       " 'TOT_DEPTH': 'totdepth',\n",
       " 'TIME': 'begperiod',\n",
       " 'AREA': 'area',\n",
       " 'NUCLIDE': 'nuclide_id',\n",
       " 'VALUE': 'activity',\n",
       " 'UNIT': 'unit_id',\n",
       " 'UNC': 'uncertaint',\n",
       " 'DL': 'detection',\n",
       " 'DLV': 'detection_lim',\n",
       " 'FILT': 'filtered',\n",
       " 'COUNT_MET': 'counmet_id',\n",
       " 'SAMP_MET': 'sampmet_id',\n",
       " 'PREP_MET': 'prepmet_id',\n",
       " 'VOL': 'volume',\n",
       " 'SAL': 'salinity',\n",
       " 'TEMP': 'temperatur',\n",
       " 'SPECIES': 'species_id',\n",
       " 'BODY_PART': 'bodypar_id',\n",
       " 'SED_TYPE': 'sedtype_id',\n",
       " 'TOP': 'sliceup',\n",
       " 'BOTTOM': 'slicedown',\n",
       " 'DRYWT': 'drywt',\n",
       " 'WETWT': 'wetwt',\n",
       " 'PERCENTWT': 'percentwt',\n",
       " 'LAB': 'lab_id',\n",
       " 'PROFILE_ID': 'profile_id',\n",
       " 'SAMPLE_TYPE': 'samptype_id',\n",
       " 'TAXONNAME': 'taxonname',\n",
       " 'TAXONREPNAME': 'taxonrepname',\n",
       " 'TAXONRANK': 'taxonrank',\n",
       " 'TAXONDB': 'taxondb',\n",
       " 'TAXONDBID': 'taxondb_id',\n",
       " 'TAXONDBURL': 'taxondb_url',\n",
       " 'REF_ID': 'ref_id',\n",
       " 'SMP_ID': 'samplabcode',\n",
       " 'STATION': 'station'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing variables that are not compatible with vars provided. \n",
      "Removing BIO_GROUP from BIOTA dataset.\n",
      "         LON        LAT  SMP_DEPTH        TIME  SMP_ID  NUCLIDE       VALUE  \\\n",
      "0  12.316667  54.283333        NaN  1348358400       0       31    0.010140   \n",
      "1  12.316667  54.283333        NaN  1348358400       0        4  135.300003   \n",
      "2  12.316667  54.283333        NaN  1348358400       0        9    0.013980   \n",
      "3  12.316667  54.283333        NaN  1348358400       0       33    4.338000   \n",
      "4  12.316667  54.283333        NaN  1348358400       1       31    0.009614   \n",
      "\n",
      "   UNIT       UNC  DL  SPECIES  BODY_PART       DRYWT  WETWT  PERCENTWT  \n",
      "0     5       NaN   2       99         52  174.934433  948.0    0.18453  \n",
      "1     5  4.830210   1       99         52  174.934433  948.0    0.18453  \n",
      "2     5       NaN   2       99         52  174.934433  948.0    0.18453  \n",
      "3     5  0.150962   1       99         52  174.934433  948.0    0.18453  \n",
      "4     5       NaN   2       99         52  177.935120  964.0    0.18458  \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        RemoveNonCompatibleVariablesCB(vars=CSV_VARS, verbose=True),\n",
    "    ]\n",
    ")\n",
    "tfm()\n",
    "print(tfm.dfs['BIOTA'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample ID Handling\n",
    "\n",
    "The MARISCO NetCDF encoding pipeline uses `SMP_ID` to store unique identifiers for each sample measurement. These IDs can come from two sources:\n",
    "\n",
    "1. Directly from data providers who supply their own unique identifiers\n",
    "2. Auto-generated by MARISCO as incremented integers when providers don't supply IDs\n",
    "\n",
    "The Maris database ingestion pipeline expects:\n",
    "\n",
    "- The original `SMP_ID` if provided by the data source\n",
    "- `None` if the ID was auto-generated by MARISCO\n",
    "\n",
    "*Note: When writing to CSV, `SMP_ID` is renamed to `samplabcode` as defined in the `CSV_VARS` mapping in `configs.ipynb`.*\n",
    "\n",
    "The callback below implements this logic by providing an option to convert auto-generated `SMP_ID` values to `None` while preserving original provider-supplied IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SampleIDConversionCB(Callback):\n",
    "    \"Convert auto-generated `SMP_ID` values to `None` while preserving original provider-supplied IDs.\"\n",
    "    def __init__(self, \n",
    "                 nonify: bool = False, # If True, convert auto-generated `SMP_ID` values to `None`\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for group_name in tfm.dfs:\n",
    "            if self.nonify: \n",
    "                tfm.dfs[group_name]['SMP_ID'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing variables that are not compatible with vars provided. \n",
      "Removing BIO_GROUP from BIOTA dataset.\n",
      "         LON        LAT  SMP_DEPTH        TIME SMP_ID  NUCLIDE       VALUE  \\\n",
      "0  12.316667  54.283333        NaN  1348358400   None       31    0.010140   \n",
      "1  12.316667  54.283333        NaN  1348358400   None        4  135.300003   \n",
      "2  12.316667  54.283333        NaN  1348358400   None        9    0.013980   \n",
      "3  12.316667  54.283333        NaN  1348358400   None       33    4.338000   \n",
      "4  12.316667  54.283333        NaN  1348358400   None       31    0.009614   \n",
      "\n",
      "   UNIT       UNC  DL  SPECIES  BODY_PART       DRYWT  WETWT  PERCENTWT  \n",
      "0     5       NaN   2       99         52  174.934433  948.0    0.18453  \n",
      "1     5  4.830210   1       99         52  174.934433  948.0    0.18453  \n",
      "2     5       NaN   2       99         52  174.934433  948.0    0.18453  \n",
      "3     5  0.150962   1       99         52  174.934433  948.0    0.18453  \n",
      "4     5       NaN   2       99         52  177.935120  964.0    0.18458  \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        RemoveNonCompatibleVariablesCB(vars=CSV_VARS, verbose=True),\n",
    "        SampleIDConversionCB(nonify=True)\n",
    "    ]\n",
    ")\n",
    "tfm()\n",
    "print(tfm.dfs['BIOTA'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Taxon Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "TAXON_MAP = {\n",
    "    'Taxonname': 'TAXONNAME',\n",
    "    'Taxonrank': 'TAXONRANK',\n",
    "    'TaxonDB': 'TAXONDB',\n",
    "    'TaxonDBID': 'TAXONDBID',\n",
    "    'TaxonDBURL': 'TAXONDBURL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_taxon_info_lut(maris_lut: str, key_names: dict = TAXON_MAP) -> dict:\n",
    "    \"Create lookup dictionary for taxon information from MARIS species lookup table.\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    # Select columns and rename them to standardized format\n",
    "    columns = ['species_id'] + list(key_names.keys())\n",
    "    df = species[columns].rename(columns=key_names)\n",
    "    return df.set_index('species_id').to_dict()\n",
    "\n",
    "lut_taxon = lambda: get_taxon_info_lut(maris_lut=species_lut_path(), key_names=TAXON_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AddTaxonInformationCB(Callback):\n",
    "    \"\"\"Add taxon information to BIOTA group based on species lookup table.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                fn_lut: Callable = lut_taxon,  # Function that returns taxon lookup dictionary\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Delegate tasks to add taxon information to the BIOTA group.\"\"\"\n",
    "        if not self.check_biota_group_exists(tfm):\n",
    "            return\n",
    "        \n",
    "        df = tfm.dfs['BIOTA']\n",
    "        if not self.check_species_column_exists(df):\n",
    "            return\n",
    "        \n",
    "        self.add_taxon_columns(df)\n",
    "\n",
    "    def check_biota_group_exists(self, tfm: Transformer) -> bool:\n",
    "        \"\"\"Check if 'BIOTA' group exists in the dataframes.\"\"\"\n",
    "        if 'BIOTA' not in tfm.dfs:\n",
    "            if self.verbose:\n",
    "                print(\"No BIOTA group found, skipping taxon information\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def check_species_column_exists(self, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Check if 'SPECIES' column exists in the BIOTA dataframe.\"\"\"\n",
    "        if 'SPECIES' not in df.columns:\n",
    "            if self.verbose:\n",
    "                print(\"No SPECIES column found in BIOTA dataframe, skipping taxon information\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def add_taxon_columns(self, df: pd.DataFrame):\n",
    "        \"\"\"Add taxon information columns to the BIOTA dataframe.\"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Add each column from the lookup table\n",
    "        for col in lut.keys():\n",
    "            df[col] = df['SPECIES'].map(lut[col]).fillna('Unknown')\n",
    "        \n",
    "        self.report_unmatched_species(df)\n",
    "\n",
    "    def report_unmatched_species(self, df: pd.DataFrame):\n",
    "        \"\"\"Report any species IDs not found in the lookup table.\"\"\"\n",
    "        unmatched = df[df['TAXONNAME'] == 'Unknown']['SPECIES'].unique()\n",
    "        if self.verbose and len(unmatched) > 0:\n",
    "            print(f\"Warning: Species IDs not found in lookup table: {', '.join(map(str, unmatched))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       0       31   \n",
       " 1      12.316667  54.283333        NaN  1348358400       0        4   \n",
       " 2      12.316667  54.283333        NaN  1348358400       0        9   \n",
       " 3      12.316667  54.283333        NaN  1348358400       0       33   \n",
       " 4      12.316667  54.283333        NaN  1348358400       1       31   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 16089  21.395000  61.241501        2.0  1652140800    4789       33   \n",
       " 16090  21.395000  61.241501        2.0  1652140800    4789        9   \n",
       " 16091  21.385000  61.343334        NaN  1663200000    4790        4   \n",
       " 16092  21.385000  61.343334        NaN  1663200000    4790       33   \n",
       " 16093  21.385000  61.343334        NaN  1663200000    4790       12   \n",
       " \n",
       "             VALUE  UNIT       UNC  DL  ...  SPECIES  BODY_PART       DRYWT  \\\n",
       " 0        0.010140     5       NaN   2  ...       99         52  174.934433   \n",
       " 1      135.300003     5  4.830210   1  ...       99         52  174.934433   \n",
       " 2        0.013980     5       NaN   2  ...       99         52  174.934433   \n",
       " 3        4.338000     5  0.150962   1  ...       99         52  174.934433   \n",
       " 4        0.009614     5       NaN   2  ...       99         52  177.935120   \n",
       " ...           ...   ...       ...  ..  ...      ...        ...         ...   \n",
       " 16089   13.700000     4  0.520600   1  ...       96         55         NaN   \n",
       " 16090    0.500000     4  0.045500   1  ...       96         55         NaN   \n",
       " 16091   50.700001     4  4.106700   1  ...      129          1         NaN   \n",
       " 16092    0.880000     4  0.140800   1  ...      129          1         NaN   \n",
       " 16093    6.600000     4  0.349800   1  ...      129          1         NaN   \n",
       " \n",
       "        WETWT  PERCENTWT          TAXONNAME TAXONRANK   TAXONDB TAXONDBID  \\\n",
       " 0      948.0    0.18453       Gadus morhua   species  Wikidata   Q199788   \n",
       " 1      948.0    0.18453       Gadus morhua   species  Wikidata   Q199788   \n",
       " 2      948.0    0.18453       Gadus morhua   species  Wikidata   Q199788   \n",
       " 3      948.0    0.18453       Gadus morhua   species  Wikidata   Q199788   \n",
       " 4      964.0    0.18458       Gadus morhua   species  Wikidata   Q199788   \n",
       " ...      ...        ...                ...       ...       ...       ...   \n",
       " 16089    NaN        NaN  Fucus vesiculosus   species  Wikidata   Q754755   \n",
       " 16090    NaN        NaN  Fucus vesiculosus   species  Wikidata   Q754755   \n",
       " 16091    NaN        NaN     Mytilus edulis   species  Wikidata    Q27855   \n",
       " 16092    NaN        NaN     Mytilus edulis   species  Wikidata    Q27855   \n",
       " 16093    NaN        NaN     Mytilus edulis   species  Wikidata    Q27855   \n",
       " \n",
       "                                   TAXONDBURL  \n",
       " 0      https://www.wikidata.org/wiki/Q199788  \n",
       " 1      https://www.wikidata.org/wiki/Q199788  \n",
       " 2      https://www.wikidata.org/wiki/Q199788  \n",
       " 3      https://www.wikidata.org/wiki/Q199788  \n",
       " 4      https://www.wikidata.org/wiki/Q199788  \n",
       " ...                                      ...  \n",
       " 16089  https://www.wikidata.org/wiki/Q754755  \n",
       " 16090  https://www.wikidata.org/wiki/Q754755  \n",
       " 16091   https://www.wikidata.org/wiki/Q27855  \n",
       " 16092   https://www.wikidata.org/wiki/Q27855  \n",
       " 16093   https://www.wikidata.org/wiki/Q27855  \n",
       " \n",
       " [16094 rows x 21 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  SMP_ID  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       0   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       1   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       2   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       3   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       4   \n",
       " ...          ...        ...        ...        ...         ...     ...   \n",
       " 21468  13.499833  54.600334        0.0       47.0  1686441600    9724   \n",
       " 21469  13.499833  54.600334       45.0       47.0  1686441600    9725   \n",
       " 21470  14.200833  54.600334        0.0       11.0  1686614400    9731   \n",
       " 21471  14.665500  54.600334        0.0       20.0  1686614400    9732   \n",
       " 21472  14.330000  54.600334        0.0       17.0  1686614400    9734   \n",
       " \n",
       "        NUCLIDE       VALUE  UNIT        UNC  DL  FILT  \n",
       " 0           33    5.300000     1   1.696000   1     0  \n",
       " 1           33   19.900000     1   3.980000   1     0  \n",
       " 2           33   25.500000     1   5.100000   1     0  \n",
       " 3           33   17.000000     1   4.930000   1     0  \n",
       " 4           33   22.200001     1   3.996000   1     0  \n",
       " ...        ...         ...   ...        ...  ..   ...  \n",
       " 21468        1  702.838074     1  51.276207   1     0  \n",
       " 21469        1  725.855713     1  52.686260   1     0  \n",
       " 21470        1  648.992920     1  48.154419   1     0  \n",
       " 21471        1  627.178406     1  46.245316   1     0  \n",
       " 21472        1  605.715088     1  45.691143   1     0  \n",
       " \n",
       " [21473 rows x 12 columns],\n",
       " 'SEDIMENT':              LON        LAT  TOT_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      27.799999  60.466667       25.0  1337904000       0       33   \n",
       " 1      27.799999  60.466667       25.0  1337904000       1       33   \n",
       " 2      27.799999  60.466667       25.0  1337904000       2       33   \n",
       " 3      27.799999  60.466667       25.0  1337904000       3       33   \n",
       " 4      27.799999  60.466667       25.0  1337904000       4       33   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 70444  15.537800  54.617832       62.0  1654646400   14121       67   \n",
       " 70445  15.537800  54.617832       62.0  1654646400   14121       77   \n",
       " 70446  15.537800  54.617832       62.0  1654646400   14122        4   \n",
       " 70447  15.537800  54.617832       62.0  1654646400   14122       33   \n",
       " 70448  15.537800  54.617832       62.0  1654646400   14122       77   \n",
       " \n",
       "              VALUE  UNIT         UNC  DL  SED_TYPE   TOP  BOTTOM  PERCENTWT  \n",
       " 0      1200.000000     3  240.000000   1         0  15.0    20.0        NaN  \n",
       " 1       250.000000     3   50.000000   1         0  20.0    25.0        NaN  \n",
       " 2       140.000000     3   29.400000   1         0  25.0    30.0        NaN  \n",
       " 3        79.000000     3   15.800000   1         0  30.0    35.0        NaN  \n",
       " 4        29.000000     3    6.960000   1         0  35.0    40.0        NaN  \n",
       " ...            ...   ...         ...  ..       ...   ...     ...        ...  \n",
       " 70444     0.044000     2    0.015312   1        10  15.0    17.0   0.257642  \n",
       " 70445     2.500000     2    0.185000   1        10  15.0    17.0   0.257642  \n",
       " 70446  5873.000000     2  164.444000   1        10  17.0    19.0   0.263965  \n",
       " 70447    21.200001     2    2.162400   1        10  17.0    19.0   0.263965  \n",
       " 70448     0.370000     2    0.048100   1        10  17.0    19.0   0.263965  \n",
       " \n",
       " [70449 rows x 14 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        AddTaxonInformationCB(\n",
    "            fn_lut=lut_taxon\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "# print(tfm.dfs['BIOTA'][['TAXONNAME','TAXONRANK','TAXONDB','TAXONDBID','TAXONDBURL']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2012-05-23\n",
      "1       2012-05-23\n",
      "2       2012-06-17\n",
      "3       2012-05-24\n",
      "4       2012-05-24\n",
      "           ...    \n",
      "21468   2023-06-11\n",
      "21469   2023-06-11\n",
      "21470   2023-06-13\n",
      "21471   2023-06-13\n",
      "21472   2023-06-13\n",
      "Name: TIME, Length: 21473, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        DecodeTimeCB(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(tfm.dfs['SEAWATER']['TIME'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sample Type ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        AddSampleTypeIdColumnCB(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "print(tfm.dfs['SEAWATER']['SAMPLE_TYPE'].unique())\n",
    "# print(tfm.dfs['BIOTA']['SAMPLE_TYPE'].unique())\n",
    "# print(tfm.dfs['SEDIMENT']['SAMPLE_TYPE'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Reference ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the `ref_id` (i.e., Zotero Archive Location). The `ZoteroArchiveLocationCB` performs a lookup of the Zotero Archive Location based on the `Zotero key` defined in the global attributes of the MARIS NetCDF file as `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26VMZZ2Q'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents.global_attrs['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AddZoteroArchiveLocationCB(Callback):\n",
    "    \"Fetch and append 'Loc. in Archive' from Zotero to DataFrame.\"\n",
    "    def __init__(self, attrs: str, cfg: dict):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \n",
    "        zotero_key = self.attrs['id']\n",
    "        item = ZoteroItem(zotero_key, self.cfg['zotero'])\n",
    "        if item.exist():\n",
    "            loc_in_archive = item.item['data']['archiveLocation'] \n",
    "            for grp, df in tfm.dfs.items():\n",
    "                df['REF_ID'] = int(loc_in_archive)\n",
    "        else:\n",
    "            print(f\"Warning: Zotero item {self.item_id} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        AddZoteroArchiveLocationCB(contents.global_attrs, cfg=cfg()),\n",
    "    ]\n",
    ")\n",
    "tfm()\n",
    "print(tfm.dfs['SEAWATER']['REF_ID'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remap encoded custom maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetCDF variables can store custom mappings as attributes, which provide a way to map between encoded values and their human-readable representations. The `RemapCustomMapsCB` callback handles this conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemapCustomMapsCB(Callback):\n",
    "    \"Remap encoded custom maps to decoded values.\"\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"Remap encoded custom maps to decoded values.\"\"\"\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            for var in tfm.dfs[grp].columns:\n",
    "                if var in tfm.custom_maps[grp]:\n",
    "                    if self.verbose:\n",
    "                        print(f\"Remapping {var} from {grp} group\")\n",
    "                    \n",
    "                    # Convert column to int type to ensure proper mapping\n",
    "                    tfm.dfs[grp][var] = tfm.dfs[grp][var].astype(int)\n",
    "                    \n",
    "                    # Create reverse mapping dictionary\n",
    "                    reverse_custom_map = {int(v): k for k, v in tfm.custom_maps[grp][var].items()}\n",
    "                    \n",
    "                    # Apply mapping\n",
    "                    tfm.dfs[grp][var] = tfm.dfs[grp][var].map(reverse_custom_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of remapped custom maps:\n",
      "BIOTA\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: SMP_ID, dtype: uint64\n",
      "SEAWATER\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: SMP_ID, dtype: uint64\n",
      "SEDIMENT\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: SMP_ID, dtype: uint64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        RemapCustomMapsCB(verbose=True),\n",
    "    ]\n",
    ")\n",
    "tfm()\n",
    "print('Example of remapped custom maps:')\n",
    "for grp in tfm.dfs:\n",
    "    print(grp)\n",
    "    print(tfm.dfs[grp]['SMP_ID'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remap to Open Refine specific mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "## FEEDBACK FOR NEXT VERSION \n",
    "\n",
    "[To be further clarified]\n",
    "\n",
    "The current approach of remapping to OR-specific mappings should be reconsidered. Considering that we already utilize MARISCO lookup tables in NetCDF for creating enums, it would be beneficial to extend their use to OpenRefine data formats as well. By doing so, we could eliminate the need for OpenRefine-specific mappings, streamlining the data transformation process. Lets review the lookup tables used to create the enums for NetCDF:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL enums: {'Not applicable': -1, 'Not available': 0, 'Detected value': 1, 'Detection limit': 2, 'Not detected': 3, 'Derived': 4}\n",
      "FILT enums: {'Not applicable': -1, 'Not available': 0, 'Yes': 1, 'No': 2}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "enums = Enums(lut_src_dir=lut_path())\n",
    "print(f'DL enums: {enums.types[\"DL\"]}')\n",
    "print(f'FILT enums: {enums.types[\"FILT\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the detection limit lookup table (LUT), as shown below, the values required for the OpenRefine CSV format are listed under the 'name' column, whereas the enums utilize the 'name_sanitized' column. \n",
    "\n",
    "Additionally, for the filtered LUT, also shown below, the values do not align consistently with the OpenRefine CSV format, which uses (`Y`, `N`, `NA`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dl_lut = pd.read_excel(detection_limit_lut_path())\n",
    "dl_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "filtered_lut = pd.read_excel(filtered_lut_path())\n",
    "filtered_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create OpenRefine specific mappings for the detection limit and filtered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "or_mappings={'DL':\n",
    "                {3:'ND',1:'=',2:'<'},\n",
    "            'FILT':\n",
    "                {0:'NA',1:'Y',2:'N'},\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RemapToORSpecificMappingsCB remaps the values of the detection limit and filtered data to the OpenRefine CSV format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemapToORSpecificMappingsCB(Callback):\n",
    "    \"Convert values using OR mappings if columns exist in dataframe.\"\n",
    "    def __init__(self, \n",
    "                or_mappings: Dict[str, Dict] = or_mappings,  # Dictionary of column mappings, \n",
    "                output_format: str = 'openrefine_csv',\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Apply OR mappings to all dataframes.\"\"\"\n",
    "        for group_name in tfm.dfs:\n",
    "            if self.verbose:\n",
    "                print(f\"\\nProcessing {group_name} group...\")\n",
    "            tfm.dfs[group_name] = self._apply_mappings(tfm.dfs[group_name])\n",
    "            \n",
    "    def _apply_mappings(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply OR mappings to columns that exist in the dataframe.\"\"\"\n",
    "        for col, mapping in self.or_mappings.items():\n",
    "            if col in df.columns:\n",
    "                if self.verbose:\n",
    "                    print(f\"    Mapping values for column: {col}\")\n",
    "                df[col] = df[col].map(mapping)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in BIOTA for columns ['DL']:\n",
      "DL: ['<' '=' nan]\n",
      "\n",
      "Unique values in SEAWATER for columns ['DL', 'FILT']:\n",
      "DL: ['=' '<' nan]\n",
      "FILT: ['NA' 'N' 'Y']\n",
      "\n",
      "Unique values in SEDIMENT for columns ['DL']:\n",
      "DL: ['=' '<' nan]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    data= contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        RemapToORSpecificMappingsCB(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "\n",
    "# Loop through each group in the 'dfs' dictionary\n",
    "for group_name, df in tfm.dfs.items():\n",
    "    # Check if the group dataframe contains any of the columns specified in or_mappings.keys()\n",
    "    relevant_columns = [col for col in or_mappings.keys() if col in df.columns]\n",
    "    if relevant_columns:\n",
    "        # Print the unique values from the relevant columns\n",
    "        print(f\"\\nUnique values in {group_name} for columns {relevant_columns}:\")\n",
    "        for col in relevant_columns:\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "    else:\n",
    "        print(f\"No relevant columns found in {group_name} based on or_mappings keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remap to CSV data type format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CSV_DTYPES` (defined in configs.ipynb) defines a state for each variable that contains a lookup table (i.e. enums). The state is either 'decoded' or 'encoded'. Lets review the variable states as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DL</th>\n",
       "      <th>FILT</th>\n",
       "      <th>COUNT_MET</th>\n",
       "      <th>SAMP_MET</th>\n",
       "      <th>PREP_MET</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>BODY_PART</th>\n",
       "      <th>SED_TYPE</th>\n",
       "      <th>LAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>decoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>decoded</td>\n",
       "      <td>decoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "      <td>encoded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AREA  NUCLIDE     UNIT       DL     FILT COUNT_MET SAMP_MET  \\\n",
       "state  decoded  encoded  encoded  decoded  decoded   encoded  encoded   \n",
       "\n",
       "      PREP_MET  SPECIES BODY_PART SED_TYPE      LAB  \n",
       "state  encoded  encoded   encoded  encoded  encoded  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "with pd.option_context('display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(pd.DataFrame.from_dict(CSV_DTYPES, orient='index').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AREA', 'BIO_GROUP', 'BODY_PART', 'COUNT_MET', 'DL', 'FILT', 'NUCLIDE', 'PREP_MET', 'SAMP_MET', 'SED_TYPE', 'SPECIES', 'UNIT', 'LAB'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "enums = Enums(lut_src_dir=lut_path())\n",
    "enums.types.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_excluded_enums(output_format: str = 'openrefine_csv') -> dict:\n",
    "    \"Get excluded enums based on output format.\"\n",
    "    return or_mappings if output_format == 'openrefine_csv' else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataFormatConversionCB(Callback):\n",
    "    \"\"\"\n",
    "    A callback to convert DataFrame enum values between encoded and decoded formats based on specified settings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dtypes: Dict,  # Dictionary defining data types and states for each lookup table\n",
    "                 excluded_mappings: Callable = get_excluded_enums,  # Dictionary of columns to exclude from conversion\n",
    "                 output_format: str = 'openrefine_csv',\n",
    "                 verbose: bool = False  # Flag for verbose output\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"\n",
    "        Apply the data format conversion to each DataFrame within the Transformer.\n",
    "        \"\"\"\n",
    "        self.load_enums()\n",
    "        \n",
    "        for group_name, df in tfm.dfs.items():\n",
    "            tfm.dfs[group_name] = self.process_dataframe(group_name, df)\n",
    "\n",
    "    def load_enums(self):\n",
    "        \"\"\"\n",
    "        Load enums from the lookup path.\n",
    "        \"\"\"\n",
    "        self.enums = Enums(lut_path())\n",
    "        if self.verbose:\n",
    "            print(f\"Loaded enums: {self.enums.types.keys()}\")\n",
    "\n",
    "    def process_dataframe(self, group_name: str, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Process each DataFrame to convert columns to the target state.\n",
    "        \"\"\"\n",
    "        for column in df.columns:\n",
    "            if column in self.dtypes and column not in self.excluded_mappings(self.output_format):\n",
    "                if self.dtypes[column]['state'] == 'decoded':\n",
    "                    if self.verbose:\n",
    "                        print(f\"Decoding column: {column}\")\n",
    "                    if column in self.enums.types:\n",
    "                        # Apply the mapping from encoded to decoded values\n",
    "                        df[column] = df[column].map(self.enums.types[column])\n",
    "                        if self.verbose:\n",
    "                            print(f\"Decoded column: {column}\")\n",
    "                    else:\n",
    "                        if self.verbose:\n",
    "                            print(f\"No enum mapping found for column: {column}, skipping decoding.\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing variables that are not compatible with vars provided. \n",
      "Removing BIO_GROUP from BIOTA dataset.\n",
      "Loaded enums: dict_keys(['AREA', 'BIO_GROUP', 'BODY_PART', 'COUNT_MET', 'DL', 'FILT', 'NUCLIDE', 'PREP_MET', 'SAMP_MET', 'SED_TYPE', 'SPECIES', 'UNIT', 'LAB'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       0       31   \n",
       " 1      12.316667  54.283333        NaN  1348358400       0        4   \n",
       " 2      12.316667  54.283333        NaN  1348358400       0        9   \n",
       " 3      12.316667  54.283333        NaN  1348358400       0       33   \n",
       " 4      12.316667  54.283333        NaN  1348358400       1       31   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 16089  21.395000  61.241501        2.0  1652140800    4789       33   \n",
       " 16090  21.395000  61.241501        2.0  1652140800    4789        9   \n",
       " 16091  21.385000  61.343334        NaN  1663200000    4790        4   \n",
       " 16092  21.385000  61.343334        NaN  1663200000    4790       33   \n",
       " 16093  21.385000  61.343334        NaN  1663200000    4790       12   \n",
       " \n",
       "             VALUE  UNIT       UNC  DL  SPECIES  BODY_PART       DRYWT  WETWT  \\\n",
       " 0        0.010140     5       NaN   2       99         52  174.934433  948.0   \n",
       " 1      135.300003     5  4.830210   1       99         52  174.934433  948.0   \n",
       " 2        0.013980     5       NaN   2       99         52  174.934433  948.0   \n",
       " 3        4.338000     5  0.150962   1       99         52  174.934433  948.0   \n",
       " 4        0.009614     5       NaN   2       99         52  177.935120  964.0   \n",
       " ...           ...   ...       ...  ..      ...        ...         ...    ...   \n",
       " 16089   13.700000     4  0.520600   1       96         55         NaN    NaN   \n",
       " 16090    0.500000     4  0.045500   1       96         55         NaN    NaN   \n",
       " 16091   50.700001     4  4.106700   1      129          1         NaN    NaN   \n",
       " 16092    0.880000     4  0.140800   1      129          1         NaN    NaN   \n",
       " 16093    6.600000     4  0.349800   1      129          1         NaN    NaN   \n",
       " \n",
       "        PERCENTWT  \n",
       " 0        0.18453  \n",
       " 1        0.18453  \n",
       " 2        0.18453  \n",
       " 3        0.18453  \n",
       " 4        0.18458  \n",
       " ...          ...  \n",
       " 16089        NaN  \n",
       " 16090        NaN  \n",
       " 16091        NaN  \n",
       " 16092        NaN  \n",
       " 16093        NaN  \n",
       " \n",
       " [16094 rows x 15 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  SMP_ID  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       0   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       1   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       2   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       3   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       4   \n",
       " ...          ...        ...        ...        ...         ...     ...   \n",
       " 21468  13.499833  54.600334        0.0       47.0  1686441600    9724   \n",
       " 21469  13.499833  54.600334       45.0       47.0  1686441600    9725   \n",
       " 21470  14.200833  54.600334        0.0       11.0  1686614400    9731   \n",
       " 21471  14.665500  54.600334        0.0       20.0  1686614400    9732   \n",
       " 21472  14.330000  54.600334        0.0       17.0  1686614400    9734   \n",
       " \n",
       "        NUCLIDE       VALUE  UNIT        UNC  DL  FILT  \n",
       " 0           33    5.300000     1   1.696000   1     0  \n",
       " 1           33   19.900000     1   3.980000   1     0  \n",
       " 2           33   25.500000     1   5.100000   1     0  \n",
       " 3           33   17.000000     1   4.930000   1     0  \n",
       " 4           33   22.200001     1   3.996000   1     0  \n",
       " ...        ...         ...   ...        ...  ..   ...  \n",
       " 21468        1  702.838074     1  51.276207   1     0  \n",
       " 21469        1  725.855713     1  52.686260   1     0  \n",
       " 21470        1  648.992920     1  48.154419   1     0  \n",
       " 21471        1  627.178406     1  46.245316   1     0  \n",
       " 21472        1  605.715088     1  45.691143   1     0  \n",
       " \n",
       " [21473 rows x 12 columns],\n",
       " 'SEDIMENT':              LON        LAT  TOT_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       " 0      27.799999  60.466667       25.0  1337904000       0       33   \n",
       " 1      27.799999  60.466667       25.0  1337904000       1       33   \n",
       " 2      27.799999  60.466667       25.0  1337904000       2       33   \n",
       " 3      27.799999  60.466667       25.0  1337904000       3       33   \n",
       " 4      27.799999  60.466667       25.0  1337904000       4       33   \n",
       " ...          ...        ...        ...         ...     ...      ...   \n",
       " 70444  15.537800  54.617832       62.0  1654646400   14121       67   \n",
       " 70445  15.537800  54.617832       62.0  1654646400   14121       77   \n",
       " 70446  15.537800  54.617832       62.0  1654646400   14122        4   \n",
       " 70447  15.537800  54.617832       62.0  1654646400   14122       33   \n",
       " 70448  15.537800  54.617832       62.0  1654646400   14122       77   \n",
       " \n",
       "              VALUE  UNIT         UNC  DL  SED_TYPE   TOP  BOTTOM  PERCENTWT  \n",
       " 0      1200.000000     3  240.000000   1         0  15.0    20.0        NaN  \n",
       " 1       250.000000     3   50.000000   1         0  20.0    25.0        NaN  \n",
       " 2       140.000000     3   29.400000   1         0  25.0    30.0        NaN  \n",
       " 3        79.000000     3   15.800000   1         0  30.0    35.0        NaN  \n",
       " 4        29.000000     3    6.960000   1         0  35.0    40.0        NaN  \n",
       " ...            ...   ...         ...  ..       ...   ...     ...        ...  \n",
       " 70444     0.044000     2    0.015312   1        10  15.0    17.0   0.257642  \n",
       " 70445     2.500000     2    0.185000   1        10  15.0    17.0   0.257642  \n",
       " 70446  5873.000000     2  164.444000   1        10  17.0    19.0   0.263965  \n",
       " 70447    21.200001     2    2.162400   1        10  17.0    19.0   0.263965  \n",
       " 70448     0.370000     2    0.048100   1        10  17.0    19.0   0.263965  \n",
       " \n",
       " [70449 rows x 14 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "tfm = Transformer(\n",
    "    contents.dfs,\n",
    "    cbs=[\n",
    "        RemoveNonCompatibleVariablesCB(vars=CSV_VARS, verbose=True),\n",
    "        DataFormatConversionCB(\n",
    "            dtypes=CSV_DTYPES,\n",
    "            excluded_mappings = get_excluded_enums,\n",
    "            output_format='openrefine_csv',\n",
    "            verbose=True\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Head of the transformed `SEAWATER` DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>FILT</th>\n",
       "      <th>SAMPLE_TYPE</th>\n",
       "      <th>REF_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.696</td>\n",
       "      <td>=</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.980</td>\n",
       "      <td>=</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.100</td>\n",
       "      <td>=</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.930</td>\n",
       "      <td>=</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>3.996</td>\n",
       "      <td>=</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LON        LAT  SMP_DEPTH  TOT_DEPTH       TIME  SMP_ID  NUCLIDE  \\\n",
       "0  29.333300  60.083302        0.0        NaN 2012-05-23       0       33   \n",
       "1  29.333300  60.083302       29.0        NaN 2012-05-23       1       33   \n",
       "2  23.150000  59.433300        0.0        NaN 2012-06-17       2       33   \n",
       "3  27.983299  60.250000        0.0        NaN 2012-05-24       3       33   \n",
       "4  27.983299  60.250000       39.0        NaN 2012-05-24       4       33   \n",
       "\n",
       "       VALUE  UNIT    UNC DL FILT  SAMPLE_TYPE  REF_ID  \n",
       "0   5.300000     1  1.696  =   NA            1     100  \n",
       "1  19.900000     1  3.980  =   NA            1     100  \n",
       "2  25.500000     1  5.100  =   NA            1     100  \n",
       "3  17.000000     1  4.930  =   NA            1     100  \n",
       "4  22.200001     1  3.996  =   NA            1     100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Head of the transformed `BIOTA` DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>...</th>\n",
       "      <th>DRYWT</th>\n",
       "      <th>WETWT</th>\n",
       "      <th>PERCENTWT</th>\n",
       "      <th>TAXONNAME</th>\n",
       "      <th>TAXONRANK</th>\n",
       "      <th>TAXONDB</th>\n",
       "      <th>TAXONDBID</th>\n",
       "      <th>TAXONDBURL</th>\n",
       "      <th>SAMPLE_TYPE</th>\n",
       "      <th>REF_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>...</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>species</td>\n",
       "      <td>Wikidata</td>\n",
       "      <td>Q199788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q199788</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>5</td>\n",
       "      <td>4.830210</td>\n",
       "      <td>=</td>\n",
       "      <td>...</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>species</td>\n",
       "      <td>Wikidata</td>\n",
       "      <td>Q199788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q199788</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>...</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>species</td>\n",
       "      <td>Wikidata</td>\n",
       "      <td>Q199788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q199788</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4.338000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.150962</td>\n",
       "      <td>=</td>\n",
       "      <td>...</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>species</td>\n",
       "      <td>Wikidata</td>\n",
       "      <td>Q199788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q199788</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>...</td>\n",
       "      <td>177.935120</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.18458</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>species</td>\n",
       "      <td>Wikidata</td>\n",
       "      <td>Q199788</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q199788</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LON        LAT  SMP_DEPTH       TIME  SMP_ID  NUCLIDE       VALUE  \\\n",
       "0  12.316667  54.283333        NaN 2012-09-23       0       31    0.010140   \n",
       "1  12.316667  54.283333        NaN 2012-09-23       0        4  135.300003   \n",
       "2  12.316667  54.283333        NaN 2012-09-23       0        9    0.013980   \n",
       "3  12.316667  54.283333        NaN 2012-09-23       0       33    4.338000   \n",
       "4  12.316667  54.283333        NaN 2012-09-23       1       31    0.009614   \n",
       "\n",
       "   UNIT       UNC DL  ...       DRYWT  WETWT  PERCENTWT     TAXONNAME  \\\n",
       "0     5       NaN  <  ...  174.934433  948.0    0.18453  Gadus morhua   \n",
       "1     5  4.830210  =  ...  174.934433  948.0    0.18453  Gadus morhua   \n",
       "2     5       NaN  <  ...  174.934433  948.0    0.18453  Gadus morhua   \n",
       "3     5  0.150962  =  ...  174.934433  948.0    0.18453  Gadus morhua   \n",
       "4     5       NaN  <  ...  177.935120  964.0    0.18458  Gadus morhua   \n",
       "\n",
       "   TAXONRANK   TAXONDB TAXONDBID                             TAXONDBURL  \\\n",
       "0    species  Wikidata   Q199788  https://www.wikidata.org/wiki/Q199788   \n",
       "1    species  Wikidata   Q199788  https://www.wikidata.org/wiki/Q199788   \n",
       "2    species  Wikidata   Q199788  https://www.wikidata.org/wiki/Q199788   \n",
       "3    species  Wikidata   Q199788  https://www.wikidata.org/wiki/Q199788   \n",
       "4    species  Wikidata   Q199788  https://www.wikidata.org/wiki/Q199788   \n",
       "\n",
       "  SAMPLE_TYPE REF_ID  \n",
       "0           2    100  \n",
       "1           2    100  \n",
       "2           2    100  \n",
       "3           2    100  \n",
       "4           2    100  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_in)\n",
    "output_format = 'openrefine_csv'\n",
    "tfm = Transformer(\n",
    "    data=contents.dfs,\n",
    "    custom_maps=contents.custom_maps,\n",
    "    cbs=[\n",
    "        ValidateEnumsCB(\n",
    "            contents = contents,\n",
    "            maris_enums=Enums(lut_src_dir=lut_path())\n",
    "        ),\n",
    "        RemoveNonCompatibleVariablesCB(vars=CSV_VARS),\n",
    "        SampleIDConversionCB(nonify=False),\n",
    "        RemapCustomMapsCB(),\n",
    "        RemapToORSpecificMappingsCB(output_format=output_format),\n",
    "        AddTaxonInformationCB(\n",
    "            fn_lut=lut_taxon\n",
    "        ),\n",
    "        DecodeTimeCB(),\n",
    "        AddSampleTypeIdColumnCB(),\n",
    "        AddZoteroArchiveLocationCB(contents.global_attrs, cfg=cfg()),\n",
    "        DataFormatConversionCB(\n",
    "            dtypes=CSV_DTYPES,\n",
    "            excluded_mappings = get_excluded_enums,\n",
    "            output_format=output_format,\n",
    "        ) \n",
    "        ]\n",
    ")\n",
    "tfm()\n",
    "for grp in ['SEAWATER', 'BIOTA']:\n",
    "    display(Markdown(f\"<b>Head of the transformed `{grp}` DataFrame:</b>\"))\n",
    "    with pd.option_context('display.max_rows', None):\n",
    "        display(tfm.dfs[grp].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decode(\n",
    "    fname_in: str, # Input file name\n",
    "    dest_out: str | None = None, # Output file name (optional)\n",
    "    output_format: str = 'openrefine_csv', # Output format\n",
    "    remap_vars: Dict[str, str] = CSV_VARS, # Mapping of OR vars to NC vars\n",
    "    remap_dtypes: Dict[str, str] = CSV_DTYPES, # Mapping of OR vars to NC dtypes\n",
    "    has_smp_id: bool = True, # If False, do not convert auto-generated `SMP_ID` values to `None`\n",
    "    verbose: bool = False, # If True, print verbose output\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Decode data from NetCDF.\"\n",
    "    valid_output_formats=['openrefine_csv', 'decoded_csv']\n",
    "    \n",
    "    if output_format not in valid_output_formats:\n",
    "        print (f'Invalid output format. Allowed formats: {valid_output_formats}')\n",
    "        return \n",
    "    \n",
    "    if output_format == 'decoded_csv':\n",
    "        remap_dtypes = {k: {'state': 'decoded'} for k in remap_dtypes.keys()}\n",
    "        \n",
    "    contents = ExtractNetcdfContents(fname_in)\n",
    "    tfm = Transformer(\n",
    "        data=contents.dfs,\n",
    "        custom_maps=contents.custom_maps,\n",
    "        cbs=[\n",
    "        ValidateEnumsCB(\n",
    "            contents = contents,\n",
    "            maris_enums=Enums(lut_src_dir=lut_path())\n",
    "        ),\n",
    "        RemoveNonCompatibleVariablesCB(vars=remap_vars),\n",
    "        SampleIDConversionCB(nonify=not has_smp_id),\n",
    "        RemapCustomMapsCB(),\n",
    "        RemapToORSpecificMappingsCB(output_format=output_format),\n",
    "        AddTaxonInformationCB(\n",
    "            fn_lut=lut_taxon\n",
    "        ),\n",
    "        DecodeTimeCB(),\n",
    "        AddSampleTypeIdColumnCB(),\n",
    "        AddZoteroArchiveLocationCB(contents.global_attrs, cfg=cfg()),\n",
    "        DataFormatConversionCB(\n",
    "            dtypes=remap_dtypes,\n",
    "            excluded_mappings = get_excluded_enums,\n",
    "            output_format=output_format\n",
    "        ) \n",
    "        ]\n",
    "    )    \n",
    "    \n",
    "    tfm()\n",
    "    decoder = NetCDFDecoder( \n",
    "                            dfs=tfm.dfs,\n",
    "                            fname_in=fname_in,  \n",
    "                            dest_out=dest_out,                           \n",
    "                            output_format='csv',\n",
    "                            # remap_vars=CSV_VARS,\n",
    "                            remap_vars=remap_vars,\n",
    "                            verbose=verbose\n",
    "                    )\n",
    "    decoder.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "decode(fname_in=fname, dest_out=fname.with_suffix(''), output_format='openrefine_csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serializers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Serializers\n",
    "> Various utilities to encode MARIS dataset as `NetCDF`, `csv`, ... formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7952355-3118-4362-86d4-c0331b5ef4e1",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NetCDFEncoder:\n",
    "    \"MARIS NetCDF encoder.\"\n",
    "    def __init__(self, \n",
    "                 dfs:dict[pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "                 src_fname:str, # File name and path to the MARIS CDL template\n",
    "                 dest_fname:str, # Name of output file to produce\n",
    "                 global_attrs:Dict, # Global attributes\n",
    "                 enums_xtra:Dict={}, # Enumeration types to overwrite\n",
    "                 verbose:bool=False, # Print currently written NetCDF group and variable names\n",
    "                 ):\n",
    "        store_attr()\n",
    "        self.enum_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seawater = pd.DataFrame({\n",
    "    'sample': [0, 1, 5], \n",
    "    'lon': [141, 142, 143], \n",
    "    'lat': [37.3, 38.3, 39.3], \n",
    "    'time': [1234, 1235, 1236], \n",
    "    'i131': [1, 1.5, 2],\n",
    "    'i131_dl': [0, 1, 2], \n",
    "    'i131_unit': [1, 1, 2],\n",
    "    'species': [134, 136, 137]\n",
    "    })\n",
    "\n",
    "df_biota = pd.DataFrame({\n",
    "    'sample': [0, 1], \n",
    "    'lon': [141, 142], \n",
    "    'lat': [37.3, 38.3], \n",
    "    'time': [1234, 1235], \n",
    "    'i131': [1, 1.5],\n",
    "    'i131_dl': [0, 1], \n",
    "    'i131_unit': [1, 1],\n",
    "    'species': [134, 136]\n",
    "    })\n",
    "\n",
    "dfs = {'seawater': df_seawater, 'biota': df_biota}\n",
    "attrs = {'id': '123', 'title': 'Test title', 'summary': 'Summary test'}\n",
    "src = './files/nc/template-test.nc'\n",
    "dest = './files/nc/encoding-test.nc'\n",
    "enums_xtra = {\n",
    "    'species_t': {'Aristeus antennatus': 134, 'Apostichopus': 136}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch \n",
    "def copy_global_attributes(self:NetCDFEncoder):\n",
    "    \"Update NetCDF template global attributes as specified by `global_attrs` argument.\"\n",
    "    self.dest.setncatts(self.src.__dict__)\n",
    "    for k, v in self.global_attrs.items(): self.dest.setncattr(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_dimensions(self:NetCDFEncoder):\n",
    "    for name, dimension in self.src.dimensions.items():\n",
    "        self.dest.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_groups(self:NetCDFEncoder):\n",
    "    for grp_name, df in self.dfs.items():\n",
    "        self.process_group(grp_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_group(self:NetCDFEncoder, group_name, df):\n",
    "    group_dest = self.dest.createGroup(group_name)\n",
    "    # Set the dimensions for each group\n",
    "    group_dest.createDimension(group_name, len(df.index))    \n",
    "    self.copy_variables(group_name, df, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variables(self:NetCDFEncoder, group_name, df, group_dest):\n",
    "    for var_name, var_src in self.src.groups[group_name].variables.items():\n",
    "        if var_name in df.reset_index().columns: \n",
    "            self.copy_variable(var_name, var_src, df, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40561907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variable(self:NetCDFEncoder, var_name, var_src, df, group_dest):\n",
    "    dtype_name = var_src.datatype.name\n",
    "    enums_src = self.src.enumtypes\n",
    "    if self.verbose: \n",
    "        print(80*'-')\n",
    "        print(f'Group: {group_dest.name}, Variable: {var_name}')\n",
    "    # If the type of the var is an enum (meaning present in the template src) then create it\n",
    "    if dtype_name in enums_src: self.copy_enum_type(dtype_name) \n",
    "    self._create_and_copy_variable(var_name, var_src, df, group_dest, dtype_name)\n",
    "    self.copy_variable_attributes(var_name, var_src, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93792604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _create_and_copy_variable(self:NetCDFEncoder, var_name, var_src, df, group_dest, dtype_name):\n",
    "    variable_type = self.enum_types.get(dtype_name, var_src.datatype)\n",
    "    # Use the group_dest dimensions\n",
    "    group_dest.createVariable(var_name, variable_type, group_dest.dimensions, compression='zlib', complevel=9)            \n",
    "    isNotEnum = type(variable_type) != netCDF4._netCDF4.EnumType\n",
    "    values = df[var_name].values\n",
    "    group_dest[var_name][:] = values if isNotEnum else self.sanitize_if_enum_and_nan(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3042eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def sanitize_if_enum_and_nan(self:NetCDFEncoder, values, fill_value=-1):\n",
    "    values[np.isnan(values)] = int(fill_value)\n",
    "    values = values.astype(int)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd48f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_enum_type(self:NetCDFEncoder, dtype_name):\n",
    "    # if enum type not already created\n",
    "    if dtype_name not in self.enum_types:\n",
    "        enum_info = self.src.enumtypes[dtype_name]\n",
    "        # If a subset of an enum is defined in enums_xtra (typically for the lengthy species_t)\n",
    "        if enum_info.name in self.enums_xtra:\n",
    "            # add \"not applicable\"\n",
    "            enum_info.enum_dict = self.enums_xtra[enum_info.name]\n",
    "            enum_info.enum_dict['Not applicable'] = -1 # TBD\n",
    "        self.enum_types[dtype_name] = self.dest.createEnumType(enum_info.dtype, \n",
    "                                                               enum_info.name, \n",
    "                                                               enum_info.enum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def copy_variable_attributes(self:NetCDFEncoder, var_name, var_src, group_dest):\n",
    "    group_dest[var_name].setncatts(var_src.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "@patch\n",
    "def cast_verbose_rf(self:NetCDFEncoder, \n",
    "                    df, \n",
    "                    col):\n",
    "    \"\"\"\n",
    "    Try to cast df column to numeric type:\n",
    "        - Silently coerce to nan if not possible\n",
    "        - But log when it failed\n",
    "    \"\"\"\n",
    "    n_before = sum(df.reset_index()[col].notna())\n",
    "    df_after = pd.to_numeric(df.reset_index()[col], errors='coerce', downcast=None)\n",
    "    n_after = sum(df_after.notna())\n",
    "    if n_before != n_after: print(f'Failed to convert type of {col} in {n_before - n_after} occurences')\n",
    "    return df_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def encode(self:NetCDFEncoder):\n",
    "    \"Encode MARIS NetCDF based on template and dataframes.\"\n",
    "    with Dataset(self.src_fname, format='NETCDF4') as self.src, Dataset(self.dest_fname, 'w', format='NETCDF4') as self.dest:\n",
    "        self.copy_global_attributes()\n",
    "        self.copy_dimensions()\n",
    "        self.process_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encoder = NetCDFEncoder(dfs, src_fname=src, dest_fname=dest, \n",
    "                        global_attrs=attrs, enums_xtra=enums_xtra, verbose=False)\n",
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b830407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that global attributes are copied\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    for k, v in {'id': '123', 'title': 'Test title', 'summary': 'Summary test'}.items():\n",
    "        fc.test_eq(getattr(nc, k), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2342f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that dimension is `sample` and unlimited\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    fc.test_eq('sample' in nc.dimensions, True)\n",
    "    fc.test_eq(nc.dimensions['sample'].isunlimited(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that groups are created\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    fc.test_eq(nc.groups.keys(), ['seawater', 'biota'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that groups are created\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    fc.test_eq(nc.groups.keys(), ['seawater', 'biota'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that correct variables are created in groups\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    fc.test_eq(nc['biota'].variables.keys(), \n",
    "               ['sample', 'lon', 'lat', 'time', 'species', 'i131', 'i131_dl', 'i131_unit'])\n",
    "    \n",
    "    fc.test_eq(nc['seawater'].variables.keys(), \n",
    "               ['sample', 'lon', 'lat', 'time', 'i131', 'i131_dl', 'i131_unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('sample', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'sample', size = 0)])\n",
      "dict_items([('biota', <class 'netCDF4._netCDF4.Dimension'>: name = 'biota', size = 2)])\n",
      "dict_items([('seawater', <class 'netCDF4._netCDF4.Dimension'>: name = 'seawater', size = 3)])\n"
     ]
    }
   ],
   "source": [
    "# Test that correct variables are created in groups\n",
    "with Dataset(dest, 'r', format='NETCDF4') as nc:\n",
    "    print(nc.dimensions.items())\n",
    "    print(nc['biota'].dimensions.items())\n",
    "    print(nc['seawater'].dimensions.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68835f6b-89be-4878-b623-8b44ea74e66e",
   "metadata": {},
   "source": [
    "## OpenRefine CSV encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aefb99-c34b-487f-905b-b94b57adff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class OpenRefineCsvEncoder:\n",
    "    \"OpenRefine CSV from NetCDF.\"\n",
    "    def __init__(self, \n",
    "                 dfs:dict[pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "                 dest_fname:str, # Name of output file to produce\n",
    "                 ref_id = -1, # ref_id to include \n",
    "                 verbose:bool=False, # Print \n",
    "                 ):\n",
    "        store_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9915154-0bd7-4699-97f2-1a15fab07a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_groups_to_csv(self:OpenRefineCsvEncoder):\n",
    "    for grp_name, df in self.dfs.items():\n",
    "        # include ref_id\n",
    "        if self.ref_id != -1:\n",
    "            df['ref_id'] = self.ref_id\n",
    "        self.process_group_to_csv(grp_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605b3cb-1915-4c4a-b7cd-5fbcb6e6ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def process_group_to_csv(self:OpenRefineCsvEncoder, group_name, df):\n",
    "    filename, file_extension=os.path.splitext(self.dest_fname)\n",
    "    path = filename + '_' + group_name + file_extension\n",
    "    df.to_csv( path_or_buf= path, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091683e-d4aa-47b6-acd3-296a3be8c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def encode(self:OpenRefineCsvEncoder):\n",
    "    \"Encode OpenRefine CSV based on dataframes from NetCDF.\"\n",
    "    # Include ref_id\n",
    "    \n",
    "    # Process to csv\n",
    "    self.process_groups_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c2653-bc84-4b0a-87bb-a187d3ac807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dest = '../files/csv/encoding-test.csv'\n",
    "\n",
    "encoder = OpenRefineCsvEncoder(dfs,  dest_fname=dest)\n",
    "encoder.encode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

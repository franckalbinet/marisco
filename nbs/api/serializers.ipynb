{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serializers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Serializers\n",
    "> Various utilities to encode MARIS dataset as `NetCDF`, `csv`, ... formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27051f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from netCDF4 import Dataset\n",
    "from cftime import num2date\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable\n",
    "import re\n",
    "import unittest\n",
    "\n",
    "from fastcore.basics import patch, store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8631fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cast_verbose(df, col):\n",
    "    \"\"\"\n",
    "    Try to cast df column to numeric type:\n",
    "        - Silently coerce to nan if not possible\n",
    "        - But log when it failed\n",
    "    \"\"\"\n",
    "    n_before = sum(df.reset_index()[col].notna())\n",
    "    df_after = pd.to_numeric(df.reset_index()[col],\n",
    "                                    errors='coerce', downcast=None)\n",
    "    n_after = sum(df_after.notna())\n",
    "    if n_before != n_after: \n",
    "        print(f'Failed to convert type of {col} in {n_before - n_after} occurences')\n",
    "    \n",
    "    return df_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import netCDF4 as nc\n",
    "\n",
    "# # Open the source NetCDF file\n",
    "# src_path = 'path/to/source.nc'\n",
    "# src_nc = nc.Dataset(src_path, 'r')\n",
    "\n",
    "# # Retrieve the enumeration type from the source file\n",
    "# enum_type_name = 'your_enum_type_name'  # Replace with your actual enum type name\n",
    "# enum_type = src_nc.cmptypes[enum_type_name]\n",
    "\n",
    "# # Open/Create the destination NetCDF file\n",
    "# dst_path = 'path/to/destination.nc'\n",
    "# dst_nc = nc.Dataset(dst_path, 'w')\n",
    "\n",
    "# # Create the enumeration type in the destination file\n",
    "# dst_nc.createEnumType(enum_type.base_datatype, enum_type_name, enum_type.enum_dict)\n",
    "\n",
    "# # Copy other relevant data if necessary\n",
    "# # ...\n",
    "\n",
    "# # Close both files\n",
    "# src_nc.close()\n",
    "# dst_nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa76c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when I create, copy type, update enum_dict\n",
    "\n",
    "# df.species -> list of ids\n",
    "# or just get the full list and just update the enum\n",
    "# by just filtering by values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51762d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_netcdf(\n",
    "    dfs:dict[pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "    src_fname:str, # Input MARIS template NetCDF path and name\n",
    "    # fname_output:str, # Name of output file to produce\n",
    "    dest_fname:str, # Output NetCDF path and name to produce\n",
    "    global_attrs:Dict, # Global attributes\n",
    "    units_fn:Callable, # (group, variable) -> unit look up function\n",
    "):\n",
    "    \"Encode MARIS dataset (provided as Pandas DataFrame) to NetCDF file\"\n",
    "    with Dataset(src_fname, format='NETCDF4') as src, Dataset(dest_fname, 'w', format='NETCDF4') as dst:\n",
    "        # copy global attributes all at once via dictionary\n",
    "        dst.setncatts(src.__dict__)\n",
    "        dst.setncatts(global_attrs) \n",
    "        \n",
    "        # copy dimensions\n",
    "        for name, dimension in src.dimensions.items():\n",
    "            dst.createDimension(\n",
    "                name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "        # copy groups\n",
    "        for grp_name, df in dfs.items():\n",
    "            # TBD: asserting group name\n",
    "            grp_dest = dst.createGroup(grp_name)\n",
    "        \n",
    "            n_before = 0\n",
    "            n_after = 0\n",
    "            \n",
    "            # copy all variables of interest and fill them\n",
    "            for name_var_src, var_src in src.groups[grp_name].variables.items():\n",
    "                # Only if source variable is in destination\n",
    "                if name_var_src in df.reset_index().columns:\n",
    "                    # x = grp_dest.createVariable(name_var_src, var_src.datatype, var_src.dimensions,\n",
    "                    grp_dest.createVariable(name_var_src, var_src.datatype, var_src.dimensions,\n",
    "                                            compression='zlib', complevel=9)\n",
    "                        \n",
    "                    df_sanitized = cast_verbose(df, name_var_src)\n",
    "                    grp_dest[name_var_src][:] = df_sanitized.values\n",
    "                    \n",
    "                    # copy variable attributes all at once via dictionary\n",
    "                    grp_dest[name_var_src].setncatts(src.groups[grp_name][name_var_src].__dict__)\n",
    "                    if (hasattr(src.groups[grp_name][name_var_src], 'units') and\n",
    "                        src.groups[grp_name][name_var_src].units == '_to_be_filled_in_'):\n",
    "                        grp_dest[name_var_src].units = units_fn(grp_name, name_var_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NetCDFConverter:\n",
    "    def __init__(self, \n",
    "                 src_fname:str, # File name and path to the MARIS CDL template\n",
    "                 dest_fname:str, # Name of output file to produce\n",
    "                 global_attrs:Dict, # Global attributes\n",
    "                 units_fn:Callable, # (group, variable) -> unit look up function\n",
    "                 ):\n",
    "        store_attr()\n",
    "        # self.src = None\n",
    "        # self.dest = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_netcdf(self:NetCDFConverter,\n",
    "              dfs:dict[pd.DataFrame], # Dataframes dict to encode with grp name as key {'sediment': df_sed, ...}\n",
    "              ):\n",
    "    with (Dataset(self.fname_cdl, format='NETCDF4') as self.src, \n",
    "          Dataset(self.fname_output, '  w', format='NETCDF4') as self.dest):\n",
    "      self.copy_global_attributes()\n",
    "      self.copy_dimensions()\n",
    "      self.process_groups(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d74bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch \n",
    "def copy_global_attributes(self:NetCDFConverter):\n",
    "    self.dest_nc.setncatts(self.src.__dict__)\n",
    "    self.dest.setncatts(self.global_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fname = './files/nc/maris-template.nc'\n",
    "src_fname = './files/nc/maris-template.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converter = NetCDFConverter(src_fname, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33694383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NetCDFConverter\n",
    "# call copy_gloabel_attributes\n",
    "# check that global_attrs have been copied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_dimensions(self:NetCDFConverter):\n",
    "    for name, dimension in self.src.dimensions.items():\n",
    "        self.dest.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_groups(self:NetCDFConverter, dfs):\n",
    "    for grp_name, df in dfs.items():\n",
    "        self.process_group(grp_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_group(self:NetCDFConverter, group_name, df):\n",
    "    group_dest = self.dest.createGroup(group_name)\n",
    "    self.copy_variables(group_name, df, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variables(self:NetCDFConverter, group_name, df, group_dest):\n",
    "    for var_name, var_src in self.src.groups[group_name].variables.items():\n",
    "        if var_name in df.reset_index().columns:\n",
    "            self.copy_variable(var_name, var_src, df, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40561907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variable(self:NetCDFConverter, var_name, var_src, df, group_dest):\n",
    "    group_dest.createVariable(var_name, var_src.datatype, var_src.dimensions,\n",
    "                              compression='zlib', complevel=9)\n",
    "    df_sanitized = self.cast_verbose_rf(df, var_name)\n",
    "    group_dest[var_name][:] = df_sanitized.values\n",
    "    self.copy_variable_attributes(var_name, var_src, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variable_attributes(self:NetCDFConverter, var_name, var_src, group_dest):\n",
    "    group_dest[var_name].setncatts(var_src.__dict__)\n",
    "    group_name = group_dest.path.split('/')[-1]\n",
    "    if (hasattr(var_src, 'units') and var_src.units == '_to_be_filled_in_'):\n",
    "        group_dest[var_name].units = self.units_fn(group_name, var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def cast_verbose_rf(self:NetCDFConverter, \n",
    "                    df, \n",
    "                    col):\n",
    "    \"\"\"\n",
    "    Try to cast df column to numeric type:\n",
    "        - Silently coerce to nan if not possible\n",
    "        - But log when it failed\n",
    "    \"\"\"\n",
    "    n_before = sum(df.reset_index()[col].notna())\n",
    "    df_after = pd.to_numeric(df.reset_index()[col],\n",
    "                                    errors='coerce', downcast=None)\n",
    "    n_after = sum(df_after.notna())\n",
    "    if n_before != n_after: \n",
    "        print(f'Failed to convert type of {col} in {n_before - n_after} occurences')\n",
    "    \n",
    "    return df_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = NetCDFConverter(fname_cdl, fname_output, global_attrs, units_fn)\n",
    "# converter.to_netcdf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6d5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_csv(\n",
    "#     fname_nc:str,\n",
    "#     fname_output:str):\n",
    "#     \"Convert MARIS NetCDF filer to `.csv`\"\n",
    "#     fname_nc = './files/nc/tepco-sediments.nc'\n",
    "#     data_dict = {}\n",
    "#     with Dataset(fname_nc) as nc:\n",
    "#         # global attrs\n",
    "#         for name in nc.ncattrs():\n",
    "#             pass\n",
    "#             #print(name)\n",
    "#         # list of vars   \n",
    "#         for name in nc.variables:\n",
    "#             #print(name)\n",
    "#             variable = nc[name]\n",
    "#             data_dict[name] = variable[:]\n",
    "#     return pd.DataFrame(data_dict)\n",
    "\n",
    "# #df = to_csv('./files/nc/tepco-sediments.nc', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname_nc = '../../_data/output/helcom.nc'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea1b9dc6",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. all smptype together\n",
    "2. unit for actvity but sometimes dl or uncertainty in different units..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f866731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# data = {}\n",
    "# units = {}\n",
    "# with Dataset(fname_nc) as nc:\n",
    "#     #print(nc.ncattrs())\n",
    "#     print(nc.groups.keys())\n",
    "#     sw_grp = nc.groups['seawater']\n",
    "#     for var in sw_grp.variables:\n",
    "#         if hasattr(sw_grp.variables[var], 'units'):\n",
    "#             units[var] = sw_grp.variables[var].units\n",
    "#         data[var] = sw_grp.variables[var][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df = pd.DataFrame(data); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "format_time = lambda x: num2date(x, units=\"seconds since 1970-01-01 00:00:00.0\")\n",
    "df['time'] = df['time'].apply(format_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df_nuc = df.set_index(['sample', 'lon', 'lat', 'depth', 'time']); df_nuc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675504b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df_nuc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# def get_multi_index(colnames):\n",
    "#     arr = []\n",
    "#     for colname in colnames:\n",
    "#         if re.search('_unc', colname):\n",
    "#             arr.append((re.split('_unc', colname)[0], 'uncertainty'))\n",
    "#         elif re.search('_dl', colname):\n",
    "#             arr.append((re.split('_dl', colname)[0], 'detection'))\n",
    "#         else:\n",
    "#             arr.append((colname, 'activity'))\n",
    "#     return pd.MultiIndex.from_tuples(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# get_multi_index(df_nuc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df_nuc.columns = get_multi_index(df_nuc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19014e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df_sw = df_nuc.stack(level=0).reset_index().rename(columns={'level_5': 'nucl'}); df_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c84f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# df_sw['unit'] = df_sw['nucl'].replace(units); df_sw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "> Various utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from math import modf\n",
    "from netCDF4 import Dataset\n",
    "from fastcore.test import test_eq\n",
    "import fastcore.all as fc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import requests\n",
    "from shapely import MultiPoint\n",
    "import jellyfish as jf\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import List, Dict, Callable, Tuple, Optional, Union\n",
    "\n",
    "from marisco.configs import cache_path\n",
    "\n",
    "\n",
    "# from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15839e",
   "metadata": {},
   "source": [
    "We define below useful constants throughout the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TBD: move to configs\n",
    "NA = 'Not available'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddde356",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d7a4c",
   "metadata": {},
   "source": [
    "Abstracting some common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31569370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_unique_across_dfs(dfs: Dict[str, pd.DataFrame],  # Dictionary of dataframes\n",
    "                          col_name: str='NUCLIDE', # Column name to extract unique values from\n",
    "                          as_df: bool=False, # Return a DataFrame of unique values\n",
    "                          include_nchars: bool=False # Add a column with the number of characters in the value\n",
    "                          ) -> List[str]: # Returns a list of unique column values across dataframes\n",
    "    \"Get a list of unique column values across dataframes.\"\n",
    "    unique_values = list(set().union(*(df[col_name].unique() for df in dfs.values() if col_name in df.columns)))\n",
    "    if not as_df:\n",
    "        return unique_values\n",
    "    else:\n",
    "        df_uniques = pd.DataFrame(unique_values, columns=['value']).reset_index()\n",
    "        if include_nchars: df_uniques['n_chars'] = df_uniques['value'].str.len()\n",
    "        return df_uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c8487",
   "metadata": {},
   "source": [
    "Example of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609599ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_test = {'SEAWATER': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134_137_tot', 'cs134_137_tot']}),\n",
    "            'BIOTA': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134', 'cs134_137_tot']}),\n",
    "            'SEDIMENT': pd.DataFrame({'NUCLIDE': ['cs134_137_tot', 'cs134_137_tot', 'cs134_137_tot']})}\n",
    "\n",
    "fc.test_eq(set(get_unique_across_dfs(dfs_test, col_name='NUCLIDE')), \n",
    "           set(['cs134', 'cs137', 'cs134_137_tot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c8edd",
   "metadata": {},
   "source": [
    "What if the column name is not in one of the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24161871",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_test = {'SEAWATER': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134_137_tot', 'cs134_137_tot']}),\n",
    "            'BIOTA': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134', 'cs134_137_tot']}),\n",
    "            'SEDIMENT': pd.DataFrame({'NONUCLIDE': ['cs134_137_tot', 'cs134_137_tot', 'cs134_137_tot']})}\n",
    "\n",
    "fc.test_eq(set(get_unique_across_dfs(dfs_test, col_name='NUCLIDE')), \n",
    "           set(['cs134', 'cs137', 'cs134_137_tot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e26bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "      <th>n_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cs134</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cs134_137_tot</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cs137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          value  n_chars\n",
       "0      0          cs134        5\n",
       "1      1  cs134_137_tot       13\n",
       "2      2          cs137        5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_across_dfs(dfs_test, col_name='NUCLIDE', as_df=True, include_nchars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Remapper():\n",
    "    \"Remap a data provider lookup table to a MARIS lookup table using fuzzy matching.\"\n",
    "    def __init__(self,\n",
    "                 provider_lut_df: pd.DataFrame, # Data provider lookup table to be remapped\n",
    "                 maris_lut_fn: Union[Callable, pd.DataFrame], # MARIS lookup table or function returning the path\n",
    "                 maris_col_id: str, # MARIS lookup table column name for the id\n",
    "                 maris_col_name: str, # MARIS lookup table column name for the name\n",
    "                 provider_col_to_match: str, # Data provider lookup table column name for the name to match\n",
    "                 provider_col_key: str, # Data provider lookup table column name for the key\n",
    "                 fname_cache: str # Cache file name\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "        self.cache_file = cache_path() / fname_cache\n",
    "        # Check if maris_lut is a callable function or already a DataFrame\n",
    "        if callable(maris_lut_fn):\n",
    "            self.maris_lut = maris_lut_fn()\n",
    "        else:\n",
    "            self.maris_lut = maris_lut_fn\n",
    "        self.lut = {}\n",
    "\n",
    "    def generate_lookup_table(self, \n",
    "                              fixes={}, # Lookup table fixes\n",
    "                              as_df=True, # Whether to return a DataFrame\n",
    "                              overwrite=True):\n",
    "        \"Generate a lookup table from a data provider lookup table to a MARIS lookup table using fuzzy matching.\"\n",
    "        self.fixes = fixes\n",
    "        self.as_df = as_df\n",
    "        if overwrite or not self.cache_file.exists():\n",
    "            self._create_lookup_table()\n",
    "            fc.save_pickle(self.cache_file, self.lut)\n",
    "        else:\n",
    "            self.lut = fc.load_pickle(self.cache_file)\n",
    "\n",
    "        return self._format_output()\n",
    "\n",
    "    def _create_lookup_table(self):\n",
    "        df = self.provider_lut_df\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"): \n",
    "            self._process_row(row)\n",
    "\n",
    "    def _process_row(self, row):\n",
    "        value_to_match = row[self.provider_col_to_match]\n",
    "        if isinstance(value_to_match, str):  # Only process if value is a string\n",
    "            # If value is in fixes, use the fixed value\n",
    "            name_to_match = self.fixes.get(value_to_match, value_to_match)\n",
    "            result = match_maris_lut(self.maris_lut, name_to_match, self.maris_col_id, self.maris_col_name).iloc[0]\n",
    "            match = Match(result[self.maris_col_id], result[self.maris_col_name], \n",
    "                          value_to_match, result['score'])\n",
    "            self.lut[row[self.provider_col_key]] = match\n",
    "        else:\n",
    "            # Handle non-string values (e.g., NaN)\n",
    "            self.lut[row[self.provider_col_key]] = Match(-1, \"Unknown\", value_to_match, 0)\n",
    "            \n",
    "    def select_match(self, match_score_threshold:int=1, verbose:bool=False):\n",
    "        if verbose:\n",
    "            matched_len= len([v for v in self.lut.values() if v.match_score < match_score_threshold])\n",
    "            print(f\"{matched_len} entries matched the criteria, while {len(self.lut) - matched_len} entries had a match score of {match_score_threshold} or higher.\")\n",
    "        \n",
    "        self.lut = {k: v for k, v in self.lut.items() if v.match_score >= match_score_threshold}\n",
    "        return self._format_output()\n",
    "\n",
    "    def _format_output(self):\n",
    "        if not self.as_df: return self.lut\n",
    "        df_lut = pd.DataFrame.from_dict(self.lut, orient='index', \n",
    "                                        columns=['matched_maris_name', 'source_name', 'match_score'])\n",
    "        df_lut.index.name = 'source_key'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df069c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# TBD: Setting unique universal id\n",
    "# import hashlib\n",
    "# combined_str = \"32.123_-180.435_2022-01-01T00:00:00.000\"\n",
    "# hash_object = hashlib.sha256(combined_str.encode())\n",
    "# unique_id = hash_object.hexdigest(); unique_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2b0c493",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TBD: Assess if still needed\n",
    "def has_valid_varname(\n",
    "    var_names: List[str], # variable names\n",
    "    cdl_path: str, # Path to MARIS CDL file (point of truth)\n",
    "    group: Optional[str] = None, # Check if the variable names is contained in the group\n",
    "):\n",
    "    \"Check that proposed variable names are in MARIS CDL\"\n",
    "    has_valid = True\n",
    "    with Dataset(cdl_path) as nc:\n",
    "        cdl_vars={}\n",
    "        all_vars=[]\n",
    "        # get variable names in CDL \n",
    "        for grp in nc.groups.values():\n",
    "            # Create a list of var for each group\n",
    "            vars = list(grp.variables.keys())\n",
    "            cdl_vars[grp.name] = vars\n",
    "            all_vars.extend(vars)\n",
    "        \n",
    "    if group != None:\n",
    "        allowed_vars= cdl_vars[group]\n",
    "    else: \n",
    "        # get unique \n",
    "        allowed_vars = list(set(all_vars))\n",
    "        \n",
    "    for name in var_names:\n",
    "        if name not in allowed_vars:\n",
    "            has_valid = False\n",
    "            if group != None:\n",
    "                print(f'\"{name}\" variable name not found in group \"{group}\" of MARIS CDL')\n",
    "            else:\n",
    "                print(f'\"{name}\" variable name not found in MARIS CDL')\n",
    "    return has_valid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARNAMES = ['lat', 'lon']\n",
    "# test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARNAMES = ['ba140_invalid', 'ba140_dl']\n",
    "# test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1777c",
   "metadata": {},
   "source": [
    "## Geoprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_bbox(df,\n",
    "             coord_cols: Tuple[str, str] = ('LON', 'LAT')\n",
    "            ):\n",
    "    \"Get the bounding box of a DataFrame.\"\n",
    "    x, y = coord_cols        \n",
    "    arr = [(row[x], row[y]) for _, row in df.iterrows()]\n",
    "    return MultiPoint(arr).envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'LON': np.linspace(-10, 5, 20), 'LAT':  np.linspace(40, 50, 20)})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e607512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10.0, 40.0, 5.0, 50.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get `lon_min`, `lon_max`, `lat_min`, `lat_max`\n",
    "bbox.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761fbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON ((-10 40, 5 40, 5 50, -10 50, -10 40))'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And its Well-Know Text representation\n",
    "bbox.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec103c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If unique (lon, lat)\n",
    "df = pd.DataFrame({'LON': [0, 0], 'LAT':  [1, 1]})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52704a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53eebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def ddmm_to_dd(\n",
    "    ddmmmm: float # Coordinates in degrees/minutes decimal format\n",
    "    ) -> float: # Coordinates in degrees decimal format\n",
    "    # Convert degrees/minutes decimal to degrees decimal.\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    mins = mins * 100\n",
    "    return round(int(degs) + (mins / 60), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.test_close(ddmm_to_dd(45.34), 45.566667)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe93f8e",
   "metadata": {},
   "source": [
    "## Downloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8da64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def download_files_in_folder(\n",
    "    owner: str, # GitHub owner\n",
    "    repo: str, # GitHub repository\n",
    "    src_dir: str, # Source directory\n",
    "    dest_dir: str # Destination directory\n",
    "    ):\n",
    "    \"Make a GET request to the GitHub API to get the contents of the folder.\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{src_dir}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contents = response.json()\n",
    "\n",
    "        # Iterate over the files and download them\n",
    "        for item in contents:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                fname = item[\"name\"]\n",
    "                download_file(owner, repo, src_dir, dest_dir, fname)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def download_file(owner, repo, src_dir, dest_dir, fname):\n",
    "    # Make a GET request to the GitHub API to get the raw file contents\n",
    "    url = f\"https://raw.githubusercontent.com/{owner}/{repo}/master/{src_dir}/{fname}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the file locally\n",
    "        with open(Path(dest_dir) / fname, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{fname} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32414dcf",
   "metadata": {},
   "source": [
    "## WorRMS\n",
    "The [World Register of Marine Species (WorMS)](https://www.marinespecies.org) is an authoritative classification and catalogue of marine names. It provides a REST API (among others) allowing to \"fuzzy\" match any species name you might encounter in marine data sources names againt their own database. There are several types of matches as described [here](https://www.marinespecies.org/tutorial_taxonmatch.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def match_worms(\n",
    "    name: str # Name of species to look up in WoRMS\n",
    "    ):\n",
    "    \"Lookup `name` in WoRMS (fuzzy match).\"\n",
    "    url = 'https://www.marinespecies.org/rest/AphiaRecordsByMatchNames'\n",
    "    params = {\n",
    "        'scientificnames[]': [name],\n",
    "        'marine_only': 'true'\n",
    "    }\n",
    "    headers = {\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2ed2b",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096a3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'AphiaID': 107083,\n",
       "   'url': 'https://www.marinespecies.org/aphia.php?p=taxdetails&id=107083',\n",
       "   'scientificname': 'Aristeus antennatus',\n",
       "   'authority': '(Risso, 1816)',\n",
       "   'status': 'accepted',\n",
       "   'unacceptreason': None,\n",
       "   'taxonRankID': 220,\n",
       "   'rank': 'Species',\n",
       "   'valid_AphiaID': 107083,\n",
       "   'valid_name': 'Aristeus antennatus',\n",
       "   'valid_authority': '(Risso, 1816)',\n",
       "   'parentNameUsageID': 106807,\n",
       "   'kingdom': 'Animalia',\n",
       "   'phylum': 'Arthropoda',\n",
       "   'class': 'Malacostraca',\n",
       "   'order': 'Decapoda',\n",
       "   'family': 'Aristeidae',\n",
       "   'genus': 'Aristeus',\n",
       "   'citation': 'DecaNet eds. (2024). DecaNet. Aristeus antennatus (Risso, 1816). Accessed through: World Register of Marine Species at: https://www.marinespecies.org/aphia.php?p=taxdetails&id=107083 on 2024-12-17',\n",
       "   'lsid': 'urn:lsid:marinespecies.org:taxname:107083',\n",
       "   'isMarine': 1,\n",
       "   'isBrackish': 0,\n",
       "   'isFreshwater': 0,\n",
       "   'isTerrestrial': 0,\n",
       "   'isExtinct': 0,\n",
       "   'match_type': 'exact',\n",
       "   'modified': '2022-08-24T09:48:14.813Z'}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "match_worms('Aristeus antennatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941575e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# open dbo_species\n",
    "#from tqdm import tqdm\n",
    "#results = []\n",
    "#species = pd.read_excel(species_lut_path()).species\n",
    "#for i, name in tqdm(enumerate(species), total=len(species)):\n",
    "#    if i > 1:\n",
    "#        worms_match = match_worms(name)\n",
    "#        if worms_match != -1:\n",
    "#            results.append(worms_match[0][0])\n",
    "# np.unique(np.array([result['phylum'] for result in results]))\n",
    "#len(maris_worms_matches)\n",
    "#maris_worms_matches = fc.load_pickle('./files/pkl/maris-worms-matches.pkl')\n",
    "#np.unique(np.array([result['phylum'] for result in maris_worms_matches]))\n",
    "#len([result for result in maris_worms_matches if result['status'] == 'accepted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70ed97",
   "metadata": {},
   "source": [
    "## Fuzzy matching for MARIS Lookup Tables\n",
    "Using https://jamesturk.github.io/jellyfish fuzzy matching distance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@dataclass\n",
    "class Match:\n",
    "    \"Match between a data provider name and a MARIS lookup table.\"\n",
    "    matched_id: int\n",
    "    matched_maris_name: str\n",
    "    source_name: str\n",
    "    match_score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def match_maris_lut(\n",
    "    lut: Union[str, pd.DataFrame, Path], # Either str, Path or DataFrame\n",
    "    data_provider_name: str, # Name of data provider nomenclature item to look up \n",
    "    maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "    maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "    dist_fn: Callable = jf.levenshtein_distance, # Distance function\n",
    "    nresults: int = 10 # Maximum number of results to return\n",
    ") -> pd.DataFrame:\n",
    "    \"Fuzzy matching data provider and MARIS lookup tables (e.g biota species, sediments, ...).\"\n",
    "    if isinstance(lut, str) or isinstance(lut, Path):\n",
    "        df = pd.read_excel(lut)  # Load the LUT if a path is provided\n",
    "    elif isinstance(lut, pd.DataFrame):\n",
    "        df = lut  # Use the DataFrame directly if provided\n",
    "    else:\n",
    "        raise ValueError(\"lut must be either a file path or a DataFrame\")\n",
    "\n",
    "    df = df.dropna(subset=[maris_name])\n",
    "    df = df.astype({maris_id: 'int'})\n",
    "    df['score'] = df[maris_name].str.lower().apply(lambda x: dist_fn(data_provider_name.lower(), x))\n",
    "    df = df.sort_values(by='score', ascending=True)[:nresults]\n",
    "    return df[[maris_id, maris_name, 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617587e",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"PLANKTON\" with `dbo_species_cleaned.xlsx` MARIS biota species lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282aa570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>species</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>280</td>\n",
       "      <td>Plankton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>695</td>\n",
       "      <td>Zooplankton</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>632</td>\n",
       "      <td>Palaemon</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>696</td>\n",
       "      <td>Phytoplankton</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>811</td>\n",
       "      <td>Chanos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>159</td>\n",
       "      <td>Neuston</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>233</td>\n",
       "      <td>Penaeus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1457</td>\n",
       "      <td>Lamnidae</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1437</td>\n",
       "      <td>Labrus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1526</td>\n",
       "      <td>Favites</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species_id        species  score\n",
       "281          280       Plankton      0\n",
       "696          695    Zooplankton      3\n",
       "633          632       Palaemon      4\n",
       "697          696  Phytoplankton      5\n",
       "812          811         Chanos      5\n",
       "160          159        Neuston      5\n",
       "234          233        Penaeus      6\n",
       "1458        1457       Lamnidae      6\n",
       "1438        1437         Labrus      6\n",
       "1527        1526        Favites      6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_species_cleaned.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='PLANKTON', \n",
    "                maris_id='species_id', maris_name='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6c3b0",
   "metadata": {},
   "source": [
    "Below, we demonstrate matching the laboratory name \"Central Mining Institute, Poland\" with the MARIS lab lookup table from `dbo_lab.xlsx`. This example utilizes the `lab` and `country` columns. Note that in this instance, `df_lut` is passed directly as the `lut` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751b366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_country</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Central Mining Institute_Poland</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>202</td>\n",
       "      <td>Polytechnic Institute_Romania</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>281</td>\n",
       "      <td>Norwegian Polar Institute_Norway</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>112</td>\n",
       "      <td>Nuclear Research Institute_Vietnam</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>245</td>\n",
       "      <td>Paul Scherrer Institute_Switzerland</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>135</td>\n",
       "      <td>Nuclear Energy Board_Ireland</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>474</td>\n",
       "      <td>Kobe University_Japan</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>432</td>\n",
       "      <td>Qatar University_Qatar</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>173</td>\n",
       "      <td>Interfaculty Reactor Institute_Netherlands</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>176</td>\n",
       "      <td>RIKILT_Netherlands</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lab_id                                 lab_country  score\n",
       "6         5             Central Mining Institute_Poland      2\n",
       "203     202               Polytechnic Institute_Romania     18\n",
       "282     281            Norwegian Polar Institute_Norway     21\n",
       "113     112          Nuclear Research Institute_Vietnam     22\n",
       "246     245         Paul Scherrer Institute_Switzerland     22\n",
       "136     135                Nuclear Energy Board_Ireland     23\n",
       "471     474                       Kobe University_Japan     23\n",
       "429     432                      Qatar University_Qatar     23\n",
       "174     173  Interfaculty Reactor Institute_Netherlands     23\n",
       "177     176                          RIKILT_Netherlands     23"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_lab.xlsx'\n",
    "df_lut=pd.read_excel(lut_fname)\n",
    "df_lut['lab_country'] = df_lut['lab'] + '_' + df_lut['country']\n",
    "\n",
    "match_maris_lut(lut=df_lut, data_provider_name='Central Mining Institute, Poland', \n",
    "                maris_id='lab_id', maris_name='lab_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753034ae",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"GLACIAL\" with dbo_sedtype.xlsx MARIS sediment lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4bc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sedtype_id</th>\n",
       "      <th>sedtype</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>Glacial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Clay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>50</td>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Marsh</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Sand</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>Silt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>Sludge</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>Soft</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51</td>\n",
       "      <td>Soft clay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sedtype_id       sedtype  score\n",
       "26          25       Glacial      0\n",
       "3            2        Gravel      4\n",
       "2            1          Clay      5\n",
       "51          50  Glacial clay      5\n",
       "4            3         Marsh      6\n",
       "7            6          Sand      6\n",
       "13          12          Silt      6\n",
       "15          14        Sludge      6\n",
       "27          26          Soft      7\n",
       "52          51     Soft clay      7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_sedtype.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='GLACIAL', \n",
    "                maris_id='sedtype_id', maris_name='sedtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa12ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuclide_id</th>\n",
       "      <th>nc_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>cs137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>cs134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>cs127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>102</td>\n",
       "      <td>cs136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>112</td>\n",
       "      <td>sb127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>114</td>\n",
       "      <td>ce139</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>sb125</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>pm147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>i131</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>113</td>\n",
       "      <td>ba133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nuclide_id nc_name  score\n",
       "31           33   cs137      1\n",
       "30           31   cs134      2\n",
       "29           30   cs127      2\n",
       "99          102   cs136      2\n",
       "109         112   sb127      3\n",
       "111         114   ce139      3\n",
       "25           24   sb125      4\n",
       "36           38   pm147      4\n",
       "28           29    i131      4\n",
       "110         113   ba133      4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_nuclide.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='CS-137', \n",
    "                maris_id='nuclide_id', maris_name='nc_name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2ef1cc9",
   "metadata": {},
   "source": [
    "## Downloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def download_files_in_folder(\n",
    "    owner: str, # GitHub owner\n",
    "    repo: str, # GitHub repository\n",
    "    src_dir: str, # Source directory\n",
    "    dest_dir: str # Destination directory\n",
    "    ):\n",
    "    \"Make a GET request to the GitHub API to get the contents of the folder\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{src_dir}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contents = response.json()\n",
    "\n",
    "        # Iterate over the files and download them\n",
    "        for item in contents:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                fname = item[\"name\"]\n",
    "                download_file(owner, repo, src_dir, dest_dir, fname)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def download_file(owner, repo, src_dir, dest_dir, fname):\n",
    "    # Make a GET request to the GitHub API to get the raw file contents\n",
    "    url = f\"https://raw.githubusercontent.com/{owner}/{repo}/master/{src_dir}/{fname}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the file locally\n",
    "        with open(Path(dest_dir) / fname, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{fname} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d865892",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16144ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def test_dfs(\n",
    "    dfs1: Dict[str, pd.DataFrame], # First dictionary of DataFrames to compare \n",
    "    dfs2: Dict[str, pd.DataFrame] # Second dictionary of DataFrames to compare\n",
    "    ) -> None: # It raises an `AssertionError` if the DataFrames are not equal\n",
    "    \"Compare two dictionaries of DataFrames for equality (also ensuring that columns are in the same order).\"\n",
    "    for grp in dfs1.keys():\n",
    "        df1, df2 = (df.sort_index() for df in (dfs1[grp], dfs2[grp]))\n",
    "        fc.test_eq(df1, df2.reindex(columns=df1.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4aeb2",
   "metadata": {},
   "source": [
    "## NetCDF Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be18ab",
   "metadata": {},
   "source": [
    "NetCDF to a dictionary of Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def nc_to_dfs(\n",
    "    fname: str # Path to NetCDF file\n",
    "    ) -> dict: # Dictionary with group names as keys and pandas DataFrames as values\n",
    "    \"Convert a NetCDF (with groups) file to a dictionary of dataframes.\"\n",
    "    dfs = {}\n",
    "    \n",
    "    with Dataset(fname, 'r') as nc:\n",
    "        # Process each group in the NetCDF file\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            \n",
    "            # Get all variables in the group\n",
    "            data = {}\n",
    "            for var_name in group.variables:\n",
    "                # Skip dimension variables (like 'id')\n",
    "                if var_name not in group.dimensions:\n",
    "                    data[var_name] = group.variables[var_name][:]\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Convert time from seconds since epoch if present\n",
    "            if 'time' in df.columns:\n",
    "                df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "                \n",
    "            dfs[group_name.upper()] = df\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94087f",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group: SEAWATER\n",
      "shape: (21477, 49)\n",
      "   sample         lon    lat                time  h3  h3_dl  mn54  mn54_dl  \\\n",
      "0       0  141.029999  37.32 2011-03-21 23:15:00 NaN    NaN   NaN      NaN   \n",
      "1       1  141.029999  37.32 2011-03-22 14:28:00 NaN    NaN   NaN      NaN   \n",
      "2       2  141.029999  37.32 2011-03-23 13:51:00 NaN    NaN   NaN      NaN   \n",
      "3       3  141.029999  37.32 2011-03-24 09:30:00 NaN    NaN   NaN      NaN   \n",
      "4       4  141.029999  37.32 2011-03-25 10:00:00 NaN    NaN   NaN      NaN   \n",
      "\n",
      "   co58  co58_dl  ...  te132  te132_dl   i132  i132_dl  cs136  cs136_dl  \\\n",
      "0   5.7      7.6  ...    NaN       NaN  160.0     44.0    6.7       4.7   \n",
      "1   NaN     15.0  ...    NaN       NaN    NaN     88.0    NaN       7.8   \n",
      "2   NaN      NaN  ...    NaN       NaN  200.0     58.0    NaN       NaN   \n",
      "3   NaN      NaN  ...    NaN       NaN  120.0     88.0   68.0      49.0   \n",
      "4   NaN      NaN  ...   13.0       7.4   58.0     22.0    4.4       3.2   \n",
      "\n",
      "   tbeta  tbeta_dl  talpha  talpha_dl  \n",
      "0    NaN       NaN     NaN        NaN  \n",
      "1    NaN       NaN     NaN        NaN  \n",
      "2    NaN       NaN     NaN        NaN  \n",
      "3    NaN       NaN     NaN        NaN  \n",
      "4    NaN       NaN     NaN        NaN  \n",
      "\n",
      "[5 rows x 49 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/tepco.nc')\n",
    "\n",
    "dfs = nc_to_dfs(fname)\n",
    "\n",
    "for grp, df in dfs.items():\n",
    "    print('group:', grp)\n",
    "    print(f'shape: {df.shape}')\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3fcd8",
   "metadata": {},
   "source": [
    "Return properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bc5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_properties(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve general properties of a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing file properties such as size, format, and dimensions.\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    \n",
    "    file = Path(file_path)\n",
    "    \n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return properties\n",
    "\n",
    "    # Get file size\n",
    "    properties['file_size_bytes'] = file.stat().st_size\n",
    "    \n",
    "    # Open the NetCDF file\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Get file format\n",
    "        properties['file_format'] = nc.file_format\n",
    "\n",
    "        # Get groups\n",
    "        properties['groups'] = list(nc.groups.keys())\n",
    "        \n",
    "        # Get global attributes\n",
    "        properties['global_attributes'] = {attr: nc.getncattr(attr) for attr in nc.ncattrs()}\n",
    "    \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e4c0c",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02791a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 864768\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: 0.0\n",
      "  geospatial_vertical_max: 437.0\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error ( % ) to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA., Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Lookup FILT value in dataframe using the lookup table., Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "properties = get_netcdf_properties(fname)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2cb702",
   "metadata": {},
   "source": [
    "Return group properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eabf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_group_properties(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve properties of each group in a NetCDF file, including dimension sizes.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing properties of each group such as variables, dimensions with sizes, and attributes.\n",
    "    \"\"\"\n",
    "    group_properties = {}\n",
    "\n",
    "    file = Path(file_path)\n",
    "\n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return group_properties\n",
    "\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Iterate over each group in the NetCDF file\n",
    "        for group_name, group in nc.groups.items():\n",
    "            # Get dimensions with their sizes\n",
    "            dimensions = {dim_name: len(dim) for dim_name, dim in group.dimensions.items()}\n",
    "            \n",
    "            group_info = {\n",
    "                'variables': list(group.variables.keys()),\n",
    "                'dimensions': dimensions,\n",
    "                'attributes': {attr: group.getncattr(attr) for attr in group.ncattrs()}\n",
    "            }\n",
    "            group_properties[group_name] = group_info\n",
    "\n",
    "    return group_properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d76c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota:\n",
      "  variables: ['lon', 'lat', 'smp_depth', 'time', 'nuclide', 'value', 'unit', 'dl', 'bio_group', 'species', 'body_part', 'drywt', 'wetwt']\n",
      "  dimensions: {'id': 14873}\n",
      "  attributes: {}\n",
      "seawater:\n",
      "  variables: ['lon', 'lat', 'smp_depth', 'tot_depth', 'time', 'nuclide', 'value', 'unit', 'dl', 'filt']\n",
      "  dimensions: {'id': 20242}\n",
      "  attributes: {}\n",
      "sediment:\n",
      "  variables: ['lon', 'lat', 'tot_depth', 'time', 'area', 'nuclide', 'value', 'unit', 'dl', 'sed_type', 'top', 'bottom']\n",
      "  dimensions: {'id': 63868}\n",
      "  attributes: {}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "properties = get_netcdf_group_properties(fname)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4f9a6",
   "metadata": {},
   "source": [
    "Return variable properties of the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_netcdf_variable_properties(file_path: str, as_df: bool = False) -> dict | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve properties of variables in each group of a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file\n",
    "    as_df (bool): If True, returns a pandas DataFrame; if False, returns nested dictionary\n",
    "\n",
    "    Returns:\n",
    "    Union[dict, pd.DataFrame]: Properties of variables either as nested dictionary or DataFrame\n",
    "    \"\"\"\n",
    "    var_properties = {}\n",
    "    \n",
    "    file = Path(file_path)\n",
    "    if not file.exists():\n",
    "        print(f'File not found: {file_path}')\n",
    "        return var_properties\n",
    "\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        for group_name, group in nc.groups.items():\n",
    "            group_vars = {}\n",
    "            for var_name, var in group.variables.items():\n",
    "                var_info = {\n",
    "                    'group': group_name,\n",
    "                    'variable': var_name,\n",
    "                    'data_type': var.dtype.str,\n",
    "                    'dimensions_id': str(var.dimensions),\n",
    "                    'dimensions_size': str(var.shape),\n",
    "                }\n",
    "                # Add variable attributes\n",
    "                for attr in var.ncattrs():\n",
    "                    var_info[f'attr_{attr}'] = str(getattr(var, attr))\n",
    "                    \n",
    "                group_vars[var_name] = var_info\n",
    "            var_properties[group_name] = group_vars\n",
    "\n",
    "    if not as_df:\n",
    "        return var_properties\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for group_name, group_vars in var_properties.items():\n",
    "        for var_name, var_info in group_vars.items():\n",
    "            rows.append(var_info)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Reorder columns to put key information first\n",
    "    first_cols = ['group', 'variable', 'dimensions_id', 'dimensions_size']\n",
    "    other_cols = [col for col in df.columns if col not in first_cols]\n",
    "    df = df[first_cols + other_cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d8d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>...</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>lon</td>\n",
       "      <td>lat</td>\n",
       "      <td>smp_depth</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>bio_group</td>\n",
       "      <td>species</td>\n",
       "      <td>...</td>\n",
       "      <td>tot_depth</td>\n",
       "      <td>time</td>\n",
       "      <td>area</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>sed_type</td>\n",
       "      <td>top</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_id</th>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>...</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_size</th>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>...</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_long_name</th>\n",
       "      <td>Measurement longitude</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Sample depth below seal level</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Biota group</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>Total depth below seal level</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Marine area/region id</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Sediment type</td>\n",
       "      <td>Top depth of sediment layer</td>\n",
       "      <td>Bottom depth of sediment layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_standard_name</th>\n",
       "      <td>longitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>sample_depth_below_sea_floor</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>biota_group_tbd</td>\n",
       "      <td>species</td>\n",
       "      <td>...</td>\n",
       "      <td>total_depth_below_sea_floor</td>\n",
       "      <td>time</td>\n",
       "      <td>area_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>sediment_type_tbd</td>\n",
       "      <td>top_depth_of_sediment_layer_tbd</td>\n",
       "      <td>bottom_depth_of_sediment_layer_tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_units</th>\n",
       "      <td>degrees_east</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>m</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_origin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_abbreviation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_calendar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                     1   \\\n",
       "group                               biota                 biota   \n",
       "variable                              lon                   lat   \n",
       "dimensions_id                     ('id',)               ('id',)   \n",
       "dimensions_size                  (14873,)              (14873,)   \n",
       "data_type                             <f4                   <f4   \n",
       "attr_long_name      Measurement longitude  Measurement latitude   \n",
       "attr_standard_name              longitude              latitude   \n",
       "attr_units                   degrees_east         degrees_north   \n",
       "attr_axis                             NaN                   NaN   \n",
       "attr_time_origin                      NaN                   NaN   \n",
       "attr_time_zone                        NaN                   NaN   \n",
       "attr_abbreviation                     NaN                   NaN   \n",
       "attr_calendar                         NaN                   NaN   \n",
       "\n",
       "                                               2   \\\n",
       "group                                       biota   \n",
       "variable                                smp_depth   \n",
       "dimensions_id                             ('id',)   \n",
       "dimensions_size                          (14873,)   \n",
       "data_type                                     <f4   \n",
       "attr_long_name      Sample depth below seal level   \n",
       "attr_standard_name   sample_depth_below_sea_floor   \n",
       "attr_units                                      m   \n",
       "attr_axis                                       Z   \n",
       "attr_time_origin                              NaN   \n",
       "attr_time_zone                                NaN   \n",
       "attr_abbreviation                             NaN   \n",
       "attr_calendar                                 NaN   \n",
       "\n",
       "                                                     3         4         5   \\\n",
       "group                                             biota     biota     biota   \n",
       "variable                                           time   nuclide     value   \n",
       "dimensions_id                                   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                                (14873,)  (14873,)  (14873,)   \n",
       "data_type                                           <u8       <i8       <f4   \n",
       "attr_long_name                      Time of measurement   Nuclide  Activity   \n",
       "attr_standard_name                                 time   nuclide  activity   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0       NaN       NaN   \n",
       "attr_axis                                             T       NaN       NaN   \n",
       "attr_time_origin                    1970-01-01 00:00:00       NaN       NaN   \n",
       "attr_time_zone                                      UTC       NaN       NaN   \n",
       "attr_abbreviation                             Date/Time       NaN       NaN   \n",
       "attr_calendar                                 gregorian       NaN       NaN   \n",
       "\n",
       "                          6                7                8         9   ...  \\\n",
       "group                  biota            biota            biota     biota  ...   \n",
       "variable                unit               dl        bio_group   species  ...   \n",
       "dimensions_id        ('id',)          ('id',)          ('id',)   ('id',)  ...   \n",
       "dimensions_size     (14873,)         (14873,)         (14873,)  (14873,)  ...   \n",
       "data_type                <i8              <i8              <i8       <i8  ...   \n",
       "attr_long_name          Unit  Detection limit      Biota group   Species  ...   \n",
       "attr_standard_name      unit  detection_limit  biota_group_tbd   species  ...   \n",
       "attr_units               NaN              NaN              NaN       NaN  ...   \n",
       "attr_axis                NaN              NaN              NaN       NaN  ...   \n",
       "attr_time_origin         NaN              NaN              NaN       NaN  ...   \n",
       "attr_time_zone           NaN              NaN              NaN       NaN  ...   \n",
       "attr_abbreviation        NaN              NaN              NaN       NaN  ...   \n",
       "attr_calendar            NaN              NaN              NaN       NaN  ...   \n",
       "\n",
       "                                              25  \\\n",
       "group                                   sediment   \n",
       "variable                               tot_depth   \n",
       "dimensions_id                            ('id',)   \n",
       "dimensions_size                         (63868,)   \n",
       "data_type                                    <f4   \n",
       "attr_long_name      Total depth below seal level   \n",
       "attr_standard_name   total_depth_below_sea_floor   \n",
       "attr_units                                     m   \n",
       "attr_axis                                      Z   \n",
       "attr_time_origin                             NaN   \n",
       "attr_time_zone                               NaN   \n",
       "attr_abbreviation                            NaN   \n",
       "attr_calendar                                NaN   \n",
       "\n",
       "                                                     26  \\\n",
       "group                                          sediment   \n",
       "variable                                           time   \n",
       "dimensions_id                                   ('id',)   \n",
       "dimensions_size                                (63868,)   \n",
       "data_type                                           <u8   \n",
       "attr_long_name                      Time of measurement   \n",
       "attr_standard_name                                 time   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0   \n",
       "attr_axis                                             T   \n",
       "attr_time_origin                    1970-01-01 00:00:00   \n",
       "attr_time_zone                                      UTC   \n",
       "attr_abbreviation                             Date/Time   \n",
       "attr_calendar                                 gregorian   \n",
       "\n",
       "                                       27        28        29        30  \\\n",
       "group                            sediment  sediment  sediment  sediment   \n",
       "variable                             area   nuclide     value      unit   \n",
       "dimensions_id                     ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                  (63868,)  (63868,)  (63868,)  (63868,)   \n",
       "data_type                             <i8       <i8       <f4       <i8   \n",
       "attr_long_name      Marine area/region id   Nuclide  Activity      Unit   \n",
       "attr_standard_name                area_id   nuclide  activity      unit   \n",
       "attr_units                            NaN       NaN       NaN       NaN   \n",
       "attr_axis                             NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                      NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                        NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                     NaN       NaN       NaN       NaN   \n",
       "attr_calendar                         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 31                 32  \\\n",
       "group                      sediment           sediment   \n",
       "variable                         dl           sed_type   \n",
       "dimensions_id               ('id',)            ('id',)   \n",
       "dimensions_size            (63868,)           (63868,)   \n",
       "data_type                       <i8                <i8   \n",
       "attr_long_name      Detection limit      Sediment type   \n",
       "attr_standard_name  detection_limit  sediment_type_tbd   \n",
       "attr_units                      NaN                NaN   \n",
       "attr_axis                       NaN                NaN   \n",
       "attr_time_origin                NaN                NaN   \n",
       "attr_time_zone                  NaN                NaN   \n",
       "attr_abbreviation               NaN                NaN   \n",
       "attr_calendar                   NaN                NaN   \n",
       "\n",
       "                                                 33  \\\n",
       "group                                      sediment   \n",
       "variable                                        top   \n",
       "dimensions_id                               ('id',)   \n",
       "dimensions_size                            (63868,)   \n",
       "data_type                                       <f4   \n",
       "attr_long_name          Top depth of sediment layer   \n",
       "attr_standard_name  top_depth_of_sediment_layer_tbd   \n",
       "attr_units                                      NaN   \n",
       "attr_axis                                       NaN   \n",
       "attr_time_origin                                NaN   \n",
       "attr_time_zone                                  NaN   \n",
       "attr_abbreviation                               NaN   \n",
       "attr_calendar                                   NaN   \n",
       "\n",
       "                                                    34  \n",
       "group                                         sediment  \n",
       "variable                                        bottom  \n",
       "dimensions_id                                  ('id',)  \n",
       "dimensions_size                               (63868,)  \n",
       "data_type                                          <f4  \n",
       "attr_long_name          Bottom depth of sediment layer  \n",
       "attr_standard_name  bottom_depth_of_sediment_layer_tbd  \n",
       "attr_units                                         NaN  \n",
       "attr_axis                                          NaN  \n",
       "attr_time_origin                                   NaN  \n",
       "attr_time_zone                                     NaN  \n",
       "attr_abbreviation                                  NaN  \n",
       "attr_calendar                                      NaN  \n",
       "\n",
       "[13 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../files/nc/encoding-test.nc')\n",
    "# fname = Path('../../_data/output/dump/100-HELCOM-MORS-2018.nc')\n",
    "#fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "\n",
    "get_netcdf_variable_properties(fname, as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04198b4e",
   "metadata": {},
   "source": [
    "Return the enum dictionary for a variable in a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_enum_dict(file_path: str, var_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get the enum dictionary for a variable in a NetCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the NetCDF file\n",
    "    var_name (str): Name of the variable to get enum for\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary mapping enum names to values, or empty dict if not found\n",
    "    \"\"\"\n",
    "    with Dataset(file_path, 'r') as nc:\n",
    "        # Look for the variable in all groups\n",
    "        enum_dict = {}\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            if var_name in group.variables:\n",
    "                var = group.variables[var_name]\n",
    "                if hasattr(var.datatype, 'enum_dict'):\n",
    "                    nc_enum_dict = var.datatype.enum_dict       \n",
    "                    # Store group info and enum dict\n",
    "                    enum_dict[group_name] = {\n",
    "                        'variable': var_name,\n",
    "                        'enum_dict': nc_enum_dict\n",
    "                    }\n",
    "                    \n",
    "        return enum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biota': {'variable': 'nuclide',\n",
       "  'enum_dict': {'NOT APPLICABLE': -1,\n",
       "   'NOT AVAILABLE': 0,\n",
       "   'h3': 1,\n",
       "   'be7': 2,\n",
       "   'c14': 3,\n",
       "   'k40': 4,\n",
       "   'cr51': 5,\n",
       "   'mn54': 6,\n",
       "   'co57': 7,\n",
       "   'co58': 8,\n",
       "   'co60': 9,\n",
       "   'zn65': 10,\n",
       "   'sr89': 11,\n",
       "   'sr90': 12,\n",
       "   'zr95': 13,\n",
       "   'nb95': 14,\n",
       "   'tc99': 15,\n",
       "   'ru103': 16,\n",
       "   'ru106': 17,\n",
       "   'rh106': 18,\n",
       "   'ag106m': 19,\n",
       "   'ag108': 20,\n",
       "   'ag108m': 21,\n",
       "   'ag110m': 22,\n",
       "   'sb124': 23,\n",
       "   'sb125': 24,\n",
       "   'te129m': 25,\n",
       "   'i129': 28,\n",
       "   'i131': 29,\n",
       "   'cs127': 30,\n",
       "   'cs134': 31,\n",
       "   'cs137': 33,\n",
       "   'ba140': 34,\n",
       "   'la140': 35,\n",
       "   'ce141': 36,\n",
       "   'ce144': 37,\n",
       "   'pm147': 38,\n",
       "   'eu154': 39,\n",
       "   'eu155': 40,\n",
       "   'pb210': 41,\n",
       "   'pb212': 42,\n",
       "   'pb214': 43,\n",
       "   'bi207': 44,\n",
       "   'bi211': 45,\n",
       "   'bi214': 46,\n",
       "   'po210': 47,\n",
       "   'rn220': 48,\n",
       "   'rn222': 49,\n",
       "   'ra223': 50,\n",
       "   'ra224': 51,\n",
       "   'ra225': 52,\n",
       "   'ra226': 53,\n",
       "   'ra228': 54,\n",
       "   'ac228': 55,\n",
       "   'th227': 56,\n",
       "   'th228': 57,\n",
       "   'th232': 59,\n",
       "   'th234': 60,\n",
       "   'pa234': 61,\n",
       "   'u234': 62,\n",
       "   'u235': 63,\n",
       "   'u238': 64,\n",
       "   'np237': 65,\n",
       "   'np239': 66,\n",
       "   'pu238': 67,\n",
       "   'pu239': 68,\n",
       "   'pu240': 69,\n",
       "   'pu241': 70,\n",
       "   'am240': 71,\n",
       "   'am241': 72,\n",
       "   'cm242': 73,\n",
       "   'cm243': 74,\n",
       "   'cm244': 75,\n",
       "   'cs134_137_tot': 76,\n",
       "   'pu239_240_tot': 77,\n",
       "   'pu239_240_iii_iv_tot': 78,\n",
       "   'pu239_240_v_vi_tot': 79,\n",
       "   'cm243_244_tot': 80,\n",
       "   'pu238_pu239_240_tot_ratio': 81,\n",
       "   'am241_pu239_240_tot_ratio': 82,\n",
       "   'cs137_134_ratio': 83,\n",
       "   'cd109': 84,\n",
       "   'eu152': 85,\n",
       "   'fe59': 86,\n",
       "   'gd153': 87,\n",
       "   'ir192': 88,\n",
       "   'pu238_240_tot': 89,\n",
       "   'rb86': 90,\n",
       "   'sc46': 91,\n",
       "   'sn113': 92,\n",
       "   'sn117m': 93,\n",
       "   'tl208': 94,\n",
       "   'mo99': 95,\n",
       "   'tc99m': 96,\n",
       "   'ru105': 97,\n",
       "   'te129': 98,\n",
       "   'te132': 99,\n",
       "   'i132': 100,\n",
       "   'i135': 101,\n",
       "   'cs136': 102,\n",
       "   'tbeta': 103,\n",
       "   'talpha': 104,\n",
       "   'i133': 105,\n",
       "   'th230': 106,\n",
       "   'pa231': 107,\n",
       "   'u236': 108,\n",
       "   'ag111': 109,\n",
       "   'in116m': 110,\n",
       "   'te123m': 111,\n",
       "   'sb127': 112,\n",
       "   'ba133': 113,\n",
       "   'ce139': 114,\n",
       "   'tl201': 116,\n",
       "   'hg203': 117,\n",
       "   'na22': 122,\n",
       "   'pa234m': 123,\n",
       "   'am243': 124,\n",
       "   'se75': 126,\n",
       "   'sr85': 127,\n",
       "   'y88': 128,\n",
       "   'ce140': 129,\n",
       "   'bi212': 130,\n",
       "   'u236_238_ratio': 131,\n",
       "   'i125': 132,\n",
       "   'ba137m': 133,\n",
       "   'u232': 134,\n",
       "   'pa233': 135,\n",
       "   'ru106_rh106_tot': 136,\n",
       "   'tu': 137,\n",
       "   'tbeta40k': 138,\n",
       "   'fe55': 139,\n",
       "   'ce144_pr144_tot': 140,\n",
       "   'pu240_pu239_ratio': 141,\n",
       "   'u233': 142,\n",
       "   'pu239_242_tot': 143,\n",
       "   'ac227': 144}},\n",
       " 'seawater': {'variable': 'nuclide',\n",
       "  'enum_dict': {'NOT APPLICABLE': -1,\n",
       "   'NOT AVAILABLE': 0,\n",
       "   'h3': 1,\n",
       "   'be7': 2,\n",
       "   'c14': 3,\n",
       "   'k40': 4,\n",
       "   'cr51': 5,\n",
       "   'mn54': 6,\n",
       "   'co57': 7,\n",
       "   'co58': 8,\n",
       "   'co60': 9,\n",
       "   'zn65': 10,\n",
       "   'sr89': 11,\n",
       "   'sr90': 12,\n",
       "   'zr95': 13,\n",
       "   'nb95': 14,\n",
       "   'tc99': 15,\n",
       "   'ru103': 16,\n",
       "   'ru106': 17,\n",
       "   'rh106': 18,\n",
       "   'ag106m': 19,\n",
       "   'ag108': 20,\n",
       "   'ag108m': 21,\n",
       "   'ag110m': 22,\n",
       "   'sb124': 23,\n",
       "   'sb125': 24,\n",
       "   'te129m': 25,\n",
       "   'i129': 28,\n",
       "   'i131': 29,\n",
       "   'cs127': 30,\n",
       "   'cs134': 31,\n",
       "   'cs137': 33,\n",
       "   'ba140': 34,\n",
       "   'la140': 35,\n",
       "   'ce141': 36,\n",
       "   'ce144': 37,\n",
       "   'pm147': 38,\n",
       "   'eu154': 39,\n",
       "   'eu155': 40,\n",
       "   'pb210': 41,\n",
       "   'pb212': 42,\n",
       "   'pb214': 43,\n",
       "   'bi207': 44,\n",
       "   'bi211': 45,\n",
       "   'bi214': 46,\n",
       "   'po210': 47,\n",
       "   'rn220': 48,\n",
       "   'rn222': 49,\n",
       "   'ra223': 50,\n",
       "   'ra224': 51,\n",
       "   'ra225': 52,\n",
       "   'ra226': 53,\n",
       "   'ra228': 54,\n",
       "   'ac228': 55,\n",
       "   'th227': 56,\n",
       "   'th228': 57,\n",
       "   'th232': 59,\n",
       "   'th234': 60,\n",
       "   'pa234': 61,\n",
       "   'u234': 62,\n",
       "   'u235': 63,\n",
       "   'u238': 64,\n",
       "   'np237': 65,\n",
       "   'np239': 66,\n",
       "   'pu238': 67,\n",
       "   'pu239': 68,\n",
       "   'pu240': 69,\n",
       "   'pu241': 70,\n",
       "   'am240': 71,\n",
       "   'am241': 72,\n",
       "   'cm242': 73,\n",
       "   'cm243': 74,\n",
       "   'cm244': 75,\n",
       "   'cs134_137_tot': 76,\n",
       "   'pu239_240_tot': 77,\n",
       "   'pu239_240_iii_iv_tot': 78,\n",
       "   'pu239_240_v_vi_tot': 79,\n",
       "   'cm243_244_tot': 80,\n",
       "   'pu238_pu239_240_tot_ratio': 81,\n",
       "   'am241_pu239_240_tot_ratio': 82,\n",
       "   'cs137_134_ratio': 83,\n",
       "   'cd109': 84,\n",
       "   'eu152': 85,\n",
       "   'fe59': 86,\n",
       "   'gd153': 87,\n",
       "   'ir192': 88,\n",
       "   'pu238_240_tot': 89,\n",
       "   'rb86': 90,\n",
       "   'sc46': 91,\n",
       "   'sn113': 92,\n",
       "   'sn117m': 93,\n",
       "   'tl208': 94,\n",
       "   'mo99': 95,\n",
       "   'tc99m': 96,\n",
       "   'ru105': 97,\n",
       "   'te129': 98,\n",
       "   'te132': 99,\n",
       "   'i132': 100,\n",
       "   'i135': 101,\n",
       "   'cs136': 102,\n",
       "   'tbeta': 103,\n",
       "   'talpha': 104,\n",
       "   'i133': 105,\n",
       "   'th230': 106,\n",
       "   'pa231': 107,\n",
       "   'u236': 108,\n",
       "   'ag111': 109,\n",
       "   'in116m': 110,\n",
       "   'te123m': 111,\n",
       "   'sb127': 112,\n",
       "   'ba133': 113,\n",
       "   'ce139': 114,\n",
       "   'tl201': 116,\n",
       "   'hg203': 117,\n",
       "   'na22': 122,\n",
       "   'pa234m': 123,\n",
       "   'am243': 124,\n",
       "   'se75': 126,\n",
       "   'sr85': 127,\n",
       "   'y88': 128,\n",
       "   'ce140': 129,\n",
       "   'bi212': 130,\n",
       "   'u236_238_ratio': 131,\n",
       "   'i125': 132,\n",
       "   'ba137m': 133,\n",
       "   'u232': 134,\n",
       "   'pa233': 135,\n",
       "   'ru106_rh106_tot': 136,\n",
       "   'tu': 137,\n",
       "   'tbeta40k': 138,\n",
       "   'fe55': 139,\n",
       "   'ce144_pr144_tot': 140,\n",
       "   'pu240_pu239_ratio': 141,\n",
       "   'u233': 142,\n",
       "   'pu239_242_tot': 143,\n",
       "   'ac227': 144}},\n",
       " 'sediment': {'variable': 'nuclide',\n",
       "  'enum_dict': {'NOT APPLICABLE': -1,\n",
       "   'NOT AVAILABLE': 0,\n",
       "   'h3': 1,\n",
       "   'be7': 2,\n",
       "   'c14': 3,\n",
       "   'k40': 4,\n",
       "   'cr51': 5,\n",
       "   'mn54': 6,\n",
       "   'co57': 7,\n",
       "   'co58': 8,\n",
       "   'co60': 9,\n",
       "   'zn65': 10,\n",
       "   'sr89': 11,\n",
       "   'sr90': 12,\n",
       "   'zr95': 13,\n",
       "   'nb95': 14,\n",
       "   'tc99': 15,\n",
       "   'ru103': 16,\n",
       "   'ru106': 17,\n",
       "   'rh106': 18,\n",
       "   'ag106m': 19,\n",
       "   'ag108': 20,\n",
       "   'ag108m': 21,\n",
       "   'ag110m': 22,\n",
       "   'sb124': 23,\n",
       "   'sb125': 24,\n",
       "   'te129m': 25,\n",
       "   'i129': 28,\n",
       "   'i131': 29,\n",
       "   'cs127': 30,\n",
       "   'cs134': 31,\n",
       "   'cs137': 33,\n",
       "   'ba140': 34,\n",
       "   'la140': 35,\n",
       "   'ce141': 36,\n",
       "   'ce144': 37,\n",
       "   'pm147': 38,\n",
       "   'eu154': 39,\n",
       "   'eu155': 40,\n",
       "   'pb210': 41,\n",
       "   'pb212': 42,\n",
       "   'pb214': 43,\n",
       "   'bi207': 44,\n",
       "   'bi211': 45,\n",
       "   'bi214': 46,\n",
       "   'po210': 47,\n",
       "   'rn220': 48,\n",
       "   'rn222': 49,\n",
       "   'ra223': 50,\n",
       "   'ra224': 51,\n",
       "   'ra225': 52,\n",
       "   'ra226': 53,\n",
       "   'ra228': 54,\n",
       "   'ac228': 55,\n",
       "   'th227': 56,\n",
       "   'th228': 57,\n",
       "   'th232': 59,\n",
       "   'th234': 60,\n",
       "   'pa234': 61,\n",
       "   'u234': 62,\n",
       "   'u235': 63,\n",
       "   'u238': 64,\n",
       "   'np237': 65,\n",
       "   'np239': 66,\n",
       "   'pu238': 67,\n",
       "   'pu239': 68,\n",
       "   'pu240': 69,\n",
       "   'pu241': 70,\n",
       "   'am240': 71,\n",
       "   'am241': 72,\n",
       "   'cm242': 73,\n",
       "   'cm243': 74,\n",
       "   'cm244': 75,\n",
       "   'cs134_137_tot': 76,\n",
       "   'pu239_240_tot': 77,\n",
       "   'pu239_240_iii_iv_tot': 78,\n",
       "   'pu239_240_v_vi_tot': 79,\n",
       "   'cm243_244_tot': 80,\n",
       "   'pu238_pu239_240_tot_ratio': 81,\n",
       "   'am241_pu239_240_tot_ratio': 82,\n",
       "   'cs137_134_ratio': 83,\n",
       "   'cd109': 84,\n",
       "   'eu152': 85,\n",
       "   'fe59': 86,\n",
       "   'gd153': 87,\n",
       "   'ir192': 88,\n",
       "   'pu238_240_tot': 89,\n",
       "   'rb86': 90,\n",
       "   'sc46': 91,\n",
       "   'sn113': 92,\n",
       "   'sn117m': 93,\n",
       "   'tl208': 94,\n",
       "   'mo99': 95,\n",
       "   'tc99m': 96,\n",
       "   'ru105': 97,\n",
       "   'te129': 98,\n",
       "   'te132': 99,\n",
       "   'i132': 100,\n",
       "   'i135': 101,\n",
       "   'cs136': 102,\n",
       "   'tbeta': 103,\n",
       "   'talpha': 104,\n",
       "   'i133': 105,\n",
       "   'th230': 106,\n",
       "   'pa231': 107,\n",
       "   'u236': 108,\n",
       "   'ag111': 109,\n",
       "   'in116m': 110,\n",
       "   'te123m': 111,\n",
       "   'sb127': 112,\n",
       "   'ba133': 113,\n",
       "   'ce139': 114,\n",
       "   'tl201': 116,\n",
       "   'hg203': 117,\n",
       "   'na22': 122,\n",
       "   'pa234m': 123,\n",
       "   'am243': 124,\n",
       "   'se75': 126,\n",
       "   'sr85': 127,\n",
       "   'y88': 128,\n",
       "   'ce140': 129,\n",
       "   'bi212': 130,\n",
       "   'u236_238_ratio': 131,\n",
       "   'i125': 132,\n",
       "   'ba137m': 133,\n",
       "   'u232': 134,\n",
       "   'pa233': 135,\n",
       "   'ru106_rh106_tot': 136,\n",
       "   'tu': 137,\n",
       "   'tbeta40k': 138,\n",
       "   'fe55': 139,\n",
       "   'ce144_pr144_tot': 140,\n",
       "   'pu240_pu239_ratio': 141,\n",
       "   'u233': 142,\n",
       "   'pu239_242_tot': 143,\n",
       "   'ac227': 144}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "nuclide_mapping = get_enum_dict(fname, 'nuclide')\n",
    "nuclide_mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

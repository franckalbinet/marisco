{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "> Various utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "from fastcore.test import test_eq\n",
    "import fastcore.all as fc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from shapely import MultiPoint\n",
    "from operator import attrgetter\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from marisco.configs import species_lut_path, sediments_lut_path\n",
    "\n",
    "import jellyfish as jf\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d474d2bd",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback(): order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61702d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_cbs(cbs, obj=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        if cb.__doc__: obj.logs.append(cb.__doc__)\n",
    "        cb(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Transformer():\n",
    "    def __init__(self, dfs, cbs=None): \n",
    "        fc.store_attr()\n",
    "        self.logs = []\n",
    "        \n",
    "    def callback(self):\n",
    "        run_cbs(self.cbs, self)\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.callback()\n",
    "        return self.dfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2b0c493",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def has_valid_varname(\n",
    "    var_names:list, # variable (nuclide) names\n",
    "    cdl_path:str, # Path to MARIS CDL file (point of truth)\n",
    "):\n",
    "    \"Check that proposed variable names are in MARIS CDL\"\n",
    "    has_valid = True\n",
    "    with Dataset(cdl_path) as nc:\n",
    "        grp = nc.groups[list(nc.groups.keys())[0]] # get any group\n",
    "        for name in var_names:\n",
    "            if name not in grp.variables.keys():\n",
    "                has_valid = False\n",
    "                print(f'\"{name}\" variable name not found in MARIS CDL')\n",
    "    \n",
    "    return has_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARNAMES = ['lat', 'lon']\n",
    "test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARNAMES = ['ba140_invalid', 'ba140_dl']\n",
    "test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b63daa4b",
   "metadata": {},
   "source": [
    "## Geoprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_bbox(df,\n",
    "             coord_cols=('lon', 'lat')\n",
    "            ):\n",
    "    x, y = coord_cols        \n",
    "    arr = [(row[x], row[y]) for _, row in df.iterrows()]\n",
    "    return MultiPoint(arr).envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb650442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'lon': np.linspace(-10, 5, 20), 'lat':  np.linspace(40, 50, 20)})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get `lon_min`, `lon_max`, `lat_min`, `lat_max`\n",
    "bbox.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4efbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And its Well-Know Text representation\n",
    "bbox.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6609bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If unique (lon, lat)\n",
    "df = pd.DataFrame({'lon': [0, 0], 'lat':  [1, 1]})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f97883",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox.bounds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2ef1cc9",
   "metadata": {},
   "source": [
    "## Downloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_files_in_folder(owner:str, \n",
    "                             repo:str, \n",
    "                             src_dir:str, \n",
    "                             dest_dir:str\n",
    "                             ):\n",
    "    \"Make a GET request to the GitHub API to get the contents of the folder\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{src_dir}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contents = response.json()\n",
    "\n",
    "        # Iterate over the files and download them\n",
    "        for item in contents:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                fname = item[\"name\"]\n",
    "                download_file(owner, repo, src_dir, dest_dir, fname)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def download_file(owner, repo, src_dir, dest_dir, fname):\n",
    "    # Make a GET request to the GitHub API to get the raw file contents\n",
    "    url = f\"https://raw.githubusercontent.com/{owner}/{repo}/master/{src_dir}/{fname}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the file locally\n",
    "        with open(Path(dest_dir) / fname, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{fname} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a2c018",
   "metadata": {},
   "source": [
    "## WorRMS\n",
    "The [World Register of Marine Species (WorMS)](https://www.marinespecies.org) is an authoritative classification and catalogue of marine names. It provides a REST API (among others) allowing to \"fuzzy\" match any species name you might encounter in marine data sources names againt their own database. There are several types of matches as described [here](https://www.marinespecies.org/tutorial_taxonmatch.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_worms(\n",
    "    name:str # Name of species to look up in WoRMS\n",
    "    ):\n",
    "    \"Lookup `name` in WoRMS (fuzzy match)\"\n",
    "    url = 'https://www.marinespecies.org/rest/AphiaRecordsByMatchNames'\n",
    "    params = {\n",
    "        'scientificnames[]': [name],\n",
    "        'marine_only': 'true'\n",
    "    }\n",
    "    headers = {\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33ce01e2",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "match_worms('Aristeus antennatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72151c-b8fa-43cf-9cfb-70237da16709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dbo_species\n",
    "#from tqdm import tqdm\n",
    "#results = []\n",
    "#species = pd.read_excel(species_lut_path()).species\n",
    "#for i, name in tqdm(enumerate(species), total=len(species)):\n",
    "#    if i > 1:\n",
    "#        worms_match = match_worms(name)\n",
    "#        if worms_match != -1:\n",
    "#            results.append(worms_match[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ca24f-cff8-49fa-8854-12787ea9c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(np.array([result['phylum'] for result in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9055a-5d83-45e7-8536-4c774b2f59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(maris_worms_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648b859-bf3f-421b-ac5a-8ba2b1c5566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maris_worms_matches = fc.load_pickle('./files/pkl/maris-worms-matches.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439af59-cfe1-4449-951e-546d90d5a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(np.array([result['phylum'] for result in maris_worms_matches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819edbcb-ede4-41ff-bc6f-e883e18a1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len([result for result in maris_worms_matches if result['status'] == 'accepted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05781f",
   "metadata": {},
   "source": [
    "## Marisco look-up table fuzzy matching\n",
    "Using https://jamesturk.github.io/jellyfish fuzzy matching distance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eaa16a-29c7-45a2-9742-30a5680b085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Match:\n",
    "    matched_id: int\n",
    "    matched_maris_name: str\n",
    "    source_name: str\n",
    "    match_score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77defe-caca-471b-b490-293b27043cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_maris_lut(\n",
    "    lut_path: str, # Path to MARIS species authoritative species look-up table\n",
    "    data_provider_name: str, # Name of data provider nomenclature item to look up \n",
    "    maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "    maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "    dist_fn: Callable = jf.levenshtein_distance, # Distance function\n",
    "    nresults: int = 10 # Maximum number of results to return\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fuzzy matching data provider and MARIS lookup tables (e.g biota species, sediments, ...).\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(lut_path)\n",
    "    df = df.dropna(subset=[maris_name])\n",
    "    df = df.astype({maris_id: 'int'})\n",
    "\n",
    "    # Vectorized operation to calculate the distance between the input name and all names in the DataFrame\n",
    "    df['score'] = df[maris_name].str.lower().apply(lambda x: dist_fn(data_provider_name.lower(), x))\n",
    "\n",
    "    # Sort the DataFrame by score and select the top nresults\n",
    "    df = df.sort_values(by='score', ascending=True)[:nresults]\n",
    "\n",
    "    # Select the id and name columns and return the DataFrame\n",
    "    return df[[maris_id, maris_name, 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857034ee-8644-4ca0-9783-618e991cfe5b",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"PLANKTON\" with `dbo_species_cleaned.xlsx` MARIS biota species lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e2047-61e1-43b8-96d6-cd3df4dbd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_fname = '../files/lut/dbo_species_cleaned.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='PLANKTON', \n",
    "                maris_id='species_id', maris_name='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191504e-ae3c-4eda-9fb6-ef377885169b",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"GLACIAL\" with dbo_sedtype.xlsx MARIS sediment lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sediments_lut_path()\n",
    "lut_fname = '../files/lut/dbo_sedtype.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='GLACIAL', \n",
    "                maris_id='sedtype_id', maris_name='sedtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def match_maris_species(\n",
    "#    lut_path:str, # Path to MARIS species authoritative species look-up table\n",
    "#    name:str, # Name of species to look up \n",
    "#    col_lookup:str='species', # Name of the column where the character strings match\n",
    "#    dist_fn:Callable=jf.levenshtein_distance, # Jellyfish distance to use\n",
    "#    coi:list=['species_id', 'species', 'Taxonname', 'TaxonDBID'], # Columns of interest to display\n",
    "#    nresults:int=10 # Maximum number of results to return\n",
    "#    ):\n",
    "#    \"Fuzzy matching biota species provided by the data provider and MARIS one.\"\n",
    "#    df = pd.read_excel(lut_path)\n",
    "#    df = df.dropna(subset=col_lookup)\n",
    "#    df = df.astype({'species_id':'int'})\n",
    "#    results = []\n",
    "#    for _, row in df.iterrows():\n",
    "#        score = dist_fn(name.lower(), row[col_lookup].lower())\n",
    "#        result = row[coi].to_dict()\n",
    "#        result['score'] = score\n",
    "#        results.append(result)\n",
    "#    return pd.DataFrame(results).sort_values(by='score', ascending=True)[:nresults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species_lut_path()\n",
    "#lut_fname = '../files/lut/dbo_species_cleaned.xlsx'\n",
    "#match_maris_species(lut_fname, 'PLANKTON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def match_maris_sediment(\n",
    "#    name:str, # Name of sediment to look up \n",
    "#    col_lookup:str='sedtype', # Name of the column where the character strings match\n",
    "#    dist_fn:Callable=jf.levenshtein_distance, # Jellyfish distance to use\n",
    "#    coi:list=['sedtype_id', 'sedtype'], # Columns of interest to display\n",
    "#    nresults:int=10 # Maxiumn number of results to return\n",
    "#    ):\n",
    "#    \"Fuzzy matching sediments type provided by the data provider and MARIS one.\"\n",
    "#    df = pd.read_excel(sediments_lut_path())\n",
    "#    df = df.dropna(subset=col_lookup)\n",
    "#    df = df.astype({'sedtype_id':'int'})\n",
    "#    results = []\n",
    "#    for _, row in df.iterrows():\n",
    "#        score = dist_fn(name.lower(), row[col_lookup].lower())\n",
    "#        result = row[coi].to_dict()\n",
    "#        result['score'] = score\n",
    "#        results.append(result)\n",
    "#    return pd.DataFrame(results).sort_values(by='score', ascending=True)[:nresults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_maris_sediment('GLACIAL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

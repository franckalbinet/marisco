{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "> Various utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from math import modf\n",
    "from netCDF4 import Dataset\n",
    "from fastcore.test import test_eq\n",
    "import fastcore.all as fc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import requests\n",
    "from shapely import MultiPoint\n",
    "import jellyfish as jf\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import List, Dict, Callable, Tuple, Optional, Union\n",
    "from marisco.configs import cache_path\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_VARS,\n",
    "    )\n",
    "# from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15839e",
   "metadata": {},
   "source": [
    "We define below useful constants throughout the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TBD: move to configs\n",
    "NA = 'Not available'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddde356",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d7a4c",
   "metadata": {},
   "source": [
    "Abstracting some common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31569370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_unique_across_dfs(dfs: Dict[str, pd.DataFrame],  # Dictionary of dataframes\n",
    "                          col_name: str='NUCLIDE', # Column name to extract unique values from\n",
    "                          as_df: bool=False, # Return a DataFrame of unique values\n",
    "                          include_nchars: bool=False # Add a column with the number of characters in the value\n",
    "                          ) -> List[str]: # Returns a list of unique column values across dataframes\n",
    "    \"Get a list of unique column values across dataframes.\"\n",
    "    unique_values = list(set().union(*(df[col_name].unique() for df in dfs.values() if col_name in df.columns)))\n",
    "    if not as_df:\n",
    "        return unique_values\n",
    "    else:\n",
    "        df_uniques = pd.DataFrame(unique_values, columns=['value']).reset_index()\n",
    "        if include_nchars: df_uniques['n_chars'] = df_uniques['value'].str.len()\n",
    "        return df_uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c8487",
   "metadata": {},
   "source": [
    "Example of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609599ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_test = {'SEAWATER': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134_137_tot', 'cs134_137_tot']}),\n",
    "            'BIOTA': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134', 'cs134_137_tot']}),\n",
    "            'SEDIMENT': pd.DataFrame({'NUCLIDE': ['cs134_137_tot', 'cs134_137_tot', 'cs134_137_tot']})}\n",
    "\n",
    "fc.test_eq(set(get_unique_across_dfs(dfs_test, col_name='NUCLIDE')), \n",
    "           set(['cs134', 'cs137', 'cs134_137_tot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c8edd",
   "metadata": {},
   "source": [
    "What if the column name is not in one of the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24161871",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_test = {'SEAWATER': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134_137_tot', 'cs134_137_tot']}),\n",
    "            'BIOTA': pd.DataFrame({'NUCLIDE': ['cs137', 'cs134', 'cs134_137_tot']}),\n",
    "            'SEDIMENT': pd.DataFrame({'NONUCLIDE': ['cs134_137_tot', 'cs134_137_tot', 'cs134_137_tot']})}\n",
    "\n",
    "fc.test_eq(set(get_unique_across_dfs(dfs_test, col_name='NUCLIDE')), \n",
    "           set(['cs134', 'cs137', 'cs134_137_tot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e26bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "      <th>n_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cs134</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cs134_137_tot</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cs137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          value  n_chars\n",
       "0      0          cs134        5\n",
       "1      1  cs134_137_tot       13\n",
       "2      2          cs137        5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_across_dfs(dfs_test, col_name='NUCLIDE', as_df=True, include_nchars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Remapper():\n",
    "    \"Remap a data provider lookup table to a MARIS lookup table using fuzzy matching.\"\n",
    "    def __init__(self,\n",
    "                 provider_lut_df: pd.DataFrame, # Data provider lookup table to be remapped\n",
    "                 maris_lut_fn: Union[Callable, pd.DataFrame], # MARIS lookup table or function returning the path\n",
    "                 maris_col_id: str, # MARIS lookup table column name for the id\n",
    "                 maris_col_name: str, # MARIS lookup table column name for the name\n",
    "                 provider_col_to_match: str, # Data provider lookup table column name for the name to match\n",
    "                 provider_col_key: str, # Data provider lookup table column name for the key\n",
    "                 fname_cache: str # Cache file name\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "        self.cache_file = cache_path() / fname_cache\n",
    "        # Check if maris_lut is a callable function or already a DataFrame\n",
    "        if callable(maris_lut_fn):\n",
    "            self.maris_lut = maris_lut_fn()\n",
    "        else:\n",
    "            self.maris_lut = maris_lut_fn\n",
    "        self.lut = {}\n",
    "\n",
    "    def generate_lookup_table(self, \n",
    "                              fixes={}, # Lookup table fixes\n",
    "                              as_df=True, # Whether to return a DataFrame\n",
    "                              overwrite=True):\n",
    "        \"Generate a lookup table from a data provider lookup table to a MARIS lookup table using fuzzy matching.\"\n",
    "        self.fixes = fixes\n",
    "        self.as_df = as_df\n",
    "        if overwrite or not self.cache_file.exists():\n",
    "            self._create_lookup_table()\n",
    "            fc.save_pickle(self.cache_file, self.lut)\n",
    "        else:\n",
    "            self.lut = fc.load_pickle(self.cache_file)\n",
    "\n",
    "        return self._format_output()\n",
    "\n",
    "    def _create_lookup_table(self):\n",
    "        df = self.provider_lut_df\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"): \n",
    "            self._process_row(row)\n",
    "\n",
    "    def _process_row(self, row):\n",
    "        value_to_match = row[self.provider_col_to_match]\n",
    "        if isinstance(value_to_match, str):  # Only process if value is a string\n",
    "            # If value is in fixes, use the fixed value\n",
    "            name_to_match = self.fixes.get(value_to_match, value_to_match)\n",
    "            result = match_maris_lut(self.maris_lut, name_to_match, self.maris_col_id, self.maris_col_name).iloc[0]\n",
    "            match = Match(result[self.maris_col_id], result[self.maris_col_name], \n",
    "                          value_to_match, result['score'])\n",
    "            self.lut[row[self.provider_col_key]] = match\n",
    "        else:\n",
    "            # Handle non-string values (e.g., NaN)\n",
    "            self.lut[row[self.provider_col_key]] = Match(-1, \"Unknown\", value_to_match, 0)\n",
    "            \n",
    "    def select_match(self, match_score_threshold:int=1, verbose:bool=False):\n",
    "        if verbose:\n",
    "            matched_len= len([v for v in self.lut.values() if v.match_score < match_score_threshold])\n",
    "            print(f\"{matched_len} entries matched the criteria, while {len(self.lut) - matched_len} entries had a match score of {match_score_threshold} or higher.\")\n",
    "        \n",
    "        self.lut = {k: v for k, v in self.lut.items() if v.match_score >= match_score_threshold}\n",
    "        return self._format_output()\n",
    "\n",
    "    def _format_output(self):\n",
    "        if not self.as_df: return self.lut\n",
    "        df_lut = pd.DataFrame.from_dict(self.lut, orient='index', \n",
    "                                        columns=['matched_maris_name', 'source_name', 'match_score'])\n",
    "        df_lut.index.name = 'source_key'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df069c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# TBD: Setting unique universal id\n",
    "# import hashlib\n",
    "# combined_str = \"32.123_-180.435_2022-01-01T00:00:00.000\"\n",
    "# hash_object = hashlib.sha256(combined_str.encode())\n",
    "# unique_id = hash_object.hexdigest(); unique_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2b0c493",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TBD: Assess if still needed\n",
    "def has_valid_varname(\n",
    "    var_names: List[str], # variable names\n",
    "    cdl_path: str, # Path to MARIS CDL file (point of truth)\n",
    "    group: Optional[str] = None, # Check if the variable names is contained in the group\n",
    "):\n",
    "    \"Check that proposed variable names are in MARIS CDL\"\n",
    "    has_valid = True\n",
    "    with Dataset(cdl_path) as nc:\n",
    "        cdl_vars={}\n",
    "        all_vars=[]\n",
    "        # get variable names in CDL \n",
    "        for grp in nc.groups.values():\n",
    "            # Create a list of var for each group\n",
    "            vars = list(grp.variables.keys())\n",
    "            cdl_vars[grp.name] = vars\n",
    "            all_vars.extend(vars)\n",
    "        \n",
    "    if group != None:\n",
    "        allowed_vars= cdl_vars[group]\n",
    "    else: \n",
    "        # get unique \n",
    "        allowed_vars = list(set(all_vars))\n",
    "        \n",
    "    for name in var_names:\n",
    "        if name not in allowed_vars:\n",
    "            has_valid = False\n",
    "            if group != None:\n",
    "                print(f'\"{name}\" variable name not found in group \"{group}\" of MARIS CDL')\n",
    "            else:\n",
    "                print(f'\"{name}\" variable name not found in MARIS CDL')\n",
    "    return has_valid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARNAMES = ['lat', 'lon']\n",
    "# test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARNAMES = ['ba140_invalid', 'ba140_dl']\n",
    "# test_eq(has_valid_varname(VARNAMES, './files/nc/maris-cdl.nc'), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1777c",
   "metadata": {},
   "source": [
    "## Geoprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_bbox(df,\n",
    "             coord_cols: Tuple[str, str] = ('LON', 'LAT')\n",
    "            ):\n",
    "    \"Get the bounding box of a DataFrame.\"\n",
    "    x, y = coord_cols        \n",
    "    arr = [(row[x], row[y]) for _, row in df.iterrows()]\n",
    "    return MultiPoint(arr).envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'LON': np.linspace(-10, 5, 20), 'LAT':  np.linspace(40, 50, 20)})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e607512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10.0, 40.0, 5.0, 50.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get `lon_min`, `lon_max`, `lat_min`, `lat_max`\n",
    "bbox.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761fbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON ((-10 40, 5 40, 5 50, -10 50, -10 40))'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And its Well-Know Text representation\n",
    "bbox.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec103c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If unique (lon, lat)\n",
    "df = pd.DataFrame({'LON': [0, 0], 'LAT':  [1, 1]})\n",
    "bbox = get_bbox(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52704a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53eebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def ddmm_to_dd(\n",
    "    ddmmmm: float # Coordinates in degrees/minutes decimal format\n",
    "    ) -> float: # Coordinates in degrees decimal format\n",
    "    # Convert degrees/minutes decimal to degrees decimal.\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    mins = mins * 100\n",
    "    return round(int(degs) + (mins / 60), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.test_close(ddmm_to_dd(45.34), 45.566667)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe93f8e",
   "metadata": {},
   "source": [
    "## Downloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8da64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def download_files_in_folder(\n",
    "    owner: str, # GitHub owner\n",
    "    repo: str, # GitHub repository\n",
    "    src_dir: str, # Source directory\n",
    "    dest_dir: str # Destination directory\n",
    "    ):\n",
    "    \"Make a GET request to the GitHub API to get the contents of the folder.\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{src_dir}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contents = response.json()\n",
    "\n",
    "        # Iterate over the files and download them\n",
    "        for item in contents:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                fname = item[\"name\"]\n",
    "                download_file(owner, repo, src_dir, dest_dir, fname)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def download_file(owner, repo, src_dir, dest_dir, fname):\n",
    "    # Make a GET request to the GitHub API to get the raw file contents\n",
    "    url = f\"https://raw.githubusercontent.com/{owner}/{repo}/master/{src_dir}/{fname}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the file locally\n",
    "        with open(Path(dest_dir) / fname, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{fname} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32414dcf",
   "metadata": {},
   "source": [
    "## WorRMS\n",
    "The [World Register of Marine Species (WorMS)](https://www.marinespecies.org) is an authoritative classification and catalogue of marine names. It provides a REST API (among others) allowing to \"fuzzy\" match any species name you might encounter in marine data sources names againt their own database. There are several types of matches as described [here](https://www.marinespecies.org/tutorial_taxonmatch.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def match_worms(\n",
    "    name: str # Name of species to look up in WoRMS\n",
    "    ):\n",
    "    \"Lookup `name` in WoRMS (fuzzy match).\"\n",
    "    url = 'https://www.marinespecies.org/rest/AphiaRecordsByMatchNames'\n",
    "    params = {\n",
    "        'scientificnames[]': [name],\n",
    "        'marine_only': 'true'\n",
    "    }\n",
    "    headers = {\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2ed2b",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096a3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'AphiaID': 107083,\n",
       "   'url': 'https://www.marinespecies.org/aphia.php?p=taxdetails&id=107083',\n",
       "   'scientificname': 'Aristeus antennatus',\n",
       "   'authority': '(Risso, 1816)',\n",
       "   'status': 'accepted',\n",
       "   'unacceptreason': None,\n",
       "   'taxonRankID': 220,\n",
       "   'rank': 'Species',\n",
       "   'valid_AphiaID': 107083,\n",
       "   'valid_name': 'Aristeus antennatus',\n",
       "   'valid_authority': '(Risso, 1816)',\n",
       "   'parentNameUsageID': 106807,\n",
       "   'kingdom': 'Animalia',\n",
       "   'phylum': 'Arthropoda',\n",
       "   'class': 'Malacostraca',\n",
       "   'order': 'Decapoda',\n",
       "   'family': 'Aristeidae',\n",
       "   'genus': 'Aristeus',\n",
       "   'citation': 'DecaNet eds. (2024). DecaNet. Aristeus antennatus (Risso, 1816). Accessed through: World Register of Marine Species at: https://www.marinespecies.org/aphia.php?p=taxdetails&id=107083 on 2024-12-17',\n",
       "   'lsid': 'urn:lsid:marinespecies.org:taxname:107083',\n",
       "   'isMarine': 1,\n",
       "   'isBrackish': 0,\n",
       "   'isFreshwater': 0,\n",
       "   'isTerrestrial': 0,\n",
       "   'isExtinct': 0,\n",
       "   'match_type': 'exact',\n",
       "   'modified': '2022-08-24T09:48:14.813Z'}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "match_worms('Aristeus antennatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941575e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# open dbo_species\n",
    "#from tqdm import tqdm\n",
    "#results = []\n",
    "#species = pd.read_excel(species_lut_path()).species\n",
    "#for i, name in tqdm(enumerate(species), total=len(species)):\n",
    "#    if i > 1:\n",
    "#        worms_match = match_worms(name)\n",
    "#        if worms_match != -1:\n",
    "#            results.append(worms_match[0][0])\n",
    "# np.unique(np.array([result['phylum'] for result in results]))\n",
    "#len(maris_worms_matches)\n",
    "#maris_worms_matches = fc.load_pickle('./files/pkl/maris-worms-matches.pkl')\n",
    "#np.unique(np.array([result['phylum'] for result in maris_worms_matches]))\n",
    "#len([result for result in maris_worms_matches if result['status'] == 'accepted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70ed97",
   "metadata": {},
   "source": [
    "## Fuzzy matching for MARIS Lookup Tables\n",
    "Using https://jamesturk.github.io/jellyfish fuzzy matching distance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@dataclass\n",
    "class Match:\n",
    "    \"Match between a data provider name and a MARIS lookup table.\"\n",
    "    matched_id: int\n",
    "    matched_maris_name: str\n",
    "    source_name: str\n",
    "    match_score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def match_maris_lut(\n",
    "    lut: Union[str, pd.DataFrame, Path], # Either str, Path or DataFrame\n",
    "    data_provider_name: str, # Name of data provider nomenclature item to look up \n",
    "    maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "    maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "    dist_fn: Callable = jf.levenshtein_distance, # Distance function\n",
    "    nresults: int = 10 # Maximum number of results to return\n",
    ") -> pd.DataFrame:\n",
    "    \"Fuzzy matching data provider and MARIS lookup tables (e.g biota species, sediments, ...).\"\n",
    "    if isinstance(lut, str) or isinstance(lut, Path):\n",
    "        df = pd.read_excel(lut)  # Load the LUT if a path is provided\n",
    "    elif isinstance(lut, pd.DataFrame):\n",
    "        df = lut  # Use the DataFrame directly if provided\n",
    "    else:\n",
    "        raise ValueError(\"lut must be either a file path or a DataFrame\")\n",
    "\n",
    "    df = df.dropna(subset=[maris_name])\n",
    "    df = df.astype({maris_id: 'int'})\n",
    "    df['score'] = df[maris_name].str.lower().apply(lambda x: dist_fn(data_provider_name.lower(), x))\n",
    "    df = df.sort_values(by='score', ascending=True)[:nresults]\n",
    "    return df[[maris_id, maris_name, 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617587e",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"PLANKTON\" with `dbo_species_cleaned.xlsx` MARIS biota species lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282aa570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>species</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>280</td>\n",
       "      <td>Plankton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>695</td>\n",
       "      <td>Zooplankton</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>632</td>\n",
       "      <td>Palaemon</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>696</td>\n",
       "      <td>Phytoplankton</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>811</td>\n",
       "      <td>Chanos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>159</td>\n",
       "      <td>Neuston</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>233</td>\n",
       "      <td>Penaeus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1457</td>\n",
       "      <td>Lamnidae</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1437</td>\n",
       "      <td>Labrus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1526</td>\n",
       "      <td>Favites</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species_id        species  score\n",
       "281          280       Plankton      0\n",
       "696          695    Zooplankton      3\n",
       "633          632       Palaemon      4\n",
       "697          696  Phytoplankton      5\n",
       "812          811         Chanos      5\n",
       "160          159        Neuston      5\n",
       "234          233        Penaeus      6\n",
       "1458        1457       Lamnidae      6\n",
       "1438        1437         Labrus      6\n",
       "1527        1526        Favites      6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_species_cleaned.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='PLANKTON', \n",
    "                maris_id='species_id', maris_name='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6c3b0",
   "metadata": {},
   "source": [
    "Below, we demonstrate matching the laboratory name \"Central Mining Institute, Poland\" with the MARIS lab lookup table from `dbo_lab.xlsx`. This example utilizes the `lab` and `country` columns. Note that in this instance, `df_lut` is passed directly as the `lut` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751b366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_country</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Central Mining Institute_Poland</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>202</td>\n",
       "      <td>Polytechnic Institute_Romania</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>281</td>\n",
       "      <td>Norwegian Polar Institute_Norway</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>112</td>\n",
       "      <td>Nuclear Research Institute_Vietnam</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>245</td>\n",
       "      <td>Paul Scherrer Institute_Switzerland</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>135</td>\n",
       "      <td>Nuclear Energy Board_Ireland</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>474</td>\n",
       "      <td>Kobe University_Japan</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>432</td>\n",
       "      <td>Qatar University_Qatar</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>173</td>\n",
       "      <td>Interfaculty Reactor Institute_Netherlands</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>176</td>\n",
       "      <td>RIKILT_Netherlands</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lab_id                                 lab_country  score\n",
       "6         5             Central Mining Institute_Poland      2\n",
       "203     202               Polytechnic Institute_Romania     18\n",
       "282     281            Norwegian Polar Institute_Norway     21\n",
       "113     112          Nuclear Research Institute_Vietnam     22\n",
       "246     245         Paul Scherrer Institute_Switzerland     22\n",
       "136     135                Nuclear Energy Board_Ireland     23\n",
       "471     474                       Kobe University_Japan     23\n",
       "429     432                      Qatar University_Qatar     23\n",
       "174     173  Interfaculty Reactor Institute_Netherlands     23\n",
       "177     176                          RIKILT_Netherlands     23"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_lab.xlsx'\n",
    "df_lut=pd.read_excel(lut_fname)\n",
    "df_lut['lab_country'] = df_lut['lab'] + '_' + df_lut['country']\n",
    "\n",
    "match_maris_lut(lut=df_lut, data_provider_name='Central Mining Institute, Poland', \n",
    "                maris_id='lab_id', maris_name='lab_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753034ae",
   "metadata": {},
   "source": [
    "Below an example trying to match the name \"GLACIAL\" with dbo_sedtype.xlsx MARIS sediment lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4bc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sedtype_id</th>\n",
       "      <th>sedtype</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>Glacial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Clay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>50</td>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Marsh</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Sand</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>Silt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>Sludge</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>Soft</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51</td>\n",
       "      <td>Soft clay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sedtype_id       sedtype  score\n",
       "26          25       Glacial      0\n",
       "3            2        Gravel      4\n",
       "2            1          Clay      5\n",
       "51          50  Glacial clay      5\n",
       "4            3         Marsh      6\n",
       "7            6          Sand      6\n",
       "13          12          Silt      6\n",
       "15          14        Sludge      6\n",
       "27          26          Soft      7\n",
       "52          51     Soft clay      7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_sedtype.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='GLACIAL', \n",
    "                maris_id='sedtype_id', maris_name='sedtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa12ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuclide_id</th>\n",
       "      <th>nc_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>cs137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>cs134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>cs127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>102</td>\n",
       "      <td>cs136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>112</td>\n",
       "      <td>sb127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>114</td>\n",
       "      <td>ce139</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>sb125</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>pm147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>i131</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>113</td>\n",
       "      <td>ba133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nuclide_id nc_name  score\n",
       "31           33   cs137      1\n",
       "30           31   cs134      2\n",
       "29           30   cs127      2\n",
       "99          102   cs136      2\n",
       "109         112   sb127      3\n",
       "111         114   ce139      3\n",
       "25           24   sb125      4\n",
       "36           38   pm147      4\n",
       "28           29    i131      4\n",
       "110         113   ba133      4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lut_fname = '../files/lut/dbo_nuclide.xlsx'\n",
    "match_maris_lut(lut_fname, data_provider_name='CS-137', \n",
    "                maris_id='nuclide_id', maris_name='nc_name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2ef1cc9",
   "metadata": {},
   "source": [
    "## Downloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def download_files_in_folder(\n",
    "    owner: str, # GitHub owner\n",
    "    repo: str, # GitHub repository\n",
    "    src_dir: str, # Source directory\n",
    "    dest_dir: str # Destination directory\n",
    "    ):\n",
    "    \"Make a GET request to the GitHub API to get the contents of the folder\"\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{src_dir}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        contents = response.json()\n",
    "\n",
    "        # Iterate over the files and download them\n",
    "        for item in contents:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                fname = item[\"name\"]\n",
    "                download_file(owner, repo, src_dir, dest_dir, fname)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def download_file(owner, repo, src_dir, dest_dir, fname):\n",
    "    # Make a GET request to the GitHub API to get the raw file contents\n",
    "    url = f\"https://raw.githubusercontent.com/{owner}/{repo}/master/{src_dir}/{fname}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the file locally\n",
    "        with open(Path(dest_dir) / fname, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{fname} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d865892",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16144ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def test_dfs(\n",
    "    dfs1: Dict[str, pd.DataFrame], # First dictionary of DataFrames to compare \n",
    "    dfs2: Dict[str, pd.DataFrame] # Second dictionary of DataFrames to compare\n",
    "    ) -> None: # It raises an `AssertionError` if the DataFrames are not equal\n",
    "    \"Compare two dictionaries of DataFrames for equality (also ensuring that columns are in the same order).\"\n",
    "    for grp in dfs1.keys():\n",
    "        df1, df2 = (df.sort_index() for df in (dfs1[grp], dfs2[grp]))\n",
    "        fc.test_eq(df1, df2.reindex(columns=df1.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4aeb2",
   "metadata": {},
   "source": [
    "## NetCDF Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2df975",
   "metadata": {},
   "source": [
    "Extract NetCDF contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e02f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ExtractNetcdfContents:\n",
    "    def __init__(self, filename: str, verbose: bool = False):\n",
    "        \"Initialize and extract data from a NetCDF file.\"\n",
    "        self.filename = filename\n",
    "        self.verbose = verbose\n",
    "        self.dfs = {}  # DataFrames extracted from the NetCDF file\n",
    "        self.enum_dicts = {}  # Enum dictionaries extracted from the NetCDF file\n",
    "        self.global_attrs = {}  # Global attributes extracted from the NetCDF file\n",
    "        self.extract_all()\n",
    "\n",
    "    def extract_all(self):\n",
    "        \"Extract data, enums, and global attributes from the NetCDF file.\"\n",
    "        if not Path(self.filename).exists():\n",
    "            print(f'File {self.filename} not found.')\n",
    "            return\n",
    "        \n",
    "        with Dataset(self.filename, 'r') as nc:\n",
    "            self.global_attrs = self.extract_global_attributes(nc)\n",
    "            for group_name in nc.groups:\n",
    "                group = nc.groups[group_name]\n",
    "                self.dfs[group_name.upper()] = self.extract_data(group)\n",
    "                self.enum_dicts[group_name.upper()] = self.extract_enums(group, group_name)\n",
    "            if self.verbose:\n",
    "                print(\"Data extraction complete.\")\n",
    "\n",
    "    def extract_data(self, group) -> pd.DataFrame:\n",
    "        \"Extract data from a group and convert to DataFrame.\"\n",
    "        data = {var_name: var[:] for var_name, var in group.variables.items() if var_name not in group.dimensions}\n",
    "        df = pd.DataFrame(data)\n",
    "        rename_map = {nc_var: col for col, nc_var in NC_VARS.items() if nc_var in df.columns}\n",
    "        df = df.rename(columns=rename_map)\n",
    "        return df\n",
    "\n",
    "    def extract_enums(self, group, group_name: str) -> Dict:\n",
    "        \"Extract enum dictionaries for variables in a group.\"\n",
    "        local_enum_dicts = {}\n",
    "        for var_name, var in group.variables.items():\n",
    "            if hasattr(var.datatype, 'enum_dict'):\n",
    "                local_enum_dicts[var_name] = {str(k): str(v) for k, v in var.datatype.enum_dict.items()}\n",
    "                if self.verbose:\n",
    "                    print(f\"Extracted enum_dict for {var_name} in {group_name}\")\n",
    "        return local_enum_dicts\n",
    "\n",
    "    def extract_global_attributes(self, nc) -> Dict:\n",
    "        \"Extract global attributes from the NetCDF file.\"\n",
    "        globattrs = {attr: getattr(nc, attr) for attr in nc.ncattrs()}\n",
    "        return globattrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SEAWATER':        sample         LON    LAT        TIME  h3  h3_dl  mn54  mn54_dl  co58  \\\n",
      "0           0  141.029999  37.32  1300749300 NaN    NaN   NaN      NaN   5.7   \n",
      "1           1  141.029999  37.32  1300804080 NaN    NaN   NaN      NaN   NaN   \n",
      "2           2  141.029999  37.32  1300888260 NaN    NaN   NaN      NaN   NaN   \n",
      "3           3  141.029999  37.32  1300959000 NaN    NaN   NaN      NaN   NaN   \n",
      "4           4  141.029999  37.32  1301047200 NaN    NaN   NaN      NaN   NaN   \n",
      "...       ...         ...    ...         ...  ..    ...   ...      ...   ...   \n",
      "21472   21472  141.039993  37.48  1657620600 NaN    NaN   NaN      NaN   NaN   \n",
      "21473   21473  141.039993  37.48  1657620600 NaN   0.37   NaN      NaN   NaN   \n",
      "21474   21474  141.039993  37.48  1658224800 NaN    NaN   NaN      NaN   NaN   \n",
      "21475   21475  141.039993  37.48  1658224800 NaN   0.38   NaN      NaN   NaN   \n",
      "21476   21476  141.039993  37.48  1658830200 NaN    NaN   NaN      NaN   NaN   \n",
      "\n",
      "       co58_dl  ...  te132  te132_dl   i132  i132_dl  cs136  cs136_dl  tbeta  \\\n",
      "0          7.6  ...    NaN       NaN  160.0     44.0    6.7       4.7    NaN   \n",
      "1         15.0  ...    NaN       NaN    NaN     88.0    NaN       7.8    NaN   \n",
      "2          NaN  ...    NaN       NaN  200.0     58.0    NaN       NaN    NaN   \n",
      "3          NaN  ...    NaN       NaN  120.0     88.0   68.0      49.0    NaN   \n",
      "4          NaN  ...   13.0       7.4   58.0     22.0    4.4       3.2    NaN   \n",
      "...        ...  ...    ...       ...    ...      ...    ...       ...    ...   \n",
      "21472      NaN  ...    NaN       NaN    NaN      NaN    NaN       NaN    NaN   \n",
      "21473      NaN  ...    NaN       NaN    NaN      NaN    NaN       NaN    NaN   \n",
      "21474      NaN  ...    NaN       NaN    NaN      NaN    NaN       NaN    NaN   \n",
      "21475      NaN  ...    NaN       NaN    NaN      NaN    NaN       NaN    NaN   \n",
      "21476      NaN  ...    NaN       NaN    NaN      NaN    NaN       NaN    NaN   \n",
      "\n",
      "       tbeta_dl  talpha  talpha_dl  \n",
      "0           NaN     NaN        NaN  \n",
      "1           NaN     NaN        NaN  \n",
      "2           NaN     NaN        NaN  \n",
      "3           NaN     NaN        NaN  \n",
      "4           NaN     NaN        NaN  \n",
      "...         ...     ...        ...  \n",
      "21472       NaN     NaN        NaN  \n",
      "21473       NaN     NaN        NaN  \n",
      "21474       NaN     NaN        NaN  \n",
      "21475      13.0     NaN        NaN  \n",
      "21476       NaN     NaN        NaN  \n",
      "\n",
      "[21477 rows x 49 columns]}\n",
      "{'SEAWATER': {}}\n",
      "{'id': '', 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances', 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.', 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Water Quality > Ocean Contaminants', 'keywords_vocabulary': 'GCMD Science Keywords', 'keywords_vocabulary_url': 'https://gcmd.earthdata.nasa.gov/static/kms/', 'record': '', 'featureType': '', 'cdm_data_type': '', 'Conventions': 'CF-1.10 ACDD-1.3', 'publisher_name': 'Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI', 'publisher_email': 'p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org', 'publisher_url': 'https://maris.iaea.org', 'publisher_institution': 'International Atomic Energy Agency - IAEA', 'creator_name': 'author: HELCOM MORS', 'institution': '', 'metadata_link': '', 'creator_email': '', 'creator_url': '', 'references': '', 'license': 'Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).', 'comment': '', 'geospatial_lat_min': '141.67', 'geospatial_lon_min': '140.6', 'geospatial_lat_max': '38.63', 'geospatial_lon_max': '35.8', 'geospatial_vertical_min': '', 'geospatial_vertical_max': '', 'geospatial_bounds': 'POLYGON ((140.6 35.8, 141.67 35.8, 141.67 38.63, 140.6 38.63, 140.6 35.8))', 'geospatial_bounds_crs': 'EPSG:4326', 'time_coverage_start': '2011-03-21T23:15:00', 'time_coverage_end': '2022-07-26T13:45:00', 'local_time_zone': '', 'date_created': '', 'date_modified': '', 'publisher_postprocess_logs': 'Assign `NaN` to values equal to `ND` (not detected) - to be confirmed , Remove  (about) char, Replace e.g `4.0E+00<&<8.0E+00` by its mean (here 6), Remap to MARIS radionuclide names, Normalizing, renaming columns, Encode time as `int` representing seconds since xxx, Drop row when both longitude & latitude equal 0'}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# fname = Path('../../_data/output/190-geotraces-2021.nc')\n",
    "fname = Path('../../_data/output/tepco.nc')\n",
    "\n",
    "contents= ExtractNetcdfContents(fname)\n",
    "\n",
    "print(contents.dfs)\n",
    "print(contents.enum_dicts)\n",
    "print(contents.global_attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84422d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

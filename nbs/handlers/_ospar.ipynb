{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.ospar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712eab9d",
   "metadata": {},
   "source": [
    "# OSPAR \n",
    "\n",
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [OSPAR data](https://odims.ospar.org/en/) into `NetCDF` format. The handler processes raw OSPAR data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw OSPAR data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring OSPAR data is properly integrated into the MARIS database.\n",
    "\n",
    "\n",
    "\n",
    "Note: *Additionally, an optional encoder (pipeline) is provided below to process data into a `.csv` format compatible with the MARIS master database. This feature is maintained for legacy purposes, as data ingestion was previously performed using OpenRefine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e3e9c",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d4c1f",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/ospar.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "#from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple, Any \n",
    "#from collections import OrderedDict, defaultdict\n",
    "import re\n",
    "#from functools import partial\n",
    "\n",
    "from marisco.utils import (\n",
    "    Remapper, \n",
    "    ddmm_to_dd,\n",
    "    Match, \n",
    "    get_unique_across_dfs,\n",
    "    NA\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback, \n",
    "    Transformer, \n",
    "    EncodeTimeCB, \n",
    "    AddSampleTypeIdColumnCB,\n",
    "    AddNuclideIdColumnCB, \n",
    "    LowerStripNameCB, \n",
    "    SanitizeLonLatCB, \n",
    "    CompareDfsAndTfmCB, \n",
    "    RemapCB\n",
    ")\n",
    "\n",
    "from marisco.metadata import (\n",
    "    GlobAttrsFeeder, \n",
    "    BboxCB, \n",
    "    DepthRangeCB, \n",
    "    TimeRangeCB, \n",
    "    ZoteroCB, \n",
    "    KeyValuePairCB\n",
    ")\n",
    "\n",
    "from marisco.configs import (\n",
    "    nuc_lut_path, \n",
    "    nc_tpl_path, \n",
    "    cfg, \n",
    "    species_lut_path, \n",
    "    sediments_lut_path, \n",
    "    bodyparts_lut_path, \n",
    "    detection_limit_lut_path, \n",
    "    filtered_lut_path, \n",
    "    get_lut, \n",
    "    unit_lut_path,\n",
    "    prepmet_lut_path,\n",
    "    sampmet_lut_path,\n",
    "    counmet_lut_path, \n",
    "    lab_lut_path,\n",
    "    NC_VARS\n",
    ")\n",
    "\n",
    "from marisco.encoders import (\n",
    "    NetCDFEncoder, \n",
    ")\n",
    "\n",
    "from marisco.decoders import (\n",
    "    nc_to_dfs,\n",
    "    get_netcdf_properties, \n",
    "    get_netcdf_group_properties,\n",
    "    get_netcdf_variable_properties\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9347cd3",
   "metadata": {},
   "source": [
    "## Configuration and file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d915b5",
   "metadata": {},
   "source": [
    "1. **fname_in** - is the path to the folder containing the OSPAR data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "2. **fname_out_nc** - is the path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "3. **Zotero key** - is used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "4. **ref_id** - refers to the location in archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "fname_in = '../../_data/accdb/ospar/20241021/csv'\n",
    "fname_out_nc = '../../_data/output/191-OSPAR-2024.nc'\n",
    "zotero_key ='LQRA4MMK' # OSPAR MORS zotero key\n",
    "ref_id = 191 # OSPAR reference id as defined by MARIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1facbd6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "[OSPAR Environmental Monitoring Data](https://odims.ospar.org/en/) is provided as a Microsoft Access database. [`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "**Example steps**:\n",
    "\n",
    "1. [Download data](https://odims.ospar.org/en/)\n",
    "2. Install `mdbtools` via `VScode` Terminal (for instance):\n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In `VS code` terminal (for instance), navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/ospar\n",
    "    ```\n",
    "\n",
    "5. Unzip `OSPAR_Env_Concentrations_20241021.zip`\n",
    "\n",
    "    ```\n",
    "    unzip OSPAR_Env_Concentrations_20241021.zip\n",
    "    ```\n",
    "\n",
    "6. Run `preprocess.sh` to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh OSPAR_Env_Concentrations_20241021.zip\n",
    "    ````\n",
    "\n",
    "7. Content of `preprocess.sh` script:\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh OSPAR_Env_Concentrations_20241021.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb *.mdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n",
    "\n",
    "Once converted to `.csv` files, the data is ready to be loaded into a dictionary of dataframes.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e237b01",
   "metadata": {},
   "source": [
    "Load OSPAR data and return the data in a Python dictionary of dataframes with the dictionary key as the sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab009087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = {'Seawater data': 'SEAWATER', 'Biota data': 'BIOTA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir:str, # Directory where the source CSV files are located\n",
    "              lut:dict=default_smp_types # A dictionary with the file name as key and the sample type as value\n",
    "              ) -> dict: # A dictionary with sample types as keys and their corresponding dataframes as values\n",
    "    \"Load `OSPAR` data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    return {\n",
    "        sample_type: pd.read_csv(Path(src_dir) / f'{file_name}.csv', encoding='unicode_escape')\n",
    "        for file_name, sample_type in lut.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47e4d4",
   "metadata": {},
   "source": [
    "`dfs` includes a dictionary of dataframes that is created from the OSPAR dataset defined by `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys/sample types:  dict_keys(['SEAWATER', 'BIOTA'])\n",
      "SEAWATER columns:  Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
      "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
      "       'LongS', 'LongDir', 'Sample type', 'Sampling depth', 'Sampling date',\n",
      "       'Nuclide', 'Value type', 'Activity or MDA', 'Uncertainty', 'Unit',\n",
      "       'Data provider', 'Measurement Comment', 'Sample Comment',\n",
      "       'Reference Comment'],\n",
      "      dtype='object')\n",
      "BIOTA columns:  Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
      "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
      "       'LongS', 'LongDir', 'Sample type', 'Biological group', 'Species',\n",
      "       'Body Part', 'Sampling date', 'Nuclide', 'Value type',\n",
      "       'Activity or MDA', 'Uncertainty', 'Unit', 'Data provider',\n",
      "       'Measurement Comment', 'Sample Comment', 'Reference Comment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('keys/sample types: ', dfs.keys())\n",
    "\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} columns: ', dfs[key].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2555648",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630dd42",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index        value  n_chars  stripped_chars\n",
      "0       0  239, 240 Pu     11.0             9.0\n",
      "2       2       99Tc        6.0             4.0\n",
      "5       5          NaN      NaN             NaN\n",
      "7       7      137Cs        7.0             5.0\n",
      "11     11      210Po        7.0             5.0\n",
      "12     12      99Tc         7.0             4.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(fname_in), 'Nuclide', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03816f19",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae83bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER Nuclides: \n",
      "['137cs' '239,240pu' '226ra' '228ra' '99tc' '3h' '210po' '210pb' nan]\n",
      "BIOTA Nuclides: \n",
      "['137cs' '226ra' '228ra' '239,240pu' '99tc' '210po' '210pb' '3h' 'cs-137'\n",
      " '238pu' '239, 240 pu' '241am']\n",
      "[\"Convert 'Nuclide' column values to lowercase, strip spaces, and store in 'Nuclide' column.\"]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='Nuclide', col_dst='Nuclide')])\n",
    "dfs_output=tfm()\n",
    "for key, df in dfs_output.items():\n",
    "    print(f'{key} Nuclides: ')\n",
    "    print(df['Nuclide'].unique())\n",
    "    \n",
    "print(tfm.logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff7a3f",
   "metadata": {},
   "source": [
    "Below, we map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures to MARIS standards is a recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "We will refer to this process as **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd510d4",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `Nuclide` column has inconsistent naming. E.g:\n",
    "\n",
    "- `Cs-137`,  `137Cs` or `CS-137`\n",
    "- `239, 240 pu` or `239,240 pu`\n",
    "- `ra-226` and `226ra` \n",
    "\n",
    "See below:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691ccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>228ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>239, 240 pu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>238pu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>239,240pu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>99tc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>226ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>137cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>cs-137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>210po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>210pb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>241am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        value\n",
       "0       0        228ra\n",
       "1       1          NaN\n",
       "2       2  239, 240 pu\n",
       "3       3           3h\n",
       "4       4        238pu\n",
       "5       5    239,240pu\n",
       "6       6         99tc\n",
       "7       7        226ra\n",
       "8       8        137cs\n",
       "9       9       cs-137\n",
       "10     10        210po\n",
       "11     11        210pb\n",
       "12     12        241am"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_unique_across_dfs(dfs_output, col_name='Nuclide', as_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6879cf4",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the nuclide names of the OSPAR dataset to the MARIS standard nuclide names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='Nuclide', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_ospar.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f4cb6",
   "metadata": {},
   "source": [
    "Lets try to match OSPAR nuclide names to MARIS standard nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|███▊      | 5/13 [00:00<00:00, 39.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 13/13 [00:00<00:00, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 entries matched the criteria, while 12 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239, 240 pu</th>\n",
       "      <td>pu240</td>\n",
       "      <td>239, 240 pu</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239,240pu</th>\n",
       "      <td>pu240</td>\n",
       "      <td>239,240pu</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228ra</th>\n",
       "      <td>u235</td>\n",
       "      <td>228ra</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226ra</th>\n",
       "      <td>u234</td>\n",
       "      <td>226ra</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137cs</th>\n",
       "      <td>i133</td>\n",
       "      <td>137cs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210po</th>\n",
       "      <td>ru106</td>\n",
       "      <td>210po</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210pb</th>\n",
       "      <td>ru106</td>\n",
       "      <td>210pb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241am</th>\n",
       "      <td>pu241</td>\n",
       "      <td>241am</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238pu</th>\n",
       "      <td>u238</td>\n",
       "      <td>238pu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99tc</th>\n",
       "      <td>tu</td>\n",
       "      <td>99tc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>tu</td>\n",
       "      <td>3h</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs-137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs-137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            matched_maris_name  source_name  match_score\n",
       "source_key                                              \n",
       "239, 240 pu              pu240  239, 240 pu            8\n",
       "239,240pu                pu240    239,240pu            6\n",
       "228ra                     u235        228ra            4\n",
       "226ra                     u234        226ra            4\n",
       "137cs                     i133        137cs            4\n",
       "210po                    ru106        210po            4\n",
       "210pb                    ru106        210pb            4\n",
       "241am                    pu241        241am            4\n",
       "238pu                     u238        238pu            3\n",
       "99tc                        tu         99tc            3\n",
       "3h                          tu           3h            2\n",
       "cs-137                   cs137       cs-137            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a6beb5",
   "metadata": {},
   "source": [
    "We can now manually inspect the unmatched nuclide names and create a table to correct them to the MARIS standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    '99tc': 'tc99',\n",
    "    '238pu': 'pu238',\n",
    "    '226ra': 'ra226',\n",
    "    '210pb': 'pb210',\n",
    "    '241am': 'am241',\n",
    "    '228ra': 'ra228',\n",
    "    '137cs': 'cs137',\n",
    "    '210po': 'po210',\n",
    "    '239,240pu': 'pu239_240_tot',\n",
    "    '239, 240 pu': 'pu239_240_tot',\n",
    "    'cs-137': 'cs137',\n",
    "    '3h': 'h3'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42861a",
   "metadata": {},
   "source": [
    "We now include the table `fixes_nuclide_names`, which applies manual corrections to the nuclide names before the remapping process. \n",
    "The `generate_lookup_table` function has an `overwrite` parameter (default is `True`), which, when set to `True`, creates a pickle file cache of the lookup table. We can now test the remapping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8dd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 13/13 [00:00<00:00, 36.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891cee8",
   "metadata": {},
   "source": [
    "If we want to view all the remapped nuclides we can set the match score threshold to 0; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44641d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 13/13 [00:00<00:00, 28.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entries matched the criteria, while 13 entries had a match score of 0 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228ra</th>\n",
       "      <td>ra228</td>\n",
       "      <td>228ra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239, 240 pu</th>\n",
       "      <td>pu239_240_tot</td>\n",
       "      <td>239, 240 pu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>h3</td>\n",
       "      <td>3h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238pu</th>\n",
       "      <td>pu238</td>\n",
       "      <td>238pu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239,240pu</th>\n",
       "      <td>pu239_240_tot</td>\n",
       "      <td>239,240pu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99tc</th>\n",
       "      <td>tc99</td>\n",
       "      <td>99tc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226ra</th>\n",
       "      <td>ra226</td>\n",
       "      <td>226ra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137cs</th>\n",
       "      <td>cs137</td>\n",
       "      <td>137cs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs-137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs-137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210po</th>\n",
       "      <td>po210</td>\n",
       "      <td>210po</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210pb</th>\n",
       "      <td>pb210</td>\n",
       "      <td>210pb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241am</th>\n",
       "      <td>am241</td>\n",
       "      <td>241am</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            matched_maris_name  source_name  match_score\n",
       "source_key                                              \n",
       "228ra                    ra228        228ra            0\n",
       "NaN                    Unknown          NaN            0\n",
       "239, 240 pu      pu239_240_tot  239, 240 pu            0\n",
       "3h                          h3           3h            0\n",
       "238pu                    pu238        238pu            0\n",
       "239,240pu        pu239_240_tot    239,240pu            0\n",
       "99tc                      tc99         99tc            0\n",
       "226ra                    ra226        226ra            0\n",
       "137cs                    cs137        137cs            0\n",
       "cs-137                   cs137       cs-137            0\n",
       "210po                    po210        210po            0\n",
       "210pb                    pb210        210pb            0\n",
       "241am                    am241        241am            0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "remapper.select_match(match_score_threshold=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39915d33",
   "metadata": {},
   "source": [
    "Values are remapped correctly! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_ospar.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66944861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    \"Remap data provider nuclide names to standardized MARIS nuclide names.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable, # Function that returns the lookup table dictionary\n",
    "                 col_name: str # Column name to remap\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name=self.col_name, as_df=True)\n",
    "        #lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        lut = {k: v.matched_id for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k][self.col_name].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d0075",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `LowerStripNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER NUCLIDE unique:  [33 77 53 54 15  1 47 41 -1]\n",
      "BIOTA NUCLIDE unique:  [33 53 54 77 15 47 41  1 67 72]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='Nuclide', col_dst='Nuclide'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='Nuclide')\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "for key in dfs_out.keys():\n",
    "    print(f'{key} NUCLIDE unique: ', dfs_out[key]['NUCLIDE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5585f",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cd209",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: `SEAWATER` dataset contains 1O rows with `NaN` values in the `Sampling date` column as shown below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in Sampling date:  10\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('Number of NaN values in Sampling date: ', dfs['SEAWATER']['Sampling date'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807cd86",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`) and handle missing dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Parse the time format in the dataframe.\"\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            df['TIME'] = pd.to_datetime(df['Sampling date'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "            df.dropna(subset=['TIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d44e5d",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the ``begperiod`` and `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           SEAWATER  BIOTA\n",
      "Number of rows in dfs         19193  15951\n",
      "Number of rows in tfm.dfs     19183  15951\n",
      "Number of rows removed           10      0 \n",
      "\n",
      "0       2010-01-27 00:00:00\n",
      "1       2010-01-27 00:00:00\n",
      "2       2010-01-27 00:00:00\n",
      "3       2010-01-27 00:00:00\n",
      "4       2010-01-26 00:00:00\n",
      "                ...        \n",
      "19183   2019-11-13 12:54:00\n",
      "19184   2019-12-10 11:37:00\n",
      "19185   2019-12-10 11:37:00\n",
      "19186   2019-12-10 11:37:00\n",
      "19187   2019-12-18 14:43:00\n",
      "Name: TIME, Length: 19183, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    ParseTimeCB(),\n",
    "    CompareDfsAndTfmCB(dfs)])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['SEAWATER']['TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c54c09",
   "metadata": {},
   "source": [
    "The NetCDF time format requires the time to be encoded as number of milliseconds since a time of origin. In our case the time of origin is `1970-01-01` as indicated in `configs.ipynb` `CONFIFS['units']['time']` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b38397",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bd204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           SEAWATER  BIOTA\n",
      "Number of rows in dfs         19193  15951\n",
      "Number of rows in tfm.dfs     19183  15951\n",
      "Number of rows removed           10      0 \n",
      "\n",
      "['Parse the time format in the dataframe.', 'Encode time as seconds since epoch.', 'Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.logs)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17063a80",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8ab6e",
   "metadata": {},
   "source": [
    "We allocate each column containing measurement values into a single column `VALUE` and remove `NA` where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38538f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class SanitizeValueCB(Callback):\n",
    "    \"Sanitize value by removing blank entries and populating `value` column.\"\n",
    "    def __init__(self, \n",
    "                 value_col: str='Activity or MDA' # Column name to sanitize\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            df.dropna(subset=[self.value_col], inplace=True)\n",
    "            df['VALUE'] = df[self.value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ecd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of VALUE column:\n",
      "   VALUE\n",
      "0   0.20\n",
      "1   0.27\n",
      "2   0.26\n",
      "3   0.25\n",
      "4   0.20\n",
      "\n",
      "Comparison stats:\n",
      "                           SEAWATER  BIOTA\n",
      "Number of rows in dfs         19193  15951\n",
      "Number of rows in tfm.dfs     19183  15951\n",
      "Number of rows removed           10      0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValueCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print('Example of VALUE column:')\n",
    "print(tfm.dfs['SEAWATER'][['VALUE']].head())\n",
    "print('\\nComparison stats:')\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83412b",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a44f1a",
   "metadata": {},
   "source": [
    "For each sample type in the OSPAR dataset, the reported uncertainty is given as an expanded uncertainty with a coverage factor `𝑘=2`. For further details, refer to the [OSPAR reporting guidelines](https://mcc.jrc.ec.europa.eu/documents/OSPAR/Guidelines_forestimationof_a_%20measurefor_uncertainty_in_OSPARmonitoring.pdf).\n",
    "\n",
    "**Note**: For MARIS the OSPAR uncertainty values are normalized to standard uncertainty with a coverage factor \n",
    "𝑘=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a933ab",
   "metadata": {},
   "source": [
    "`NormalizeUncCB` callback normalizes the uncertainty using the following `lambda` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c84351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "unc_exp2stan = lambda df, unc_col: df[unc_col] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"\"\"Normalize uncertainty values in DataFrames.\"\"\"\n",
    "    def __init__(self, \n",
    "                 col_unc: str='Uncertainty', # Column name to normalize\n",
    "                 fn_convert_unc: Callable=unc_exp2stan, # Function correcting coverage factor\n",
    "                 ): \n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            df['UNCERTAINTY'] = self.fn_convert_unc(df, self.col_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a18010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEAWATER:\n",
      "   VALUE  UNCERTAINTY\n",
      "0   0.20          NaN\n",
      "1   0.27          NaN\n",
      "2   0.26          NaN\n",
      "3   0.25          NaN\n",
      "4   0.20          NaN\n",
      "\n",
      "BIOTA:\n",
      "      VALUE  UNCERTAINTY\n",
      "0  0.326416          NaN\n",
      "1  0.442704          NaN\n",
      "2  0.412989          NaN\n",
      "3  0.202768          NaN\n",
      "4  0.652833          NaN\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "        SanitizeValueCB(),               \n",
    "        NormalizeUncCB()\n",
    "    ])\n",
    "tfm()\n",
    "\n",
    "for grp in ['SEAWATER', 'BIOTA']:\n",
    "    print(f'\\n{grp}:')\n",
    "    print(tfm.dfs[grp][['VALUE', 'UNCERTAINTY']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68441b6",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f14236",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: It would be easier to work with the units if they were standardized. The units are not consistent across the dataset, for instance `BQ/L`, `Bq/l` and `Bq/L` are used interchangeably.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b04a3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `Unit` column contains `NaN` values for the `SEAWATER` dataset, as shown below.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af1b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
       "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
       "       'LongS', 'LongDir', 'Sample type', 'Sampling depth', 'Sampling date',\n",
       "       'Nuclide', 'Value type', 'Activity or MDA', 'Uncertainty', 'Unit',\n",
       "       'Data provider', 'Measurement Comment', 'Sample Comment',\n",
       "       'Reference Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['SEAWATER'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a69cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contracting Party</th>\n",
       "      <th>RSC Sub-division</th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>LatD</th>\n",
       "      <th>LatM</th>\n",
       "      <th>LatS</th>\n",
       "      <th>LatDir</th>\n",
       "      <th>LongD</th>\n",
       "      <th>...</th>\n",
       "      <th>LongDir</th>\n",
       "      <th>Sample type</th>\n",
       "      <th>Sampling depth</th>\n",
       "      <th>Sampling date</th>\n",
       "      <th>Nuclide</th>\n",
       "      <th>Value type</th>\n",
       "      <th>Activity or MDA</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Data provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>120369</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Salthill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16162</th>\n",
       "      <td>120370</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Woodstown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16586</th>\n",
       "      <td>120363</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19188</th>\n",
       "      <td>120364</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19189</th>\n",
       "      <td>120365</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Contracting Party  RSC Sub-division Station ID Sample ID  LatD  \\\n",
       "16161  120369           Ireland               1.0   Salthill       NaN    53   \n",
       "16162  120370           Ireland               1.0  Woodstown       NaN    52   \n",
       "16586  120363           Ireland               4.0         N1       NaN    53   \n",
       "19188  120364           Ireland               4.0         N2       NaN    53   \n",
       "19189  120365           Ireland               4.0         N3       NaN    53   \n",
       "\n",
       "       LatM  LatS LatDir  LongD  ...  LongDir  Sample type Sampling depth  \\\n",
       "16161  15.0  40.0      N      9  ...        W          NaN            NaN   \n",
       "16162  11.0  55.0      N      6  ...        W          NaN            NaN   \n",
       "16586  25.0   0.0      N      6  ...        W          NaN            NaN   \n",
       "19188  36.0   0.0      N      5  ...        W          NaN            NaN   \n",
       "19189  44.0   0.0      N      5  ...        W          NaN            NaN   \n",
       "\n",
       "      Sampling date  Nuclide Value type Activity or MDA Uncertainty  Unit  \\\n",
       "16161           NaN      NaN        NaN             NaN         NaN   NaN   \n",
       "16162           NaN      NaN        NaN             NaN         NaN   NaN   \n",
       "16586           NaN      NaN        NaN             NaN         NaN   NaN   \n",
       "19188           NaN      NaN        NaN             NaN         NaN   NaN   \n",
       "19189           NaN      NaN        NaN             NaN         NaN   NaN   \n",
       "\n",
       "       Data provider  \n",
       "16161            NaN  \n",
       "16162            NaN  \n",
       "16586            NaN  \n",
       "19188            NaN  \n",
       "19189            NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['SEAWATER'][dfs['SEAWATER']['Unit'].isnull()].drop(columns=['Measurement Comment','Sample Comment','Reference Comment']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b984de",
   "metadata": {},
   "source": [
    "Let's inspect the unique units used by OSPAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a486579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg f.w.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BQ/L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       value\n",
       "0      0         NaN\n",
       "1      1        Bq/l\n",
       "2      2        Bq/L\n",
       "3      3  Bq/kg f.w.\n",
       "4      4        BQ/L"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_across_dfs(dfs, col_name='Unit', as_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b05fd",
   "metadata": {},
   "source": [
    "We define unit renaming rules for OSPAR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {'Bq/l': 1, #'Bq/m3'\n",
    "                       'Bq/L': 1,\n",
    "                       'BQ/L': 1,\n",
    "                       'Bq/kg f.w.': 5, # Bq/kgw\n",
    "                       } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd777d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapUnitCB(Callback):\n",
    "    \"\"\"Callback to update DataFrame 'UNIT' columns based on a lookup table.\"\"\"\n",
    "\n",
    "    def __init__(self, lut: Dict[str, str]):\n",
    "        fc.store_attr('lut')  # Store the lookup table as an attribute\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            #if grp == 'seawater':\n",
    "            #    self._apply_default_units(df)\n",
    "            self._print_na_units(df)\n",
    "            self._update_units(df)\n",
    "\n",
    "    def _apply_default_units(self, df: pd.DataFrame):\n",
    "        df.loc[df['Unit'].isnull(), 'Unit'] = 'Bq/l'\n",
    "\n",
    "    def _print_na_units(self, df: pd.DataFrame):\n",
    "        na_count = df['Unit'].isnull().sum()\n",
    "        if na_count > 0:\n",
    "            print(f\"Number of rows with NaN in 'Unit' column: {na_count}\")\n",
    "\n",
    "    def _update_units(self, df: pd.DataFrame):\n",
    "        df['UNIT'] = df['Unit'].apply(lambda x: self.lut.get(x, 'Unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ebf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           SEAWATER  BIOTA\n",
      "Number of rows in dfs         19193  15951\n",
      "Number of rows in tfm.dfs     19183  15951\n",
      "Number of rows removed           10      0 \n",
      "\n",
      "Unit unique values:\n",
      "BIOTA: [5]\n",
      "SEAWATER: [1]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValueCB(), # Remove blank value entries (also removes NaN values in Unit column) \n",
    "                            RemapUnitCB(renaming_unit_rules),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('Unit unique values:')\n",
    "for grp in ['BIOTA', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm.dfs[grp]['UNIT'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46934ac0",
   "metadata": {},
   "source": [
    "## Remap detection limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62974e04",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `Value type` column contains many `nan` values, see below.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN 'Value type' entries in 'SEAWATER': 64\n",
      "Number of NaN 'Value type' entries in 'BIOTA': 23\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN entries in the 'Value type' column for 'SEAWATER'\n",
    "na_count_seawater = dfs['SEAWATER']['Value type'].isnull().sum()\n",
    "print(f\"Number of NaN 'Value type' entries in 'SEAWATER': {na_count_seawater}\")\n",
    "\n",
    "# Count the number of NaN entries in the 'Value type' column for 'BIOTA'\n",
    "na_count_biota = dfs['BIOTA']['Value type'].isnull().sum()\n",
    "print(f\"Number of NaN 'Value type' entries in 'BIOTA': {na_count_biota}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de72f18f",
   "metadata": {},
   "source": [
    "In the OSPAR dataset the detection limit is encoded as `<`  in the `Value type` column. If a value is `<` then the `Activity or MDA` column contains the detection limit value. If the `Value type` is `=` then the `Activity or MDA` column contains the measurement value.\n",
    "\n",
    "\n",
    "Lets review the `Value type` column values for the OSPAR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER:\n",
      "['<' '=' nan]\n",
      "BIOTA:\n",
      "['<' '=' nan]\n"
     ]
    }
   ],
   "source": [
    "for grp in dfs.keys():\n",
    "    print(f'{grp}:')\n",
    "    print(tfm.dfs[grp]['Value type'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126490ff",
   "metadata": {},
   "source": [
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84736d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'SEAWATER' : {'DL' : 'Value type'},\n",
    "          'BIOTA':  {'DL' : 'Value type'}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6bea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 coi: dict,  # Column configuration dictionary\n",
    "                 fn_lut: Callable  # Lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "\n",
    "    def _update_detection_limit(self, \n",
    "                                df: pd.DataFrame,  # The DataFrame to modify\n",
    "                                grp: str,  # The group name to get the column configuration\n",
    "                                lut: dict  # The lookup table dictionary\n",
    "                               ) -> None:\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        \n",
    "        print('Attempting to update detection limit column...')\n",
    "        print(f'Group: {grp}')\n",
    "        print(self.coi)\n",
    "        \n",
    "        # Access column names from coi_dl\n",
    "        detection_col = self.coi[grp]['DL']   \n",
    "        \n",
    "        print(f'Detection column: {detection_col}') \n",
    "        \n",
    "        # Initialize detection limit column\n",
    "        df['DL'] = df[detection_col]\n",
    "        \n",
    "        # Set detection limits based on conditions\n",
    "        self._set_detection_limits(df, lut)\n",
    "\n",
    "    def _set_detection_limits(self, df: pd.DataFrame, lut: dict) -> None:\n",
    "        \"Set detection limits based on value and uncertainty columns.\"\n",
    "        \n",
    "        # Condition for setting '='\n",
    "        condition_eq = (df['VALUE'].notna() & \n",
    "                        df['UNCERTAINTY'].notna() & \n",
    "                        ~df['DL'].isin(lut.keys()))\n",
    "        \n",
    "        df.loc[condition_eq, 'DL'] = '='\n",
    "\n",
    "        # Set 'Not Available' for unmatched detection limits\n",
    "        df.loc[~df['DL'].isin(lut.keys()), 'DL'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup to map detection limits\n",
    "        df['DL'] = df['DL'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce844f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to update detection limit column...\n",
      "Group: SEAWATER\n",
      "{'SEAWATER': {'DL': 'Value type'}, 'BIOTA': {'DL': 'Value type'}}\n",
      "Detection column: Value type\n",
      "Attempting to update detection limit column...\n",
      "Group: BIOTA\n",
      "{'SEAWATER': {'DL': 'Value type'}, 'BIOTA': {'DL': 'Value type'}}\n",
      "Detection column: Value type\n",
      "BIOTA: [2 1]\n",
      "SEAWATER: [2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValueCB(),\n",
    "                            NormalizeUncCB(),                  \n",
    "                            RemapUnitCB(renaming_unit_rules),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl)])\n",
    "tfm()\n",
    "for grp in ['BIOTA', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm.dfs[grp]['DL'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d25e19",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a498b08",
   "metadata": {},
   "source": [
    "We will remap the OSPAR `Species` column to the MARIS `SPECIES` column using the **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply) pattern. First lets **inspect** inspect unique `Species` values used by OSPAR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcc466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FUCUS SPP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LITTORINA LITTOREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Melanogrammus aeglefinus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MELANOGRAMMUS AEGLEFINUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>Gadus sp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>Pleuronectes platessa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>Gadiculus argenteus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>Cyclopterus lumpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>Tapes sp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                     value\n",
       "0        0                FUCUS SPP.\n",
       "1        1                       NaN\n",
       "2        2        LITTORINA LITTOREA\n",
       "3        3  Melanogrammus aeglefinus\n",
       "4        4  MELANOGRAMMUS AEGLEFINUS\n",
       "..     ...                       ...\n",
       "162    162                 Gadus sp.\n",
       "163    163    Pleuronectes platessa \n",
       "164    164       Gadiculus argenteus\n",
       "165    165        Cyclopterus lumpus\n",
       "166    166                 Tapes sp.\n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = load_data(fname_in)\n",
    "get_unique_across_dfs(dfs, col_name='Species', as_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47017e",
   "metadata": {},
   "source": [
    "Now we try to **MATCH** the `Species` column of ``OSPAR`` ``BIOTA`` dataset to the `species` column of the MARIS species lookup table, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs, col_name='Species', as_df=True),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='species_ospar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb98f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|███████▉  | 133/167 [00:33<01:11,  2.10s/it]"
     ]
    }
   ],
   "source": [
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a388bf",
   "metadata": {},
   "source": [
    "Below, we will correct the entries that were not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "fixes_biota_species = {\n",
    "    'RHODYMENIA PSEUDOPALAMATA & PALMARIA PALMATA': NA,    \n",
    "    'Mixture of green, red and brown algae': NA,\n",
    "    'SOLEA SOLEA (S.VULGARIS)': 'Solea solea',\n",
    "    'Solea solea (S.vulgaris)': 'Solea solea',\n",
    "    'RAJIDAE/BATOIDEA': NA,\n",
    "    'PALMARIA PALMATA': NA,\n",
    "    'Gadiculus argenteus': 'Gadiculus argenteus thori',\n",
    "    'MONODONTA LINEATA': 'Phorcus lineatus', #PMG please check is this is correct\n",
    "    'Unknown': NA,\n",
    "    'unknown': NA,\n",
    "    'Flatfish': 'Pisces',\n",
    "    'Gadus sp.': 'Gadus'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacedba9",
   "metadata": {},
   "source": [
    "And give it an another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 167/167 [00:32<00:00,  5.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CERASTODERMA (CARDIUM) EDULE</th>\n",
       "      <td>Cerastoderma edule</td>\n",
       "      <td>CERASTODERMA (CARDIUM) EDULE</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerastoderma (Cardium) Edule</th>\n",
       "      <td>Cerastoderma edule</td>\n",
       "      <td>Cerastoderma (Cardium) Edule</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICENTRARCHUS (MORONE) LABRAX</th>\n",
       "      <td>Dicentrarchus labrax</td>\n",
       "      <td>DICENTRARCHUS (MORONE) LABRAX</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleuronectiformes [order]</th>\n",
       "      <td>Pleuronectiformes</td>\n",
       "      <td>Pleuronectiformes [order]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUCUS SPP.</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>FUCUS SPP.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhodymenia spp.</th>\n",
       "      <td>Rhodymenia</td>\n",
       "      <td>Rhodymenia spp.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sepia spp.</th>\n",
       "      <td>Sepia</td>\n",
       "      <td>Sepia spp.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAJA DIPTURUS BATIS</th>\n",
       "      <td>Dipturus batis</td>\n",
       "      <td>RAJA DIPTURUS BATIS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunnus sp.</th>\n",
       "      <td>Thunnus</td>\n",
       "      <td>Thunnus sp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patella sp.</th>\n",
       "      <td>Patella</td>\n",
       "      <td>Patella sp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHODYMENIA spp</th>\n",
       "      <td>Rhodymenia</td>\n",
       "      <td>RHODYMENIA spp</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tapes sp.</th>\n",
       "      <td>Tapes</td>\n",
       "      <td>Tapes sp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUCUS spp</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>FUCUS spp</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fucus sp.</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>Fucus sp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MERLANGUIS MERLANGUIS</th>\n",
       "      <td>Merlangius merlangus</td>\n",
       "      <td>MERLANGUIS MERLANGUIS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaidropsarus argenteus</th>\n",
       "      <td>Gaidropsarus argentatus</td>\n",
       "      <td>Gaidropsarus argenteus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLUERONECTES PLATESSA</th>\n",
       "      <td>Pleuronectes platessa</td>\n",
       "      <td>PLUERONECTES PLATESSA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trisopterus esmarki</th>\n",
       "      <td>Trisopterus esmarkii</td>\n",
       "      <td>Trisopterus esmarki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gadus morhua</th>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>Gadus morhua</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melanogrammus aeglefinus</th>\n",
       "      <td>Melanogrammus aeglefinus</td>\n",
       "      <td>Melanogrammus aeglefinus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clupea harengus</th>\n",
       "      <td>Clupea harengus</td>\n",
       "      <td>Clupea harengus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sebastes vivipares</th>\n",
       "      <td>Sebastes viviparus</td>\n",
       "      <td>Sebastes vivipares</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippoglossus hippoglossus</th>\n",
       "      <td>Hippoglossus hippoglossus</td>\n",
       "      <td>Hippoglossus hippoglossus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASCOPHYLLUN NODOSUM</th>\n",
       "      <td>Ascophyllum nodosum</td>\n",
       "      <td>ASCOPHYLLUN NODOSUM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleuronectes platessa</th>\n",
       "      <td>Pleuronectes platessa</td>\n",
       "      <td>Pleuronectes platessa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MERLUCCIUS MERLUCCIUS</th>\n",
       "      <td>Merluccius merluccius</td>\n",
       "      <td>MERLUCCIUS MERLUCCIUS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      matched_maris_name  \\\n",
       "source_key                                                 \n",
       "CERASTODERMA (CARDIUM) EDULE          Cerastoderma edule   \n",
       "Cerastoderma (Cardium) Edule          Cerastoderma edule   \n",
       "DICENTRARCHUS (MORONE) LABRAX       Dicentrarchus labrax   \n",
       "Pleuronectiformes [order]              Pleuronectiformes   \n",
       "FUCUS SPP.                                         Fucus   \n",
       "Rhodymenia spp.                               Rhodymenia   \n",
       "Sepia spp.                                         Sepia   \n",
       "RAJA DIPTURUS BATIS                       Dipturus batis   \n",
       "Thunnus sp.                                      Thunnus   \n",
       "Patella sp.                                      Patella   \n",
       "RHODYMENIA spp                                Rhodymenia   \n",
       "Tapes sp.                                          Tapes   \n",
       "FUCUS spp                                          Fucus   \n",
       "Fucus sp.                                          Fucus   \n",
       "MERLANGUIS MERLANGUIS               Merlangius merlangus   \n",
       "Gaidropsarus argenteus           Gaidropsarus argentatus   \n",
       "PLUERONECTES PLATESSA              Pleuronectes platessa   \n",
       "Trisopterus esmarki                 Trisopterus esmarkii   \n",
       "Gadus morhua                                Gadus morhua   \n",
       "Melanogrammus aeglefinus        Melanogrammus aeglefinus   \n",
       "Clupea harengus                          Clupea harengus   \n",
       "Sebastes vivipares                    Sebastes viviparus   \n",
       "Hippoglossus hippoglossus      Hippoglossus hippoglossus   \n",
       "ASCOPHYLLUN NODOSUM                  Ascophyllum nodosum   \n",
       "Pleuronectes platessa              Pleuronectes platessa   \n",
       "MERLUCCIUS MERLUCCIUS              Merluccius merluccius   \n",
       "\n",
       "                                                 source_name  match_score  \n",
       "source_key                                                                 \n",
       "CERASTODERMA (CARDIUM) EDULE    CERASTODERMA (CARDIUM) EDULE           10  \n",
       "Cerastoderma (Cardium) Edule    Cerastoderma (Cardium) Edule           10  \n",
       "DICENTRARCHUS (MORONE) LABRAX  DICENTRARCHUS (MORONE) LABRAX            9  \n",
       "Pleuronectiformes [order]          Pleuronectiformes [order]            8  \n",
       "FUCUS SPP.                                        FUCUS SPP.            5  \n",
       "Rhodymenia spp.                              Rhodymenia spp.            5  \n",
       "Sepia spp.                                        Sepia spp.            5  \n",
       "RAJA DIPTURUS BATIS                      RAJA DIPTURUS BATIS            5  \n",
       "Thunnus sp.                                      Thunnus sp.            4  \n",
       "Patella sp.                                      Patella sp.            4  \n",
       "RHODYMENIA spp                                RHODYMENIA spp            4  \n",
       "Tapes sp.                                          Tapes sp.            4  \n",
       "FUCUS spp                                          FUCUS spp            4  \n",
       "Fucus sp.                                          Fucus sp.            4  \n",
       "MERLANGUIS MERLANGUIS                  MERLANGUIS MERLANGUIS            3  \n",
       "Gaidropsarus argenteus                Gaidropsarus argenteus            2  \n",
       "PLUERONECTES PLATESSA                  PLUERONECTES PLATESSA            2  \n",
       "Trisopterus esmarki                      Trisopterus esmarki            1  \n",
       "Gadus morhua                                   Gadus morhua             1  \n",
       "Melanogrammus aeglefinus           Melanogrammus aeglefinus             1  \n",
       "Clupea harengus                             Clupea harengus             1  \n",
       "Sebastes vivipares                        Sebastes vivipares            1  \n",
       "Hippoglossus hippoglossus         Hippoglossus hippoglossus             1  \n",
       "ASCOPHYLLUN NODOSUM                      ASCOPHYLLUN NODOSUM            1  \n",
       "Pleuronectes platessa                 Pleuronectes platessa             1  \n",
       "MERLUCCIUS MERLUCCIUS                 MERLUCCIUS MERLUCCIUS             1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4e864",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `Species` column to the `SPECIES` column after having defined the lookup table `lut_biota`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=get_unique_across_dfs(dfs, col_name='Species', as_df=True),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='value',\n",
    "                             provider_col_key='value',\n",
    "                             fname_cache='species_ospar.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88311de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: Hippoglossus hippoglossus\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "Unmatched value: nan\n",
      "[ 377  129   96   -1  192   99   50  378  270  379  380  381  382  383\n",
      "  384  385  244  386  387  388  389  390  391  392  393  394  395  396\n",
      "  274  397  398  243  399  400  401  402  403  404  405  406  407    0\n",
      "  191  139  408  409  410  712  412  413  272  414  415  416  417  418\n",
      "  419  420  421  422  423  424  425  426  427  428  411  429  430  431\n",
      "  432  433  434  435  436  437  438  439  440  441  442  443  444  294\n",
      " 1607 1610 1609 1605 1608   23 1606  234  556 1701 1752  158]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='Species', dest_grps='BIOTA', verbose=True)\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "print(tfm.dfs['BIOTA']['SPECIES'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a539ca2",
   "metadata": {},
   "source": [
    "## Remap Biota species enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ac2f3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Many entries for `Species` in the Ospar biota dataset are nan, see below.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2198"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BIOTA']['Species'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a944621",
   "metadata": {},
   "source": [
    "The values that include a `-1` in the `SPECIES` column are not matched by the `Remapper` object. The corresponding `Biological group` values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af1711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fish'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BIOTA'][tfm.dfs['BIOTA']['SPECIES'] == -1]['Biological group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffe69f",
   "metadata": {},
   "source": [
    "The ``Biological group`` column in the ``OSPAR`` dataset provides valuable insights related to ``SPECIES``. We will leverage this information to enrich the ``species`` column. To achieve this, we will employ the generic ``RemapCB`` callback to create an ``enhanced_species`` column. Subsequently, this enhanced_species column will be used to further enrich the species column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c175d",
   "metadata": {},
   "source": [
    "First we inspect the unique values in the Biological group column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67872ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Seaweeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Molluscs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>molluscs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Seaweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>SEAWEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>seaweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>MOLLUSCS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     value\n",
       "0      0  Seaweeds\n",
       "1      1  Molluscs\n",
       "2      2  molluscs\n",
       "3      3      fish\n",
       "4      4      Fish\n",
       "5      5   Seaweed\n",
       "6      6   SEAWEED\n",
       "7      7      FISH\n",
       "8      8   seaweed\n",
       "9      9  MOLLUSCS"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_across_dfs(dfs, col_name='Biological group', as_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1435f",
   "metadata": {},
   "source": [
    "We will remap the Biological group columns data to the species column of the MARIS nomenclature, again using a Remapper object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b62054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs, col_name='Biological group', as_df=True),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='enhance_species_ospar.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c71d7",
   "metadata": {},
   "source": [
    "Like before we will generate the lookup table and select matches that meet a specified threshold (i.e., greater than 1), which means that matches requiring more than one character change are shown.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c945312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 entries matched the criteria, while 7 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>fish</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>Fish</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FISH</th>\n",
       "      <td>Fucus</td>\n",
       "      <td>FISH</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seaweeds</th>\n",
       "      <td>Seaweed</td>\n",
       "      <td>Seaweeds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Molluscs</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>Molluscs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molluscs</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>molluscs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOLLUSCS</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>MOLLUSCS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "fish                    Fucus        fish            4\n",
       "Fish                    Fucus        Fish            4\n",
       "FISH                    Fucus        FISH            4\n",
       "Seaweeds              Seaweed    Seaweeds            1\n",
       "Molluscs             Mollusca    Molluscs            1\n",
       "molluscs             Mollusca    molluscs            1\n",
       "MOLLUSCS             Mollusca    MOLLUSCS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fd08c",
   "metadata": {},
   "source": [
    "`fixes_biota_species_enhanced` applies manual fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "fixes_enhanced_biota_species = {\n",
    "    'fish': 'Pisces',\n",
    "    'FISH': 'Pisces',\n",
    "    'Fish': 'Pisces'    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b193f4c",
   "metadata": {},
   "source": [
    "Now we will apply the manual corrections to the lookup table and generate the lookup table again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10/10 [00:02<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seaweeds</th>\n",
       "      <td>Seaweed</td>\n",
       "      <td>Seaweeds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Molluscs</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>Molluscs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molluscs</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>molluscs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOLLUSCS</th>\n",
       "      <td>Mollusca</td>\n",
       "      <td>MOLLUSCS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "Seaweeds              Seaweed    Seaweeds            1\n",
       "Molluscs             Mollusca    Molluscs            1\n",
       "molluscs             Mollusca    molluscs            1\n",
       "MOLLUSCS             Mollusca    MOLLUSCS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_enhanced_biota_species)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de55056",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining imperfectly matched entries appears acceptable. We can now proceed with the final remapping process:\n",
    "\n",
    "Create Remapper Lambda Function:\n",
    "\n",
    "We'll define a lambda function that instantiates a Remapper object and returns its corrected lookup table.\n",
    "\n",
    "Apply RemapCB:\n",
    "\n",
    "Using the generic RemapCB callback, we'll perform the actual remapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae403c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| exports\n",
    "lut_biota_enhanced = lambda: Remapper(provider_lut_df=get_unique_across_dfs(dfs, col_name='Biological group', as_df=True),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='value',\n",
    "                             provider_col_key='value',\n",
    "                             fname_cache='enhance_species_ospar.pkl').generate_lookup_table(fixes=fixes_enhanced_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3e948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 873, 1059,  712])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota_enhanced, col_remap='enhanced_species', col_src='Biological group', dest_grps='BIOTA')    \n",
    "    ])\n",
    "\n",
    "tfm()['BIOTA']['enhanced_species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e565948",
   "metadata": {},
   "source": [
    "Now that we have the enhanced_species column, we can use it to enrich the species column. We will use the enhanced species column in the absence of a species match if the enhanced species column is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class EnhanceSpeciesCB(Callback):\n",
    "    \"\"\"Enhance the 'species' column using the 'enhanced_species' column if conditions are met.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        self._enhance_species(tfm.dfs['BIOTA'])\n",
    "\n",
    "    def _enhance_species(self, df: pd.DataFrame):\n",
    "        df['SPECIES'] = df.apply(\n",
    "            lambda row: row['enhanced_species'] if row['SPECIES'] in [-1, 0] and pd.notnull(row['enhanced_species']) else row['SPECIES'],\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaed46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 377,  129,   96,  712,  192,   99,   50,  378,  270,  379,  380,\n",
       "        381,  382,  383,  384,  385,  244,  386,  387,  388,  389,  390,\n",
       "        391,  392,  393,  394,  395,  396,  274,  397,  398,  243,  399,\n",
       "        400,  401,  402,  403,  404,  405,  406,  407, 1059,  191,  139,\n",
       "        408,  409,  410,  412,  413,  272,  414,  415,  416,  417,  418,\n",
       "        419,  420,  421,  422,  423,  424,  425,  426,  427,  428,  411,\n",
       "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  439,\n",
       "        440,  441,  442,  443,  444,  294, 1607, 1610, 1609, 1605, 1608,\n",
       "         23, 1606,  234,  556, 1701, 1752,  158])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='Species', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_biota_enhanced, col_remap='enhanced_species', col_src='Biological group', dest_grps='BIOTA'),\n",
    "    EnhanceSpeciesCB()\n",
    "    ])\n",
    "\n",
    "tfm()['BIOTA']['SPECIES'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf49f45",
   "metadata": {},
   "source": [
    "## Remap Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f8214",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "FEEDBACK TO DATA PROVIDER: biota dataset includes 1 entry where the Body Part is FLESH WITHOUT BONES for the Biological group of SEAWEED, see below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c048c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contracting Party</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Biological group</th>\n",
       "      <th>Body Part</th>\n",
       "      <th>Measurement Comment</th>\n",
       "      <th>Sample Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13057</th>\n",
       "      <td>87356</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>THFAG17C</td>\n",
       "      <td>SEAWEED</td>\n",
       "      <td>FLESH WITHOUT BONES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Contracting Party Sample ID Biological group  \\\n",
       "13057  87356           Iceland  THFAG17C          SEAWEED   \n",
       "\n",
       "                 Body Part Measurement Comment Sample Comment  \n",
       "13057  FLESH WITHOUT BONES                 NaN            NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BIOTA'][['ID','Contracting Party','Sample ID','Biological group','Body Part', 'Measurement Comment', 'Sample Comment']][(tfm.dfs['BIOTA']['Body Part'] == 'FLESH WITHOUT BONES') & (tfm.dfs['BIOTA']['Biological group'] == 'SEAWEED')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6b178",
   "metadata": {},
   "source": [
    "The ``OSPAR`` dataset includes entries where the ``Body Part`` is labeled as ``whole``. However, the MARIS data standard requires a more specific distinction in the ``body_part`` field, differentiating between ``Whole animal`` and ``Whole plant``. Fortunately, the OSPAR data provides a Biological group field that allows us to make this distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4370a",
   "metadata": {},
   "source": [
    "To address this discrepancy and ensure compatibility with MARIS standards, we will:\n",
    "\n",
    "1. Create a temporary column body_part_temp that combines information from both Body Part and Biological group.\n",
    "2. Use this temporary column to perform the lookup using our Remapper object.\n",
    "\n",
    "Lets create the temporary column, body_part_temp, that combines Body Part and Biological group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba445992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddBodyPartTempCB(Callback):\n",
    "    \"Add a temporary column with the body part and biological group combined.\"    \n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs['BIOTA']['body_part_temp'] = (\n",
    "            tfm.dfs['BIOTA']['Body Part'] + ' ' + \n",
    "            tfm.dfs['BIOTA']['Biological group']\n",
    "            ).astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e3950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['whole animal molluscs', 'whole plant seaweed', 'whole fish fish',\n",
       "       'flesh without bones fish', 'whole animal fish', 'muscle fish',\n",
       "       'head fish', 'soft parts molluscs', 'growing tips seaweed',\n",
       "       'soft parts fish', 'unknown fish', 'flesh without bone fish',\n",
       "       'flesh fish', 'flesh with scales fish', 'liver fish',\n",
       "       'flesh without bones seaweed', 'whole  fish',\n",
       "       'flesh without bones molluscs', 'whole  seaweed',\n",
       "       'whole plant seaweeds', 'whole fish', 'whole without head fish',\n",
       "       'mix of muscle and whole fish without liver fish',\n",
       "       'whole fisk fish', 'muscle  fish', 'cod medallion fish',\n",
       "       'tail and claws fish'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[  \n",
    "                            AddBodyPartTempCB(),\n",
    "                            ])\n",
    "dfs_test = tfm()\n",
    "dfs_test['BIOTA']['body_part_temp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867c4f0",
   "metadata": {},
   "source": [
    "To align the body_part_temp column with the bodypar column in the MARIS nomenclature, we utilize a Remapper object. Since the OSPAR dataset does not include a predefined lookup table for the body_part column, we first create a lookup table by extracting unique values from the body_part_temp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6465c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>head fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>whole animal molluscs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>growing tips seaweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>muscle  fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>whole without head fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>whole fish fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>flesh without bones molluscs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>unknown fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>whole plant seaweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>whole fish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         value\n",
       "0      0                     head fish\n",
       "1      1         whole animal molluscs\n",
       "2      2          growing tips seaweed\n",
       "3      3                  muscle  fish\n",
       "4      4       whole without head fish\n",
       "5      5               whole fish fish\n",
       "6      6  flesh without bones molluscs\n",
       "7      7                  unknown fish\n",
       "8      8           whole plant seaweed\n",
       "9      9                    whole fish"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_across_dfs(dfs_test, col_name='body_part_temp', as_df=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcabfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 27/27 [00:00<00:00, 84.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mix of muscle and whole fish without liver fish</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>mix of muscle and whole fish without liver fish</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cod medallion fish</th>\n",
       "      <td>Old leaf</td>\n",
       "      <td>cod medallion fish</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole without head fish</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>whole without head fish</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tail and claws fish</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>tail and claws fish</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole plant seaweeds</th>\n",
       "      <td>Whole plant</td>\n",
       "      <td>whole plant seaweeds</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    matched_maris_name  \\\n",
       "source_key                                                               \n",
       "mix of muscle and whole fish without liver fish    Flesh without bones   \n",
       "cod medallion fish                                            Old leaf   \n",
       "whole without head fish                            Flesh without bones   \n",
       "tail and claws fish                              Stomach and intestine   \n",
       "whole plant seaweeds                                       Whole plant   \n",
       "\n",
       "                                                                                     source_name  \\\n",
       "source_key                                                                                         \n",
       "mix of muscle and whole fish without liver fish  mix of muscle and whole fish without liver fish   \n",
       "cod medallion fish                                                            cod medallion fish   \n",
       "whole without head fish                                                  whole without head fish   \n",
       "tail and claws fish                                                          tail and claws fish   \n",
       "whole plant seaweeds                                                        whole plant seaweeds   \n",
       "\n",
       "                                                 match_score  \n",
       "source_key                                                    \n",
       "mix of muscle and whole fish without liver fish           31  \n",
       "cod medallion fish                                        13  \n",
       "whole without head fish                                   13  \n",
       "tail and claws fish                                       13  \n",
       "whole plant seaweeds                                       9  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_test, col_name='body_part_temp', as_df=True),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='bodyparts_ospar.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=0).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213246de",
   "metadata": {},
   "source": [
    "Many of the lookup entries are sufficient for our needs. However, for values that don't find a match, we can use the fixes_biota_bodyparts dictionary to apply manual corrections. First we will create the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69440d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "fixes_biota_tissues = {\n",
    "                    'mix of muscle and whole fish without liver fish': NA,\n",
    "                    'cod medallion fish': NA,\n",
    "                    'whole without head fish': 'Whole animal eviscerated without head',\n",
    "                    'tail and claws fish': NA,\n",
    "                    'whole plant seaweeds': NA,\n",
    "                    'soft parts molluscs': NA,\n",
    "                    'whole animal molluscs': NA,\n",
    "                    'whole fisk fish': NA,\n",
    "                    'unknown fish': NA,\n",
    "                    'flesh without bones seaweed': NA, # This isnt possible\n",
    "                    'flesh fish': 'Flesh without bones'\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3c925",
   "metadata": {},
   "source": [
    "Lets correct the unmatched entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 27/27 [00:00<00:00, 83.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whole fish fish</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>whole fish fish</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh without bones molluscs</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>flesh without bones molluscs</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growing tips seaweed</th>\n",
       "      <td>Growing tips</td>\n",
       "      <td>growing tips seaweed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole plant seaweed</th>\n",
       "      <td>Whole plant</td>\n",
       "      <td>whole plant seaweed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole  seaweed</th>\n",
       "      <td>Whole plant</td>\n",
       "      <td>whole  seaweed</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muscle  fish</th>\n",
       "      <td>Muscle</td>\n",
       "      <td>muscle  fish</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head fish</th>\n",
       "      <td>Head</td>\n",
       "      <td>head fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muscle fish</th>\n",
       "      <td>Muscle</td>\n",
       "      <td>muscle fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole  fish</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>whole  fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liver fish</th>\n",
       "      <td>Liver</td>\n",
       "      <td>liver fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole animal fish</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>whole animal fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh with scales fish</th>\n",
       "      <td>Flesh with scales</td>\n",
       "      <td>flesh with scales fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh without bones fish</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>flesh without bones fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft parts fish</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>soft parts fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole fish</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>whole fish</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh without bone fish</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>flesh without bone fish</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole animal molluscs</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>whole animal molluscs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tail and claws fish</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>tail and claws fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole plant seaweeds</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>whole plant seaweeds</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft parts molluscs</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>soft parts molluscs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole fisk fish</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>whole fisk fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesh without bones seaweed</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>flesh without bones seaweed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cod medallion fish</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>cod medallion fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown fish</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>unknown fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mix of muscle and whole fish without liver fish</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>mix of muscle and whole fish without liver fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  matched_maris_name  \\\n",
       "source_key                                                             \n",
       "whole fish fish                                         Whole animal   \n",
       "flesh without bones molluscs                     Flesh without bones   \n",
       "growing tips seaweed                                    Growing tips   \n",
       "whole plant seaweed                                      Whole plant   \n",
       "whole  seaweed                                           Whole plant   \n",
       "muscle  fish                                                  Muscle   \n",
       "head fish                                                       Head   \n",
       "muscle fish                                                   Muscle   \n",
       "whole  fish                                             Whole animal   \n",
       "liver fish                                                     Liver   \n",
       "whole animal fish                                       Whole animal   \n",
       "flesh with scales fish                             Flesh with scales   \n",
       "flesh without bones fish                         Flesh without bones   \n",
       "soft parts fish                                           Soft parts   \n",
       "whole fish                                              Whole animal   \n",
       "flesh without bone fish                          Flesh without bones   \n",
       "whole animal molluscs                                (Not available)   \n",
       "tail and claws fish                                  (Not available)   \n",
       "whole plant seaweeds                                 (Not available)   \n",
       "soft parts molluscs                                  (Not available)   \n",
       "whole fisk fish                                      (Not available)   \n",
       "flesh without bones seaweed                          (Not available)   \n",
       "cod medallion fish                                   (Not available)   \n",
       "unknown fish                                         (Not available)   \n",
       "mix of muscle and whole fish without liver fish      (Not available)   \n",
       "\n",
       "                                                                                     source_name  \\\n",
       "source_key                                                                                         \n",
       "whole fish fish                                                                  whole fish fish   \n",
       "flesh without bones molluscs                                        flesh without bones molluscs   \n",
       "growing tips seaweed                                                        growing tips seaweed   \n",
       "whole plant seaweed                                                          whole plant seaweed   \n",
       "whole  seaweed                                                                    whole  seaweed   \n",
       "muscle  fish                                                                        muscle  fish   \n",
       "head fish                                                                              head fish   \n",
       "muscle fish                                                                          muscle fish   \n",
       "whole  fish                                                                          whole  fish   \n",
       "liver fish                                                                            liver fish   \n",
       "whole animal fish                                                              whole animal fish   \n",
       "flesh with scales fish                                                    flesh with scales fish   \n",
       "flesh without bones fish                                                flesh without bones fish   \n",
       "soft parts fish                                                                  soft parts fish   \n",
       "whole fish                                                                            whole fish   \n",
       "flesh without bone fish                                                  flesh without bone fish   \n",
       "whole animal molluscs                                                      whole animal molluscs   \n",
       "tail and claws fish                                                          tail and claws fish   \n",
       "whole plant seaweeds                                                        whole plant seaweeds   \n",
       "soft parts molluscs                                                          soft parts molluscs   \n",
       "whole fisk fish                                                                  whole fisk fish   \n",
       "flesh without bones seaweed                                          flesh without bones seaweed   \n",
       "cod medallion fish                                                            cod medallion fish   \n",
       "unknown fish                                                                        unknown fish   \n",
       "mix of muscle and whole fish without liver fish  mix of muscle and whole fish without liver fish   \n",
       "\n",
       "                                                 match_score  \n",
       "source_key                                                    \n",
       "whole fish fish                                            9  \n",
       "flesh without bones molluscs                               9  \n",
       "growing tips seaweed                                       8  \n",
       "whole plant seaweed                                        8  \n",
       "whole  seaweed                                             7  \n",
       "muscle  fish                                               6  \n",
       "head fish                                                  5  \n",
       "muscle fish                                                5  \n",
       "whole  fish                                                5  \n",
       "liver fish                                                 5  \n",
       "whole animal fish                                          5  \n",
       "flesh with scales fish                                     5  \n",
       "flesh without bones fish                                   5  \n",
       "soft parts fish                                            5  \n",
       "whole fish                                                 5  \n",
       "flesh without bone fish                                    4  \n",
       "whole animal molluscs                                      2  \n",
       "tail and claws fish                                        2  \n",
       "whole plant seaweeds                                       2  \n",
       "soft parts molluscs                                        2  \n",
       "whole fisk fish                                            2  \n",
       "flesh without bones seaweed                                2  \n",
       "cod medallion fish                                         2  \n",
       "unknown fish                                               2  \n",
       "mix of muscle and whole fish without liver fish            2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1777716",
   "metadata": {},
   "source": [
    "At this stage, the majority of entries have been successfully matched to MARIS nomenclature. For those entries that remain unmatched, they are appropriately marked as not available. We can now proceed with the final remapping process:\n",
    "\n",
    "- Create Remapper Lambda Function:\n",
    "\n",
    "    We'll define a lambda function that instantiates a Remapper object and returns its corrected lookup table.\n",
    "\n",
    "- Apply RemapCB:\n",
    "\n",
    "    Using the generic RemapCB callback, we'll perform the actual remapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=get_unique_across_dfs(tfm.dfs, col_name='body_part_temp', as_df=True),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='value',\n",
    "                               provider_col_key='value',\n",
    "                               fname_cache='bodyparts_ospar.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4a31b",
   "metadata": {},
   "source": [
    "Putting it all together, we now apply the RemapCB to our data. This process results in the addition of a body_part column to our biota dataframe, containing standardized species IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 40,  1, 52, 34, 13, 56, 19, 60, 25,  3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[  \n",
    "                            AddBodyPartTempCB(),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='body_part_temp' , dest_grps='BIOTA')\n",
    "                            ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA']['BODY_PART'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {\n",
    "'Mix of muscle and whole fish without liver' : 'Not available', # Drop\n",
    " 'Whole without head' : 'Whole animal eviscerated without head', # Drop? eviscerated? ,\n",
    " 'Cod medallion' : 'Whole animal eviscerated without head',\n",
    " 'FLESH' : 'Flesh without bones', # Drop? with or without bones?\n",
    " 'Flesh' : 'Flesh without bones', # Drop? with or without bones?\n",
    " 'UNKNOWN' : 'Not available',\n",
    " 'FLESH WITHOUT BONE' : 'Flesh without bones'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6076a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_maris_lut' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [174], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tissues_lut_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_maris_lut\u001b[49m(df_biota\u001b[38;5;241m=\u001b[39mtfm\u001b[38;5;241m.\u001b[39mdfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiota\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                 fname_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtissues_ospar.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m                                 data_provider_name_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_part\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                 maris_lut\u001b[38;5;241m=\u001b[39mbodyparts_lut_path,\n\u001b[1;32m      6\u001b[0m                                 maris_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbodypar_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                 maris_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbodypar\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                 unmatched_fixes\u001b[38;5;241m=\u001b[39munmatched_fixes_biota_tissues,\n\u001b[1;32m      9\u001b[0m                                 as_dataframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                                 overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m tissues_lut_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_maris_lut' is not defined"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# tissues_lut_df = get_maris_lut(df_biota=tfm.dfs['biota'], \n",
    "#                                 fname_cache='tissues_ospar.pkl', \n",
    "#                                 data_provider_name_col='body_part',\n",
    "#                                 maris_lut=bodyparts_lut_path,\n",
    "#                                 maris_id='bodypar_id',\n",
    "#                                 maris_name='bodypar',\n",
    "#                                 unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "#                                 as_dataframe=True,\n",
    "#                                 overwrite=True)\n",
    "# tissues_lut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b66cf5",
   "metadata": {},
   "source": [
    "List unmatched OSPAR tissues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mix of muscle and whole fish without liver', 'UNKNOWN']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df[tissues_lut_df['match_score'] >= 1]['source_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866927f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    \"\"\"Update body part id based on MARIS dbo_bodypar.xlsx\"\"\"\n",
    "\n",
    "    def __init__(self, fn_lut: Callable, unmatched_fixes_biota_tissues: Dict[str, str]):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        lut = self.fn_lut(df_biota=tfm.dfs['biota'])\n",
    "        self.drop_nan_species(tfm.dfs['biota'])\n",
    "        self.drop_unmatched(tfm.dfs['biota'])\n",
    "        self.perform_lookup(tfm.dfs['biota'], lut)\n",
    "\n",
    "    def drop_nan_species(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Drop rows where 'body_part' is NaN.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "        \"\"\"\n",
    "        df.dropna(subset=['body_part'], inplace=True)\n",
    "\n",
    "    def drop_unmatched(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Drop rows where the 'body_part' is in the unmatched_fixes_biota_tissues list with value 'Not available'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "        \"\"\"\n",
    "        na_list = ['Not available']\n",
    "        na_biota_tissues = [k for k, v in self.unmatched_fixes_biota_tissues.items() if v in na_list]\n",
    "        df.drop(df[df['body_part'].isin(na_biota_tissues)].index, inplace=True)\n",
    "\n",
    "    def perform_lookup(self, df: pd.DataFrame, lut: Dict[str, 'Match']):\n",
    "        \"\"\"\n",
    "        Perform lookup to update 'body_part' with matched IDs.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "            lut (Dict[str, Match]): The lookup table.\n",
    "        \"\"\"\n",
    "        df['body_part'] = df['body_part'].apply(lambda x: lut[x].matched_id if x in lut else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_maris_bodypart=partial(get_maris_lut, \n",
    "                            fname_cache='tissues_ospar.pkl', \n",
    "                            data_provider_name_col='body_part',\n",
    "                            maris_lut=bodyparts_lut_path,\n",
    "                            maris_id='bodypar_id',\n",
    "                            maris_name='bodypar',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baf396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15308\n",
      "Number of dropped rows                                     0      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n",
      "      Body Part  body_part\n",
      "0    SOFT PARTS         19\n",
      "1  GROWING TIPS         56\n",
      "2    SOFT PARTS         19\n",
      "3    SOFT PARTS         19\n",
      "4  GROWING TIPS         56\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['Body Part', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c00f4",
   "metadata": {},
   "source": [
    "#### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51217e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE DONE\n",
    "# Species column contains nan\n",
    "# Niall replace with Biological group where missing\n",
    "# In our case, we will use remapped species, once \n",
    "# done we can use internal MARIS lookup to remap to biota group. \n",
    "# If species is missing, we can use the biological group to perform the lookup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmatched_fixes_biota_species.update({\n",
    "# # Biological group corrections\n",
    "# 'Molluscs' : 'Mollusca',\n",
    "# 'Seaweed' : 'Seaweed',\n",
    "# 'Fish' : 'Pisces',\n",
    "# 'FISH' : 'Pisces',\n",
    "# 'seaweed' : 'Seaweed',\n",
    "# 'SEAWEED' : 'Seaweed',\n",
    "# 'molluscs' : 'Mollusca',\n",
    "# 'fish' : 'Pisces',\n",
    "# 'MOLLUSCS' : 'Mollusca' })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c2023",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``bio_group``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75ca3c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Biogroup is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ae63b",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08392de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_biogroup_lut(maris_lut: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve a lookup table for biogroup ids from a MARIS lookup table.\n",
    "\n",
    "    Args:\n",
    "        maris_lut (str): Path to the MARIS lookup table (Excel file).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping species_id to biogroup_id.\n",
    "    \"\"\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620eef3b",
   "metadata": {},
   "source": [
    "`LookupBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiogroupCB(Callback):\n",
    "    \"\"\"Update biogroup id based on MARIS dbo_species.xlsx.\"\"\"\n",
    "\n",
    "    def __init__(self, fn_lut: Callable):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        lut = self.fn_lut()\n",
    "        self.update_bio_group(tfm.dfs['biota'], lut)\n",
    "\n",
    "    def update_bio_group(self, df: pd.DataFrame, lut: dict):\n",
    "        \"\"\"\n",
    "        Update the 'bio_group' column in the DataFrame based on the lookup table.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "            lut (Dict[str, Any]): The lookup table for updating 'bio_group'.\n",
    "        \"\"\"\n",
    "        df['bio_group'] = df['species'].apply(lambda x: lut.get(x, -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7e09c",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks ``LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species)``,``CorrectWholeBodyPartCB()``, ``LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues)``,             ``LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))``,   ``CompareDfsAndTfmCB(dfs)`` . Then, print the ``Body Part``, ``body_part``, ``species``,``bio_group`` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15308\n",
      "Number of dropped rows                                     0      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n",
      "      Body Part  body_part  species  bio_group\n",
      "0    SOFT PARTS         19      394         13\n",
      "1  GROWING TIPS         56       96         11\n",
      "2    SOFT PARTS         19      394         13\n",
      "3    SOFT PARTS         19      394         13\n",
      "4  GROWING TIPS         56       96         11\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['Body Part', 'body_part', 'species','bio_group']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393e5a3",
   "metadata": {},
   "source": [
    "Biota data dropped due to 'unkown' Body Part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mix of muscle and whole fish without liver' 'UNKNOWN']\n"
     ]
    }
   ],
   "source": [
    "print(tfm.dfs_dropped['biota']['Body Part'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ed5aa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1241ed",
   "metadata": {},
   "source": [
    "#### Lookup : Taxon Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72dee19",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Not included`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68672b28",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Taxonname`` , ``TaxonRepName``, ``Taxonrank``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb2734",
   "metadata": {},
   "source": [
    "`get_taxonname_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `Taxonname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_taxon_info_lut(maris_lut: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve a lookup table for Taxonname from a MARIS lookup table.\n",
    "\n",
    "    Args:\n",
    "        maris_lut (str): Path to the MARIS lookup table (Excel file).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping species_id to biogroup_id.\n",
    "    \"\"\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].set_index('species_id').to_dict()\n",
    "\n",
    "# TODO include Commonname field after next MARIS data reconciling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be821537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "class LookupTaxonInformationCB(Callback):\n",
    "    \"\"\"Update taxon names based on MARIS species LUT (dbo_species.xlsx).\"\"\"\n",
    "    def __init__(self, fn_lut: Callable[[], dict]):\n",
    "        \"\"\"\n",
    "        Initialize the LookupTaxonNameCB with a function to generate the lookup table.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Update the 'taxon_name' column in the DataFrame using the lookup table and print unmatched species IDs.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        \n",
    "        self._set_taxon_rep_name(tfm.dfs['biota'])\n",
    "        tfm.dfs['biota']['Taxonname'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Taxonname']))\n",
    "        #df['Commonname'] = df['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Commonname']))\n",
    "        tfm.dfs['biota']['Taxonrank'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Taxonrank']))\n",
    "        tfm.dfs['biota']['TaxonDB'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDB']))\n",
    "        tfm.dfs['biota']['TaxonDBID'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDBID']))\n",
    "        tfm.dfs['biota']['TaxonDBURL'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDBURL']))\n",
    "\n",
    "\n",
    "    def _set_taxon_rep_name(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap the 'TaxonRepName' column to the 'Species' column values.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        # Ensure both columns exist before attempting to remap\n",
    "        if 'Species' in df.columns:\n",
    "            df['TaxonRepName'] = df['Species']\n",
    "        else:\n",
    "            print(\"Warning: 'Species' column not found in DataFrame.\")\n",
    "            \n",
    "            \n",
    "\n",
    "    def _get_name_by_species_id(self, species_id: str, lut: dict) -> str:\n",
    "        \"\"\"\n",
    "        Get the  name from the lookup table and print species ID if the taxon name is not found.\n",
    "\n",
    "        Args:\n",
    "            species_id (str): The species ID from the DataFrame.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "\n",
    "        Returns:\n",
    "            str: The name from the lookup table.\n",
    "        \"\"\"\n",
    "        name = lut.get(species_id, 'Unknown')  # Default to 'Unknown' if not found\n",
    "        if name == 'Unknown':\n",
    "            print(f\"Unmatched species ID: {species_id} for {lut.keys()[0]}\")\n",
    "        return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15308\n",
      "Number of dropped rows                                     0      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n",
      "               Taxonname Taxonrank   TaxonDB TaxonDBID  \\\n",
      "0     Littorina littorea   species  Wikidata    Q27935   \n",
      "1      Fucus vesiculosus   species  Wikidata   Q754755   \n",
      "15        Mytilus edulis   species  Wikidata    Q27855   \n",
      "24       Clupea harengus   species  Wikidata  Q2396858   \n",
      "28  Merlangius merlangus   species  Wikidata   Q273083   \n",
      "\n",
      "                                TaxonDBURL  \n",
      "0     https://www.wikidata.org/wiki/Q27935  \n",
      "1    https://www.wikidata.org/wiki/Q754755  \n",
      "15    https://www.wikidata.org/wiki/Q27855  \n",
      "24  https://www.wikidata.org/wiki/Q2396858  \n",
      "28   https://www.wikidata.org/wiki/Q273083  \n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da9eda",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c8b5d",
   "metadata": {},
   "source": [
    "#### Lookup : Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68033b39",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1305c9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75061f",
   "metadata": {},
   "source": [
    "Create `renaming_unit_rules` to rename the units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {'Bq/l': 1, #'Bq/m3'\n",
    "                       'Bq/L': 1,\n",
    "                       'BQ/L': 1,\n",
    "                       'Bq/kg f.w.': 5, # Bq/kgw\n",
    "                       'Bq/kg.fw' : 5,\n",
    "                       'Bq/kg fw' : 5,\n",
    "                       'Bq/kg f.w' : 5 \n",
    "                       } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    \"\"\"Update the 'unit' column in DataFrames based on a lookup table.\n",
    "    The class handles:\n",
    "    - Assigning a default unit for NaN values in the 'Unit' column for specific groups.\n",
    "    - Dropping rows with NaN values in the 'Unit' column.\n",
    "    - Performing lookup to update the 'unit' column based on the provided lookup table.\"\"\"\n",
    "\n",
    "    def __init__(self, lut: dict = renaming_unit_rules):\n",
    "        \"\"\"\n",
    "        Initialize the LookupUnitCB with a lookup table.\n",
    "\n",
    "        Args:\n",
    "            lut (dict): A dictionary used for lookup to update the 'unit' column.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the callback to each DataFrame in the transformer.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer containing DataFrames to process.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp == 'seawater':\n",
    "                self._apply_units(tfm.dfs[grp])\n",
    "            self._drop_na_units(tfm.dfs[grp])\n",
    "            self._perform_lookup(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_units(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Apply a default unit where the 'Unit' column is NaN.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "        \"\"\"\n",
    "        df.loc[df['Unit'].isnull(), 'Unit'] = 'Bq/l'\n",
    "\n",
    "    def _drop_na_units(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Drop rows where the 'Unit' column has NaN values.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "        \"\"\"\n",
    "        df.dropna(subset=['Unit'], inplace=True)\n",
    "\n",
    "    def _perform_lookup(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Perform lookup to update the 'unit' column based on the lookup table.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "        \"\"\"\n",
    "        df['unit'] = df['Unit'].apply(lambda x: self.lut.get(x, 'Unknown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota']['unit'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73ac41",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fc3be",
   "metadata": {},
   "source": [
    "#### Lookup : Detection limit or Value type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9c6ae",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``detection_limit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a994a8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine foramt variable: ``Value type``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae826e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['=', '<', '>', nan], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "grp='biota'\n",
    "tfm.dfs[grp]['Value type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e102f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    \"\"\"Remap activity value, activity uncertainty, and detection limit to MARIS format.\n",
    "    This class performs the following operations:\n",
    "    - Reads a lookup table from an Excel file.\n",
    "    - Copies and processes the 'Value type' column.\n",
    "    - Fills NaN values with 'Not Available'.\n",
    "    - Drops rows where 'Value type' is not in the lookup table.\n",
    "    - Performs a lookup to update the 'detection_limit' column based on the lookup table.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lut_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the LookupDetectionLimitCB with a path to the lookup table.\n",
    "\n",
    "        Args:\n",
    "            lut_path (str): The path to the Excel file containing the lookup table.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the callback to each DataFrame in the transformer.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer containing DataFrames to process.\n",
    "        \"\"\"\n",
    "        lut = self._load_lookup_table()\n",
    "        for grp in tfm.dfs.keys():\n",
    "            df = tfm.dfs[grp]\n",
    "            df = self._copy_and_fill_na(df)\n",
    "            df = self._correct_greater_than(df)  # Ensure to correct 'Value type' if necessary\n",
    "            df = self._drop_na_rows(df, lut)\n",
    "            self._perform_lookup(df, lut)\n",
    "            tfm.dfs[grp] = df  # Update the DataFrame in the transformer\n",
    "\n",
    "    def _load_lookup_table(self) -> dict:\n",
    "        \"\"\"\n",
    "        Load the lookup table from the Excel file and create a mapping dictionary.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary mapping value types to detection limits.\n",
    "        \"\"\"\n",
    "        df = pd.read_excel(self.lut_path)\n",
    "        df = df.astype({'id': 'int'})\n",
    "        return dict((v, k) for k, v in df.set_index('id')['name'].to_dict().items())\n",
    "\n",
    "    def _copy_and_fill_na(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Copy the 'Value type' column and fill NaN values with 'Not Available'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with updated 'detection_limit' column.\n",
    "        \"\"\"\n",
    "        df['detection_limit'] = df['Value type']\n",
    "        df['detection_limit'].fillna('Not Available', inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def _correct_greater_than(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Correct the 'Value type' where it is '>' by changing it to '<'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with corrected 'Value type'.\n",
    "        \"\"\"\n",
    "        df.loc[df['detection_limit'] == '>', 'detection_limit'] = '<'\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _drop_na_rows(self, df: pd.DataFrame, lut: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drop rows where the 'detection_limit' column has values not in the lookup table.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with rows dropped where 'detection_limit' is not in the lookup table.\n",
    "        \"\"\"\n",
    "        return df[df['detection_limit'].isin(lut.keys())]\n",
    "\n",
    "    def _perform_lookup(self, df: pd.DataFrame, lut: dict):\n",
    "        \"\"\"\n",
    "        Perform lookup to update the 'detection_limit' column based on the lookup table.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "        \"\"\"\n",
    "        df['detection_limit'] = df['detection_limit'].apply(lambda x: lut.get(x, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44862cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detection_limit</th>\n",
       "      <th>Value type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18851</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18852</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18853</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18854</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18855</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       detection_limit Value type\n",
       "0                    2          <\n",
       "1                    2          <\n",
       "2                    2          <\n",
       "3                    2          <\n",
       "4                    2          <\n",
       "...                ...        ...\n",
       "18851                2          <\n",
       "18852                2          <\n",
       "18853                1          =\n",
       "18854                1          =\n",
       "18855                2          <\n",
       "\n",
       "[18856 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "tfm.dfs['seawater'][['detection_limit','Value type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1c44a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295f55a",
   "metadata": {},
   "source": [
    "### Include Sample Laboratory code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfc4c7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Sample Laboratory code is not included.*`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56622d1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``samplabcode``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f2e7f",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF format does not include Sample Laboratory code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16eb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapDataProviderSampleIdCB(Callback):\n",
    "    \"\"\"Remap 'KEY' column to 'samplabcode' in each DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapDataProviderSampleIdCB.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap 'KEY' column to 'samplabcode' in the DataFrames.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp])\n",
    "    \n",
    "    def _remap_sample_id(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap the 'KEY' column to 'samplabcode' in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['samplabcode'] = df['Sample ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68413052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WNZ 01' 'WNZ 02' 'WNZ 03' ... '21-656' '21-657' '21-654']\n",
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['samplabcode'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40886dea",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5000d",
   "metadata": {},
   "source": [
    "### Include Station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995fdf8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Station ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b9a1a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Station``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418efd4",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF format does not include Station ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7ee5a",
   "metadata": {},
   "source": [
    "The OSPAR dataset includes look-up in the `Seawater_Station_Dictionary.xlsx` file for Station information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca9df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../../_data/accdb/ospar/csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(fname_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc69efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
       "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
       "       'LongS', 'LongDir', 'Sample type', 'Sampling depth', 'Sampling date',\n",
       "       'Nuclide', 'Value type', 'Activity or MDA', 'Uncertainty', 'Unit',\n",
       "       'Data provider', 'Measurement Comment', 'Sample Comment',\n",
       "       'Reference Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['seawater'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a253a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapStationIdCB(Callback):\n",
    "    \"\"\"Remap Station ID to MARIS format.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapStationIdCB with no specific parameters.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Iterate through all DataFrames in the transformer object and remap 'STATION' to 'station_id'.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._remap_station_id(tfm.dfs[grp])\n",
    "\n",
    "    def _remap_station_id(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap 'STATION' column to 'station_id' in the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['station'] = df['Station ID'] + ', ' + df['Contracting Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9124fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapStationIdCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "#print(tfm.dfs['seawater']['station'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44e86a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289cb24e",
   "metadata": {},
   "source": [
    "### Measurement note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45f2b0",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: Not included in NetCDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7de23",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``measurenote``*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RecordMeasurementNoteCB(Callback):\n",
    "    \"\"\"Record measurement notes by adding a 'measurenote' column to DataFrames.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RecordMeasurementNoteCB.\n",
    "\n",
    "        This class does not require additional arguments or setup for initialization.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the callback to each DataFrame in the transformer to add the 'measurenote' column.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames to process.\n",
    "        \n",
    "        This method iterates over all DataFrames in the transformer and checks for the\n",
    "        presence of the 'Measurement Comment' column. If found, it copies the values\n",
    "        to a new 'measurenote' column. If not found, it prints a warning message.\n",
    "        \"\"\"\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            if 'Measurement Comment' in df.columns:\n",
    "                self._add_measurementnote(df)\n",
    "            else:\n",
    "                print(f\"Warning: 'Measurement Comment' column not found in DataFrame for group '{grp}'\")\n",
    "\n",
    "    def _add_measurementnote(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Add the 'measurenote' column to the DataFrame by mapping values from 'Measurement Comment'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the 'Measurement Comment' column.\n",
    "        \n",
    "        The 'Measurement Comment' column values are copied to the new 'measurenote' column.\n",
    "        \"\"\"\n",
    "        df['measurenote'] = df['Measurement Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428399d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9445aaa",
   "metadata": {},
   "source": [
    "### Reference note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223c84c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: Not included in NetCDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31522b6b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``refnote``* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09069fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RecordRefNoteCB(Callback):\n",
    "    \"\"\"Record reference notes by adding a 'refnote' column to DataFrames.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RecordRefNoteCB.\n",
    "\n",
    "        This class does not require additional arguments or setup for initialization.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the callback to each DataFrame in the transformer to add the 'refnote' column.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames to process.\n",
    "        \n",
    "        This method iterates over all DataFrames in the transformer and checks for the\n",
    "        presence of the 'Reference Comment' column. If found, it copies the values\n",
    "        to a new 'refnote' column. If not found, it prints a warning message.\n",
    "        \"\"\"\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            if 'Reference Comment' in df.columns:\n",
    "                self._add_refnote(df)\n",
    "            else:\n",
    "                print(f\"Warning: 'Reference Comment' column not found in DataFrame for group '{grp}'\")\n",
    "\n",
    "    def _add_refnote(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Add the 'refnote' column to the DataFrame by mapping values from 'Reference Comment'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the 'Reference Comment' column.\n",
    "        \n",
    "        The 'Reference Comment' column values are copied to the new 'refnote' column.\n",
    "        \"\"\"\n",
    "        df['refnote'] = df['Reference Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2206d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RecordRefNoteCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab2579",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11bd59",
   "metadata": {},
   "source": [
    "### Sample note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26abe1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: Not included in NetCDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed12c21",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``sampnote``*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d96b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
       "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
       "       'LongS', 'LongDir', 'Sample type', 'Biological group', 'Species',\n",
       "       'Body Part', 'Sampling date', 'Nuclide', 'Value type',\n",
       "       'Activity or MDA', 'Uncertainty', 'Unit', 'Data provider',\n",
       "       'Measurement Comment', 'Sample Comment', 'Reference Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['biota'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RecordSampleNoteCB(Callback):\n",
    "    \"\"\"Record sample notes by adding a 'sampnote' column to DataFrames.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RecordSampleNoteCB.\n",
    "\n",
    "        This class does not require additional arguments or setup for initialization.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the callback to each DataFrame in the transformer to add the 'sampnote' column.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames to process.\n",
    "        \n",
    "        This method iterates over all DataFrames in the transformer and checks for the\n",
    "        presence of the 'Sample Comment' column. If found, it copies the values\n",
    "        to a new 'sampnote' column. If not found, it prints a warning message.\n",
    "        \"\"\"\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            if 'Sample Comment' in df.columns:\n",
    "                self._add_samplenote(df)\n",
    "            else:\n",
    "                print(f\"Warning: 'Sample Comment' column not found in DataFrame for group '{grp}'\")\n",
    "\n",
    "    def _add_samplenote(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Add the 'sampnote' column to the DataFrame by mapping values from 'Sample Comment'.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the 'Measurement Comment' column.\n",
    "        \n",
    "        The 'Sample Comment' column values are copied to the new 'sampnote' column.\n",
    "        \"\"\"\n",
    "        df['sampnote'] = df['Sample Comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fab891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RecordSampleNoteCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd232d3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433bc90",
   "metadata": {},
   "source": [
    "### Standardize Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8b7f8",
   "metadata": {},
   "source": [
    "#### Capture Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af67f55",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dca27",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude`` and ``Latitude``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95422e",
   "metadata": {},
   "source": [
    "Use decimal degree coordinates if available; otherwise, convert from ``LatD``, ``LatM``, ``LatS``, ``LongD``, ``LongM`` and ``LongS``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94730c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ConvertLonLatCB(Callback):\n",
    "    \"\"\"Convert Longitude and Latitude values to decimal degrees (DDD.DDDDD°). This class processes DataFrames to convert latitude and longitude from degrees, minutes, and seconds \n",
    "    (DMS) format with direction indicators to decimal degrees format.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the ConvertLonLatCB class.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the conversion to latitude and longitude in each DataFrame within the transformer.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames to process.\n",
    "        \n",
    "        This method processes each DataFrame to convert latitude and longitude values into decimal degrees.\n",
    "        \"\"\"\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            df['lat'] = self._convert_latitude(df)\n",
    "            df['lon'] = self._convert_longitude(df)\n",
    "\n",
    "    def _convert_latitude(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Convert latitude values from DMS format to decimal degrees.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing latitude columns.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Series with latitude values converted to decimal degrees.\n",
    "        \"\"\"\n",
    "        return np.where(\n",
    "            df['LatDir'].isin(['S']),\n",
    "            self._dms_to_decimal(df['LatD'], df['LatM'], df['LatS']) * -1,\n",
    "            self._dms_to_decimal(df['LatD'], df['LatM'], df['LatS'])\n",
    "        )\n",
    "\n",
    "    def _convert_longitude(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Convert longitude values from DMS format to decimal degrees.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing longitude columns.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Series with longitude values converted to decimal degrees.\n",
    "        \"\"\"\n",
    "        return np.where(\n",
    "            df['LongDir'].isin(['W']),\n",
    "            self._dms_to_decimal(df['LongD'], df['LongM'], df['LongS']) * -1,\n",
    "            self._dms_to_decimal(df['LongD'], df['LongM'], df['LongS'])\n",
    "        )\n",
    "\n",
    "    def _dms_to_decimal(self, degrees: pd.Series, minutes: pd.Series, seconds: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Convert DMS (degrees, minutes, seconds) format to decimal degrees.\n",
    "\n",
    "        Args:\n",
    "            degrees (pd.Series): Series containing degree values.\n",
    "            minutes (pd.Series): Series containing minute values.\n",
    "            seconds (pd.Series): Series containing second values.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: Series with values converted to decimal degrees.\n",
    "        \"\"\"\n",
    "        return degrees + minutes / 60 + seconds / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7900d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>LatD</th>\n",
       "      <th>LatM</th>\n",
       "      <th>LatS</th>\n",
       "      <th>lon</th>\n",
       "      <th>LatDir</th>\n",
       "      <th>LongD</th>\n",
       "      <th>LongM</th>\n",
       "      <th>LongS</th>\n",
       "      <th>LongDir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.375278</td>\n",
       "      <td>51.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.188056</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.223611</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.859444</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.184444</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.713611</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.420278</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.262222</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.416111</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.809722</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18851</th>\n",
       "      <td>56.011111</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-3.406667</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18852</th>\n",
       "      <td>56.011111</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-3.406667</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18853</th>\n",
       "      <td>53.413333</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-3.870278</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18854</th>\n",
       "      <td>53.569722</td>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.769722</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18855</th>\n",
       "      <td>53.123333</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-4.086389</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18856 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat  LatD  LatM  LatS       lon LatDir  LongD  LongM  LongS  \\\n",
       "0      51.375278  51.0  22.0  31.0  3.188056      N    3.0   11.0   17.0   \n",
       "1      51.223611  51.0  13.0  25.0  2.859444      N    2.0   51.0   34.0   \n",
       "2      51.184444  51.0  11.0   4.0  2.713611      N    2.0   42.0   49.0   \n",
       "3      51.420278  51.0  25.0  13.0  3.262222      N    3.0   15.0   44.0   \n",
       "4      51.416111  51.0  24.0  58.0  2.809722      N    2.0   48.0   35.0   \n",
       "...          ...   ...   ...   ...       ...    ...    ...    ...    ...   \n",
       "18851  56.011111  56.0   0.0  40.0 -3.406667      N    3.0   24.0   24.0   \n",
       "18852  56.011111  56.0   0.0  40.0 -3.406667      N    3.0   24.0   24.0   \n",
       "18853  53.413333  53.0  24.0  48.0 -3.870278      N    3.0   52.0   13.0   \n",
       "18854  53.569722  53.0  34.0  11.0 -3.769722      N    3.0   46.0   11.0   \n",
       "18855  53.123333  53.0   7.0  24.0 -4.086389      N    4.0    5.0   11.0   \n",
       "\n",
       "      LongDir  \n",
       "0           E  \n",
       "1           E  \n",
       "2           E  \n",
       "3           E  \n",
       "4           E  \n",
       "...       ...  \n",
       "18851       W  \n",
       "18852       W  \n",
       "18853       W  \n",
       "18854       W  \n",
       "18855       W  \n",
       "\n",
       "[18856 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ConvertLonLatCB()\n",
    "                            ])\n",
    "tfm()\n",
    "tfm.dfs['seawater'][['lat','LatD', 'LatM', 'LatS', 'lon', 'LatDir', 'LongD', 'LongM','LongS', 'LongDir']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025c29d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831dd5a",
   "metadata": {},
   "source": [
    "#### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4091a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067e5bd",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01454c1",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b834378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18856  15314\n",
      "Number of dropped rows                                     0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n",
      "             lat       lon\n",
      "0      55.725278 -4.901944\n",
      "1      54.968889 -3.240556\n",
      "2      58.565833 -3.791389\n",
      "3      58.618611 -3.647778\n",
      "4      55.964722 -2.398056\n",
      "...          ...       ...\n",
      "15309  54.455000 -3.566111\n",
      "15310  48.832778 -1.591389\n",
      "15311  48.832778 -1.591389\n",
      "15312  49.551667 -1.860000\n",
      "15313  49.714444 -1.946111\n",
      "\n",
      "[15314 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ConvertLonLatCB(),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c319e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68e395",
   "metadata": {},
   "source": [
    "### Combine Callbacks and review DFS and TFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18308  15308\n",
      "Number of dropped rows                                   548      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValueCB(),                       \n",
    "                            NormalizeUncCB(unc_exp2stan),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            RecordRefNoteCB(),\n",
    "                            RecordSampleNoteCB(),   \n",
    "                            ConvertLonLatCB(),                    \n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_dfs_dropped_review=tfm.dfs_dropped['seawater']\n",
    "biota_dfs_dropped_review=tfm.dfs_dropped['biota']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c639e47",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5535529",
   "metadata": {},
   "source": [
    "### Rename columns of interest for NetCDF or Open Refine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
       "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
       "       'LongS', 'LongDir', 'Sample type', 'Sampling depth', 'Sampling date',\n",
       "       'Nuclide', 'Value type', 'Activity or MDA', 'Uncertainty', 'Unit',\n",
       "       'Data provider', 'Measurement Comment', 'Sample Comment',\n",
       "       'Reference Comment', 'samptype_id', 'NUCLIDE', 'nuclide_id', 'time',\n",
       "       'begperiod', 'value', 'uncertainty', 'unit', 'detection_limit',\n",
       "       'samplabcode', 'station', 'measurenote', 'refnote', 'sampnote', 'lat',\n",
       "       'lon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b7cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Contracting Party', 'RSC Sub-division', 'Station ID',\n",
       "       'Sample ID', 'LatD', 'LatM', 'LatS', 'LatDir', 'LongD', 'LongM',\n",
       "       'LongS', 'LongDir', 'Sample type', 'Biological group', 'Species',\n",
       "       'Body Part', 'Sampling date', 'Nuclide', 'Value type',\n",
       "       'Activity or MDA', 'Uncertainty', 'Unit', 'Data provider',\n",
       "       'Measurement Comment', 'Sample Comment', 'Reference Comment',\n",
       "       'samptype_id', 'NUCLIDE', 'nuclide_id', 'time', 'begperiod', 'value',\n",
       "       'uncertainty', 'species', 'body_part', 'bio_group', 'TaxonRepName',\n",
       "       'Taxonname', 'Taxonrank', 'TaxonDB', 'TaxonDBID', 'TaxonDBURL', 'unit',\n",
       "       'detection_limit', 'samplabcode', 'station', 'measurenote', 'refnote',\n",
       "       'sampnote', 'lat', 'lon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['biota'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).\n",
    "def get_renaming_rules(encoding_type='netcdf'):\n",
    "    vars = cdl_cfg()['vars']\n",
    "    if encoding_type == 'netcdf':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'lat': vars['defaults']['lat']['name'],\n",
    "                'lon': vars['defaults']['lon']['name'],\n",
    "                'time': vars['defaults']['time']['name'],\n",
    "                'NUCLIDE': 'nuclide',\n",
    "                'detection_limit': vars['suffixes']['detection_limit']['name'],\n",
    "                'unit': vars['suffixes']['unit']['name'],\n",
    "                'value': 'value',\n",
    "                'uncertainty': vars['suffixes']['uncertainty']['name'],\n",
    "                #'counting_method': vars['suffixes']['counting_method']['name'],\n",
    "                #'sampling_method': vars['suffixes']['sampling_method']['name'],\n",
    "                #'preparation_method': vars['suffixes']['preparation_method']['name']\n",
    "            },\n",
    "            ('seawater',): {\n",
    "                # SEAWATER\n",
    "            },\n",
    "            ('biota',): {\n",
    "                # BIOTA\n",
    "                'species': vars['bio']['species']['name'],\n",
    "                'body_part': vars['bio']['body_part']['name'],\n",
    "                'bio_group': vars['bio']['bio_group']['name']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif encoding_type == 'openrefine':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'samptype_id': 'samptype_id',\n",
    "                'lat': 'latitude',\n",
    "                'lon': 'longitude',\n",
    "                'station': 'station',\n",
    "                'begperiod': 'begperiod',\n",
    "                'samplabcode': 'samplabcode',\n",
    "                #'endperiod': 'endperiod',\n",
    "                'nuclide_id': 'nuclide_id',\n",
    "                'detection_limit': 'detection',\n",
    "                'unit': 'unit_id',\n",
    "                'value': 'activity',\n",
    "                'uncertainty': 'uncertaint',\n",
    "                'sampnote': 'sampnote',\n",
    "                'measurenote': 'measurenote',\n",
    "                'refnote' : 'refnote'\n",
    "            },\n",
    "            ('seawater',) : {\n",
    "                # SEAWATER\n",
    "                #'volume': 'volume',\n",
    "                #'filtpore': 'filtpore',\n",
    "                #'acid': 'acid'\n",
    "            },\n",
    "            ('biota',) : {\n",
    "                # BIOTA\n",
    "                'species': 'species_id',\n",
    "                'Taxonname': 'Taxonname',\n",
    "                'TaxonRepName': 'TaxonRepName',\n",
    "                #'Commonname': 'Commonname',\n",
    "                'Taxonrank': 'Taxonrank',\n",
    "                'TaxonDB': 'TaxonDB',\n",
    "                'TaxonDBID': 'TaxonDBID',\n",
    "                'TaxonDBURL': 'TaxonDBURL',\n",
    "                'body_part': 'bodypar_id',\n",
    "            }\n",
    "        })\n",
    "    else:\n",
    "        print(\"Invalid encoding_type provided. Please use 'netcdf' or 'openrefine'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SelectAndRenameColumnCB(Callback):\n",
    "    \"\"\"A callback to select and rename columns in a DataFrame based on provided renaming rules\n",
    "    for a specified encoding type. It also prints renaming rules that were not applied\n",
    "    because their keys were not found in the DataFrame.\"\"\"\n",
    "    \n",
    "    def __init__(self, fn_renaming_rules, encoding_type='netcdf', verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize the SelectAndRenameColumnCB callback.\n",
    "\n",
    "        Args:\n",
    "            fn_renaming_rules (function): A function that returns an OrderedDict of renaming rules.\n",
    "            encoding_type (str): The encoding type ('netcdf' or 'openrefine') to determine which renaming rules to use.\n",
    "            verbose (bool): Whether to print out renaming rules that were not applied.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"\n",
    "        Apply column selection and renaming to DataFrames in the transformer, and identify unused rules.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            renaming_rules = self.fn_renaming_rules(self.encoding_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fetching renaming rules: {e}\")\n",
    "            return\n",
    "\n",
    "        for group in tfm.dfs.keys():\n",
    "            # Get relevant renaming rules for the current group\n",
    "            group_rules = self._get_group_rules(renaming_rules, group)\n",
    "\n",
    "            if not group_rules:\n",
    "                continue\n",
    "\n",
    "            # Apply renaming rules and track keys not found in the DataFrame\n",
    "            df = tfm.dfs[group]\n",
    "            df, not_found_keys = self._apply_renaming(df, group_rules)\n",
    "            tfm.dfs[group] = df\n",
    "            \n",
    "            # Print any renaming rules that were not used\n",
    "            if not_found_keys and self.verbose:\n",
    "                print(f\"\\nGroup '{group}' has the following renaming rules not applied:\")\n",
    "                for old_col in not_found_keys:\n",
    "                    print(f\"Key '{old_col}' from renaming rules was not found in the DataFrame.\")\n",
    "\n",
    "    def _get_group_rules(self, renaming_rules, group):\n",
    "        \"\"\"\n",
    "        Retrieve and merge renaming rules for the specified group based on the encoding type.\n",
    "\n",
    "        Args:\n",
    "            renaming_rules (OrderedDict): OrderedDict of all renaming rules.\n",
    "            group (str): Group name to filter rules.\n",
    "\n",
    "        Returns:\n",
    "            OrderedDict: An OrderedDict of renaming rules applicable to the specified group.\n",
    "        \"\"\"\n",
    "        relevant_rules = [rules for key, rules in renaming_rules.items() if group in key]\n",
    "        merged_rules = OrderedDict()\n",
    "        for rules in relevant_rules:\n",
    "            merged_rules.update(rules)\n",
    "        return merged_rules\n",
    "\n",
    "    def _apply_renaming(self, df, rename_rules):\n",
    "        \"\"\"\n",
    "        Select columns based on renaming rules and apply renaming, only for existing columns,\n",
    "        while maintaining the order of the dictionary columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to modify.\n",
    "            rename_rules (OrderedDict): OrderedDict of column renaming rules.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - The DataFrame with columns renamed and filtered.\n",
    "                - A set of column names from renaming rules that were not found in the DataFrame.\n",
    "        \"\"\"\n",
    "        existing_columns = set(df.columns)\n",
    "        valid_rules = OrderedDict((old_col, new_col) for old_col, new_col in rename_rules.items() if old_col in existing_columns)\n",
    "\n",
    "        # Create a list to maintain the order of columns\n",
    "        columns_to_keep = [col for col in rename_rules.keys() if col in existing_columns]\n",
    "        columns_to_keep += [new_col for old_col, new_col in valid_rules.items() if new_col in df.columns]\n",
    "\n",
    "        df = df[list(OrderedDict.fromkeys(columns_to_keep))]\n",
    "\n",
    "        # Apply renaming\n",
    "        df.rename(columns=valid_rules, inplace=True)\n",
    "\n",
    "        # Determine which keys were not found\n",
    "        not_found_keys = set(rename_rules.keys()) - existing_columns\n",
    "        return df, not_found_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc'], dtype='object')\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       'species', 'body_part', 'bio_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValueCB(),                       \n",
    "                            NormalizeUncCB(unc_exp2stan),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            RecordRefNoteCB(),\n",
    "                            RecordSampleNoteCB(),   \n",
    "                            ConvertLonLatCB(),                    \n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(tfm.dfs['seawater'].columns)\n",
    "print(tfm.dfs['biota'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfce27b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ed29f",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f919e5",
   "metadata": {},
   "source": [
    "Convert data from long to wide and rename columns to comply with NetCDF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns=['nuclide'], values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        df.index.name = 'org_index'\n",
    "        df=df.reset_index()\n",
    "        idx = list(set(df.columns) - set(self.columns + derived_coi + self.values))\n",
    "        \n",
    "        # Create a fill_value to replace NaN values in the columns used as the index in the pivot table.\n",
    "        # Check if num_fill_value is already in the dataframe index values. If num_fill_value already exists\n",
    "        # then increase num_fill_value by 1 until a value is found for num_fill_value that is not in the dataframe. \n",
    "        num_fill_value = -999\n",
    "        while (df[idx] == num_fill_value).any().any():\n",
    "            num_fill_value += 1\n",
    "        # Fill in nan values for each col found in idx. \n",
    "        for col in idx:   \n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                fill_value = num_fill_value\n",
    "            if pd.api.types.is_string_dtype(df[col]):\n",
    "                fill_value = 'NOT AVAILABLE'\n",
    "                \n",
    "            df[col]=df[col].fillna(fill_value)\n",
    "\n",
    "        pivot_df=df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "        \n",
    "\n",
    "        # Replace fill_value  with  np.nan\n",
    "        pivot_df[idx]=pivot_df[idx].replace({'NOT AVAILABLE': np.nan,\n",
    "                                             num_fill_value : np.nan})\n",
    "        # Set the index to be the org_index\n",
    "        pivot_df = pivot_df.set_index('org_index')\n",
    "                \n",
    "        return (pivot_df)\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp] = self.pivot(tfm.dfs[grp])\n",
    "            tfm.dfs[grp].columns = self.renamed_cols(tfm.dfs[grp].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b45c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 lon  species        time  bio_group        lat  body_part  \\\n",
      "org_index                                                                    \n",
      "11474     -39.634444       99  1017014400          4  66.784167         52   \n",
      "4714      -39.150000      426  1375228800          4  62.116667         52   \n",
      "6465      -35.920000       99  1287273600          4  64.289722         52   \n",
      "6466      -35.100000      381  1287100800          4  64.720000         52   \n",
      "6143      -34.000000       99  1306886400          4  64.000000         52   \n",
      "\n",
      "           am241_dl  cs134_dl  cs137_dl  h3_dl  ...  cs134   cs137  h3  pb210  \\\n",
      "org_index                                       ...                             \n",
      "11474           NaN       NaN       1.0    NaN  ...    NaN  0.1800 NaN    NaN   \n",
      "4714            NaN       NaN       1.0    NaN  ...    NaN  0.2198 NaN    NaN   \n",
      "6465            NaN       NaN       1.0    NaN  ...    NaN  0.2090 NaN    NaN   \n",
      "6466            NaN       NaN       1.0    NaN  ...    NaN  0.1830 NaN    NaN   \n",
      "6143            NaN       NaN       1.0    NaN  ...    NaN  0.1696 NaN    NaN   \n",
      "\n",
      "           po210  pu238  pu239_240_tot  ra226  ra228  tc99  \n",
      "org_index                                                   \n",
      "11474        NaN    NaN            NaN    NaN    NaN   NaN  \n",
      "4714         NaN    NaN            NaN    NaN    NaN   NaN  \n",
      "6465         NaN    NaN            NaN    NaN    NaN   NaN  \n",
      "6466         NaN    NaN            NaN    NaN    NaN   NaN  \n",
      "6143         NaN    NaN            NaN    NaN    NaN   NaN  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18308  15308\n",
      "Number of dropped rows                                   548      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValueCB(),                       \n",
    "                            NormalizeUncCB(unc_exp2stan),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            RecordRefNoteCB(),\n",
    "                            RecordSampleNoteCB(),   \n",
    "                            ConvertLonLatCB(),                    \n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(tfm.dfs['biota'].head())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_dfs_review=tfm.dfs['seawater']\n",
    "biota_dfs_review=tfm.dfs['biota']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb8b99",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0bea3",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d87c3a",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Set the 'Sample type' column in the DataFrames based on a lookup table.\",\n",
       " 'Convert nuclide names to lowercase and strip any trailing spaces.',\n",
       " 'Remap and standardize radionuclide names to MARIS radionuclide names and define nuclide ids.',\n",
       " 'Encode time as `int` representing seconds since xxx',\n",
       " 'Sanitize value by removing blank entries.',\n",
       " 'Callback to normalize uncertainty values in DataFrames. This callback applies a conversion function to standardize the uncertainty values in each DataFrame.',\n",
       " \"Remap biota species to MARIS database format.This class updates the 'Species' column in the biota DataFrame by:\\n    - Replacing 'NaN' or 'Not available' values with corresponding biological groups.\\n    - Performing a lookup to remap species to MARIS format.\",\n",
       " \"Update body parts labeled as 'whole' to either 'Whole animal' or 'Whole plant'.\",\n",
       " 'Update body part id based on MARIS dbo_bodypar.xlsx',\n",
       " 'Update biogroup id based on MARIS dbo_species.xlsx.',\n",
       " 'Update taxon names based on MARIS species LUT (dbo_species.xlsx).',\n",
       " \"Update the 'unit' column in DataFrames based on a lookup table.\\n    The class handles:\\n    - Assigning a default unit for NaN values in the 'Unit' column for specific groups.\\n    - Dropping rows with NaN values in the 'Unit' column.\\n    - Performing lookup to update the 'unit' column based on the provided lookup table.\",\n",
       " \"Remap activity value, activity uncertainty, and detection limit to MARIS format.\\n    This class performs the following operations:\\n    - Reads a lookup table from an Excel file.\\n    - Copies and processes the 'Value type' column.\\n    - Fills NaN values with 'Not Available'.\\n    - Drops rows where 'Value type' is not in the lookup table.\\n    - Performs a lookup to update the 'detection_limit' column based on the lookup table.\\n    \",\n",
       " \"Remap 'KEY' column to 'samplabcode' in each DataFrame.\",\n",
       " 'Remap Station ID to MARIS format.',\n",
       " \"Record measurement notes by adding a 'measurenote' column to DataFrames.\",\n",
       " \"Record reference notes by adding a 'refnote' column to DataFrames.\",\n",
       " \"Record sample notes by adding a 'sampnote' column to DataFrames.\",\n",
       " 'Convert Longitude and Latitude values to decimal degrees (DDD.DDDDD°). This class processes DataFrames to convert latitude and longitude from degrees, minutes, and seconds \\n    (DMS) format with direction indicators to decimal degrees format.',\n",
       " 'Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.',\n",
       " 'A callback to select and rename columns in a DataFrame based on provided renaming rules\\n    for a specified encoding type. It also prints renaming rules that were not applied\\n    because their keys were not found in the DataFrame.',\n",
       " 'Convert data from long to wide with renamed columns.',\n",
       " 'Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                         \n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValueCB(),                       \n",
    "                            NormalizeUncCB(unc_exp2stan),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            RecordRefNoteCB(),\n",
    "                            RecordSampleNoteCB(),   \n",
    "                            ConvertLonLatCB(),                    \n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "# Transform\n",
    "tfm()\n",
    "# Check transformation logs\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2e267",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5ef65",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7519752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed59598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '49.43222222222222',\n",
       " 'geospatial_lat_max': '81.26805555555555',\n",
       " 'geospatial_lon_min': '-58.23166666666667',\n",
       " 'geospatial_lon_max': '36.181666666666665',\n",
       " 'geospatial_bounds': 'POLYGON ((-58.23166666666667 36.181666666666665, 49.43222222222222 36.181666666666665, 49.43222222222222 81.26805555555555, -58.23166666666667 81.26805555555555, -58.23166666666667 36.181666666666665))',\n",
       " 'time_coverage_start': '1995-01-01T00:00:00',\n",
       " 'time_coverage_end': '2021-12-31T00:00:00',\n",
       " 'title': 'OSPAR Environmental Monitoring of Radioactive Substances',\n",
       " 'summary': '',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"firstName\": \"\", \"lastName\": \"OSPAR Comission\\'s Radioactive Substances Committee (RSC)\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Set the 'Sample type' column in the DataFrames based on a lookup table., Convert nuclide names to lowercase and strip any trailing spaces., Remap and standardize radionuclide names to MARIS radionuclide names and define nuclide ids., Encode time as `int` representing seconds since xxx, Sanitize value by removing blank entries., Callback to normalize uncertainty values in DataFrames. This callback applies a conversion function to standardize the uncertainty values in each DataFrame., Remap biota species to MARIS database format.This class updates the 'Species' column in the biota DataFrame by:\\n    - Replacing 'NaN' or 'Not available' values with corresponding biological groups.\\n    - Performing a lookup to remap species to MARIS format., Update body parts labeled as 'whole' to either 'Whole animal' or 'Whole plant'., Update body part id based on MARIS dbo_bodypar.xlsx, Update biogroup id based on MARIS dbo_species.xlsx., Update taxon names based on MARIS species LUT (dbo_species.xlsx)., Update the 'unit' column in DataFrames based on a lookup table.\\n    The class handles:\\n    - Assigning a default unit for NaN values in the 'Unit' column for specific groups.\\n    - Dropping rows with NaN values in the 'Unit' column.\\n    - Performing lookup to update the 'unit' column based on the provided lookup table., Remap activity value, activity uncertainty, and detection limit to MARIS format.\\n    This class performs the following operations:\\n    - Reads a lookup table from an Excel file.\\n    - Copies and processes the 'Value type' column.\\n    - Fills NaN values with 'Not Available'.\\n    - Drops rows where 'Value type' is not in the lookup table.\\n    - Performs a lookup to update the 'detection_limit' column based on the lookup table.\\n    , Remap 'KEY' column to 'samplabcode' in each DataFrame., Remap Station ID to MARIS format., Record measurement notes by adding a 'measurenote' column to DataFrames., Record reference notes by adding a 'refnote' column to DataFrames., Record sample notes by adding a 'sampnote' column to DataFrames., Convert Longitude and Latitude values to decimal degrees (DDD.DDDDD°). This class processes DataFrames to convert latitude and longitude from degrees, minutes, and seconds \\n    (DMS) format with direction indicators to decimal degrees format., Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator., A callback to select and rename columns in a DataFrame based on provided renaming rules\\n    for a specified encoding type. It also prints renaming rules that were not applied\\n    because their keys were not found in the DataFrame., Convert data from long to wide with renamed columns., Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17278f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6ad69",
   "metadata": {},
   "source": [
    "### Encoding NETCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                                GetSampleTypeCB(type_lut),\n",
    "                                LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),        \n",
    "                                SanitizeValueCB(),                       \n",
    "                                NormalizeUncCB(unc_exp2stan),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                                CorrectWholeBodyPartCB(),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                                LookupUnitCB(renaming_unit_rules),\n",
    "                                LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RecordMeasurementNoteCB(),\n",
    "                                RecordRefNoteCB(),\n",
    "                                RecordSampleNoteCB(),   \n",
    "                                ConvertLonLatCB(),                    \n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                                ReshapeLongToWide(),\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra226\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra226_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra226_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra226_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ra228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bio_group\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: species\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: body_part\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: h3\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: h3_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: h3_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: h3_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_unit\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, fname_out_nc, nc_tpl_path(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c35b7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700e3c8",
   "metadata": {},
   "source": [
    "## Open Refine Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04517175",
   "metadata": {},
   "source": [
    "### Rename columns for Open Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  biota\n",
      "Number of rows in dfs                                  18856  15314\n",
      "Number of rows in tfm.dfs                              18308  15308\n",
      "Number of dropped rows                                   548      6\n",
      "Number of rows in tfm.dfs + Number of dropped rows     18856  15314 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValueCB(),                       \n",
    "                            NormalizeUncCB(unc_exp2stan),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RecordMeasurementNoteCB(),\n",
    "                            RecordRefNoteCB(),\n",
    "                            RecordSampleNoteCB(),   \n",
    "                            ConvertLonLatCB(),                    \n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine', verbose=True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df77447",
   "metadata": {},
   "source": [
    "**Example of data included in dfs_dropped.**\n",
    "\n",
    "Main reasons for data to be dropped from dfs:\n",
    "- No activity value reported (i.e. ``Activity or MDA``)\n",
    "\n",
    "Reason 6 biota values are dropped:\n",
    "- The body part is not known (i.e.'Mix of muscle and whole fish without liver' or 'UNKNOWN') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7ef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Contracting Party</th>\n",
       "      <th>RSC Sub-division</th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>LatD</th>\n",
       "      <th>LatM</th>\n",
       "      <th>LatS</th>\n",
       "      <th>LatDir</th>\n",
       "      <th>LongD</th>\n",
       "      <th>...</th>\n",
       "      <th>Sampling date</th>\n",
       "      <th>Nuclide</th>\n",
       "      <th>Value type</th>\n",
       "      <th>Activity or MDA</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Data provider</th>\n",
       "      <th>Measurement Comment</th>\n",
       "      <th>Sample Comment</th>\n",
       "      <th>Reference Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>97147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16800</th>\n",
       "      <td>97148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16801</th>\n",
       "      <td>97149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16802</th>\n",
       "      <td>97150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16803</th>\n",
       "      <td>97151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18474</th>\n",
       "      <td>120366</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021 data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18475</th>\n",
       "      <td>120367</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021 data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18476</th>\n",
       "      <td>120368</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021 data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18477</th>\n",
       "      <td>120369</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Salthill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021 data</td>\n",
       "      <td>Woodstown (County Waterford) and Salthill (Cou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18478</th>\n",
       "      <td>120370</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Woodstown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>N</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Contracting Party  RSC Sub-division Station ID Sample ID  LatD  \\\n",
       "16799   97147               NaN               NaN        NaN       NaN   NaN   \n",
       "16800   97148               NaN               NaN        NaN       NaN   NaN   \n",
       "16801   97149               NaN               NaN        NaN       NaN   NaN   \n",
       "16802   97150               NaN               NaN        NaN       NaN   NaN   \n",
       "16803   97151               NaN               NaN        NaN       NaN   NaN   \n",
       "...       ...               ...               ...        ...       ...   ...   \n",
       "18474  120366           Ireland               4.0         N8       NaN  53.0   \n",
       "18475  120367           Ireland               4.0         N9       NaN  53.0   \n",
       "18476  120368           Ireland               4.0        N10       NaN  53.0   \n",
       "18477  120369           Ireland               1.0   Salthill       NaN  53.0   \n",
       "18478  120370           Ireland               1.0  Woodstown       NaN  52.0   \n",
       "\n",
       "       LatM  LatS LatDir  LongD  ...  Sampling date  Nuclide Value type  \\\n",
       "16799   NaN   NaN    NaN    NaN  ...            NaN      NaN        NaN   \n",
       "16800   NaN   NaN    NaN    NaN  ...            NaN      NaN        NaN   \n",
       "16801   NaN   NaN    NaN    NaN  ...            NaN      NaN        NaN   \n",
       "16802   NaN   NaN    NaN    NaN  ...            NaN      NaN        NaN   \n",
       "16803   NaN   NaN    NaN    NaN  ...            NaN      NaN        NaN   \n",
       "...     ...   ...    ...    ...  ...            ...      ...        ...   \n",
       "18474  39.0   0.0      N    5.0  ...            NaN      NaN        NaN   \n",
       "18475  53.0   0.0      N    5.0  ...            NaN      NaN        NaN   \n",
       "18476  52.0   0.0      N    5.0  ...            NaN      NaN        NaN   \n",
       "18477  15.0  40.0      N    9.0  ...            NaN      NaN        NaN   \n",
       "18478  11.0  55.0      N    6.0  ...            NaN      NaN        NaN   \n",
       "\n",
       "      Activity or MDA  Uncertainty Unit Data provider Measurement Comment  \\\n",
       "16799             NaN          NaN  NaN           NaN                 NaN   \n",
       "16800             NaN          NaN  NaN           NaN                 NaN   \n",
       "16801             NaN          NaN  NaN           NaN                 NaN   \n",
       "16802             NaN          NaN  NaN           NaN                 NaN   \n",
       "16803             NaN          NaN  NaN           NaN                 NaN   \n",
       "...               ...          ...  ...           ...                 ...   \n",
       "18474             NaN          NaN  NaN           NaN           2021 data   \n",
       "18475             NaN          NaN  NaN           NaN           2021 data   \n",
       "18476             NaN          NaN  NaN           NaN           2021 data   \n",
       "18477             NaN          NaN  NaN           NaN           2021 data   \n",
       "18478             NaN          NaN  NaN           NaN                 NaN   \n",
       "\n",
       "                                          Sample Comment  Reference Comment  \n",
       "16799                                                NaN                NaN  \n",
       "16800                                                NaN                NaN  \n",
       "16801                                                NaN                NaN  \n",
       "16802                                                NaN                NaN  \n",
       "16803                                                NaN                NaN  \n",
       "...                                                  ...                ...  \n",
       "18474                                                NaN                NaN  \n",
       "18475                                                NaN                NaN  \n",
       "18476                                                NaN                NaN  \n",
       "18477  Woodstown (County Waterford) and Salthill (Cou...                NaN  \n",
       "18478                                                NaN                NaN  \n",
       "\n",
       "[548 rows x 25 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='seawater'\n",
    "#grp='biota'\n",
    "tfm.dfs_dropped[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12ac1d",
   "metadata": {},
   "source": [
    "## Open Refine encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b001d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_or(fname_in, fname_out_csv, ref_id, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                                GetSampleTypeCB(type_lut),\n",
    "                                LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),        \n",
    "                                SanitizeValueCB(),                       \n",
    "                                NormalizeUncCB(unc_exp2stan),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                                CorrectWholeBodyPartCB(),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                                LookupUnitCB(renaming_unit_rules),\n",
    "                                LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RecordMeasurementNoteCB(),\n",
    "                                RecordRefNoteCB(),\n",
    "                                RecordSampleNoteCB(),   \n",
    "                                ConvertLonLatCB(),                    \n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine', verbose=True),\n",
    "                                CompareDfsAndTfmCB(dfs)\n",
    "                                ])\n",
    "    tfm()\n",
    "\n",
    "    encoder = OpenRefineCsvEncoder(tfm.dfs, \n",
    "                                    dest_fname=fname_out_csv, \n",
    "                                    ref_id = ref_id,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encode_or(fname_in, fname_out_csv, ref_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c52ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

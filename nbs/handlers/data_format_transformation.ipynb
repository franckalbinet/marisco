{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.data_format_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data format transformation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A data pipeline handler that transforms MARIS data between different formats. The primary focus is converting NetCDF data into human-readable formats (like CSV, Excel) while preserving data integrity and maintaining standardized variable names and units. This handler implements a modular transformation pipeline using callbacks for each processing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "> Required packages and internal modules for data format transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from fastcore.basics import patch, store_attr\n",
    "import fastcore.all as fc\n",
    "from typing import Dict, Callable\n",
    "\n",
    "from marisco.configs import (\n",
    "    NC_VARS,\n",
    "    OR_VARS,\n",
    "    NC_GROUPS,\n",
    "    OR_DTYPES,\n",
    "    Enums,\n",
    "    lut_path,\n",
    "    species_lut_path\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback,\n",
    "    Transformer,\n",
    "    DecodeTimeCB,\n",
    "    RemapCB\n",
    ")  \n",
    "    \n",
    "from marisco.decoders import (\n",
    "        NetCDFDecoder\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "fname_in =  Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "fname_out = fname_in.with_suffix('.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and validate data from standardized MARIS NetCDF files. The NetCDF files follow CF conventions and include standardized variable names, units, and metadata according to MARIS specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_to_dataframes(fname:str, verbose: bool = False):\n",
    "    \"\"\"Load NetCDF groups into DataFrames with standardized column names.\"\"\"\n",
    "    dfs = {}\n",
    "    with Dataset(fname, 'r') as nc:\n",
    "        for group_name in nc.groups:\n",
    "            group = nc.groups[group_name]\n",
    "            # Get all variables in the group\n",
    "            data = {}\n",
    "            for var_name, var in group.variables.items():\n",
    "                if var_name not in group.dimensions:  # Skip dimension variables\n",
    "                    data[var_name] = var[:]\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            # Rename columns using NC_VARS mapping\n",
    "            rename_map = {nc_var: col for col, nc_var in NC_VARS.items() \n",
    "                         if nc_var in df.columns}\n",
    "            df = df.rename(columns=rename_map)\n",
    "            dfs[group_name.upper()] = df\n",
    "            if verbose:\n",
    "                print(f\"Loaded group {group_name} with columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded group biota with columns: ['LON', 'LAT', 'SMP_DEPTH', 'TIME', 'NUCLIDE', 'VALUE', 'UNIT', 'DL', 'BIO_GROUP', 'SPECIES', 'BODY_PART', 'DRYWT', 'WETWT']\n",
      "Loaded group seawater with columns: ['LON', 'LAT', 'SMP_DEPTH', 'TOT_DEPTH', 'TIME', 'NUCLIDE', 'VALUE', 'UNIT', 'DL', 'FILT']\n",
      "Loaded group sediment with columns: ['LON', 'LAT', 'TOT_DEPTH', 'TIME', 'AREA', 'NUCLIDE', 'VALUE', 'UNIT', 'DL', 'SED_TYPE', 'TOP', 'BOTTOM']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "dfs = load_to_dataframes(fname_in, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate NetCDF Enumerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that enumerated values in the NetCDF file match MARIS lookup tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The enumeration validation process is a diagnostic step that identifies inconsistencies between NetCDF enumerations and MARIS lookup tables. While this validation does not modify the dataset, it generates detailed feedback about any mismatches or undefined values. \n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ValidateEnumsCB(Callback):\n",
    "    \"Validate enumeration mappings between NetCDF file and MARIS lookup tables.\"\n",
    "    def __init__(self, \n",
    "                src_fname: str,  # Path to NetCDF file\n",
    "                enums: Enums,    # MARIS lookup table enums\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Process each group in the NetCDF file and validate its enums.\"\"\"\n",
    "        with Dataset(self.src_fname, 'r') as nc:\n",
    "            for group_name in nc.groups:\n",
    "                group = nc.groups[group_name]\n",
    "                self._validate_group(group, group_name)\n",
    "    \n",
    "    def _validate_group(self, group, group_name: str):\n",
    "        \"\"\"Validate enum mappings for a specific group.\"\"\"\n",
    "        for var_name, var in group.variables.items():\n",
    "            if not hasattr(var.datatype, 'enum_dict'): \n",
    "                continue\n",
    "            \n",
    "            nc_enum_dict = var.datatype.enum_dict\n",
    "            if self.verbose:\n",
    "                print(f\"nc_enum_dict [{var_name}]:\", nc_enum_dict)\n",
    "\n",
    "            # Get original column name from NC_VARS mapping\n",
    "            original_col = next((col for col, nc_var in NC_VARS.items() \n",
    "                               if nc_var == var_name), None)\n",
    "            if not original_col: \n",
    "                continue\n",
    "\n",
    "            # Compare enum mappings\n",
    "            self._compare_mappings(\n",
    "                nc_enum_dict,\n",
    "                self.enums.types[original_col],\n",
    "                group_name,\n",
    "                var_name,\n",
    "                original_col\n",
    "            )\n",
    "    \n",
    "    def _compare_mappings(self, nc_dict: dict, lut_dict: dict, \n",
    "                         group_name: str, var_name: str, col_name: str):\n",
    "        \"\"\"Compare NetCDF enum dictionary with lookup table dictionary.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"lut_enum [{col_name}]:\", lut_dict)\n",
    "            \n",
    "        # Check for mismatches between NetCDF and lookup table\n",
    "        for key, value in nc_dict.items():\n",
    "            if key not in lut_dict or lut_dict[key] != value:\n",
    "                print(f\"\\nWarning: Enum mismatch in {group_name}/{var_name}\")\n",
    "                print(f\"NetCDF value: {key} -> {value}\")\n",
    "                print(f\"Lookup value: {key} -> {lut_dict.get(key, 'Not found')}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  NUCLIDE       VALUE  UNIT  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       31    0.010140     5   \n",
       " 1      12.316667  54.283333        NaN  1348358400        4  135.300003     5   \n",
       " 2      12.316667  54.283333        NaN  1348358400        9    0.013980     5   \n",
       " 3      12.316667  54.283333        NaN  1348358400       33    4.338000     5   \n",
       " 4      12.316667  54.283333        NaN  1348358400       31    0.009614     5   \n",
       " ...          ...        ...        ...         ...      ...         ...   ...   \n",
       " 14868  19.000000  54.583302       61.0  1519603200       53    0.043000     5   \n",
       " 14869  15.500000  54.333302       65.0  1518480000        4   98.000000     5   \n",
       " 14870  15.500000  54.333302       65.0  1518480000       33    3.690000     5   \n",
       " 14871  15.500000  54.333302       65.0  1518480000       53    0.049000     5   \n",
       " 14872  19.433300  54.363899        NaN  1538524800       33    0.830000     5   \n",
       " \n",
       "        DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \n",
       " 0       2          4       99         52  174.934433  948.0  \n",
       " 1       1          4       99         52  174.934433  948.0  \n",
       " 2       2          4       99         52  174.934433  948.0  \n",
       " 3       1          4       99         52  174.934433  948.0  \n",
       " 4       2          4       99         52  177.935120  964.0  \n",
       " ...    ..        ...      ...        ...         ...    ...  \n",
       " 14868   1          4      191          3  120.000000  500.0  \n",
       " 14869   1          4      191         52  112.500000  500.0  \n",
       " 14870   1          4      191         52  112.500000  500.0  \n",
       " 14871   1          4      191         52  112.500000  500.0  \n",
       " 14872   1          4      247         52         NaN  120.0  \n",
       " \n",
       " [14873 rows x 13 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  NUCLIDE  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       33   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       33   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       33   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       33   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       33   \n",
       " ...          ...        ...        ...        ...         ...      ...   \n",
       " 20237  14.200000  54.006802        4.0       12.0  1434931200       12   \n",
       " 20238  14.667200  54.499500        4.0       20.0  1435017600       12   \n",
       " 20239  14.334200  54.750500        4.0       17.0  1435017600       12   \n",
       " 20240  13.500200  54.916500        4.0       47.0  1435104000       12   \n",
       " 20241  13.500200  54.916500       45.0       47.0  1435104000       12   \n",
       " \n",
       "            VALUE  UNIT  DL  FILT  \n",
       " 0       5.300000     1   1     0  \n",
       " 1      19.900000     1   1     0  \n",
       " 2      25.500000     1   1     0  \n",
       " 3      17.000000     1   1     0  \n",
       " 4      22.200001     1   1     0  \n",
       " ...          ...   ...  ..   ...  \n",
       " 20237   6.600000     1   1     1  \n",
       " 20238   6.900000     1   1     1  \n",
       " 20239   6.800000     1   1     1  \n",
       " 20240   7.300000     1   1     1  \n",
       " 20241   5.500000     1   1     1  \n",
       " \n",
       " [20242 rows x 10 columns],\n",
       " 'SEDIMENT':            LON        LAT  TOT_DEPTH        TIME  AREA  NUCLIDE        VALUE  \\\n",
       " 0      24.0000  59.666698       71.0  1339891200     0       53    35.000000   \n",
       " 1      24.0000  59.666698       71.0  1339891200     0       53    36.000000   \n",
       " 2      28.8433  59.860001       23.0  1344556800     0       53    38.000000   \n",
       " 3      28.8433  59.860001       23.0  1344556800     0       53    36.000000   \n",
       " 4      28.8433  59.860001       23.0  1344556800     0       53    30.000000   \n",
       " ...        ...        ...        ...         ...   ...      ...          ...   \n",
       " 63863  21.0830  59.035999      171.0  1465430400     0       33     8.916443   \n",
       " 63864  21.0830  59.035999      171.0  1465430400     0       33     5.992929   \n",
       " 63865  19.7297  61.066700      131.0  1464480000     0       33  2164.945801   \n",
       " 63866  19.7297  61.066700      131.0  1464480000     0       33  2523.279053   \n",
       " 63867  19.7297  61.066700      131.0  1464480000     0       33  3929.780029   \n",
       " \n",
       "        UNIT  DL  SED_TYPE   TOP  BOTTOM  \n",
       " 0         4   1         0  15.0    20.0  \n",
       " 1         4   1         0  20.0    27.0  \n",
       " 2         4   1         0   0.0     2.0  \n",
       " 3         4   1         0   2.0     4.0  \n",
       " 4         4   1         0   4.0     6.0  \n",
       " ...     ...  ..       ...   ...     ...  \n",
       " 63863     4   1        50  18.0    20.0  \n",
       " 63864     4   1        50  20.0    22.0  \n",
       " 63865     4   1        59   0.0     2.0  \n",
       " 63866     4   1        51   2.0     4.0  \n",
       " 63867     4   1        50   4.0     6.0  \n",
       " \n",
       " [63868 rows x 12 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        ValidateEnumsCB(\n",
    "            src_fname=fname_in,\n",
    "            enums=Enums(lut_src_dir=lut_path()),\n",
    "            #verbose=True\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate NetCDF Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that variable names in the NetCDF file match those used in MARIS ternminogy, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ValidateNetCDFVarsCB(Callback):\n",
    "    \" Validate that all variables in the NetCDF file are included in NC_VARS mapping. Identifies and reports any unmapped variables.\"\n",
    "    def __init__(self, \n",
    "                src_fname: str,  # Path to NetCDF file\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Check each group's variables against NC_VARS mapping.\"\"\"\n",
    "        unmapped_vars = {}\n",
    "        \n",
    "        with Dataset(self.src_fname, 'r') as nc:\n",
    "            for group_name in nc.groups:\n",
    "                group = nc.groups[group_name]\n",
    "                group_vars = set(group.variables.keys())\n",
    "                mapped_vars = {v for k, v in NC_VARS.items()}\n",
    "                unmapped = group_vars - mapped_vars - {'id'}  # Exclude dimension variables\n",
    "                \n",
    "                if unmapped:\n",
    "                    unmapped_vars[group_name] = unmapped\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nWarning: Unmapped variables in group {group_name}:\")\n",
    "                        print(f\"Variables: {unmapped}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  NUCLIDE       VALUE  UNIT  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       31    0.010140     5   \n",
       " 1      12.316667  54.283333        NaN  1348358400        4  135.300003     5   \n",
       " 2      12.316667  54.283333        NaN  1348358400        9    0.013980     5   \n",
       " 3      12.316667  54.283333        NaN  1348358400       33    4.338000     5   \n",
       " 4      12.316667  54.283333        NaN  1348358400       31    0.009614     5   \n",
       " ...          ...        ...        ...         ...      ...         ...   ...   \n",
       " 14868  19.000000  54.583302       61.0  1519603200       53    0.043000     5   \n",
       " 14869  15.500000  54.333302       65.0  1518480000        4   98.000000     5   \n",
       " 14870  15.500000  54.333302       65.0  1518480000       33    3.690000     5   \n",
       " 14871  15.500000  54.333302       65.0  1518480000       53    0.049000     5   \n",
       " 14872  19.433300  54.363899        NaN  1538524800       33    0.830000     5   \n",
       " \n",
       "        DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \n",
       " 0       2          4       99         52  174.934433  948.0  \n",
       " 1       1          4       99         52  174.934433  948.0  \n",
       " 2       2          4       99         52  174.934433  948.0  \n",
       " 3       1          4       99         52  174.934433  948.0  \n",
       " 4       2          4       99         52  177.935120  964.0  \n",
       " ...    ..        ...      ...        ...         ...    ...  \n",
       " 14868   1          4      191          3  120.000000  500.0  \n",
       " 14869   1          4      191         52  112.500000  500.0  \n",
       " 14870   1          4      191         52  112.500000  500.0  \n",
       " 14871   1          4      191         52  112.500000  500.0  \n",
       " 14872   1          4      247         52         NaN  120.0  \n",
       " \n",
       " [14873 rows x 13 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  NUCLIDE  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       33   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       33   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       33   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       33   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       33   \n",
       " ...          ...        ...        ...        ...         ...      ...   \n",
       " 20237  14.200000  54.006802        4.0       12.0  1434931200       12   \n",
       " 20238  14.667200  54.499500        4.0       20.0  1435017600       12   \n",
       " 20239  14.334200  54.750500        4.0       17.0  1435017600       12   \n",
       " 20240  13.500200  54.916500        4.0       47.0  1435104000       12   \n",
       " 20241  13.500200  54.916500       45.0       47.0  1435104000       12   \n",
       " \n",
       "            VALUE  UNIT  DL  FILT  \n",
       " 0       5.300000     1   1     0  \n",
       " 1      19.900000     1   1     0  \n",
       " 2      25.500000     1   1     0  \n",
       " 3      17.000000     1   1     0  \n",
       " 4      22.200001     1   1     0  \n",
       " ...          ...   ...  ..   ...  \n",
       " 20237   6.600000     1   1     1  \n",
       " 20238   6.900000     1   1     1  \n",
       " 20239   6.800000     1   1     1  \n",
       " 20240   7.300000     1   1     1  \n",
       " 20241   5.500000     1   1     1  \n",
       " \n",
       " [20242 rows x 10 columns],\n",
       " 'SEDIMENT':            LON        LAT  TOT_DEPTH        TIME  AREA  NUCLIDE        VALUE  \\\n",
       " 0      24.0000  59.666698       71.0  1339891200     0       53    35.000000   \n",
       " 1      24.0000  59.666698       71.0  1339891200     0       53    36.000000   \n",
       " 2      28.8433  59.860001       23.0  1344556800     0       53    38.000000   \n",
       " 3      28.8433  59.860001       23.0  1344556800     0       53    36.000000   \n",
       " 4      28.8433  59.860001       23.0  1344556800     0       53    30.000000   \n",
       " ...        ...        ...        ...         ...   ...      ...          ...   \n",
       " 63863  21.0830  59.035999      171.0  1465430400     0       33     8.916443   \n",
       " 63864  21.0830  59.035999      171.0  1465430400     0       33     5.992929   \n",
       " 63865  19.7297  61.066700      131.0  1464480000     0       33  2164.945801   \n",
       " 63866  19.7297  61.066700      131.0  1464480000     0       33  2523.279053   \n",
       " 63867  19.7297  61.066700      131.0  1464480000     0       33  3929.780029   \n",
       " \n",
       "        UNIT  DL  SED_TYPE   TOP  BOTTOM  \n",
       " 0         4   1         0  15.0    20.0  \n",
       " 1         4   1         0  20.0    27.0  \n",
       " 2         4   1         0   0.0     2.0  \n",
       " 3         4   1         0   2.0     4.0  \n",
       " 4         4   1         0   4.0     6.0  \n",
       " ...     ...  ..       ...   ...     ...  \n",
       " 63863     4   1        50  18.0    20.0  \n",
       " 63864     4   1        50  20.0    22.0  \n",
       " 63865     4   1        59   0.0     2.0  \n",
       " 63866     4   1        51   2.0     4.0  \n",
       " 63867     4   1        50   4.0     6.0  \n",
       " \n",
       " [63868 rows x 12 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        ValidateNetCDFVarsCB(\n",
    "            src_fname=fname_in,\n",
    "            verbose=True\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Taxon information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "TAXON_KEY_MAP = {\n",
    "    'Taxonname': 'TAXONNAME',\n",
    "    'Taxonrank': 'TAXONRANK',\n",
    "    'TaxonDB': 'TAXONDB',\n",
    "    'TaxonDBID': 'TAXONDBID',\n",
    "    'TaxonDBURL': 'TAXONDBURL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_taxon_info_lut(maris_lut: str, key_names: dict = TAXON_KEY_MAP) -> dict:\n",
    "    \"Create lookup dictionary for taxon information from MARIS species lookup table.\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    # Select columns and rename them to standardized format\n",
    "    columns = ['species_id'] + list(key_names.keys())\n",
    "    df = species[columns].rename(columns=key_names)\n",
    "    return df.set_index('species_id').to_dict()\n",
    "\n",
    "lut_taxon = lambda: get_taxon_info_lut(maris_lut=species_lut_path(), key_names=TAXON_KEY_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlut_taxon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "lut_taxon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddTaxonInformationCB(Callback):\n",
    "    \"Add taxon information to BIOTA group based on species lookup table.\"\n",
    "    def __init__(self, \n",
    "                fn_lut: Callable = lut_taxon,  # Function that returns taxon lookup dictionary\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Add taxon information columns to BIOTA group.\"\"\"\n",
    "        if 'BIOTA' not in tfm.dfs:\n",
    "            if self.verbose:\n",
    "                print(\"No BIOTA group found, skipping taxon information\")\n",
    "            return\n",
    "            \n",
    "        lut = self.fn_lut()\n",
    "        df = tfm.dfs['BIOTA']\n",
    "        \n",
    "        # Add each column from the lookup table\n",
    "        for col in lut.keys():\n",
    "            df[col] = df['SPECIES'].map(lut[col]).fillna('Unknown')\n",
    "            \n",
    "        if self.verbose:\n",
    "            unmatched = df[df['TAXONNAME'] == 'Unknown']['SPECIES'].unique()\n",
    "            if len(unmatched) > 0:\n",
    "                print(f\"Warning: Species IDs not found in lookup table: {', '.join(map(str, unmatched))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  NUCLIDE       VALUE  UNIT  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       31    0.010140     5   \n",
       " 1      12.316667  54.283333        NaN  1348358400        4  135.300003     5   \n",
       " 2      12.316667  54.283333        NaN  1348358400        9    0.013980     5   \n",
       " 3      12.316667  54.283333        NaN  1348358400       33    4.338000     5   \n",
       " 4      12.316667  54.283333        NaN  1348358400       31    0.009614     5   \n",
       " ...          ...        ...        ...         ...      ...         ...   ...   \n",
       " 14868  19.000000  54.583302       61.0  1519603200       53    0.043000     5   \n",
       " 14869  15.500000  54.333302       65.0  1518480000        4   98.000000     5   \n",
       " 14870  15.500000  54.333302       65.0  1518480000       33    3.690000     5   \n",
       " 14871  15.500000  54.333302       65.0  1518480000       53    0.049000     5   \n",
       " 14872  19.433300  54.363899        NaN  1538524800       33    0.830000     5   \n",
       " \n",
       "        DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \\\n",
       " 0       2          4       99         52  174.934433  948.0   \n",
       " 1       1          4       99         52  174.934433  948.0   \n",
       " 2       2          4       99         52  174.934433  948.0   \n",
       " 3       1          4       99         52  174.934433  948.0   \n",
       " 4       2          4       99         52  177.935120  964.0   \n",
       " ...    ..        ...      ...        ...         ...    ...   \n",
       " 14868   1          4      191          3  120.000000  500.0   \n",
       " 14869   1          4      191         52  112.500000  500.0   \n",
       " 14870   1          4      191         52  112.500000  500.0   \n",
       " 14871   1          4      191         52  112.500000  500.0   \n",
       " 14872   1          4      247         52         NaN  120.0   \n",
       " \n",
       "                 TAXONNAME TAXONRANK   TAXONDB TAXONDBID  \\\n",
       " 0            Gadus morhua   species  Wikidata   Q199788   \n",
       " 1            Gadus morhua   species  Wikidata   Q199788   \n",
       " 2            Gadus morhua   species  Wikidata   Q199788   \n",
       " 3            Gadus morhua   species  Wikidata   Q199788   \n",
       " 4            Gadus morhua   species  Wikidata   Q199788   \n",
       " ...                   ...       ...       ...       ...   \n",
       " 14868  Platichthys flesus   species  Wikidata   Q214034   \n",
       " 14869  Platichthys flesus   species  Wikidata   Q214034   \n",
       " 14870  Platichthys flesus   species  Wikidata   Q214034   \n",
       " 14871  Platichthys flesus   species  Wikidata   Q214034   \n",
       " 14872   Perca fluviatilis   species  Wikidata   Q166812   \n",
       " \n",
       "                                   TAXONDBURL  \n",
       " 0      https://www.wikidata.org/wiki/Q199788  \n",
       " 1      https://www.wikidata.org/wiki/Q199788  \n",
       " 2      https://www.wikidata.org/wiki/Q199788  \n",
       " 3      https://www.wikidata.org/wiki/Q199788  \n",
       " 4      https://www.wikidata.org/wiki/Q199788  \n",
       " ...                                      ...  \n",
       " 14868  https://www.wikidata.org/wiki/Q214034  \n",
       " 14869  https://www.wikidata.org/wiki/Q214034  \n",
       " 14870  https://www.wikidata.org/wiki/Q214034  \n",
       " 14871  https://www.wikidata.org/wiki/Q214034  \n",
       " 14872  https://www.wikidata.org/wiki/Q166812  \n",
       " \n",
       " [14873 rows x 18 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  NUCLIDE  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       33   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       33   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       33   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       33   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       33   \n",
       " ...          ...        ...        ...        ...         ...      ...   \n",
       " 20237  14.200000  54.006802        4.0       12.0  1434931200       12   \n",
       " 20238  14.667200  54.499500        4.0       20.0  1435017600       12   \n",
       " 20239  14.334200  54.750500        4.0       17.0  1435017600       12   \n",
       " 20240  13.500200  54.916500        4.0       47.0  1435104000       12   \n",
       " 20241  13.500200  54.916500       45.0       47.0  1435104000       12   \n",
       " \n",
       "            VALUE  UNIT  DL  FILT  \n",
       " 0       5.300000     1   1     0  \n",
       " 1      19.900000     1   1     0  \n",
       " 2      25.500000     1   1     0  \n",
       " 3      17.000000     1   1     0  \n",
       " 4      22.200001     1   1     0  \n",
       " ...          ...   ...  ..   ...  \n",
       " 20237   6.600000     1   1     1  \n",
       " 20238   6.900000     1   1     1  \n",
       " 20239   6.800000     1   1     1  \n",
       " 20240   7.300000     1   1     1  \n",
       " 20241   5.500000     1   1     1  \n",
       " \n",
       " [20242 rows x 10 columns],\n",
       " 'SEDIMENT':            LON        LAT  TOT_DEPTH        TIME  AREA  NUCLIDE        VALUE  \\\n",
       " 0      24.0000  59.666698       71.0  1339891200     0       53    35.000000   \n",
       " 1      24.0000  59.666698       71.0  1339891200     0       53    36.000000   \n",
       " 2      28.8433  59.860001       23.0  1344556800     0       53    38.000000   \n",
       " 3      28.8433  59.860001       23.0  1344556800     0       53    36.000000   \n",
       " 4      28.8433  59.860001       23.0  1344556800     0       53    30.000000   \n",
       " ...        ...        ...        ...         ...   ...      ...          ...   \n",
       " 63863  21.0830  59.035999      171.0  1465430400     0       33     8.916443   \n",
       " 63864  21.0830  59.035999      171.0  1465430400     0       33     5.992929   \n",
       " 63865  19.7297  61.066700      131.0  1464480000     0       33  2164.945801   \n",
       " 63866  19.7297  61.066700      131.0  1464480000     0       33  2523.279053   \n",
       " 63867  19.7297  61.066700      131.0  1464480000     0       33  3929.780029   \n",
       " \n",
       "        UNIT  DL  SED_TYPE   TOP  BOTTOM  \n",
       " 0         4   1         0  15.0    20.0  \n",
       " 1         4   1         0  20.0    27.0  \n",
       " 2         4   1         0   0.0     2.0  \n",
       " 3         4   1         0   2.0     4.0  \n",
       " 4         4   1         0   4.0     6.0  \n",
       " ...     ...  ..       ...   ...     ...  \n",
       " 63863     4   1        50  18.0    20.0  \n",
       " 63864     4   1        50  20.0    22.0  \n",
       " 63865     4   1        59   0.0     2.0  \n",
       " 63866     4   1        51   2.0     4.0  \n",
       " 63867     4   1        50   4.0     6.0  \n",
       " \n",
       " [63868 rows x 12 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        AddTaxonInformationCB(\n",
    "            fn_lut=lut_taxon\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remap to human readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ConvertToHumanReadableCB(Callback):\n",
    "    \"\"\"\n",
    "    Convert enum values in DataFrames to their human-readable format,\n",
    "    but only for variables defined as 'human_readable' in OR_DTYPES.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                src_fname: str,  # Path to NetCDF file\n",
    "                or_dtypes: Dict = OR_DTYPES,  # Dictionary defining variable types\n",
    "                verbose: bool = False\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"\"\"Convert numeric enum values to human-readable strings for specified variables.\"\"\"\n",
    "        with Dataset(self.src_fname, 'r') as nc:\n",
    "            for group_name, df in tfm.dfs.items():\n",
    "                nc_group_name = NC_GROUPS[group_name]\n",
    "                group = nc.groups[nc_group_name]\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f'Processing {group_name} enums ...')\n",
    "                \n",
    "                # Process each variable that has an enum\n",
    "                for var_name, var in group.variables.items():\n",
    "                    if hasattr(var.datatype, 'enum_dict'):\n",
    "                        # Get the original column name from NC_VARS mapping\n",
    "                        original_col = next((col for col, nc_var in NC_VARS.items() \n",
    "                                          if nc_var == var_name), None)\n",
    "                        \n",
    "                        # Only convert if variable is marked as human_readable in OR_DTYPES\n",
    "                        if (original_col and original_col in df.columns and \n",
    "                            original_col in self.or_dtypes and \n",
    "                            self.or_dtypes[original_col]['type'] == 'human_readable'):\n",
    "                            \n",
    "                            if self.verbose:\n",
    "                                print(f\"Converting '{original_col}' to human readable format\")\n",
    "                                print(f\"Enum values: {var.datatype.enum_dict}\")\n",
    "                            \n",
    "                            enum_dict = {v: k for k, v in var.datatype.enum_dict.items()}\n",
    "                            tfm.dfs[group_name][original_col] = df[original_col].map(enum_dict)\n",
    "                            \n",
    "                            if self.verbose:\n",
    "                                print(f\"Converted {original_col} in {group_name}\")\n",
    "                                print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BIOTA enums ...\n",
      "Converting 'DL' to human readable format\n",
      "Enum values: {'Not applicable': -1, 'Not available': 0, 'Detected value': 1, 'Detection limit': 2, 'Not detected': 3, 'Derived': 4}\n",
      "Converted DL in BIOTA\n",
      "--------------------------------------------------------------------------------\n",
      "Processing SEAWATER enums ...\n",
      "Converting 'DL' to human readable format\n",
      "Enum values: {'Not applicable': -1, 'Not available': 0, 'Detected value': 1, 'Detection limit': 2, 'Not detected': 3, 'Derived': 4}\n",
      "Converted DL in SEAWATER\n",
      "--------------------------------------------------------------------------------\n",
      "Converting 'FILT' to human readable format\n",
      "Enum values: {'Not applicable': -1, 'Not available': 0, 'Yes': 1, 'No': 2}\n",
      "Converted FILT in SEAWATER\n",
      "--------------------------------------------------------------------------------\n",
      "Processing SEDIMENT enums ...\n",
      "Converting 'AREA' to human readable format\n",
      "Enum values: {'Not applicable': -1, 'Not available': 0, 'North Atlantic Ocean': 1912, 'Baltic Sea': 2, 'Mediterranean Region': 3, 'South Atlantic Ocean': 1914, 'Indian Ocean': 1904, 'South China & Eastern Archipelagic Seas': 6, 'North Pacific Ocean': 1908, 'South Pacific Ocean': 1910, 'Arctic Ocean': 1906, 'Southern Ocean': 1907, 'Arctic Sea': 18, 'Atlantic, Northwest': 21, 'Atlantic, Northeast': 27, 'Atlantic, Western Central': 31, 'Atlantic, Eastern Central': 34, 'Mediterranean and Black Sea': 37, 'Atlantic, Southwest': 41, 'Atlantic, Southeast': 47, 'Atlantic, Antarctic': 48, 'Indian Ocean, Western': 51, 'Indian Ocean, Eastern': 57, 'Indian Ocean, Antarctic': 58, 'Pacific, Northwest': 61, 'Pacific, Northeast': 67, 'Pacific, Western Central': 71, 'Pacific, Eastern Central': 77, 'Pacific, Southwest': 81, 'Pacific, Southeast': 87, 'Pacific, Antarctic': 88, 'North Sea': 2350, 'Celtic Sea': 2351, 'Norwegian Sea': 2353, 'Greenland Sea': 2356, 'Irish Sea': 2357, 'Bay of Biscay': 2359, 'Kattegat': 2374, 'Skagerrak': 2379, 'English Channel': 2389, 'Central Baltic Sea': 2401, 'Gulf of Bothnia': 2402, 'Gulf of Finland': 2407, 'Gulf of Riga': 2409, 'Bristol Channel': 3141, 'Adriatic Sea': 3314, 'Aegean Sea': 3315, 'Black Sea': 3319, 'Sea of Azov': 3320, 'Balearic Sea': 3322, 'Alboran Sea': 3324, 'Strait of Gibraltar': 3346, 'Ionian Sea': 3351, 'Ligurian Sea': 3363, 'Sea of Marmara': 3369, 'Tyrrhenian Sea': 3386, 'East Siberian Sea': 4244, 'Laptev Sea': 4245, 'Kara Sea': 4246, 'Barentsz Sea': 4247, 'White Sea': 4248, 'Davis Strait': 4250, 'Hudson Strait': 4251, 'Hudson Bay': 4252, 'Baffin Bay': 4253, 'Lincoln Sea': 4254, 'Beaufort Sea': 4256, 'Chukchi Sea': 4257, 'Mozambique Channel': 4261, 'Gulf of Suez': 4262, 'Gulf of Aqaba': 4263, 'Red Sea': 4264, 'Gulf of Aden': 4265, 'Persian Gulf': 4266, 'Gulf of Oman': 4267, 'Arabian Sea': 4268, 'Laccadive Sea': 4269, 'Bay of Bengal': 4273, 'Andaman Sea': 4274, 'Malacca Strait': 4275, 'Great Australian Bight': 4276, 'Mediterranean Sea   Western Basin_x000D_': 4279, 'Mediterranean Sea   Eastern Basin': 4280, 'Inner Seas off the West Coast of Scotland': 4283, 'Gulf of Guinea': 4286, 'Caribbean Sea': 4287, 'Gulf of Mexico': 4288, 'Bay of Fundy': 4289, 'Gulf of St Lawrence': 4290, 'Labrador Sea': 4291, 'Philippine Sea': 4300, 'East China Sea': 4302, 'Yellow Sea': 4303, 'Seto Naikai': 4306, 'Japan Sea': 4307, 'Sea of Okhotsk': 4309, 'Bering Sea': 4310, 'Gulf of Alaska': 4312, 'Coastal Waters of Southeast Alaska and British Columbia': 4313, 'Gulf of California': 4314, 'Rio de La Plata': 4325, 'South China Sea': 4332, 'Gulf of Thailand': 4334, 'Singapore Strait': 4336, 'Jawa Sea': 4338, 'Selat Makasar': 4339, 'Bali Sea': 4340, 'Flores Sea': 4341, 'Sawu Sea': 4343, 'Timor Sea': 4344, 'Arafura Sea': 4347, 'Banda Sea': 4349, 'Teluk Bone': 4350, 'Ceram Sea': 4351, 'Halmahera Sea': 4353, 'Molucca Sea': 4354, 'Teluk Tomini': 4355, 'Sulu Sea': 4358, 'Celebes Sea': 4359, 'Bismarck Sea': 4360, 'Solomon Sea': 4361, 'Coral Sea': 4364, 'Tasman Sea': 4365, 'Bass Strait': 4366, 'Northwestern Passages': 5698, 'Unassigned': 9999}\n",
      "Converted AREA in SEDIMENT\n",
      "--------------------------------------------------------------------------------\n",
      "Converting 'DL' to human readable format\n",
      "Enum values: {'Not applicable': -1, 'Not available': 0, 'Detected value': 1, 'Detection limit': 2, 'Not detected': 3, 'Derived': 4}\n",
      "Converted DL in SEDIMENT\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  NUCLIDE       VALUE  UNIT  \\\n",
       " 0      12.316667  54.283333        NaN  1348358400       31    0.010140     5   \n",
       " 1      12.316667  54.283333        NaN  1348358400        4  135.300003     5   \n",
       " 2      12.316667  54.283333        NaN  1348358400        9    0.013980     5   \n",
       " 3      12.316667  54.283333        NaN  1348358400       33    4.338000     5   \n",
       " 4      12.316667  54.283333        NaN  1348358400       31    0.009614     5   \n",
       " ...          ...        ...        ...         ...      ...         ...   ...   \n",
       " 14868  19.000000  54.583302       61.0  1519603200       53    0.043000     5   \n",
       " 14869  15.500000  54.333302       65.0  1518480000        4   98.000000     5   \n",
       " 14870  15.500000  54.333302       65.0  1518480000       33    3.690000     5   \n",
       " 14871  15.500000  54.333302       65.0  1518480000       53    0.049000     5   \n",
       " 14872  19.433300  54.363899        NaN  1538524800       33    0.830000     5   \n",
       " \n",
       "                     DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \n",
       " 0      Detection limit          4       99         52  174.934433  948.0  \n",
       " 1       Detected value          4       99         52  174.934433  948.0  \n",
       " 2      Detection limit          4       99         52  174.934433  948.0  \n",
       " 3       Detected value          4       99         52  174.934433  948.0  \n",
       " 4      Detection limit          4       99         52  177.935120  964.0  \n",
       " ...                ...        ...      ...        ...         ...    ...  \n",
       " 14868   Detected value          4      191          3  120.000000  500.0  \n",
       " 14869   Detected value          4      191         52  112.500000  500.0  \n",
       " 14870   Detected value          4      191         52  112.500000  500.0  \n",
       " 14871   Detected value          4      191         52  112.500000  500.0  \n",
       " 14872   Detected value          4      247         52         NaN  120.0  \n",
       " \n",
       " [14873 rows x 13 columns],\n",
       " 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  NUCLIDE  \\\n",
       " 0      29.333300  60.083302        0.0        NaN  1337731200       33   \n",
       " 1      29.333300  60.083302       29.0        NaN  1337731200       33   \n",
       " 2      23.150000  59.433300        0.0        NaN  1339891200       33   \n",
       " 3      27.983299  60.250000        0.0        NaN  1337817600       33   \n",
       " 4      27.983299  60.250000       39.0        NaN  1337817600       33   \n",
       " ...          ...        ...        ...        ...         ...      ...   \n",
       " 20237  14.200000  54.006802        4.0       12.0  1434931200       12   \n",
       " 20238  14.667200  54.499500        4.0       20.0  1435017600       12   \n",
       " 20239  14.334200  54.750500        4.0       17.0  1435017600       12   \n",
       " 20240  13.500200  54.916500        4.0       47.0  1435104000       12   \n",
       " 20241  13.500200  54.916500       45.0       47.0  1435104000       12   \n",
       " \n",
       "            VALUE  UNIT              DL           FILT  \n",
       " 0       5.300000     1  Detected value  Not available  \n",
       " 1      19.900000     1  Detected value  Not available  \n",
       " 2      25.500000     1  Detected value  Not available  \n",
       " 3      17.000000     1  Detected value  Not available  \n",
       " 4      22.200001     1  Detected value  Not available  \n",
       " ...          ...   ...             ...            ...  \n",
       " 20237   6.600000     1  Detected value            Yes  \n",
       " 20238   6.900000     1  Detected value            Yes  \n",
       " 20239   6.800000     1  Detected value            Yes  \n",
       " 20240   7.300000     1  Detected value            Yes  \n",
       " 20241   5.500000     1  Detected value            Yes  \n",
       " \n",
       " [20242 rows x 10 columns],\n",
       " 'SEDIMENT':            LON        LAT  TOT_DEPTH        TIME           AREA  NUCLIDE  \\\n",
       " 0      24.0000  59.666698       71.0  1339891200  Not available       53   \n",
       " 1      24.0000  59.666698       71.0  1339891200  Not available       53   \n",
       " 2      28.8433  59.860001       23.0  1344556800  Not available       53   \n",
       " 3      28.8433  59.860001       23.0  1344556800  Not available       53   \n",
       " 4      28.8433  59.860001       23.0  1344556800  Not available       53   \n",
       " ...        ...        ...        ...         ...            ...      ...   \n",
       " 63863  21.0830  59.035999      171.0  1465430400  Not available       33   \n",
       " 63864  21.0830  59.035999      171.0  1465430400  Not available       33   \n",
       " 63865  19.7297  61.066700      131.0  1464480000  Not available       33   \n",
       " 63866  19.7297  61.066700      131.0  1464480000  Not available       33   \n",
       " 63867  19.7297  61.066700      131.0  1464480000  Not available       33   \n",
       " \n",
       "              VALUE  UNIT              DL  SED_TYPE   TOP  BOTTOM  \n",
       " 0        35.000000     4  Detected value         0  15.0    20.0  \n",
       " 1        36.000000     4  Detected value         0  20.0    27.0  \n",
       " 2        38.000000     4  Detected value         0   0.0     2.0  \n",
       " 3        36.000000     4  Detected value         0   2.0     4.0  \n",
       " 4        30.000000     4  Detected value         0   4.0     6.0  \n",
       " ...            ...   ...             ...       ...   ...     ...  \n",
       " 63863     8.916443     4  Detected value        50  18.0    20.0  \n",
       " 63864     5.992929     4  Detected value        50  20.0    22.0  \n",
       " 63865  2164.945801     4  Detected value        59   0.0     2.0  \n",
       " 63866  2523.279053     4  Detected value        51   2.0     4.0  \n",
       " 63867  3929.780029     4  Detected value        50   4.0     6.0  \n",
       " \n",
       " [63868 rows x 12 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        ConvertToHumanReadableCB(\n",
    "            src_fname=fname_in,\n",
    "            verbose=True\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2012-09-23\n",
      "1       2012-09-23\n",
      "2       2012-09-23\n",
      "3       2012-09-23\n",
      "4       2012-09-23\n",
      "           ...    \n",
      "14868   2018-02-26\n",
      "14869   2018-02-13\n",
      "14870   2018-02-13\n",
      "14871   2018-02-13\n",
      "14872   2018-10-03\n",
      "Name: TIME, Length: 14873, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        DecodeTimeCB(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(tfm.dfs['BIOTA']['TIME'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             LON        LAT  SMP_DEPTH       TIME  NUCLIDE       VALUE  UNIT  \\\n",
      "0      12.316667  54.283333        NaN 2012-09-23       31    0.010140     5   \n",
      "1      12.316667  54.283333        NaN 2012-09-23        4  135.300003     5   \n",
      "2      12.316667  54.283333        NaN 2012-09-23        9    0.013980     5   \n",
      "3      12.316667  54.283333        NaN 2012-09-23       33    4.338000     5   \n",
      "4      12.316667  54.283333        NaN 2012-09-23       31    0.009614     5   \n",
      "...          ...        ...        ...        ...      ...         ...   ...   \n",
      "14868  19.000000  54.583302       61.0 2018-02-26       53    0.043000     5   \n",
      "14869  15.500000  54.333302       65.0 2018-02-13        4   98.000000     5   \n",
      "14870  15.500000  54.333302       65.0 2018-02-13       33    3.690000     5   \n",
      "14871  15.500000  54.333302       65.0 2018-02-13       53    0.049000     5   \n",
      "14872  19.433300  54.363899        NaN 2018-10-03       33    0.830000     5   \n",
      "\n",
      "                    DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \\\n",
      "0      Detection limit          4       99         52  174.934433  948.0   \n",
      "1       Detected value          4       99         52  174.934433  948.0   \n",
      "2      Detection limit          4       99         52  174.934433  948.0   \n",
      "3       Detected value          4       99         52  174.934433  948.0   \n",
      "4      Detection limit          4       99         52  177.935120  964.0   \n",
      "...                ...        ...      ...        ...         ...    ...   \n",
      "14868   Detected value          4      191          3  120.000000  500.0   \n",
      "14869   Detected value          4      191         52  112.500000  500.0   \n",
      "14870   Detected value          4      191         52  112.500000  500.0   \n",
      "14871   Detected value          4      191         52  112.500000  500.0   \n",
      "14872   Detected value          4      247         52         NaN  120.0   \n",
      "\n",
      "                TAXONNAME TAXONRANK   TAXONDB TAXONDBID  \\\n",
      "0            Gadus morhua   species  Wikidata   Q199788   \n",
      "1            Gadus morhua   species  Wikidata   Q199788   \n",
      "2            Gadus morhua   species  Wikidata   Q199788   \n",
      "3            Gadus morhua   species  Wikidata   Q199788   \n",
      "4            Gadus morhua   species  Wikidata   Q199788   \n",
      "...                   ...       ...       ...       ...   \n",
      "14868  Platichthys flesus   species  Wikidata   Q214034   \n",
      "14869  Platichthys flesus   species  Wikidata   Q214034   \n",
      "14870  Platichthys flesus   species  Wikidata   Q214034   \n",
      "14871  Platichthys flesus   species  Wikidata   Q214034   \n",
      "14872   Perca fluviatilis   species  Wikidata   Q166812   \n",
      "\n",
      "                                  TAXONDBURL  \n",
      "0      https://www.wikidata.org/wiki/Q199788  \n",
      "1      https://www.wikidata.org/wiki/Q199788  \n",
      "2      https://www.wikidata.org/wiki/Q199788  \n",
      "3      https://www.wikidata.org/wiki/Q199788  \n",
      "4      https://www.wikidata.org/wiki/Q199788  \n",
      "...                                      ...  \n",
      "14868  https://www.wikidata.org/wiki/Q214034  \n",
      "14869  https://www.wikidata.org/wiki/Q214034  \n",
      "14870  https://www.wikidata.org/wiki/Q214034  \n",
      "14871  https://www.wikidata.org/wiki/Q214034  \n",
      "14872  https://www.wikidata.org/wiki/Q166812  \n",
      "\n",
      "[14873 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_to_dataframes(fname_in)\n",
    "tfm = Transformer(\n",
    "    dfs,\n",
    "    cbs=[\n",
    "        ValidateEnumsCB(\n",
    "            src_fname=fname_in,\n",
    "            enums=Enums(lut_src_dir=lut_path())\n",
    "            ),\n",
    "        ValidateNetCDFVarsCB(\n",
    "            src_fname=fname_in\n",
    "            ),            \n",
    "        AddTaxonInformationCB(\n",
    "            fn_lut=lut_taxon\n",
    "            ),\n",
    "        ConvertToHumanReadableCB(\n",
    "            src_fname=fname_in),      \n",
    "        DecodeTimeCB()\n",
    "    ]\n",
    ")\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(tfm.dfs['BIOTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2012-09-23\n",
       "1       2012-09-23\n",
       "2       2012-09-23\n",
       "3       2012-09-23\n",
       "4       2012-09-23\n",
       "           ...    \n",
       "14868   2018-02-26\n",
       "14869   2018-02-13\n",
       "14870   2018-02-13\n",
       "14871   2018-02-13\n",
       "14872   2018-10-03\n",
       "Name: TIME, Length: 14873, dtype: datetime64[ns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['BIOTA']['TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LON', 'LAT', 'SMP_DEPTH', 'TIME', 'NUCLIDE', 'VALUE', 'UNIT', 'DL',\n",
       "       'BIO_GROUP', 'SPECIES', 'BODY_PART', 'DRYWT', 'WETWT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['BIOTA'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding NETCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decode(\n",
    "    fname_in: str, # Input file name\n",
    "    dest_out: str | None = None, # Output file name (optional)\n",
    "    output_format: str = 'csv',\n",
    "    remap_vars: Dict[str, str] = OR_VARS,\n",
    "    verbose: bool = False,\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Decode data from NetCDF.\"\n",
    "    dfs = load_to_dataframes(fname_in)\n",
    "    print (dfs)\n",
    "    tfm = Transformer(\n",
    "        dfs,\n",
    "        cbs=[\n",
    "            ValidateEnumsCB(\n",
    "                src_fname=fname_in,\n",
    "                enums=Enums(lut_src_dir=lut_path())\n",
    "                ),\n",
    "            ValidateNetCDFVarsCB(\n",
    "                src_fname=fname_in\n",
    "                ),            \n",
    "            ConvertToHumanReadableCB(\n",
    "                src_fname=fname_in),      \n",
    "            DecodeTimeCB()\n",
    "        ]\n",
    "    )    \n",
    "    \n",
    "    tfm()\n",
    "    decoder = NetCDFDecoder( \n",
    "                            dfs=tfm.dfs,\n",
    "                            fname_in=fname_in,  \n",
    "                            dest_out=dest_out,                           \n",
    "                            output_format='csv',\n",
    "                            remap_vars=OR_VARS,\n",
    "                            verbose=verbose\n",
    "                    )\n",
    "    decoder.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BIOTA':              LON        LAT  SMP_DEPTH        TIME  NUCLIDE       VALUE  UNIT  \\\n",
      "0      12.316667  54.283333        NaN  1348358400       31    0.010140     5   \n",
      "1      12.316667  54.283333        NaN  1348358400        4  135.300003     5   \n",
      "2      12.316667  54.283333        NaN  1348358400        9    0.013980     5   \n",
      "3      12.316667  54.283333        NaN  1348358400       33    4.338000     5   \n",
      "4      12.316667  54.283333        NaN  1348358400       31    0.009614     5   \n",
      "...          ...        ...        ...         ...      ...         ...   ...   \n",
      "14868  19.000000  54.583302       61.0  1519603200       53    0.043000     5   \n",
      "14869  15.500000  54.333302       65.0  1518480000        4   98.000000     5   \n",
      "14870  15.500000  54.333302       65.0  1518480000       33    3.690000     5   \n",
      "14871  15.500000  54.333302       65.0  1518480000       53    0.049000     5   \n",
      "14872  19.433300  54.363899        NaN  1538524800       33    0.830000     5   \n",
      "\n",
      "       DL  BIO_GROUP  SPECIES  BODY_PART       DRYWT  WETWT  \n",
      "0       2          4       99         52  174.934433  948.0  \n",
      "1       1          4       99         52  174.934433  948.0  \n",
      "2       2          4       99         52  174.934433  948.0  \n",
      "3       1          4       99         52  174.934433  948.0  \n",
      "4       2          4       99         52  177.935120  964.0  \n",
      "...    ..        ...      ...        ...         ...    ...  \n",
      "14868   1          4      191          3  120.000000  500.0  \n",
      "14869   1          4      191         52  112.500000  500.0  \n",
      "14870   1          4      191         52  112.500000  500.0  \n",
      "14871   1          4      191         52  112.500000  500.0  \n",
      "14872   1          4      247         52         NaN  120.0  \n",
      "\n",
      "[14873 rows x 13 columns], 'SEAWATER':              LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  NUCLIDE  \\\n",
      "0      29.333300  60.083302        0.0        NaN  1337731200       33   \n",
      "1      29.333300  60.083302       29.0        NaN  1337731200       33   \n",
      "2      23.150000  59.433300        0.0        NaN  1339891200       33   \n",
      "3      27.983299  60.250000        0.0        NaN  1337817600       33   \n",
      "4      27.983299  60.250000       39.0        NaN  1337817600       33   \n",
      "...          ...        ...        ...        ...         ...      ...   \n",
      "20237  14.200000  54.006802        4.0       12.0  1434931200       12   \n",
      "20238  14.667200  54.499500        4.0       20.0  1435017600       12   \n",
      "20239  14.334200  54.750500        4.0       17.0  1435017600       12   \n",
      "20240  13.500200  54.916500        4.0       47.0  1435104000       12   \n",
      "20241  13.500200  54.916500       45.0       47.0  1435104000       12   \n",
      "\n",
      "           VALUE  UNIT  DL  FILT  \n",
      "0       5.300000     1   1     0  \n",
      "1      19.900000     1   1     0  \n",
      "2      25.500000     1   1     0  \n",
      "3      17.000000     1   1     0  \n",
      "4      22.200001     1   1     0  \n",
      "...          ...   ...  ..   ...  \n",
      "20237   6.600000     1   1     1  \n",
      "20238   6.900000     1   1     1  \n",
      "20239   6.800000     1   1     1  \n",
      "20240   7.300000     1   1     1  \n",
      "20241   5.500000     1   1     1  \n",
      "\n",
      "[20242 rows x 10 columns], 'SEDIMENT':            LON        LAT  TOT_DEPTH        TIME  AREA  NUCLIDE        VALUE  \\\n",
      "0      24.0000  59.666698       71.0  1339891200     0       53    35.000000   \n",
      "1      24.0000  59.666698       71.0  1339891200     0       53    36.000000   \n",
      "2      28.8433  59.860001       23.0  1344556800     0       53    38.000000   \n",
      "3      28.8433  59.860001       23.0  1344556800     0       53    36.000000   \n",
      "4      28.8433  59.860001       23.0  1344556800     0       53    30.000000   \n",
      "...        ...        ...        ...         ...   ...      ...          ...   \n",
      "63863  21.0830  59.035999      171.0  1465430400     0       33     8.916443   \n",
      "63864  21.0830  59.035999      171.0  1465430400     0       33     5.992929   \n",
      "63865  19.7297  61.066700      131.0  1464480000     0       33  2164.945801   \n",
      "63866  19.7297  61.066700      131.0  1464480000     0       33  2523.279053   \n",
      "63867  19.7297  61.066700      131.0  1464480000     0       33  3929.780029   \n",
      "\n",
      "       UNIT  DL  SED_TYPE   TOP  BOTTOM  \n",
      "0         4   1         0  15.0    20.0  \n",
      "1         4   1         0  20.0    27.0  \n",
      "2         4   1         0   0.0     2.0  \n",
      "3         4   1         0   2.0     4.0  \n",
      "4         4   1         0   4.0     6.0  \n",
      "...     ...  ..       ...   ...     ...  \n",
      "63863     4   1        50  18.0    20.0  \n",
      "63864     4   1        50  20.0    22.0  \n",
      "63865     4   1        59   0.0     2.0  \n",
      "63866     4   1        51   2.0     4.0  \n",
      "63867     4   1        50   4.0     6.0  \n",
      "\n",
      "[63868 rows x 12 columns]}\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "fname = Path('../../_data/output/100-HELCOM-MORS-2024.nc')\n",
    "decode(fname_in=fname, dest_out=fname.with_suffix(''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

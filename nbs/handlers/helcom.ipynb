{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709cfb6",
   "metadata": {},
   "source": [
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [HELCOM data](https://helcom.fi/about-us) into `NetCDF` format. The handler processes raw HELCOM data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw HELCOM data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring HELCOM data is properly integrated into the MARIS database.\n",
    "\n",
    "\n",
    "Note: *Additionally, an optional encoder (pipeline) is provided below to process data into a `.csv` format compatible with the MARIS master database. This feature is maintained for legacy purposes, as data ingestion was previously performed using OpenRefine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121843",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/helcom.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "#from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple, Any \n",
    "from collections import OrderedDict, defaultdict\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "from marisco.utils import (\n",
    "    Remapper, \n",
    "    ddmm_to_dd,\n",
    "    Match, \n",
    "    get_unique_across_dfs\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback, \n",
    "    Transformer, \n",
    "    EncodeTimeCB, \n",
    "    AddSampleTypeIdColumnCB,\n",
    "    AddNuclideIdColumnCB, \n",
    "    LowerStripNameCB, \n",
    "    SanitizeLonLatCB, \n",
    "    CompareDfsAndTfmCB, \n",
    "    RemapCB\n",
    ")\n",
    "\n",
    "from marisco.metadata import (\n",
    "    GlobAttrsFeeder, \n",
    "    BboxCB, \n",
    "    DepthRangeCB, \n",
    "    TimeRangeCB, \n",
    "    ZoteroCB, \n",
    "    KeyValuePairCB\n",
    ")\n",
    "\n",
    "from marisco.configs import (\n",
    "    nuc_lut_path, \n",
    "    nc_tpl_path, \n",
    "    cfg, \n",
    "    species_lut_path, \n",
    "    sediments_lut_path, \n",
    "    bodyparts_lut_path, \n",
    "    detection_limit_lut_path, \n",
    "    filtered_lut_path, \n",
    "    get_lut, \n",
    "    unit_lut_path,\n",
    "    prepmet_lut_path,\n",
    "    sampmet_lut_path,\n",
    "    counmet_lut_path, \n",
    "    NC_VARS\n",
    ")\n",
    "\n",
    "from marisco.encoders import (\n",
    "    NetCDFEncoder, \n",
    ")\n",
    "\n",
    "from marisco.decoders import (\n",
    "    nc_to_dfs,\n",
    "    get_netcdf_properties, \n",
    "    get_netcdf_group_properties,\n",
    "    get_netcdf_variable_properties\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration & file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **fname_in**: path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "- **ref_id**: refers to the location in Archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034b0a9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**:  Review NetCDF file name format, see (https://trello.com/c/RlB7mM8N#comment-6747489a3ef094e3520a4272)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "zotero_key ='26VMZZ2Q' # HELCOM MORS zotero key\n",
    "ref_id = 100 # HELCOM MORS reference id as defined by MARIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc83f",
   "metadata": {},
   "source": [
    "[Helcom MORS (Monitoring of Radioactive Substances in the Baltic Sea) data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "Metadata for the HELCOM MORS dataset is available [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    "**Example steps**:\n",
    "\n",
    "\n",
    "1. [Download data](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24)\n",
    "\n",
    "2. Install mdbtools via VScode Terminal: \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ```\n",
    "\n",
    "3. Install unzip via VScode Terminal:\n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ```\n",
    "\n",
    "4. In `VS Code` terminal (for instance), navigate to the marisco data folder:\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip `MORS_ENVIRONMENT.zip`:\n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run `preprocess.sh` to generate the required data files:\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ```\n",
    "\n",
    "7. Content of `preprocess.sh` script:\n",
    "\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n",
    "\n",
    "Once converted to `.csv` files, the data is ready to be loaded into a dictionary of dataframes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = {  \n",
    "    'BIO': 'BIOTA', \n",
    "    'SEA': 'SEAWATER', \n",
    "    'SED': 'SEDIMENT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir: str|Path, \n",
    "              smp_types: dict = default_smp_types \n",
    "             ) -> Dict[str, pd.DataFrame]: \n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df_meas = pd.read_csv(src_path / f'{file_prefix}02.csv')\n",
    "            df_smp = pd.read_csv(src_path / f'{file_prefix}01.csv')\n",
    "            return pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files for {file_prefix}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if files are not found\n",
    "    \n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types.items()}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys/sample types:  dict_keys(['BIOTA', 'SEAWATER', 'SEDIMENT'])\n",
      "BIOTA columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEAWATER columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEDIMENT columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('keys/sample types: ', dfs.keys())\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} columns: ', dfs[key].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4ceb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d84ed7",
   "metadata": {},
   "source": [
    "This is demonstrated below for the `NUCLIDE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      value  n_chars  stripped_chars\n",
      "6       6   AM241           8               5\n",
      "14     14     CS137         6               5\n",
      "16     16     SR90          6               4\n",
      "18     18    SR90           7               4\n",
      "20     20   CO60            8               4\n",
      "31     31    TC99           7               4\n",
      "33     33   CS134           8               5\n",
      "34     34   CS137           8               5\n",
      "39     39   SR90            8               4\n",
      "52     52   PU238           8               5\n",
      "53     53  CS137            9               5\n",
      "57     57      SR90         5               4\n",
      "80     80   K40             8               3\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(fname_in), 'NUCLIDE', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "SEAWATER nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "SEDIMENT nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "for key in tfm().keys():\n",
    "    print(f'{key} nuclides: ')\n",
    "    print(tfm()[key]['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58baf14",
   "metadata": {},
   "source": [
    "Below, we map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures to MARIS standards is a recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "We will refer to this process as **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31bc",
   "metadata": {},
   "source": [
    "The `get_unique_across_dfs` function is a utility in MARISCO that retrieves unique values from a specified column across all DataFrames. \n",
    "Note that there is one DataFrame for each sample type, such as biota, sediment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ee8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>k40</td>\n",
       "      <td>sb125</td>\n",
       "      <td>fe59</td>\n",
       "      <td>th228</td>\n",
       "      <td>ag110m</td>\n",
       "      <td>co60</td>\n",
       "      <td>be7</td>\n",
       "      <td>u238</td>\n",
       "      <td>pu239</td>\n",
       "      <td>sn113</td>\n",
       "      <td>...</td>\n",
       "      <td>bi214</td>\n",
       "      <td>ag108m</td>\n",
       "      <td>cs145</td>\n",
       "      <td>ra226</td>\n",
       "      <td>sc46</td>\n",
       "      <td>pu241</td>\n",
       "      <td>ce144</td>\n",
       "      <td>u234</td>\n",
       "      <td>am241</td>\n",
       "      <td>cs140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2      3       4     5    6     7      8      9   ...  \\\n",
       "index    0      1     2      3       4     5    6     7      8      9  ...   \n",
       "value  k40  sb125  fe59  th228  ag110m  co60  be7  u238  pu239  sn113  ...   \n",
       "\n",
       "          67      68     69     70    71     72     73    74     75     76  \n",
       "index     67      68     69     70    71     72     73    74     75     76  \n",
       "value  bi214  ag108m  cs145  ra226  sc46  pu241  ce144  u234  am241  cs140  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "dfs_output = tfm()\n",
    "\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1bdf",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the nuclide names of the HELCOM dataset to the MARIS standard nuclide names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0ea0c",
   "metadata": {},
   "source": [
    "Lets try to match HELCOM nuclide names to MARIS standard nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 38.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 entries matched the criteria, while 14 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cs134137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs134137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cm243244</th>\n",
       "      <td>cm242</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu238240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu238240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu239240</th>\n",
       "      <td>pu239</td>\n",
       "      <td>pu239240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs143</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs142</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs145</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs144</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-40</th>\n",
       "      <td>k40</td>\n",
       "      <td>k-40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs138</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs139</th>\n",
       "      <td>ce139</td>\n",
       "      <td>cs139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs146</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs141</th>\n",
       "      <td>ce141</td>\n",
       "      <td>cs141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs140</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "cs134137                cs137    cs134137            3\n",
       "cm243244                cm242    cm243244            3\n",
       "pu238240                pu240    pu238240            3\n",
       "pu239240                pu239    pu239240            3\n",
       "cs143                   ce140       cs143            2\n",
       "cs142                   ce140       cs142            2\n",
       "cs145                   ce140       cs145            2\n",
       "cs144                   cs134       cs144            1\n",
       "k-40                      k40        k-40            1\n",
       "cs138                   cs134       cs138            1\n",
       "cs139                   ce139       cs139            1\n",
       "cs146                   cs136       cs146            1\n",
       "cs141                   ce141       cs141            1\n",
       "cs140                   ce140       cs140            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cb838",
   "metadata": {},
   "source": [
    "We can now manually inspect the unmatched nuclide names and create a table to correct them to the MARIS standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs143': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'k-40': 'k40',\n",
    "    'cs140': 'cs137',\n",
    "    'cs146': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs138': 'cs137'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575e7e",
   "metadata": {},
   "source": [
    "We now include the table `fixes_nuclide_names`, which applies manual corrections to the nuclide names before the remapping process. \n",
    "The `generate_lookup_table` function has an `overwrite` parameter (default is `True`), which, when set to `True`, creates a pickle file cache of the lookup table. We can now test the remapping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 34.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 entries matched the criteria, while 0 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1, verbose=True)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1276f",
   "metadata": {},
   "source": [
    "Test passes! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a189ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_helcom.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0281b22",
   "metadata": {},
   "source": [
    "We now create the callback `RemapNuclideNameCB`, which will remap the nuclide names using the `lut_nuclides` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    \"Remap data provider nuclide names to MARIS nuclide names.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name='NUCLIDE', as_df=True)\n",
    "        #lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        lut = {k: v.matched_id for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce649d7a",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `RemapRdnNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31,  4,  9, 33, 12, 21,  6,  8, 22, 10, 24, 77, 17,  2, 37, 41, 47,\n",
       "       23, 11, 13, 25, 16, 14, 36, 35, 29, 34, 67, 63, 46, 43, 42, 94, 55,\n",
       "       50, 40, 53, 87, 92, 86, 15,  7, 93, 85, 91, 90, 51, 59, 76, 72, 54,\n",
       "       57])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides)\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "dfs_out['BIOTA'].NUCLIDE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24856dc5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Time/date is provide in the `DATE`, `YEAR`\n",
    ", `MONTH`, `DAY` columns. Note that the `DATE` contains missing values as indicated below. When missing, we fallback on the `YEAR`, `MONTH`, `DAY` columns. Note also that sometimes `DAY` and `MONTH` contain 0. In this case we systematically set them to 1.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612873e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA DATE null values:  84\n",
      "SEAWATER DATE null values:  494\n",
      "SEDIMENT DATE null values:  741\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} DATE null values: ', dfs[key]['DATE'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Parse and standardize time information in the dataframe.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._process_dates(df)\n",
    "\n",
    "    def _process_dates(self, df: pd.DataFrame) -> None:\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['TIME'] = self._parse_date(df)\n",
    "        self._handle_missing_dates(df)\n",
    "        self._fill_missing_time(df)\n",
    "\n",
    "    def _parse_date(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"Parse the DATE column if present.\"\n",
    "        return pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "\n",
    "    def _handle_missing_dates(self, df: pd.DataFrame):\n",
    "        \"Handle cases where DAY or MONTH is 0 or missing.\"\n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        missing_day_month = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[missing_day_month, [\"DAY\", \"MONTH\"]] = 1\n",
    "\n",
    "    def _fill_missing_time(self, df: pd.DataFrame) -> None:\n",
    "        \"Fill missing time values using YEAR, MONTH, and DAY columns.\"\n",
    "        missing_time = df['TIME'].isna()\n",
    "        df.loc[missing_time, 'TIME'] = pd.to_datetime(\n",
    "            df.loc[missing_time, ['YEAR', 'MONTH', 'DAY']], \n",
    "            format='%Y%m%d', \n",
    "            errors='coerce'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the `TIME` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "            TIME\n",
      "0     2012-05-23\n",
      "1     2012-05-23\n",
      "2     2012-06-17\n",
      "3     2012-05-24\n",
      "4     2012-05-24\n",
      "...          ...\n",
      "20313 2015-06-22\n",
      "20314 2015-06-23\n",
      "20315 2015-06-23\n",
      "20316 2015-06-24\n",
      "20317 2015-06-24\n",
      "\n",
      "[20318 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['SEAWATER'][['TIME']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "The NetCDF time format requires that time be encoded as the number of milliseconds since a specified origin. In our case, the origin is `1970-01-01`, as indicated in the `cdl.toml` file under the `[vars.defaults.time.attrs]` section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de49e39",
   "metadata": {},
   "source": [
    "We allocate each column containing measurement values (named differently across sample types) into a single column `VALUE` and remove NA where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_val = {'SEAWATER' : {'VALUE': 'VALUE_Bq/m³'},\n",
    "           'BIOTA':  {'VALUE': 'VALUE_Bq/kg'},\n",
    "           'SEDIMENT': {'VALUE': 'VALUE_Bq/kg'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SanitizeValue(Callback):\n",
    "    \"Sanitize value/measurement by removing blank entries and populating `value` column.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, str]] # Columns of interest. Format: {group_name: {'val': 'column_name'}}\n",
    "                 ): \n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            value_col = self.coi[grp]['VALUE']\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            df['VALUE'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14873     20242     37090\n",
      "Number of rows removed        20        76       257 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df: pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col: str, # Name of the column with measurement values\n",
    "    unc_col: str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the `UNCERTAINTY` is provided as a relative uncertainty. The column names for both the `VALUE` and the `UNCERTAINTY` vary by sample type. The `coi_units_unc` dictionary defines the column names for the `VALUE` and `UNCERTAINTY` for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('SEAWATER', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('BIOTA', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('SEDIMENT', 'VALUE_Bq/kg', 'ERROR%_kg')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the ``UNCERTAINTY`` by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"Convert from relative error % to standard uncertainty.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc: Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi: List[Tuple[str, str, str]]=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['UNCERTAINTY'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback ``NormalizeUncCB``. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALUE  UNCERTAINTY\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        VALUE  UNCERTAINTY\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   VALUE  UNCERTAINTY\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val)])\n",
    "tfm()\n",
    "print(tfm.dfs['SEAWATER'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['BIOTA'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['SEDIMENT'][['VALUE', 'UNCERTAINTY']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda9f9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: RUBIN contains codes that are not found in the HELCOM biota dataset. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe37ba",
   "metadata": {},
   "source": [
    "For example, 'CH HI;BA', its not in the HELCOM biota dataset. Lets return the uniue RUBIN of the HELCOM biota dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33953cd",
   "metadata": {},
   "source": [
    "Other unused RUBIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e11297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused RUBIN names: ['CH HI;BA', 'SOLE SOL']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "unique_rubin = dfs['BIOTA']['RUBIN'].unique()\n",
    "unique_rubin_set = set(unique_rubin)\n",
    "rubin_lut = list(pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')['RUBIN'])\n",
    "unused_rubins = [rune for rune in rubin_lut if rune not in unique_rubin_set]\n",
    "print(\"Unused RUBIN names:\", unused_rubins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7129a",
   "metadata": {},
   "source": [
    "We will remap the HELCOM `RUBIN` column to the MARIS `SPECIES` column using the **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply) pattern. First lets **inspect** the `RUBIN_NAME.csv` file provided by HELCOM, which describes the nomenclature of biota species.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d23db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/marisco/.marisco/lut/dbo_species_2024_11_19.xlsx')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "species_lut_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1858121",
   "metadata": {},
   "source": [
    "Now we try to **MATCH** the `SCIENTIFIC NAME` column of HELCOM biota dataset to the `species` column of the MARIS species lookup table, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:07<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMI SAC</th>\n",
       "      <td>Laminaria japonica</td>\n",
       "      <td>LAMINARIA SACCHARINA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD EDU</th>\n",
       "      <td>Cardiidae</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH HI;BA</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>CHARA BALTICA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSET MAX</th>\n",
       "      <td>Pinctada maxima</td>\n",
       "      <td>PSETTA MAXIMA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA           10\n",
       "LAMI SAC     Laminaria japonica     LAMINARIA SACCHARINA            7\n",
       "CARD EDU              Cardiidae            CARDIUM EDULE            6\n",
       "CH HI;BA        Macoma balthica            CHARA BALTICA            6\n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "PSET MAX        Pinctada maxima            PSETTA MAXIMA            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='SCIENTIFIC NAME',\n",
    "                    provider_col_key='RUBIN',\n",
    "                    fname_cache='species_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3b8aa",
   "metadata": {},
   "source": [
    "Below, we will correct the entries that were not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_species = {\n",
    "    'CHARA BALTICA': 'NOT AVAILABLE', # CHARA BALTICA (RUBIN: CH HI;BA) is not listed in the biota data. \n",
    "    'CARDIUM EDULE': 'Cerastoderma edule',\n",
    "    'LAMINARIA SACCHARINA': 'Saccharina latissima',\n",
    "    'PSETTA MAXIMA': 'Scophthalmus maximus',\n",
    "    'STIZOSTEDION LUCIOPERCA': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781f210",
   "metadata": {},
   "source": [
    "And give the ``remapper`` another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb07a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:07<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a5",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `RUBIN` column to the `species` column after having defined the lookup table `lut_biota`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='SCIENTIFIC NAME',\n",
    "                             provider_col_key='RUBIN',\n",
    "                             fname_cache='species_helcom.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA')\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "print(tfm.dfs['BIOTA']['SPECIES'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "## Remap Biota tissues\n",
    "Let's inspect the `TISSUE.csv` file provided by HELCOM describing the tissue nomenclature. Biota tissue is known as `body part` in the maris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 95.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>SKIN/EPIDERMIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brain</td>\n",
       "      <td>ENTRAILS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                           source_name  \\\n",
       "source_key                                                                \n",
       "3             Flesh without bones  WHOLE FISH WITHOUT HEAD AND ENTRAILS   \n",
       "2             Flesh without bones           WHOLE FISH WITHOUT ENTRAILS   \n",
       "8                      Soft parts                        SKIN/EPIDERMIS   \n",
       "5             Flesh without bones          FLESH WITHOUT BONES (FILETS)   \n",
       "1                    Whole animal                            WHOLE FISH   \n",
       "12                          Brain                              ENTRAILS   \n",
       "15          Stomach and intestine                   STOMACH + INTESTINE   \n",
       "41                   Whole animal                         WHOLE ANIMALS   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "3                    20  \n",
       "2                    13  \n",
       "8                    10  \n",
       "5                     9  \n",
       "1                     5  \n",
       "12                    5  \n",
       "15                    3  \n",
       "41                    1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                    provider_col_key='TISSUE',\n",
    "                    fname_cache='tissues_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1bb9",
   "metadata": {},
   "source": [
    "We address several entries that were not correctly matched by the Remapper object, as detailed below:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_tissues = {\n",
    "    'WHOLE FISH WITHOUT HEAD AND ENTRAILS': 'Whole animal eviscerated without head',\n",
    "    'ENTRAILS': 'Viscera',\n",
    "    'SKIN/EPIDERMIS': 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 99.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 entries matched the criteria, while 5 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                   source_name  match_score\n",
       "source_key                                                                  \n",
       "2             Flesh without bones   WHOLE FISH WITHOUT ENTRAILS           13\n",
       "5             Flesh without bones  FLESH WITHOUT BONES (FILETS)            9\n",
       "1                    Whole animal                    WHOLE FISH            5\n",
       "15          Stomach and intestine           STOMACH + INTESTINE            3\n",
       "41                   Whole animal                 WHOLE ANIMALS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef75cb1",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `TISSUE` column to the `body_part` column after having defined the lookup table `lut_tissues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                               provider_col_key='TISSUE',\n",
    "                               fname_cache='tissues_helcom.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1887c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  BODY_PART\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA'][['TISSUE', 'BODY_PART']][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "## Remap biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f111f2",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "\n",
    "1) Is this needed in NETCDF? Can enum include the species and biogroup LUT?\n",
    "\n",
    "2) Include the `lut_biogroup_from_biota` callback in utils.ipynb. \n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`lut_biogroup_from_biota` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biogroup_from_biota = lambda: get_lut(src_dir=species_lut_path().parent, fname=species_lut_path().name, \n",
    "                               key='species_id', value='biogroup_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a37157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA')\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA']['BIO_GROUP'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "## Remap Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938d40",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `SEDI` values `56` and `73` are not found in the `SEDIMENT_TYPE.csv` lookup table provided. Note also there are many `nan` values in the `SEDIMENT_TYPE.csv` file.\n",
    "\n",
    "We reassign them to `-99` for now but should be clarified/fixed. This is demonstrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SEDI values: {56.0, 73.0, nan}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_sed_lut = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "sediment_sedi = set(dfs['SEDIMENT'].SEDI.unique())\n",
    "lookup_sedi = set(df_sed_lut['SEDI'])\n",
    "missing = sediment_sedi - lookup_sedi\n",
    "print(f\"Missing SEDI values: {missing if missing else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1b5c5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    " ``SedRepName`` is used by OpenRefine. ``SedRepName`` is not included in the NetCDF encoding. Description of the `SedRepName` from [MARIS Data Formats\n",
    "](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide); 'Name of the sediment as reported by the data provider. The sediment name should be stored exactly as provided, without any modifications'. \n",
    "\n",
    "This information will be lost with the latest workflow (creating netcdf and decoding to csv) if we do not include strings in the netcdf encoding. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffefc5",
   "metadata": {},
   "source": [
    "Once again, we employ the **IMFA** (Inspect, Match, Fix, Apply) pattern to remap the HELCOM sediment types. Let's inspect the `SEDIMENT_TYPE.csv` file provided by HELCOM describing the sediment type nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI    SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99          NO DATA                    NaN\n",
       "1    30  SILT AND GRAVEL                    YES\n",
       "2     0           GRAVEL                    YES\n",
       "3     1             SAND                    YES\n",
       "4     2        FINE SAND                     NO"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e669f",
   "metadata": {},
   "source": [
    "Let's try to match as many as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 82.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 entries matched the criteria, while 3 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>Soft</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99                      Soft         NO DATA            5\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in)/'SEDIMENT_TYPE.csv'),\n",
    "                    maris_lut_fn=sediments_lut_path,\n",
    "                    maris_col_id='sedtype_id',\n",
    "                    maris_col_name='sedtype',\n",
    "                    provider_col_to_match='SEDIMENT TYPE',\n",
    "                    provider_col_key='SEDI',\n",
    "                    fname_cache='sediments_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a92e4",
   "metadata": {},
   "source": [
    "We address the remaining unmatched values by adding fixes_sediments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_sediments = {\n",
    "    'NO DATA': '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05728a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 86.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 entries matched the criteria, while 2 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "50             Mud and gravel  MUD AND GARVEL            2\n",
       "46               Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_sediments)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152c8c7",
   "metadata": {},
   "source": [
    "A visual inspection of the remaining values shows that they are acceptable to proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedimentCB(Callback):\n",
    "    \"Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable,  # Function that returns the lookup table dictionary\n",
    "                 sed_grp_name: str = 'SEDIMENT',  # The name of the sediment group\n",
    "                 replace_lut: dict = None  # Dictionary for replacing SEDI values\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Fix inconsistent SEDI values\n",
    "        tfm.dfs[self.sed_grp_name] = self._fix_inconsistent_sedi(tfm.dfs[self.sed_grp_name], self.replace_lut)\n",
    "        \n",
    "        # Get unique SEDI values\n",
    "        unique_sedi = tfm.dfs[self.sed_grp_name]['SEDI'].unique()\n",
    "        \n",
    "        # Get sediment types for unique SEDI values\n",
    "        sediment_mapping = self._get_sediment_types(unique_sedi, lut)\n",
    "        \n",
    "        # Replace SEDI values in the DataFrame using the mapping\n",
    "        tfm.dfs[self.sed_grp_name]['SED_TYPE'] = tfm.dfs[self.sed_grp_name]['SEDI'].map(sediment_mapping)\n",
    "\n",
    "    def _fix_inconsistent_sedi(self, df: pd.DataFrame, replace_lut: dict) -> pd.DataFrame:\n",
    "        \"Temporary fix for inconsistent SEDI values. Data provider to confirm and clarify.\"\n",
    "        df['SEDI'] = df['SEDI'].replace(replace_lut)\n",
    "        return df\n",
    "\n",
    "    def _get_sediment_types(self, unique_sedi: np.ndarray, lut: dict) -> dict:\n",
    "        \"Get sediment types for unique SEDI values and return a mapping dictionary.\"\n",
    "        sediment_mapping = {}\n",
    "        \n",
    "        for sedi_value in unique_sedi:\n",
    "            match = lut.get(sedi_value, Match(0, None, None, None))\n",
    "            if match.matched_id == 0:\n",
    "                self._print_unmatched_sedi(sedi_value)\n",
    "            sediment_mapping[sedi_value] = match.matched_id\n",
    "        \n",
    "        return sediment_mapping\n",
    "\n",
    "    def _print_unmatched_sedi(self, \n",
    "                              sedi_value: int,  # The `SEDI` value from the DataFrame\n",
    "                             ) -> None:\n",
    "        \"Print the SEDI value if the matched_id is 0 (i.e. Not available).\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_sediments = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv'),\n",
    "                                 maris_lut_fn=sediments_lut_path,\n",
    "                                 maris_col_id='sedtype_id',\n",
    "                                 maris_col_name='sedtype',\n",
    "                                 provider_col_to_match='SEDIMENT TYPE',\n",
    "                                 provider_col_key='SEDI',\n",
    "                                 fname_cache='sediments_helcom.pkl'\n",
    "                                 ).generate_lookup_table(fixes=fixes_sediments, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e7e02",
   "metadata": {},
   "source": [
    "Reassign the `SEDI` values of `56`, `73`, and `nan` to `-99`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63482233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "sed_replace_lut = {\n",
    "    56: -99,\n",
    "    73: -99,\n",
    "    np.nan: -99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d334ac",
   "metadata": {},
   "source": [
    "Utilize the RemapSedimentCB callback to remap the SEDI values in the HELCOM dataset to the corresponding MARIS standard sediment type, referred to as SED_TYPE. After the remapping process, display the SEDI and SED_TYPE columns from the SEDIMENT DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25495b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 58, 30, 59, 55, 56, 36, 29, 47,  4, 54, 33,  6, 44, 42, 48,\n",
       "       61, 57, 28, 49, 32, 45, 39, 46, 38, 31, 60, 62, 26, 53, 52,  1, 51,\n",
       "       37, 34, 50,  7, 10, 41, 43, 35])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut)])\n",
    "\n",
    "tfm()\n",
    "\n",
    "tfm.dfs['SEDIMENT']['SED_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4064ed",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The handling of unit types varies between `biota` and `sediment` sample types. For consistency and ease of use, it would be beneficial to have dedicated unit columns for all sample types.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a682ac",
   "metadata": {},
   "source": [
    "Given the inconsistent handling of units across sample types, we need to define custom mapping rules for standardizing the units. The units available in MARIS are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab93970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized\n",
       "0        -1  Not applicable  Not applicable\n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE\n",
       "2         1           Bq/m3       Bq per m3\n",
       "3         2           Bq/m2       Bq per m2\n",
       "4         3           Bq/kg       Bq per kg\n",
       "5         4          Bq/kgd      Bq per kgd\n",
       "6         5          Bq/kgw      Bq per kgw\n",
       "7         6           kg/kg       kg per kg\n",
       "8         7              TU              TU\n",
       "9         8      DELTA/mill  DELTA per mill\n",
       "10        9         atom/kg     atom per kg\n",
       "11       10        atom/kgd    atom per kgd\n",
       "12       11        atom/kgw    atom per kgw\n",
       "13       12          atom/l      atom per l\n",
       "14       13          Bq/kgC      Bq per kgC"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())[['unit_id', 'unit', 'unit_sanitized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "We define unit renaming rules for HELCOM in an **ad hoc** way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_units = {\n",
    "    'SEAWATER': 1,  # 'Bq/m3'\n",
    "    'SEDIMENT': 4,  # 'Bq/kgd' for sediment\n",
    "    'BIOTA': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapUnitCB(Callback):\n",
    "    \"Set the `unit` id column in the DataFrames based on a lookup table.\"\n",
    "    def __init__(self, \n",
    "                 lut_units: dict=lut_units # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp in ['SEAWATER', 'SEDIMENT']:\n",
    "                tfm.dfs[grp]['UNIT'] = self.lut_units[grp]\n",
    "            else:\n",
    "                tfm.dfs[grp]['UNIT'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut_units[grp].get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `RemapUnitCB()`. Then, print the unique `UNIT` for the `SEAWATER` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [5 0 4]\n",
      "SEDIMENT: [4]\n",
      "SEAWATER: [1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapUnitCB()])\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['UNIT'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "## Remap detection limit\n",
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b07268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7083b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023ddb4",
   "metadata": {},
   "source": [
    "Based on columns of interest for each sample type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc43c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'SEAWATER' : {'VALUE' : 'VALUE_Bq/m³',\n",
    "                       'UNCERTAINTY' : 'ERROR%_m³',\n",
    "                       'DL' : '< VALUE_Bq/m³'},\n",
    "          'BIOTA':  {'VALUE' : 'VALUE_Bq/kg',\n",
    "                     'UNCERTAINTY' : 'ERROR%',\n",
    "                     'DL' : '< VALUE_Bq/kg'},\n",
    "          'SEDIMENT': {\n",
    "              'VALUE' : 'VALUE_Bq/kg',\n",
    "              'UNCERTAINTY' : 'ERROR%_kg',\n",
    "              'DL' : '< VALUE_Bq/kg'}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ac6a6",
   "metadata": {},
   "source": [
    "We follow the following business logic to encode the detection limit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`RemapDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or DL) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 coi: dict,  # Configuration options for column names\n",
    "                 fn_lut: Callable  # Function that returns a lookup table\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "\n",
    "    def _update_detection_limit(self, \n",
    "                                df: pd.DataFrame,  # The DataFrame to modify\n",
    "                                grp: str,  # The group name to get the column configuration\n",
    "                                lut: dict  # The lookup table dictionary\n",
    "                               ) -> None:\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        \n",
    "        # Check if the group exists in coi_dl\n",
    "        if grp not in coi_dl:\n",
    "            raise ValueError(f\"Group '{grp}' not found in coi_dl configuration.\")\n",
    "        \n",
    "        # Access column names from coi_dl\n",
    "        value_col = coi_dl[grp]['VALUE']\n",
    "        uncertainty_col = coi_dl[grp]['UNCERTAINTY']\n",
    "        detection_col = coi_dl[grp]['DL']\n",
    "\n",
    "        # Initialize detection limit column\n",
    "        df['DL'] = df[detection_col]\n",
    "        \n",
    "        # Set detection limits based on conditions\n",
    "        self._set_detection_limits(df, value_col, uncertainty_col, lut)\n",
    "\n",
    "    def _set_detection_limits(self, df: pd.DataFrame, value_col: str, uncertainty_col: str, lut: dict) -> None:\n",
    "        \"Set detection limits based on value and uncertainty columns.\"\n",
    "        \n",
    "        # Condition for setting '='\n",
    "        # 'DL' defaults to equal (i.e. '=') if there is a value and uncertainty and 'DL' value is not \n",
    "        # in the lookup table.\n",
    "        \n",
    "        condition_eq =(df[value_col].notna() & \n",
    "                       df[uncertainty_col].notna() & \n",
    "                       ~df['DL'].isin(lut.keys())\n",
    "        )\n",
    "        \n",
    "        df.loc[condition_eq, 'DL'] = '='\n",
    "\n",
    "        # Set 'Not Available' for unmatched detection limits\n",
    "        df.loc[~df['DL'].isin(lut.keys()), 'DL'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup to map detection limits\n",
    "        df['DL'] = df['DL'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [2 1 0]\n",
      "SEDIMENT: [1 2 0]\n",
      "SEAWATER: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl)])\n",
    "\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['DL'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "## Remap filtering status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea63f3",
   "metadata": {},
   "source": [
    "HELCOM filtered status is encoded as follows in the `FILT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index value\n",
       "0      0   NaN\n",
       "1      1     N\n",
       "2      2     n\n",
       "3      3     F"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "get_unique_across_dfs(dfs, col_name='FILT', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee067",
   "metadata": {},
   "source": [
    "MARIS uses a different encoding for filtered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(filtered_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf457",
   "metadata": {},
   "source": [
    "For only four categories to remap, the `Remapper` is an overkill. We can use a simple dictionary to map the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_filtered = {\n",
    "    'N': 2, # No\n",
    "    'n': 2, # No\n",
    "    'F': 1 # Yes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`RemapFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapFiltCB(Callback):\n",
    "    \"Lookup FILT value in dataframe using the lookup table.\"\n",
    "    def __init__(self,\n",
    "                 lut_filtered: dict=lut_filtered, # Dictionary mapping FILT codes to their corresponding names\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'FILT' in df.columns:\n",
    "                df['FILT'] = df['FILT'].map(lambda x: self.lut_filtered.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719feb2c",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapFiltCB(lut_filtered)])\n",
    "\n",
    "print(tfm()['SEAWATER']['FILT'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "## Add Sample Laboratory code (REVIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3625631",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "A sample laboratory code allows for entires in the netcdf or csv to be traced back to the samples in the datasource. \n",
    "A sample laboratory code is not included in the NetCDF output as it requries string values data types. We planned to include way to reference the entries using the SMP_ID (of data type integer). The SMP_ID works for some datasets (e.g. GEOTRACES) but not for others (e.g. HELCOM). The `KEY` column of the HELCOM dataset contains a unique code that comprises of a station code followed by a integer sequence. Below the uniqueness of the integer part of the `KEY` column is checked. It was found that the integer part of the `KEY` column is not unique.\n",
    "\n",
    "Possible solutions:\n",
    "- Use `SMP_ID` to generate unique integer IDs for each sample. Then link the `SMP_ID` to the `samplabcode` using a lookup table. How best to share the lookup table? \n",
    "- Use fixed length string IDs for each entry.\n",
    "- Use VLEN strings in the netcdf and pass the the `samplabcode` as is.\n",
    "\n",
    "Options will be explored in a separate notebook.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def check_unique_key_int(tfm):\n",
    "    \"\"\"\n",
    "    Extracts unique 'KEY' values from specified DataFrames, separates them into string and integer components,\n",
    "    and groups keys by their integer components.\n",
    "\n",
    "    Parameters:\n",
    "    tfm (Transformer): The transformer object containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with the unique keys, their string and integer components, and grouped keys by integer component.\n",
    "    \"\"\"\n",
    "    # Define the groups to extract keys from\n",
    "    groups = ['SEAWATER', 'BIOTA', 'SEDIMENT']\n",
    "    \n",
    "    # Initialize a set to store unique keys\n",
    "    unique_keys = set()\n",
    "    \n",
    "    # Collect unique keys from each DataFrame\n",
    "    for grp in groups:\n",
    "        unique_keys.update(tfm.dfs[grp]['KEY'].unique())\n",
    "    \n",
    "    # Initialize a dictionary to group keys by their integer components\n",
    "    int_key_map = {}\n",
    "    \n",
    "    for key in unique_keys:\n",
    "        # Assuming the integer part starts after the first 5 characters\n",
    "        int_part = int(key[5:]) if key[5:].isdigit() else None  # Remaining part as integer\n",
    "        \n",
    "        if int_part is not None:\n",
    "            if int_part not in int_key_map:\n",
    "                int_key_map[int_part] = []  # Initialize list for this integer part\n",
    "            int_key_map[int_part].append(key)  # Append the complete key to the list\n",
    "    \n",
    "    return {\n",
    "        'int_key_map': int_key_map  # Return the mapping of integer parts to complete keys\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEYS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT COMPONENT OF `KEY`</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012025</th>\n",
       "      <td>[WKRIL2012025, SSTUK2012025, BVTIG2012025, WRISO2012025, SDHIG2012025, SSSSM2012025, SCLOR2012025, SKRIL2012025, WIMGW2012025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005011</th>\n",
       "      <td>[WIMGW2005011, SCLOR2005011, BRISO2005011, BSTUK2005011, WRISO2005011, WLEPA2005011, SLEPA2005011, WSTUK2005011, SKRIL2005011, SLVEA2005011, BSSSI2005011, BCLOR2005011, SSSSI2005011, SRISO2005011, WKRIL2005011, BBFFG2005011, SSTUK2005011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987079</th>\n",
       "      <td>[SDHIG1987079, WSAAS1987079, BBFFG1987079, SSAAS1987079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004022</th>\n",
       "      <td>[WRISO2004022, WKRIL2004022, WIMGW2004022, SSSSI2004022, WSTUK2004022, SCLOR2004022, SKRIL2004022, BCLOR2004022, SLVEA2004022, SSTUK2004022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006077</th>\n",
       "      <td>[SSTUK2006077, SCLOR2006077]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                  KEYS\n",
       "INT COMPONENT OF `KEY`                                                                                                                                                                                                                                                \n",
       "2012025                                                                                                                                 [WKRIL2012025, SSTUK2012025, BVTIG2012025, WRISO2012025, SDHIG2012025, SSSSM2012025, SCLOR2012025, SKRIL2012025, WIMGW2012025]\n",
       "2005011                 [WIMGW2005011, SCLOR2005011, BRISO2005011, BSTUK2005011, WRISO2005011, WLEPA2005011, SLEPA2005011, WSTUK2005011, SKRIL2005011, SLVEA2005011, BSSSI2005011, BCLOR2005011, SSSSI2005011, SRISO2005011, WKRIL2005011, BBFFG2005011, SSTUK2005011]\n",
       "1987079                                                                                                                                                                                                       [SDHIG1987079, WSAAS1987079, BBFFG1987079, SSAAS1987079]\n",
       "2004022                                                                                                                   [WRISO2004022, WKRIL2004022, WIMGW2004022, SSSSI2004022, WSTUK2004022, SCLOR2004022, SKRIL2004022, BCLOR2004022, SLVEA2004022, SSTUK2004022]\n",
       "2006077                                                                                                                                                                                                                                   [SSTUK2006077, SCLOR2006077]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Create DataFrame from dictionary and set index name and column name\n",
    "unique_key_df = pd.DataFrame.from_dict(check_unique_key_int(tfm)).rename_axis('INT COMPONENT OF `KEY`')\n",
    "unique_key_df=unique_key_df.rename(columns={unique_key_df.columns[0]: 'KEYS'})\n",
    "unique_key_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a6766",
   "metadata": {},
   "source": [
    "The INT component of the `KEY` column is not unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c5e32",
   "metadata": {},
   "source": [
    "Sample Laboratory code is currently stored in MARIS master DB but not encoded as NetCDF variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a02de8",
   "metadata": {},
   "source": [
    "Remove the samplabcode column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# | exports\\nclass AddSampleLabCodeCB(Callback):\\n    \"Remap `KEY` column to `samplabcode` in each DataFrame.\"\\n    def __call__(self, tfm: Transformer):\\n        for grp in tfm.dfs:\\n            self._remap_sample_id(tfm.dfs[grp])\\n    \\n    def _remap_sample_id(self, df: pd.DataFrame):\\n        df[\\'samplabcode\\'] = df[\\'KEY\\']\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# | exports\n",
    "class AddSampleLabCodeCB(Callback):\n",
    "    \"Remap `KEY` column to `samplabcode` in each DataFrame.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp])\n",
    "    \n",
    "    def _remap_sample_id(self, df: pd.DataFrame):\n",
    "        df['samplabcode'] = df['KEY']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AttributeError\\n#| eval: false\\ndfs = load_data(fname_in)\\ntfm = Transformer(dfs, cbs=[\\n                            AddSampleLabCodeCB(),\\n                            CompareDfsAndTfmCB(dfs)\\n                            ])\\n\\nprint(tfm()['seawater']['samplabcode'].unique())\\nprint(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\\n\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''AttributeError\n",
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['samplabcode'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05383c",
   "metadata": {},
   "source": [
    "## Add Methods (FOR NEXT VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7dcdb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "\n",
    "The HELCOM analysis method descriptions currently lack standardization, resulting in 63 unique descriptions for the methods used in the dataset. This variability complicates the integration of counting methods, sample methods, and preparation methods into the NetCDF output. The contents of the description field maps to MARIS NetCDF variables `COUNT_MET`, `SAMP_MET`, and `PREP_MET`. The HELCOM dataset includes 63 unique descriptions. \n",
    "Perhaps a LLM could help to standardize the methods?\n",
    "The MARIS counting method LUT includes methods that are similar. This might be challenging to identify by the LLM (or manually)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307c018",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a look-up table `ANALYSIS_METHOD.csv` which captures the methods used by HELCOM in a description field (free text). Lets review the ANALYSIS METHOD descriptions of HELCOM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG01</td>\n",
       "      <td>6</td>\n",
       "      <td>Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFFG02</td>\n",
       "      <td>6</td>\n",
       "      <td>Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLOR02</td>\n",
       "      <td>67</td>\n",
       "      <td>Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   METHOD  COUNTRY  \\\n",
       "0  BFFG01        6   \n",
       "1  BFFG02        6   \n",
       "2  CLOR02       67   \n",
       "\n",
       "                                                                                                                                                                                                                                               DESCRIPTION  \n",
       "0                                                            Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)  \n",
       "1                                                    Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)  \n",
       "2  Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "analsis_method_df=pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv')\n",
    "analsis_method_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39ead8",
   "metadata": {},
   "source": [
    "Number of unique ANALYSIS_METHOD DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28536ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "len(analsis_method_df['DESCRIPTION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9976e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_method = lambda: pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a7232",
   "metadata": {},
   "source": [
    "Review of MARIS METHOD LUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef89d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "prepmet_lut = pd.read_excel(prepmet_lut_path())\n",
    "sampmet_lut = pd.read_excel(sampmet_lut_path())\n",
    "counmet_lut = pd.read_excel(counmet_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d625717",
   "metadata": {},
   "source": [
    "**DISCUSS** repition of counting method in `counmet_lut`. When should we use each of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counmet_id</th>\n",
       "      <th>counmet</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Atomic absorption</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>ALP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Alpha ionization chamber spectrometry</td>\n",
       "      <td>ALPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Alpha liquid scintillation spectrometry</td>\n",
       "      <td>ALPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Alpha semiconductor spectrometry</td>\n",
       "      <td>ALPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Alpha total</td>\n",
       "      <td>ALPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Accelerator mass spectrometry</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>Beta</td>\n",
       "      <td>BET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counmet_id                                  counmet  code\n",
       "0          -1                           Not applicable   NaN\n",
       "1           0                            Not available     0\n",
       "2           1                        Atomic absorption    AA\n",
       "3           2                                    Alpha   ALP\n",
       "4           3    Alpha ionization chamber spectrometry  ALPI\n",
       "5           4  Alpha liquid scintillation spectrometry  ALPL\n",
       "6           5         Alpha semiconductor spectrometry  ALPS\n",
       "7           6                              Alpha total  ALPT\n",
       "8           7            Accelerator mass spectrometry   AMS\n",
       "9           8                                     Beta   BET"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "counmet_lut.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "## Add slice position (TOP and BOTTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['UPPSLI']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOP  BOTTOM\n",
      "0  15.0    20.0\n",
      "1  20.0    27.0\n",
      "2   0.0     2.0\n",
      "3   2.0     4.0\n",
      "4   4.0     6.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedSliceTopBottomCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEDIMENT'][['TOP','BOTTOM']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "## Add dry weight, wet weight and percentage weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d2796",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Entries for the ``BASIS`` value of the ``BIOTA`` dataset report a value of `F` which is not consistent with the HELCOM description provided in the metadata. The `GUIDELINES FOR MONITORING OF RADIOACTIVE SUBSTANCES` was obtained from [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2b08",
   "metadata": {},
   "source": [
    "Lets take a look at the BIOTA BASIS values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcfc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafeff5",
   "metadata": {},
   "source": [
    "Number of entries for each ``BASIS`` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d37b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASIS\n",
       "W    11167\n",
       "D     3634\n",
       "F       25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc763755",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some entries for ``DW%`` (Dry weight as percentage (%) of fresh weight) are much higher than 100%. Additionally, ``DW%`` is repoted as 0% in some cases.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f3249",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc7826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b30b6b",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f386973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b1201",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f48f6",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44234014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00833c1f",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Several SEDIMENT entries have `DW%` (Dry weight as percentage of fresh weight) values less than 1%. While technically possible, this would indicate samples contained more than 99% water content.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fb178",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` less than 1% but greater than 0.001%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c78c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "percent=1\n",
    "dfs['SEDIMENT']['DW%'][(dfs['SEDIMENT']['DW%'] < percent) & (dfs['SEDIMENT']['DW%'] > 0.001)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c2a",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS description of the `percentwt`, `drywt` and `wetwt` variables:\n",
    "\n",
    "- `percentwt`: Dry weight as ratio of fresh weight, expressed as a decimal .\n",
    "- `drywt`: Dry weight in grams.\n",
    "- `wetwt`: Fresh weight in grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735dd22",
   "metadata": {},
   "source": [
    "HELCOM Description:\n",
    "\n",
    "**Sediment:**\n",
    "1. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "\n",
    "**Biota:**\n",
    "1. WEIGHT: Average weight (in g) of specimen in the sample\n",
    "2. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "3. BASIS: Code for the basis the value is reported;\n",
    "        - W=WET WEIGHT\n",
    "        - D=DRY WEIGHT\n",
    "        - A= ASH WEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92f75f",
   "metadata": {},
   "source": [
    "Lets take a look at the HELCOM dataset, the weight of the sample is not reported for ``SEDIMENT``. However, the percentage dry weight is reported as `DW%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92c9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1037bff",
   "metadata": {},
   "source": [
    "The BIOTA dataset reports the weight of the sample as `WEIGHT` and the percentage dry weight as `DW%`. The `BASIS` column describes the basis the value reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
       "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
       "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
       "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
       "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
       "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
       "       'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA'].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetPercentWeightCB(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "            if 'WEIGHT' in tfm.dfs[grp].columns and 'BASIS' in tfm.dfs[grp].columns:\n",
    "                self._correct_basis(tfm.dfs[grp])\n",
    "                self._apply_weight(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['PERCENTWT'] = df['DW%'] / 100  # Convert percentage to fraction\n",
    "        df.loc[df['PERCENTWT'] == 0, 'PERCENTWT'] = np.NaN  # Convert 0% to NaN\n",
    "\n",
    "    def _correct_basis(self, df: pd.DataFrame) -> None:\n",
    "        \"Correct BASIS values. Assuming F = Fresh weight, so F = W\"\n",
    "        df.loc[df['BASIS'] == 'F', 'BASIS'] = 'W'\n",
    "\n",
    "    def _apply_weight(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply weight conversion and formatting to the given DataFrame.\"\n",
    "        dry_condition = df['BASIS'] == 'D'\n",
    "        wet_condition = df['BASIS'] == 'W'\n",
    "        \n",
    "        df.loc[dry_condition, 'DRYWT'] = df['WEIGHT']\n",
    "        df.loc[dry_condition & df['PERCENTWT'].notna(), 'WETWT'] = df['WEIGHT'] / df['PERCENTWT']\n",
    "        \n",
    "        df.loc[wet_condition, 'WETWT'] = df['WEIGHT']\n",
    "        df.loc[wet_condition & df['PERCENTWT'].notna(), 'DRYWT'] = df['WEIGHT'] * df['PERCENTWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "BIOTA:    PERCENTWT      DRYWT  WETWT\n",
      "0    0.18453  174.93444  948.0\n",
      "1    0.18453  174.93444  948.0\n",
      "2    0.18453  174.93444  948.0\n",
      "3    0.18453  174.93444  948.0\n",
      "4    0.18458  177.93512  964.0\n",
      "SEDIMENT: 0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: PERCENTWT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('BIOTA:', tfm.dfs['BIOTA'][['PERCENTWT','DRYWT','WETWT']].head())\n",
    "print('SEDIMENT:', tfm.dfs['SEDIMENT']['PERCENTWT'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68925d7c",
   "metadata": {},
   "source": [
    "Note that the dry weight is greater than the wet weight for some entries in the BIOTA dataset due to the DW% being greater than 100%, see above. Lets take a look at the number of entries where this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRYWT    20\n",
       "WETWT    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['BIOTA'][['DRYWT','WETWT']][tfm.dfs['BIOTA']['DRYWT'] > tfm.dfs['BIOTA']['WETWT']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b9aa0",
   "metadata": {},
   "source": [
    "## Standardize Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203cb3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Column names for geographical coordinates are inconsistent across sample types (biota, sediment, seawater). Sometimes using parentheses, sometimes not.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c04fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: ['LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
      "SEAWATER: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
      "SEDIMENT: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for grp in dfs.keys():\n",
    "    print(f'{grp}: {[col for col in dfs[grp].columns if \"LON\" in col or \"LAT\" in col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83c2e1",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: HELCOM SEAWATER datase includes values of 0 for both latitude and longitude. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "19238  WSTUK2015001      H3  STUK04             <        920.0        0.0   \n",
      "19239  WSTUK2015002      H3  STUK04             <        920.0        0.0   \n",
      "19240  WSTUK2015003      H3  STUK04             <        920.0        0.0   \n",
      "19241  WSTUK2015004      H3  STUK04             <        920.0        0.0   \n",
      "19242  WSTUK2015005      H3  STUK04             <        920.0        0.0   \n",
      "\n",
      "         DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ...  \\\n",
      "19238  12/07/16 00:00:00       34       STUK   2015001  ...   \n",
      "19239  12/07/16 00:00:00       34       STUK   2015002  ...   \n",
      "19240  12/07/16 00:00:00       34       STUK   2015003  ...   \n",
      "19241  12/07/16 00:00:00       34       STUK   2015004  ...   \n",
      "19242  12/07/16 00:00:00       34       STUK   2015005  ...   \n",
      "\n",
      "      LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
      "19238            23.3761                 0.0    81.0     1.0   NaN    NaN   \n",
      "19239            23.3761                 0.0    81.0    80.0   NaN    NaN   \n",
      "19240            26.2080                 0.0    69.0     1.0   NaN    NaN   \n",
      "19241            26.2080                 0.0    69.0    68.0   NaN    NaN   \n",
      "19242            21.0477                 0.0   173.0     1.0   NaN    NaN   \n",
      "\n",
      "       FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
      "19238     N             11               11  12/07/16 00:00:00  \n",
      "19239     N             11               11  12/07/16 00:00:00  \n",
      "19240     N             11               11  12/07/16 00:00:00  \n",
      "19241     N             11               11  12/07/16 00:00:00  \n",
      "19242     N              3                3  12/07/16 00:00:00  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (ddmmmm)_LONGITUDE (ddmmmm):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "def get_invalid_coordinate_df(df, lat_cols, lon_cols):\n",
    "    invalid_dfs = {}\n",
    "    \n",
    "    for lat_col, lon_col in zip(lat_cols, lon_cols):\n",
    "        # Filter rows where latitude or longitude is NaN or zero\n",
    "        invalid_df = df[(df[lat_col].isna() | df[lon_col].isna()) | \n",
    "                        (df[lat_col] == 0) | (df[lon_col] == 0)]\n",
    "        \n",
    "        # Store the invalid DataFrame in the dictionary\n",
    "        if not invalid_df.empty:\n",
    "            invalid_dfs[f'{lat_col}_{lon_col}'] = invalid_df\n",
    "\n",
    "    return invalid_dfs\n",
    "\n",
    "def print_invalid_coordinates(invalid_dfs, dataset_name):\n",
    "    for key, invalid_df in invalid_dfs.items():\n",
    "        print(f'{dataset_name} invalid coordinates for {key}:')\n",
    "        print(invalid_df.head())\n",
    "\n",
    "# Define the columns for each dataset\n",
    "biota_lat_cols = ['LATITUDE ddmmmm', 'LATITUDE dddddd']\n",
    "biota_lon_cols = ['LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
    "\n",
    "seawater_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "seawater_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "sediment_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "sediment_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "# Get invalid coordinate DataFrames for each dataset\n",
    "biota_invalid_dfs = get_invalid_coordinate_df(dfs['BIOTA'], biota_lat_cols, biota_lon_cols)\n",
    "seawater_invalid_dfs = get_invalid_coordinate_df(dfs['SEAWATER'], seawater_lat_cols, seawater_lon_cols)\n",
    "sediment_invalid_dfs = get_invalid_coordinate_df(dfs['SEDIMENT'], sediment_lat_cols, sediment_lon_cols)\n",
    "\n",
    "# Print only non-empty invalid DataFrames\n",
    "print_invalid_coordinates(biota_invalid_dfs, 'BIOTA')\n",
    "print_invalid_coordinates(seawater_invalid_dfs, 'SEAWATER')\n",
    "print_invalid_coordinates(sediment_invalid_dfs, 'SEDIMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseCoordinates(Callback):\n",
    "    \"\"\"\n",
    "    Get geographical coordinates from columns expressed in degrees decimal format \n",
    "    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_cor: Callable # Function that converts coordinates from degree-minute to decimal degree format\n",
    "                 ):\n",
    "        self.fn_convert_cor = fn_convert_cor\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._format_coordinates(df)\n",
    "\n",
    "    def _format_coordinates(self, df:pd.DataFrame) -> None:\n",
    "        coord_cols = self._get_coord_columns(df.columns)\n",
    "        \n",
    "        for coord in ['lat', 'lon']:\n",
    "            decimal_col, minute_col = coord_cols[f'{coord}_d'], coord_cols[f'{coord}_m']\n",
    "            \n",
    "            condition = df[decimal_col].isna() | (df[decimal_col] == 0)\n",
    "            df[coord.upper()] = np.where(condition,\n",
    "                                 df[minute_col].apply(self._safe_convert),\n",
    "                                 df[decimal_col])\n",
    "        \n",
    "        df.dropna(subset=['LAT', 'LON'], inplace=True)\n",
    "\n",
    "    def _get_coord_columns(self, columns) -> dict:\n",
    "        return {\n",
    "            'lon_d': self._find_coord_column(columns, 'LON', 'dddddd'),\n",
    "            'lat_d': self._find_coord_column(columns, 'LAT', 'dddddd'),\n",
    "            'lon_m': self._find_coord_column(columns, 'LON', 'ddmmmm'),\n",
    "            'lat_m': self._find_coord_column(columns, 'LAT', 'ddmmmm')\n",
    "        }\n",
    "\n",
    "    def _find_coord_column(self, columns, coord_type, coord_format) -> str:\n",
    "        pattern = re.compile(f'{coord_type}.*{coord_format}', re.IGNORECASE)\n",
    "        matching_columns = [col for col in columns if pattern.search(col)]\n",
    "        return matching_columns[0] if matching_columns else None\n",
    "\n",
    "    def _safe_convert(self, value) -> str:\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14873     20242     37089\n",
      "Number of rows removed        20        76       258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA columns:\n",
      "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y', 'TIME', 'VALUE', 'UNCERTAINTY', 'SPECIES',\n",
      "       'BODY_PART', 'BIO_GROUP', 'UNIT', 'DL', 'PERCENTWT', 'DRYWT', 'WETWT',\n",
      "       'LAT', 'LON'],\n",
      "      dtype='object')\n",
      "[31  4  9 33 12 21  6  8 22 10 24 77 17  2 37 41 47 23 11 13 25 16 14 36\n",
      " 35 29 34 67 63 46 43 42 94 55 50 40 53 87 92 86 15  7 93 85 91 90 51 59\n",
      " 76 72 54 57]\n"
     ]
    }
   ],
   "source": [
    "grp = 'BIOTA'\n",
    "print(f'{grp} columns:')\n",
    "print(tfm.dfs[grp].columns)\n",
    "print(tfm.dfs[grp].NUCLIDE.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c7a2",
   "metadata": {},
   "source": [
    "For instance, lets inspect dropped rows for SEAWATER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29baf65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows: 76\n",
      "Example of dropped rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>WRISO2001025</td>\n",
       "      <td>CS137</td>\n",
       "      <td>RISO02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>RISO</td>\n",
       "      <td>2001025</td>\n",
       "      <td>...</td>\n",
       "      <td>10.500</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>WLEPA2002001</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002001</td>\n",
       "      <td>...</td>\n",
       "      <td>21.030</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>14.40</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>WLEPA2002002</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002004</td>\n",
       "      <td>...</td>\n",
       "      <td>20.574</td>\n",
       "      <td>20.956667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.57</td>\n",
       "      <td>11.95</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>WLEPA2002003</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002007</td>\n",
       "      <td>...</td>\n",
       "      <td>19.236</td>\n",
       "      <td>19.393333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>WLEPA2002004</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002010</td>\n",
       "      <td>...</td>\n",
       "      <td>20.205</td>\n",
       "      <td>20.341700</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.06</td>\n",
       "      <td>8.65</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "13439  WRISO2001025   CS137  RISO02           NaN          NaN       10.0   \n",
       "14017  WLEPA2002001   CS134  LEPA02             <          NaN        NaN   \n",
       "14020  WLEPA2002002   CS134  LEPA02             <          NaN        NaN   \n",
       "14023  WLEPA2002003   CS134  LEPA02             <          NaN        NaN   \n",
       "14026  WLEPA2002004   CS134  LEPA02             <          NaN        NaN   \n",
       "\n",
       "      DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "13439             NaN       26       RISO   2001025  ...             10.500   \n",
       "14017             NaN       93       LEPA   2002001  ...             21.030   \n",
       "14020             NaN       93       LEPA   2002004  ...             20.574   \n",
       "14023             NaN       93       LEPA   2002007  ...             19.236   \n",
       "14026             NaN       93       LEPA   2002010  ...             20.205   \n",
       "\n",
       "       LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "13439           10.833333    22.0    20.0  0.00    NaN     N              5   \n",
       "14017           21.050000    16.0     0.0  3.77  14.40     N              4   \n",
       "14020           20.956667    14.0     0.0  6.57  11.95     N              4   \n",
       "14023           19.393333    73.0     0.0  7.00   9.19     N              4   \n",
       "14026           20.341700    47.0     0.0  7.06   8.65     N              4   \n",
       "\n",
       "       HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \n",
       "13439                5              NaN  \n",
       "14017                9              NaN  \n",
       "14020                9              NaN  \n",
       "14023                9              NaN  \n",
       "14026                9              NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of dropped rows:', tfm.dfs_dropped['SEAWATER'].shape[0])\n",
    "print('Example of dropped rows:')\n",
    "tfm.dfs_dropped['SEAWATER'].head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'.\",\n",
       " 'Remap data provider nuclide names to MARIS nuclide names.',\n",
       " 'Parse and standardize time information in the dataframe.',\n",
       " 'Encode time as seconds since epoch.',\n",
       " 'Sanitize value/measurement by removing blank entries and populating `value` column.',\n",
       " 'Convert from relative error % to standard uncertainty.',\n",
       " \"Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A.\",\n",
       " \"Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A.\",\n",
       " \"Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A.\",\n",
       " 'Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).',\n",
       " 'Set the `unit` id column in the DataFrames based on a lookup table.',\n",
       " 'Remap value type to MARIS format.',\n",
       " 'Lookup FILT value in dataframe using the lookup table.',\n",
       " 'Remap Sediment slice top and bottom to MARIS format.',\n",
       " 'Lookup dry-wet ratio and format for MARIS.',\n",
       " '\\n    Get geographical coordinates from columns expressed in degrees decimal format \\n    or from columns in degrees/minutes decimal format where degrees decimal format is missing.\\n    ',\n",
       " 'Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.',\n",
       " 'Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(\n",
    "    tfm: Transformer, # Transformer object\n",
    "    zotero_key: str, # Zotero dataset record key\n",
    "    kw: list = kw # List of keywords\n",
    "    ) -> dict: # Global attributes\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2018-12-14T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \\n    Get geographical coordinates from columns expressed in degrees decimal format \\n    or from columns in degrees/minutes decimal format where degrees decimal format is missing.\\n    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator., Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### <a name=\"encoding-netcdf\"></a>Encoding NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(\n",
    "    fname_in: str, # Input file name\n",
    "    fname_out_nc: str, # Output file name\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Encode data to NetCDF.\"\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bio_group\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: species\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: body_part\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: drywt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: wetwt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: filt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: area\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sed_type\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: top\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bottom\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "encode(fname_in, fname_out_nc, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7e258",
   "metadata": {},
   "source": [
    "## NetCDF QA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e5e7",
   "metadata": {},
   "source": [
    "First lets review the general properties of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 669483\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: TBD\n",
      "  geospatial_vertical_max: TBD\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \n",
      "    Get geographical coordinates from columns expressed in degrees decimal format \n",
      "    or from columns in degrees/minutes decimal format where degrees decimal format is missing.\n",
      "    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties=get_netcdf_properties(fname_out_nc)\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c821d",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Update TBD values. \n",
    "The publisher_postprocess_logs may include ',' in the string. Can we review how the publisher_postprocess_logs are encoded? Would a dictionary be better?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b8243",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Enums (LUTS) should be encoded in the NetCDF file. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cc5bc",
   "metadata": {},
   "source": [
    "Review the publisher_postprocess_logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \n",
      "    Get geographical coordinates from columns expressed in degrees decimal format \n",
      "    or from columns in degrees/minutes decimal format where degrees decimal format is missing.\n",
      "    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(properties['global_attributes']['publisher_postprocess_logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b00241",
   "metadata": {},
   "source": [
    "Now lets review the properties of the groups in the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'bio_group', 'species', 'body_part', 'drywt', 'wetwt']\n",
      "  dimensions: {'id': 14873}\n",
      "  attributes: {}\n",
      "seawater:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'filt']\n",
      "  dimensions: {'id': 20242}\n",
      "  attributes: {}\n",
      "sediment:\n",
      "  variables: ['lon', 'lat', 'time', 'area', 'nuclide', 'value', 'unit', 'dl', 'sed_type', 'top', 'bottom']\n",
      "  dimensions: {'id': 37089}\n",
      "  attributes: {}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties = get_netcdf_group_properties(fname_out_nc)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09981ba",
   "metadata": {},
   "source": [
    "Lets review all variable attributes for the groups of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff21c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>...</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>lon</td>\n",
       "      <td>lat</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>bio_group</td>\n",
       "      <td>species</td>\n",
       "      <td>body_part</td>\n",
       "      <td>...</td>\n",
       "      <td>lat</td>\n",
       "      <td>time</td>\n",
       "      <td>area</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>sed_type</td>\n",
       "      <td>top</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_id</th>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>...</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_size</th>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>...</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_long_name</th>\n",
       "      <td>Measurement longitude</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Biota group</td>\n",
       "      <td>Species</td>\n",
       "      <td>Body part</td>\n",
       "      <td>...</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Marine area/region id</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Sediment type</td>\n",
       "      <td>Top depth of sediment layer</td>\n",
       "      <td>Bottom depth of sediment layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_standard_name</th>\n",
       "      <td>longitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>biota_group_tbd</td>\n",
       "      <td>species</td>\n",
       "      <td>body_part_tbd</td>\n",
       "      <td>...</td>\n",
       "      <td>latitude</td>\n",
       "      <td>time</td>\n",
       "      <td>area_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>sediment_type_tbd</td>\n",
       "      <td>top_depth_of_sediment_layer_tbd</td>\n",
       "      <td>bottom_depth_of_sediment_layer_tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_units</th>\n",
       "      <td>degrees_east</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_origin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_abbreviation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_calendar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                     1   \\\n",
       "group                               biota                 biota   \n",
       "variable                              lon                   lat   \n",
       "dimensions_id                     ('id',)               ('id',)   \n",
       "dimensions_size                  (14873,)              (14873,)   \n",
       "data_type                             <f4                   <f4   \n",
       "attr_long_name      Measurement longitude  Measurement latitude   \n",
       "attr_standard_name              longitude              latitude   \n",
       "attr_units                   degrees_east         degrees_north   \n",
       "attr_time_origin                      NaN                   NaN   \n",
       "attr_time_zone                        NaN                   NaN   \n",
       "attr_abbreviation                     NaN                   NaN   \n",
       "attr_axis                             NaN                   NaN   \n",
       "attr_calendar                         NaN                   NaN   \n",
       "\n",
       "                                                     2         3         4   \\\n",
       "group                                             biota     biota     biota   \n",
       "variable                                           time   nuclide     value   \n",
       "dimensions_id                                   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                                (14873,)  (14873,)  (14873,)   \n",
       "data_type                                           <u8       <i8       <f4   \n",
       "attr_long_name                      Time of measurement   Nuclide  Activity   \n",
       "attr_standard_name                                 time   nuclide  activity   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0       NaN       NaN   \n",
       "attr_time_origin                    1970-01-01 00:00:00       NaN       NaN   \n",
       "attr_time_zone                                      UTC       NaN       NaN   \n",
       "attr_abbreviation                             Date/Time       NaN       NaN   \n",
       "attr_axis                                             T       NaN       NaN   \n",
       "attr_calendar                                 gregorian       NaN       NaN   \n",
       "\n",
       "                          5                6                7         8   \\\n",
       "group                  biota            biota            biota     biota   \n",
       "variable                unit               dl        bio_group   species   \n",
       "dimensions_id        ('id',)          ('id',)          ('id',)   ('id',)   \n",
       "dimensions_size     (14873,)         (14873,)         (14873,)  (14873,)   \n",
       "data_type                <i8              <i8              <i8       <i8   \n",
       "attr_long_name          Unit  Detection limit      Biota group   Species   \n",
       "attr_standard_name      unit  detection_limit  biota_group_tbd   species   \n",
       "attr_units               NaN              NaN              NaN       NaN   \n",
       "attr_time_origin         NaN              NaN              NaN       NaN   \n",
       "attr_time_zone           NaN              NaN              NaN       NaN   \n",
       "attr_abbreviation        NaN              NaN              NaN       NaN   \n",
       "attr_axis                NaN              NaN              NaN       NaN   \n",
       "attr_calendar            NaN              NaN              NaN       NaN   \n",
       "\n",
       "                               9   ...                    21  \\\n",
       "group                       biota  ...              sediment   \n",
       "variable                body_part  ...                   lat   \n",
       "dimensions_id             ('id',)  ...               ('id',)   \n",
       "dimensions_size          (14873,)  ...              (37089,)   \n",
       "data_type                     <i8  ...                   <f4   \n",
       "attr_long_name          Body part  ...  Measurement latitude   \n",
       "attr_standard_name  body_part_tbd  ...              latitude   \n",
       "attr_units                    NaN  ...         degrees_north   \n",
       "attr_time_origin              NaN  ...                   NaN   \n",
       "attr_time_zone                NaN  ...                   NaN   \n",
       "attr_abbreviation             NaN  ...                   NaN   \n",
       "attr_axis                     NaN  ...                   NaN   \n",
       "attr_calendar                 NaN  ...                   NaN   \n",
       "\n",
       "                                                     22  \\\n",
       "group                                          sediment   \n",
       "variable                                           time   \n",
       "dimensions_id                                   ('id',)   \n",
       "dimensions_size                                (37089,)   \n",
       "data_type                                           <u8   \n",
       "attr_long_name                      Time of measurement   \n",
       "attr_standard_name                                 time   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0   \n",
       "attr_time_origin                    1970-01-01 00:00:00   \n",
       "attr_time_zone                                      UTC   \n",
       "attr_abbreviation                             Date/Time   \n",
       "attr_axis                                             T   \n",
       "attr_calendar                                 gregorian   \n",
       "\n",
       "                                       23        24        25        26  \\\n",
       "group                            sediment  sediment  sediment  sediment   \n",
       "variable                             area   nuclide     value      unit   \n",
       "dimensions_id                     ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                  (37089,)  (37089,)  (37089,)  (37089,)   \n",
       "data_type                             <i8       <i8       <f4       <i8   \n",
       "attr_long_name      Marine area/region id   Nuclide  Activity      Unit   \n",
       "attr_standard_name                area_id   nuclide  activity      unit   \n",
       "attr_units                            NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                      NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                        NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                     NaN       NaN       NaN       NaN   \n",
       "attr_axis                             NaN       NaN       NaN       NaN   \n",
       "attr_calendar                         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 27                 28  \\\n",
       "group                      sediment           sediment   \n",
       "variable                         dl           sed_type   \n",
       "dimensions_id               ('id',)            ('id',)   \n",
       "dimensions_size            (37089,)           (37089,)   \n",
       "data_type                       <i8                <i8   \n",
       "attr_long_name      Detection limit      Sediment type   \n",
       "attr_standard_name  detection_limit  sediment_type_tbd   \n",
       "attr_units                      NaN                NaN   \n",
       "attr_time_origin                NaN                NaN   \n",
       "attr_time_zone                  NaN                NaN   \n",
       "attr_abbreviation               NaN                NaN   \n",
       "attr_axis                       NaN                NaN   \n",
       "attr_calendar                   NaN                NaN   \n",
       "\n",
       "                                                 29  \\\n",
       "group                                      sediment   \n",
       "variable                                        top   \n",
       "dimensions_id                               ('id',)   \n",
       "dimensions_size                            (37089,)   \n",
       "data_type                                       <f4   \n",
       "attr_long_name          Top depth of sediment layer   \n",
       "attr_standard_name  top_depth_of_sediment_layer_tbd   \n",
       "attr_units                                      NaN   \n",
       "attr_time_origin                                NaN   \n",
       "attr_time_zone                                  NaN   \n",
       "attr_abbreviation                               NaN   \n",
       "attr_axis                                       NaN   \n",
       "attr_calendar                                   NaN   \n",
       "\n",
       "                                                    30  \n",
       "group                                         sediment  \n",
       "variable                                        bottom  \n",
       "dimensions_id                                  ('id',)  \n",
       "dimensions_size                               (37089,)  \n",
       "data_type                                          <f4  \n",
       "attr_long_name          Bottom depth of sediment layer  \n",
       "attr_standard_name  bottom_depth_of_sediment_layer_tbd  \n",
       "attr_units                                         NaN  \n",
       "attr_time_origin                                   NaN  \n",
       "attr_time_zone                                     NaN  \n",
       "attr_abbreviation                                  NaN  \n",
       "attr_axis                                          NaN  \n",
       "attr_calendar                                      NaN  \n",
       "\n",
       "[13 rows x 31 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_var_prop=get_netcdf_variable_properties(fname_out_nc, as_df=True).T\n",
    "df_var_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c543039",
   "metadata": {},
   "source": [
    "Lets convert the NetCDF file to a dictionary of DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df252c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota\n",
      "seawater\n",
      "sediment\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs=nc_to_dfs(fname_out_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750b936",
   "metadata": {},
   "source": [
    "Lets review the biota data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>bio_group</th>\n",
       "      <th>species</th>\n",
       "      <th>body_part</th>\n",
       "      <th>drywt</th>\n",
       "      <th>wetwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>4</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>33</td>\n",
       "      <td>4.338000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>177.935120</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>54.583302</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>53</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>3</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>4</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>33</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14871</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>53</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14872</th>\n",
       "      <td>19.433300</td>\n",
       "      <td>54.363899</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>33</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14873 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide       value  unit  dl  \\\n",
       "0      12.316667  54.283333 2012-09-23       31    0.010140     5   2   \n",
       "1      12.316667  54.283333 2012-09-23        4  135.300003     5   1   \n",
       "2      12.316667  54.283333 2012-09-23        9    0.013980     5   2   \n",
       "3      12.316667  54.283333 2012-09-23       33    4.338000     5   1   \n",
       "4      12.316667  54.283333 2012-09-23       31    0.009614     5   2   \n",
       "...          ...        ...        ...      ...         ...   ...  ..   \n",
       "14868  19.000000  54.583302 2018-02-26       53    0.043000     5   1   \n",
       "14869  15.500000  54.333302 2018-02-13        4   98.000000     5   1   \n",
       "14870  15.500000  54.333302 2018-02-13       33    3.690000     5   1   \n",
       "14871  15.500000  54.333302 2018-02-13       53    0.049000     5   1   \n",
       "14872  19.433300  54.363899 2018-10-03       33    0.830000     5   1   \n",
       "\n",
       "       bio_group  species  body_part       drywt  wetwt  \n",
       "0              4       99         52  174.934433  948.0  \n",
       "1              4       99         52  174.934433  948.0  \n",
       "2              4       99         52  174.934433  948.0  \n",
       "3              4       99         52  174.934433  948.0  \n",
       "4              4       99         52  177.935120  964.0  \n",
       "...          ...      ...        ...         ...    ...  \n",
       "14868          4      191          3  120.000000  500.0  \n",
       "14869          4      191         52  112.500000  500.0  \n",
       "14870          4      191         52  112.500000  500.0  \n",
       "14871          4      191         52  112.500000  500.0  \n",
       "14872          4      247         52         NaN  120.0  \n",
       "\n",
       "[14873 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_biota=dfs['BIOTA']\n",
    "nc_dfs_biota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef71cc",
   "metadata": {},
   "source": [
    "Lets review the sediment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e068f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>area</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>sed_type</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>38.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37084</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37085</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37086</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>512.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37087</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>527.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>684.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37089 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lon        lat       time  area  nuclide   value  unit  dl  \\\n",
       "0      24.0000  59.666698 2012-06-17     0       53   35.00     4   1   \n",
       "1      24.0000  59.666698 2012-06-17     0       53   36.00     4   1   \n",
       "2      28.8433  59.860001 2012-08-10     0       53   38.00     4   1   \n",
       "3      28.8433  59.860001 2012-08-10     0       53   36.00     4   1   \n",
       "4      28.8433  59.860001 2012-08-10     0       53   30.00     4   1   \n",
       "...        ...        ...        ...   ...      ...     ...   ...  ..   \n",
       "37084  21.0830  59.035999 2016-06-09     0       33    1.20     4   1   \n",
       "37085  21.0830  59.035999 2016-06-09     0       33    0.79     4   1   \n",
       "37086  19.7297  61.066700 2016-05-29     0       33  512.00     4   1   \n",
       "37087  19.7297  61.066700 2016-05-29     0       33  527.00     4   1   \n",
       "37088  19.7297  61.066700 2016-05-29     0       33  684.00     4   1   \n",
       "\n",
       "       sed_type   top  bottom  \n",
       "0             0  15.0    20.0  \n",
       "1             0  20.0    27.0  \n",
       "2             0   0.0     2.0  \n",
       "3             0   2.0     4.0  \n",
       "4             0   4.0     6.0  \n",
       "...         ...   ...     ...  \n",
       "37084        50  18.0    20.0  \n",
       "37085        50  20.0    22.0  \n",
       "37086        59   0.0     2.0  \n",
       "37087        51   2.0     4.0  \n",
       "37088        50   4.0     6.0  \n",
       "\n",
       "[37089 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_sediment=dfs['SEDIMENT']\n",
    "nc_dfs_sediment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d6fc",
   "metadata": {},
   "source": [
    "Lets review the seawater data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20237</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>54.006802</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>12</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20238</th>\n",
       "      <td>14.667200</td>\n",
       "      <td>54.499500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20239</th>\n",
       "      <td>14.334200</td>\n",
       "      <td>54.750500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20242 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide      value  unit  dl  filt\n",
       "0      29.333300  60.083302 2012-05-23       33   5.300000     1   1     0\n",
       "1      29.333300  60.083302 2012-05-23       33  19.900000     1   1     0\n",
       "2      23.150000  59.433300 2012-06-17       33  25.500000     1   1     0\n",
       "3      27.983299  60.250000 2012-05-24       33  17.000000     1   1     0\n",
       "4      27.983299  60.250000 2012-05-24       33  22.200001     1   1     0\n",
       "...          ...        ...        ...      ...        ...   ...  ..   ...\n",
       "20237  14.200000  54.006802 2015-06-22       12   6.600000     1   1     1\n",
       "20238  14.667200  54.499500 2015-06-23       12   6.900000     1   1     1\n",
       "20239  14.334200  54.750500 2015-06-23       12   6.800000     1   1     1\n",
       "20240  13.500200  54.916500 2015-06-24       12   7.300000     1   1     1\n",
       "20241  13.500200  54.916500 2015-06-24       12   5.500000     1   1     1\n",
       "\n",
       "[20242 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_seawater=dfs['SEAWATER']\n",
    "nc_dfs_seawater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05beed7f",
   "metadata": {},
   "source": [
    "## Open Refine Decoder (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d380cb",
   "metadata": {},
   "source": [
    "Currently, the processing of MARIS data to the master dataset is done in OpenRefine. A standardised CSV is processed in OpenRefine and exported to the MARIS database. \n",
    "\n",
    "A decoder is needed to convert the NetCDF file format to the standardised CSV format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2c6f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

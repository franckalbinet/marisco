{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "> Data pipeline (handler) to convert HELCOM data ([source](https://helcom.fi/about-us)) to `NetCDF` format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5eece",
   "metadata": {},
   "source": [
    "<!-- ## HELCOM MORS Environment database -->\n",
    "\n",
    "[Helcom MORS data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "Example steps:\n",
    "1. Download data (e.g. https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24). \n",
    "2. Install mdbtools via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In VS code terminal, navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip MORS_ENVIRONMENT.zip \n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run preprocess.sh to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ````\n",
    "7. Conetens of 'preprocess.sh' script.\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c4c6b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "df103c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd # Python package that provides fast, flexible, and expressive data structures.\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Python Progress Bar Library\n",
    "from functools import partial # Function which Return a new partial object which when called will behave like func called with the positional arguments args and keyword arguments keywords\n",
    "import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.\n",
    "from pathlib import Path # This module offers classes representing filesystem paths\n",
    "from dataclasses import asdict\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, match_maris_lut, Match)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, SanitizeLonLatCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (base_path, nc_tpl_path, cfg, cache_path, cdl_cfg, Enums, lut_path,\n",
    "                             species_lut_path, sediments_lut_path, bodyparts_lut_path, \n",
    "                             detection_limit_lut_path, filtered_lut_path, area_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed39cdd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a65e9b",
   "metadata": {},
   "source": [
    "##  MARIS NetCDF \n",
    "When MARISCO is installed, it uses `cdl.toml` to create the `maris-template.nc`, which acts as a standardized template for MARIS NetCDF files. The `cdl.toml` is a configuration file listing all the variables allowed in the NetCDF4 files. The contents of the cdl.toml can be retrieved with the function `cdl_cfg()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "50406959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['defaults', 'bio', 'sed', 'suffixes'])\n"
     ]
    }
   ],
   "source": [
    "print (cdl_cfg()['vars'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "535b6a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data_provider_sample_id', 'lon', 'lat', 'smp_depth', 'tot_depth', 'time', 'area', 'sample_notes', 'measurement_notes'])\n",
      "dict_keys(['bio_group', 'species', 'body_part'])\n",
      "dict_keys(['sed_type'])\n",
      "dict_keys(['uncertainty', 'detection_limit', 'volume', 'salinity', 'temperature', 'filtered', 'counting_method', 'sampling_method', 'preparation_method', 'unit'])\n"
     ]
    }
   ],
   "source": [
    "print (cdl_cfg()['vars']['defaults'].keys())\n",
    "print (cdl_cfg()['vars']['bio'].keys())\n",
    "print (cdl_cfg()['vars']['sed'].keys())\n",
    "print (cdl_cfg()['vars']['suffixes'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5519f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **fname_in** - is the path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "2. **fname_out** - is the path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "3. **Zotero key** - is used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "zotero_key='26VMZZ2Q'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf9628",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd04abcd",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7f9f0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(src_dir,\n",
    "                smp_types=['SEA', 'SED', 'BIO']):\n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type\"\n",
    "    dfs = {}\n",
    "    lut_smp_type = {'SEA': 'seawater', 'SED': 'sediment', 'BIO': 'biota'}\n",
    "    for smp_type in smp_types:\n",
    "        fname_meas = smp_type + '02.csv' # measurement (i.e. radioactivity) information.\n",
    "        fname_smp = smp_type + '01.csv' # sample information \n",
    "        df = pd.merge(pd.read_csv(Path(src_dir)/fname_meas),  # measurements\n",
    "                      pd.read_csv(Path(src_dir)/fname_smp),  # sample\n",
    "                      on='KEY', how='left')\n",
    "        dfs[lut_smp_type[smp_type]] = df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "c906677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename_cols(cols):\n",
    "    \"Flatten multiindex columns\"\n",
    "    new_cols = []\n",
    "    for outer, inner in cols:\n",
    "        if not inner:\n",
    "            new_cols.append(outer)\n",
    "        else:\n",
    "            if outer == 'unit':\n",
    "                new_cols.append(inner + '_' + outer)\n",
    "            if outer == 'unc':\n",
    "                new_cols.append(inner + '_' + outer)\n",
    "            if outer == 'value':\n",
    "                new_cols.append(inner)\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bb0fd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e534545",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['seawater', 'sediment', 'biota'])\n",
      "Seawater cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Sediment cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Biota cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print(dfs.keys())\n",
    "print(f\"Seawater cols: {dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785805a",
   "metadata": {},
   "source": [
    "Show the structure of the `seawater` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7f9aeb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005</td>\n",
       "      <td>...</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "0  08/20/14 00:00:00       90       KRIL   2012003  ...              29.20   \n",
       "1  08/20/14 00:00:00       90       KRIL   2012004  ...              29.20   \n",
       "2  08/20/14 00:00:00       90       KRIL   2012005  ...              23.09   \n",
       "3  08/20/14 00:00:00       90       KRIL   2012006  ...              27.59   \n",
       "4  08/20/14 00:00:00       90       KRIL   2012007  ...              27.59   \n",
       "\n",
       "   LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "0             29.3333     NaN     0.0   NaN    NaN   NaN             11   \n",
       "1             29.3333     NaN    29.0   NaN    NaN   NaN             11   \n",
       "2             23.1500     NaN     0.0   NaN    NaN   NaN             11   \n",
       "3             27.9833     NaN     0.0   NaN    NaN   NaN             11   \n",
       "4             27.9833     NaN    39.0   NaN    NaN   NaN             11   \n",
       "\n",
       "   HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0               11  08/20/14 00:00:00  \n",
       "1               11  08/20/14 00:00:00  \n",
       "2                3  08/20/14 00:00:00  \n",
       "3               11  08/20/14 00:00:00  \n",
       "4               11  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423d697",
   "metadata": {},
   "source": [
    "Show the structure of the `biota` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "1ac781a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>BIOTATYPE</th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>NO</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>135.300000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CO60</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS137</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>4.338000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BVTIG2012040</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.9</td>\n",
       "      <td>964.0</td>\n",
       "      <td>18.458</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY   NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "0  BVTIG2012041  CS134     VTIG01             <     0.010140     W     NaN   \n",
       "1  BVTIG2012041  K40       VTIG01                 135.300000     W    3.57   \n",
       "2  BVTIG2012041  CO60      VTIG01             <     0.013980     W     NaN   \n",
       "3  BVTIG2012041  CS137     VTIG01                   4.338000     W    3.48   \n",
       "4  BVTIG2012040  CS134     VTIG01             <     0.009614     W     NaN   \n",
       "\n",
       "   NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE    NO  LENGTH  \\\n",
       "0     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "1     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "2     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "3     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "4     NaN  02/27/14 00:00:00      6.0  ...         F       5  17.0    45.9   \n",
       "\n",
       "   WEIGHT     DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "1   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "2   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "3   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "4   964.0  18.458  92.9              2               16  02/27/14 00:00:00  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['biota'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840141d5",
   "metadata": {},
   "source": [
    "Show the structure of the `sediment` dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "b6013611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0  SKRIL2012048   RA226    NaN           NaN         35.0       26.0   \n",
       "1  SKRIL2012049   RA226    NaN           NaN         36.0       22.0   \n",
       "2  SKRIL2012050   RA226    NaN           NaN         38.0       24.0   \n",
       "3  SKRIL2012051   RA226    NaN           NaN         36.0       25.0   \n",
       "4  SKRIL2012052   RA226    NaN           NaN         30.0       23.0   \n",
       "\n",
       "  < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00  ...    20.0   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00  ...    27.0   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00  ...     2.0   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00  ...     4.0   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00  ...     6.0   \n",
       "\n",
       "    AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "0  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "1  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "2  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "3  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "4  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "\n",
       "     DATE_OF_ENTRY_y  \n",
       "0  08/20/14 00:00:00  \n",
       "1  08/20/14 00:00:00  \n",
       "2  08/20/14 00:00:00  \n",
       "3  08/20/14 00:00:00  \n",
       "4  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['sediment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f3eef",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d68abc3",
   "metadata": {},
   "source": [
    "## Data transformation pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b690d9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``nuclide``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b23c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Nuclide``.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "#### Lower & strip nuclide names\n",
    "\n",
    "Create a callback function, `LowerStripRdnNameCB`, that receives a dictionary of dataframes. For each dataframe in the dictionary, it converts the contents of the `Nuclides` column to lowercase and removes any leading or trailing whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "5b10f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LowerStripRdnNameCB(Callback):\n",
    "    \"Convert nuclide names to lowercase & strip any trailing space(s)\"\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].apply(\n",
    "                lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb73d9",
   "metadata": {},
   "source": [
    "Here we call a transformer, which applies the callback (e.g. `LowerStripRdnNameCB`) to the dictionary of dataframes, `dfs`. We then print the unique entries of the transformed `NUCLIDE` column for each dataframe included in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB()])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm()['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "#### Remap HELCOM nuclide names to MARIS nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9905c7",
   "metadata": {},
   "source": [
    "The `maris-template.nc` file, which  is created from the `cdl.toml` on installation of the Marisco package, provides details of the nuclides permitted in the  MARIS NetCDF file. Here we define a function  `get_unique_nuclides()` which creates a list of the unique nuclides from each dataframe in the dictionary of dataframes `dfs`. The function `has_valid_varname` checks that each nuclide in this list is included in the `maris-template.nc` (i.e. the `cdl.toml`). `has_valid_varname` returns all variables in the list that are not in the `maris-template.nc` or returns `True`. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "bbf213bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unique_nuclides(dfs):\n",
    "    \"Get list of unique radionuclide types measured across samples.\"\n",
    "    nuclides = []\n",
    "    for k in dfs.keys():\n",
    "        nuclides += dfs[k]['NUCLIDE'].unique().tolist()\n",
    "    # remove duplicates from nuclides list.\n",
    "    nuclides=list(set(nuclides))\n",
    "    return nuclides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "a68dacd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cs145\" variable name not found in MARIS CDL\n",
      "\"cs134137\" variable name not found in MARIS CDL\n",
      "\"cs143\" variable name not found in MARIS CDL\n",
      "\"cs146\" variable name not found in MARIS CDL\n",
      "\"cs141\" variable name not found in MARIS CDL\n",
      "\"cs144\" variable name not found in MARIS CDL\n",
      "\"cs140\" variable name not found in MARIS CDL\n",
      "\"cs138\" variable name not found in MARIS CDL\n",
      "\"cs142\" variable name not found in MARIS CDL\n",
      "\"pu239240\" variable name not found in MARIS CDL\n",
      "\"cs139\" variable name not found in MARIS CDL\n",
      "\"k-40\" variable name not found in MARIS CDL\n",
      "\"pu238240\" variable name not found in MARIS CDL\n",
      "\"cm243244\" variable name not found in MARIS CDL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Check if these variable names are consistent with MARIS CDL\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501bd59",
   "metadata": {},
   "source": [
    "Many nuclide names are not listed in the `maris-template.nc`. Here we create a look up table, `varnames_lut_updates`, which will be used to correct the nuclide names in the dictionary of dataframes (i.e. dfs) that are not compatible with the `maris-template.nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "b4abac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "varnames_lut_updates = {\n",
    "    'k-40': 'k40',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs138': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs140': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs143': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs146': 'cs137'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b877d3d",
   "metadata": {},
   "source": [
    "Function `get_varnames_lut` returns a dictionary of nuclide names. This dictionary includes the `NUCLIDE` names from the dataframes in dfs, along with corrections specified in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "35f89931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_varnames_lut(dfs, lut=varnames_lut_updates):\n",
    "    lut = {n: n for n in set(get_unique_nuclides(dfs))}\n",
    "    lut.update(varnames_lut_updates)\n",
    "    return lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d2ea0",
   "metadata": {},
   "source": [
    "Create a callback that remaps the nuclide names in the dataframes within dfs to the updated names in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6f6b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapRdnNameCB(Callback):\n",
    "    \"Remap to MARIS radionuclide names.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=partial(get_varnames_lut, lut=varnames_lut_updates)):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut(tfm.dfs)\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['NUCLIDE'].replace(lut, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa0d93",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB` and `RemapRdnNameCB`. Then, print the unique nuclides for each dataframe in the dictionary dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "1c075d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239_240_tot' 'am241' 'cm242'\n",
      " 'cm244' 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95'\n",
      " 'ag110m' 'cm243_244_tot' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239'\n",
      " 'pb210' 'po210' 'np237' 'pu240' 'mn54']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239_240_tot' 'ru106' 'be7' 'ce144' 'pb210' 'po210'\n",
      " 'sb124' 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131'\n",
      " 'ba140' 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223'\n",
      " 'eu155' 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152'\n",
      " 'sc46' 'rb86' 'ra224' 'th232' 'cs134_137_tot' 'am241' 'ra228' 'th228']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134_137_tot' 'cs134'\n",
      " 'pu239_240_tot' 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144'\n",
      " 'am241' 'be7' 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210'\n",
      " 'ra224' 'nb95' 'pu238_240_tot' 'pu241' 'pu239' 'eu155' 'ir192' 'th232'\n",
      " 'cd109' 'sb124' 'zn65' 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228'\n",
      " 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB()])\n",
    "\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm()['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9359a",
   "metadata": {},
   "source": [
    "After apply correction to the nuclide names check that all nuclide in the dictionary of dataframees are valid. Returns `True` if all are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "3c644322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca601fc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23281e3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: `time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691210e1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83309a2",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "ed0aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParseTimeCB(Callback):\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['time'] = pd.to_datetime(tfm.dfs[k]['DATE'], format='%m/%d/%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB` and `ParseTimeCB`. Then, print the `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2012-05-23\n",
      "1       2012-05-23\n",
      "2       2012-06-17\n",
      "3       2012-05-24\n",
      "4       2012-05-24\n",
      "           ...    \n",
      "20313   2015-06-22\n",
      "20314   2015-06-23\n",
      "20315   2015-06-23\n",
      "20316   2015-06-24\n",
      "20317   2015-06-24\n",
      "Name: time, Length: 20318, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB()])\n",
    "\n",
    "print(tfm()['seawater']['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e52eb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b97c7a",
   "metadata": {},
   "source": [
    "### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ba887",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``time``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582dcd2c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2896aa6",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "0066313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 of 20318 entries for `time` are invalid for seawater.\n",
      "741 of 37347 entries for `time` are invalid for sediment.\n",
      "84 of 14893 entries for `time` are invalid for biota.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seawater':                 KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       " 0      WKRIL2012003   cs137     NaN           NaN          5.3       32.0   \n",
       " 1      WKRIL2012004   cs137     NaN           NaN         19.9       20.0   \n",
       " 2      WKRIL2012005   cs137     NaN           NaN         25.5       20.0   \n",
       " 3      WKRIL2012006   cs137     NaN           NaN         17.0       29.0   \n",
       " 4      WKRIL2012007   cs137     NaN           NaN         22.2       18.0   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 20313  WDHIG2015227    sr90  DHIG02           NaN          6.6        7.5   \n",
       " 20314  WDHIG2015237    sr90  DHIG02           NaN          6.9        7.5   \n",
       " 20315  WDHIG2015239    sr90  DHIG02           NaN          6.8        7.5   \n",
       " 20316  WDHIG2015255    sr90  DHIG02           NaN          7.3        7.5   \n",
       " 20317  WDHIG2015256    sr90  DHIG02           NaN          5.5        7.6   \n",
       " \n",
       "          DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ...  \\\n",
       " 0      08/20/14 00:00:00       90       KRIL   2012003  ...   \n",
       " 1      08/20/14 00:00:00       90       KRIL   2012004  ...   \n",
       " 2      08/20/14 00:00:00       90       KRIL   2012005  ...   \n",
       " 3      08/20/14 00:00:00       90       KRIL   2012006  ...   \n",
       " 4      08/20/14 00:00:00       90       KRIL   2012007  ...   \n",
       " ...                  ...      ...        ...       ...  ...   \n",
       " 20313  11/22/16 00:00:00        6       DHIG   2015227  ...   \n",
       " 20314  11/22/16 00:00:00        6       DHIG   2015237  ...   \n",
       " 20315  11/22/16 00:00:00        6       DHIG   2015239  ...   \n",
       " 20316  11/22/16 00:00:00        6       DHIG   2015255  ...   \n",
       " 20317  11/22/16 00:00:00        6       DHIG   2015256  ...   \n",
       " \n",
       "       LONGITUDE (dddddd)  TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  \\\n",
       " 0                29.3333     NaN     0.0    NaN   NaN   NaN             11   \n",
       " 1                29.3333     NaN    29.0    NaN   NaN   NaN             11   \n",
       " 2                23.1500     NaN     0.0    NaN   NaN   NaN             11   \n",
       " 3                27.9833     NaN     0.0    NaN   NaN   NaN             11   \n",
       " 4                27.9833     NaN    39.0    NaN   NaN   NaN             11   \n",
       " ...                  ...     ...     ...    ...   ...   ...            ...   \n",
       " 20313            14.2000    12.0     4.0    7.5   NaN     F              2   \n",
       " 20314            14.6672    20.0     4.0    7.7   NaN     F              2   \n",
       " 20315            14.3342    17.0     4.0    7.8   NaN     F              2   \n",
       " 20316            13.5002    47.0     4.0    8.4   NaN     F              2   \n",
       " 20317            13.5002    47.0    45.0   15.9   NaN     F              2   \n",
       " \n",
       "        HELCOM_SUBBASIN    DATE_OF_ENTRY_y        time  \n",
       " 0                   11  08/20/14 00:00:00  1337731200  \n",
       " 1                   11  08/20/14 00:00:00  1337731200  \n",
       " 2                    3  08/20/14 00:00:00  1339891200  \n",
       " 3                   11  08/20/14 00:00:00  1337817600  \n",
       " 4                   11  08/20/14 00:00:00  1337817600  \n",
       " ...                ...                ...         ...  \n",
       " 20313                6  11/22/16 00:00:00  1434931200  \n",
       " 20314                6  11/22/16 00:00:00  1435017600  \n",
       " 20315                2  11/22/16 00:00:00  1435017600  \n",
       " 20316                2  11/22/16 00:00:00  1435104000  \n",
       " 20317                2  11/22/16 00:00:00  1435104000  \n",
       " \n",
       " [19824 rows x 28 columns],\n",
       " 'sediment':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       " 0      SKRIL2012048   ra226     NaN           NaN        35.00       26.0   \n",
       " 1      SKRIL2012049   ra226     NaN           NaN        36.00       22.0   \n",
       " 2      SKRIL2012050   ra226     NaN           NaN        38.00       24.0   \n",
       " 3      SKRIL2012051   ra226     NaN           NaN        36.00       25.0   \n",
       " 4      SKRIL2012052   ra226     NaN           NaN        30.00       23.0   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 37342  SSTUK2016044   cs137  STUK01           NaN         1.20       12.0   \n",
       " 37343  SSTUK2016045   cs137  STUK01           NaN         0.79       20.0   \n",
       " 37344  SSTUK2016050   cs137  STUK01           NaN       512.00       11.0   \n",
       " 37345  SSTUK2016051   cs137  STUK01           NaN       527.00        6.3   \n",
       " 37346  SSTUK2016052   cs137  STUK01           NaN       684.00        5.0   \n",
       " \n",
       "       < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...      AREA  \\\n",
       " 0               NaN          NaN        NaN  08/20/14 00:00:00  ...  0.006000   \n",
       " 1               NaN          NaN        NaN  08/20/14 00:00:00  ...  0.006000   \n",
       " 2               NaN          NaN        NaN  08/20/14 00:00:00  ...  0.006000   \n",
       " 3               NaN          NaN        NaN  08/20/14 00:00:00  ...  0.006000   \n",
       " 4               NaN          NaN        NaN  08/20/14 00:00:00  ...  0.006000   \n",
       " ...             ...          ...        ...                ...  ...       ...   \n",
       " 37342           NaN     8.916443       15.0                NaN  ...  0.006362   \n",
       " 37343           NaN     5.992930       23.0                NaN  ...  0.006362   \n",
       " 37344           NaN  2164.945699       14.0                NaN  ...  0.006362   \n",
       " 37345           NaN  2523.279045        9.3                NaN  ...  0.006362   \n",
       " 37346           NaN  3929.780107        8.0                NaN  ...  0.006362   \n",
       " \n",
       "        SEDI  OXIC DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN SUM_LINK  \\\n",
       " 0       NaN   NaN NaN   NaN           11.0             11.0      NaN   \n",
       " 1       NaN   NaN NaN   NaN           11.0             11.0      NaN   \n",
       " 2       NaN   NaN NaN   NaN           11.0             11.0      NaN   \n",
       " 3       NaN   NaN NaN   NaN           11.0             11.0      NaN   \n",
       " 4       NaN   NaN NaN   NaN           11.0             11.0      NaN   \n",
       " ...     ...   ...  ..   ...            ...              ...      ...   \n",
       " 37342  46.0   NaN NaN   NaN            3.0              3.0      NaN   \n",
       " 37343  46.0   NaN NaN   NaN            3.0              3.0      NaN   \n",
       " 37344  57.0   NaN NaN   NaN            8.0              8.0      NaN   \n",
       " 37345  47.0   NaN NaN   NaN            8.0              8.0      NaN   \n",
       " 37346  46.0   NaN NaN   NaN            8.0              8.0      NaN   \n",
       " \n",
       "          DATE_OF_ENTRY_y        time  \n",
       " 0      08/20/14 00:00:00  1339891200  \n",
       " 1      08/20/14 00:00:00  1339891200  \n",
       " 2      08/20/14 00:00:00  1344556800  \n",
       " 3      08/20/14 00:00:00  1344556800  \n",
       " 4      08/20/14 00:00:00  1344556800  \n",
       " ...                  ...         ...  \n",
       " 37342                NaN  1465430400  \n",
       " 37343                NaN  1465430400  \n",
       " 37344                NaN  1464480000  \n",
       " 37345                NaN  1464480000  \n",
       " 37346                NaN  1464480000  \n",
       " \n",
       " [36606 rows x 36 columns],\n",
       " 'biota':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       " 0      BVTIG2012041   cs134  VTIG01             <     0.010140     W     NaN   \n",
       " 1      BVTIG2012041     k40  VTIG01                 135.300000     W    3.57   \n",
       " 2      BVTIG2012041    co60  VTIG01             <     0.013980     W     NaN   \n",
       " 3      BVTIG2012041   cs137  VTIG01                   4.338000     W    3.48   \n",
       " 4      BVTIG2012040   cs134  VTIG01             <     0.009614     W     NaN   \n",
       " ...             ...     ...     ...           ...          ...   ...     ...   \n",
       " 14822  BSSSM2018014   cs137      42           NaN     6.500000     D    9.70   \n",
       " 14823  BSSSM2018015     k40      42           NaN   780.000000     D    1.80   \n",
       " 14824  BSSSM2018015   cs137      42           NaN    12.000000     D    3.00   \n",
       " 14825  BSSSM2018015     be7      42           NaN   110.000000     D    5.60   \n",
       " 14892  BIMGW2018011   cs137  IMGW03           NaN     0.830000     W   27.71   \n",
       " \n",
       "        NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... TISSUE     NO LENGTH  WEIGHT  \\\n",
       " 0         NaN  02/27/14 00:00:00      6.0  ...      5   16.0   45.7   948.0   \n",
       " 1         NaN  02/27/14 00:00:00      6.0  ...      5   16.0   45.7   948.0   \n",
       " 2         NaN  02/27/14 00:00:00      6.0  ...      5   16.0   45.7   948.0   \n",
       " 3         NaN  02/27/14 00:00:00      6.0  ...      5   16.0   45.7   948.0   \n",
       " 4         NaN  02/27/14 00:00:00      6.0  ...      5   17.0   45.9   964.0   \n",
       " ...       ...                ...      ...  ...    ...    ...    ...     ...   \n",
       " 14822     NaN  04/29/20 00:00:00      NaN  ...     41  153.0    NaN     NaN   \n",
       " 14823     NaN  04/29/20 00:00:00      NaN  ...     51    NaN    NaN     NaN   \n",
       " 14824     NaN  04/29/20 00:00:00      NaN  ...     51    NaN    NaN     NaN   \n",
       " 14825     NaN  04/29/20 00:00:00      NaN  ...     51    NaN    NaN     NaN   \n",
       " 14892     NaN  04/30/20 00:00:00     67.0  ...      5    1.0   21.0   120.0   \n",
       " \n",
       "           DW%  LOI% MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \\\n",
       " 0      18.453  92.9             2               16  02/27/14 00:00:00   \n",
       " 1      18.453  92.9             2               16  02/27/14 00:00:00   \n",
       " 2      18.453  92.9             2               16  02/27/14 00:00:00   \n",
       " 3      18.453  92.9             2               16  02/27/14 00:00:00   \n",
       " 4      18.458  92.9             2               16  02/27/14 00:00:00   \n",
       " ...       ...   ...           ...              ...                ...   \n",
       " 14822  34.650   0.0             1                8  04/29/20 00:00:00   \n",
       " 14823  26.800   0.0             1                8  04/29/20 00:00:00   \n",
       " 14824  26.800   0.0             1                8  04/29/20 00:00:00   \n",
       " 14825  26.800   0.0             1                8  04/29/20 00:00:00   \n",
       " 14892     NaN   NaN             4                4  04/30/20 00:00:00   \n",
       " \n",
       "              time  \n",
       " 0      1348358400  \n",
       " 1      1348358400  \n",
       " 2      1348358400  \n",
       " 3      1348358400  \n",
       " 4      1348358400  \n",
       " ...           ...  \n",
       " 14822  1536019200  \n",
       " 14823  1536796800  \n",
       " 14824  1536796800  \n",
       " 14825  1536796800  \n",
       " 14892  1538524800  \n",
       " \n",
       " [14809 rows x 34 columns]}"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg(), verbose = True)\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8928f5",
   "metadata": {},
   "source": [
    "``EncodeTimeCB`` includes a ``verbose`` argument. When ``verbose`` is set to ``True``, a dictionary of dataframes, called ``invalid_time_dfs``, is created for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0011d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>WKRIL2011013</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17326</th>\n",
       "      <td>WKRIL2011014</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17327</th>\n",
       "      <td>WKRIL2011015</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17328</th>\n",
       "      <td>WKRIL2011016</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>WKRIL2011017</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20058</th>\n",
       "      <td>WLEPA2017011</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20059</th>\n",
       "      <td>WLEPA2017012</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20060</th>\n",
       "      <td>WLEPA2017012</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20061</th>\n",
       "      <td>WLEPA2017013</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>WLEPA2017013</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY  COUNTRY DATE time\n",
       "17325  WKRIL2011013       90  NaN  NaT\n",
       "17326  WKRIL2011014       90  NaN  NaT\n",
       "17327  WKRIL2011015       90  NaN  NaT\n",
       "17328  WKRIL2011016       90  NaN  NaT\n",
       "17329  WKRIL2011017       90  NaN  NaT\n",
       "...             ...      ...  ...  ...\n",
       "20058  WLEPA2017011       93  NaN  NaT\n",
       "20059  WLEPA2017012       93  NaN  NaT\n",
       "20060  WLEPA2017012       93  NaN  NaT\n",
       "20061  WLEPA2017013       93  NaN  NaT\n",
       "20062  WLEPA2017013       93  NaN  NaT\n",
       "\n",
       "[494 rows x 4 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k='seawater'\n",
    "tfm.invalid_time_dfs[k][['KEY','COUNTRY','DATE','time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffdf2f0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "### Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12185ee",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``_unc``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b02a81",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Uncertainty`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` coverts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Make measurement and uncertainty units consistent\n",
    "def unc_rel2stan(df, meas_col, unc_col):\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col]/100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the uncertainty is given as a relative uncertainty to the value (i.e., activity). The column names for both the value and the uncertainty vary by sample type. The coi_units_unc dictionary defines the column names for the Value and Uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncUnitCB callback normalizes the uncertainty by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormalizeUncUnitCB(Callback):\n",
    "    \"Convert from relative error % to uncertainty of activity unit\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc=unc_rel2stan,\n",
    "                 coi=coi_units_unc):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp, val, unc in self.coi:\n",
    "            tfm.dfs[grp][unc] = self.fn_convert_unc(tfm.dfs[grp], val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB` and `NormalizeUncUnitCB()`. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALUE_Bq/m³  ERROR%_m³\n",
      "0          5.3      1.696\n",
      "1         19.9      3.980\n",
      "2         25.5      5.100\n",
      "3         17.0      4.930\n",
      "4         22.2      3.996\n",
      "   VALUE_Bq/kg    ERROR%\n",
      "0     0.010140       NaN\n",
      "1   135.300000  6.535274\n",
      "2     0.013980       NaN\n",
      "3     4.338000  0.006549\n",
      "4     0.009614       NaN\n",
      "   VALUE_Bq/kg  ERROR%_kg\n",
      "0         35.0   1.114750\n",
      "1         36.0   1.026432\n",
      "2         38.0   1.316928\n",
      "3         36.0   1.166400\n",
      "4         30.0   0.621000\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB()])\n",
    "\n",
    "print(tfm()['seawater'][['VALUE_Bq/m³', 'ERROR%_m³']][:5])\n",
    "print(tfm()['biota'][['VALUE_Bq/kg', 'ERROR%']][:5])\n",
    "print(tfm()['sediment'][['VALUE_Bq/kg', 'ERROR%_kg']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8540",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "### Lookup transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6e294",
   "metadata": {},
   "source": [
    "`get_maris_lut` performs a lookup of data provided in `data_provider_lut` against the MARIS lookup (`maris_lut`) using a fuzzy matching algorithm based on Levenshtein distance. The `get_maris_lut` is used to correct the HELCOM data to a standard format for MARIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "2f6f0c03-7666-461d-a5ce-d0021bc9e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_maris_lut(fname_in, \n",
    "                  fname_cache, # For instance 'species_helcom.pkl'\n",
    "                  data_provider_lut:str, # Data provider lookup table name\n",
    "                  data_provider_id_col:str, # Data provider lookup column id of interest\n",
    "                  data_provider_name_col:str, # Data provider lookup column name of interest\n",
    "                  maris_lut:Callable, # Function retrieving MARIS source lookup table\n",
    "                  maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "                  maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "                  unmatched_fixes={},\n",
    "                  as_dataframe=False,\n",
    "                  overwrite=False\n",
    "                 ):\n",
    "    fname_cache = cache_path() / fname_cache\n",
    "    lut = {}\n",
    "    maris_lut = maris_lut()\n",
    "    df = pd.read_csv(Path(fname_in) / data_provider_lut)\n",
    "    if overwrite or (not fname_cache.exists()):\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "            # Fix if unmatched\n",
    "            has_to_be_fixed = row[data_provider_id_col] in unmatched_fixes            \n",
    "            name_to_match = unmatched_fixes[row[data_provider_id_col]] if has_to_be_fixed else row[data_provider_name_col]\n",
    "\n",
    "            # Match\n",
    "            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)\n",
    "            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], \n",
    "                          row[data_provider_name_col], result.iloc[0]['score'])\n",
    "            \n",
    "            lut[row[data_provider_id_col]] = match\n",
    "        fc.save_pickle(fname_cache, lut)\n",
    "    else:\n",
    "        lut = fc.load_pickle(fname_cache)\n",
    "\n",
    "    if as_dataframe:\n",
    "        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()\n",
    "        df_lut.index.name = 'source_id'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)\n",
    "    else:\n",
    "        return lut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5868c16b",
   "metadata": {},
   "source": [
    "#### Lookup : Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2bbb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``species``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19098ae",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Species`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40671f8f",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `RUBIN_NAME.csv` file for biota species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "bdd0d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "df_rubin = pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')\n",
    "df_rubin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa8871",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_species` to correct the spelling of names that are unmatched in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "15acca89-169a-45eb-98fe-cf7c7b2ee0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_species = {\n",
    "    'CARD EDU': 'Cerastoderma edule',\n",
    "    'LAMI SAC': 'Saccharina latissima',\n",
    "    'PSET MAX': 'Scophthalmus maximus',\n",
    "    'STIZ LUC': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "2adaa417-6b01-45d8-80d7-2e3d97cb0f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:07<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "species_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='species_helcom.pkl', \n",
    "                               data_provider_lut='RUBIN_NAME.csv',\n",
    "                               data_provider_id_col='RUBIN',\n",
    "                               data_provider_name_col='SCIENTIFIC NAME',\n",
    "                               maris_lut=species_lut_path,\n",
    "                               maris_id='species_id',\n",
    "                               maris_name='species',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915a7fc",
   "metadata": {},
   "source": [
    "Display `species_lut_df`. The `match_score` represents the number insertions, deletions, or substitutions needed to transform from the HECOM source name (`source_name`) to the maris name, (`matched_maris_name`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c341f814-3343-47b7-958c-5df7d34a683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLY FUC</th>\n",
       "      <td>245</td>\n",
       "      <td>Polysiphonia fucoides</td>\n",
       "      <td>POLYSIPHONIA FUCOIDES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id     matched_maris_name              source_name  \\\n",
       "source_id                                                              \n",
       "ENCH CIM         276          Echinodermata       ENCHINODERMATA CIM   \n",
       "MACO BAL         122        Macoma balthica           MACOMA BALTICA   \n",
       "STUC PEC         704    Stuckenia pectinata      STUCKENIA PECTINATE   \n",
       "STIZ LUC         285      Sander lucioperca  STIZOSTEDION LUCIOPERCA   \n",
       "POLY FUC         245  Polysiphonia fucoides    POLYSIPHONIA FUCOIDES   \n",
       "\n",
       "          match_score  \n",
       "source_id              \n",
       "ENCH CIM            5  \n",
       "MACO BAL            1  \n",
       "STUC PEC            1  \n",
       "STIZ LUC            1  \n",
       "POLY FUC            0  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "species_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557931bd",
   "metadata": {},
   "source": [
    "Show `species_lut_df` where `match_type` is not a perfect match ( i.e. not equal 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "657f297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id   matched_maris_name              source_name match_score\n",
       "source_id                                                                     \n",
       "ENCH CIM         276        Echinodermata       ENCHINODERMATA CIM           5\n",
       "MACO BAL         122      Macoma balthica           MACOMA BALTICA           1\n",
       "STUC PEC         704  Stuckenia pectinata      STUCKENIA PECTINATE           1\n",
       "STIZ LUC         285    Sander lucioperca  STIZOSTEDION LUCIOPERCA           1"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_lut_df[species_lut_df['match_score'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900eb6",
   "metadata": {},
   "source": [
    "`LookupBiotaSpeciesCB` applies the corrected `biota` `species` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "c2798566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaSpeciesCB(Callback):\n",
    "    \"\"\"\n",
    "    Biota species remapped to MARIS db:\n",
    "        CARD EDU: Cerastoderma edule\n",
    "        LAMI SAC: Saccharina latissima\n",
    "        PSET MAX: Scophthalmus maximus\n",
    "        STIZ LUC: Sander luciopercas\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: lut[x.strip()].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98d51",
   "metadata": {},
   "source": [
    "`get_maris_species` defines a partial function of `get_maris_lut`, with predefined arguments  for species lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "33ddf185-8ee8-4cb0-abd6-427fe4e52c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_species = partial(get_maris_lut,\n",
    "                            fname_in, fname_cache='species_helcom.pkl', \n",
    "                            data_provider_lut='RUBIN_NAME.csv',\n",
    "                            data_provider_id_col='RUBIN',\n",
    "                            data_provider_name_col='SCIENTIFIC NAME',\n",
    "                            maris_lut=species_lut_path,\n",
    "                            maris_id='species_id',\n",
    "                            maris_name='species',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18132f3",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()` and `LookupBiotaSpeciesCB(get_maris_species)`. Then, print the unique `species` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "b83ffe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species)\n",
    "                            ])\n",
    "\n",
    "#print(tfm()['biota'][['RUBIN', 'species']][:10])\n",
    "print(tfm()['biota']['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0faa085",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "#### Lookup : Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92384b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``body_part``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7388fd",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Body part`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31449525",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `TISSUE.csv` file for biota tissues. Biota tissue is known as `body part` in the maris data set.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6a4e9",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_tissues` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {\n",
    "    3: 'Whole animal eviscerated without head',\n",
    "    12: 'Viscera',\n",
    "    8: 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "2d2a502e-3826-404c-84e1-0d60b4be0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 66.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='tissues_helcom.pkl', \n",
    "                               data_provider_lut='TISSUE.csv',\n",
    "                               data_provider_id_col='TISSUE',\n",
    "                               data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                               maris_lut=bodyparts_lut_path,\n",
    "                               maris_id='bodypar_id',\n",
    "                               maris_name='bodypar',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "967c1a7d-ba91-4400-ba0a-bad180eee1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id     matched_maris_name                   source_name  \\\n",
       "source_id                                                                   \n",
       "2                 52    Flesh without bones   WHOLE FISH WITHOUT ENTRAILS   \n",
       "5                 52    Flesh without bones  FLESH WITHOUT BONES (FILETS)   \n",
       "1                  1           Whole animal                    WHOLE FISH   \n",
       "15                53  Stomach and intestine           STOMACH + INTESTINE   \n",
       "41                 1           Whole animal                 WHOLE ANIMALS   \n",
       "\n",
       "          match_score  \n",
       "source_id              \n",
       "2                  13  \n",
       "5                   9  \n",
       "1                   5  \n",
       "15                  3  \n",
       "41                  1  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissues_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811aa06",
   "metadata": {},
   "source": [
    "`LookupBiotaBodyPartCB` applies the corrected `biota` `TISSUE` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "bbe9a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    \"\"\"\n",
    "    Update bodypart id based on MARIS dbo_bodypar.xlsx:\n",
    "        - 3: 'Whole animal eviscerated without head',\n",
    "        - 12: 'Viscera',\n",
    "        - 8: 'Skin'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: lut[x].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a3904",
   "metadata": {},
   "source": [
    "`get_maris_bodypart` defines a partial function of `get_maris_lut`, with predefined arguments  for  `TISSUE` (or `bodypar`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5460dc4c-6927-460f-924f-322606ad903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_bodypart = partial(get_maris_lut,\n",
    "                             fname_in,\n",
    "                             fname_cache='tissues_helcom.pkl', \n",
    "                             data_provider_lut='TISSUE.csv',\n",
    "                             data_provider_id_col='TISSUE',\n",
    "                             data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                             maris_lut=bodyparts_lut_path,\n",
    "                             maris_id='bodypar_id',\n",
    "                             maris_name='bodypar',\n",
    "                             unmatched_fixes=unmatched_fixes_biota_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877064bf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)` and `LookupBiotaBodyPartCB(get_maris_bodypart)`. Then, print the `TISSUE` and `body_part` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "53a195f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  body_part\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'][['TISSUE', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718285f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "#### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513576a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``bio_group``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421826",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Biogroup is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_biogroup_lut(maris_lut):\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291637e",
   "metadata": {},
   "source": [
    "`LookupBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class LookupBiogroupCB(Callback):\n",
    "    \"\"\"\n",
    "    Update biogroup id  based on MARIS dbo_species.xlsx\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: lut[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f2d40",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)` and `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` . Then, print the `bio_group` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "3e74513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                            \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158b423",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "#### Lookup : Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1fe91",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `SEDIMENT_TYPE.csv` file for Sediment types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169727",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sed_type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be172080",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Sediment type`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "bf7665a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI    SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99          NO DATA                    NaN\n",
       "1    30  SILT AND GRAVEL                    YES\n",
       "2     0           GRAVEL                    YES\n",
       "3     1             SAND                    YES\n",
       "4     2        FINE SAND                     NO"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "df_sediment = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "df_sediment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dba05",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_sediments` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d553b9bf-d305-456f-9bf1-620f2804637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_sediments = {\n",
    "    #np.nan: 'Not applicable',\n",
    "    -99: '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "480c716f-d2de-455f-b58f-22af28ca01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 94.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "sediments_lut_df = get_maris_lut(\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments,\n",
    "    as_dataframe=True,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17cfe1",
   "metadata": {},
   "source": [
    "`get_maris_sediments` defines a partial function of `get_maris_lut`, with predefined arguments  for  `SEDI` (or `sedtype`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "4053bfbb-8f04-434c-a8a1-35b4d58dd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_sediments = partial(\n",
    "    get_maris_lut,\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528f164",
   "metadata": {},
   "source": [
    "`LookupSedimentCB` applies the corrected `sediment` `SEDI` data obtained from the `get_maris_lut` function to the `sediment` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "6a9fb63d-2459-4497-9086-bb98ccd524e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupSedimentCB(Callback):\n",
    "    \"\"\"\n",
    "    Update sediment id  based on MARIS dbo_sedtype.xlsx\n",
    "        -99: '(Not available)'\n",
    "        - na: '(Not available)'\n",
    "        - 56: '(Not available)'\n",
    "        - 73: '(Not available)'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "\n",
    "        # To check with Helcom\n",
    "        tfm.dfs['sediment']['SEDI'] = dfs['sediment']['SEDI'].fillna(-99).astype('int')\n",
    "        tfm.dfs['sediment']['SEDI'].replace(56, -99, inplace=True)\n",
    "        tfm.dfs['sediment']['SEDI'].replace(73, -99, inplace=True)\n",
    "        \n",
    "        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: lut[x].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131e929",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)` and `LookupSedimentCB(get_maris_sediments)`. Then, print the `SEDI` and `sed_type` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "16d42cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEDI  sed_type\n",
      "0   -99         0\n",
      "1   -99         0\n",
      "2   -99         0\n",
      "3   -99         0\n",
      "4   -99         0\n",
      "{'seawater':                 KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "0      WKRIL2012003   cs137     NaN           NaN          5.3   0.089888   \n",
      "1      WKRIL2012004   cs137     NaN           NaN         19.9   0.792020   \n",
      "2      WKRIL2012005   cs137     NaN           NaN         25.5   1.300500   \n",
      "3      WKRIL2012006   cs137     NaN           NaN         17.0   0.838100   \n",
      "4      WKRIL2012007   cs137     NaN           NaN         22.2   0.887112   \n",
      "...             ...     ...     ...           ...          ...        ...   \n",
      "20313  WDHIG2015227    sr90  DHIG02           NaN          6.6   0.032670   \n",
      "20314  WDHIG2015237    sr90  DHIG02           NaN          6.9   0.035707   \n",
      "20315  WDHIG2015239    sr90  DHIG02           NaN          6.8   0.034680   \n",
      "20316  WDHIG2015255    sr90  DHIG02           NaN          7.3   0.039968   \n",
      "20317  WDHIG2015256    sr90  DHIG02           NaN          5.5   0.022990   \n",
      "\n",
      "         DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ...  \\\n",
      "0      08/20/14 00:00:00       90       KRIL   2012003  ...   \n",
      "1      08/20/14 00:00:00       90       KRIL   2012004  ...   \n",
      "2      08/20/14 00:00:00       90       KRIL   2012005  ...   \n",
      "3      08/20/14 00:00:00       90       KRIL   2012006  ...   \n",
      "4      08/20/14 00:00:00       90       KRIL   2012007  ...   \n",
      "...                  ...      ...        ...       ...  ...   \n",
      "20313  11/22/16 00:00:00        6       DHIG   2015227  ...   \n",
      "20314  11/22/16 00:00:00        6       DHIG   2015237  ...   \n",
      "20315  11/22/16 00:00:00        6       DHIG   2015239  ...   \n",
      "20316  11/22/16 00:00:00        6       DHIG   2015255  ...   \n",
      "20317  11/22/16 00:00:00        6       DHIG   2015256  ...   \n",
      "\n",
      "      LONGITUDE (dddddd)  TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  \\\n",
      "0                29.3333     NaN     0.0    NaN   NaN   NaN             11   \n",
      "1                29.3333     NaN    29.0    NaN   NaN   NaN             11   \n",
      "2                23.1500     NaN     0.0    NaN   NaN   NaN             11   \n",
      "3                27.9833     NaN     0.0    NaN   NaN   NaN             11   \n",
      "4                27.9833     NaN    39.0    NaN   NaN   NaN             11   \n",
      "...                  ...     ...     ...    ...   ...   ...            ...   \n",
      "20313            14.2000    12.0     4.0    7.5   NaN     F              2   \n",
      "20314            14.6672    20.0     4.0    7.7   NaN     F              2   \n",
      "20315            14.3342    17.0     4.0    7.8   NaN     F              2   \n",
      "20316            13.5002    47.0     4.0    8.4   NaN     F              2   \n",
      "20317            13.5002    47.0    45.0   15.9   NaN     F              2   \n",
      "\n",
      "       HELCOM_SUBBASIN    DATE_OF_ENTRY_y        time  \n",
      "0                   11  08/20/14 00:00:00  1337731200  \n",
      "1                   11  08/20/14 00:00:00  1337731200  \n",
      "2                    3  08/20/14 00:00:00  1339891200  \n",
      "3                   11  08/20/14 00:00:00  1337817600  \n",
      "4                   11  08/20/14 00:00:00  1337817600  \n",
      "...                ...                ...         ...  \n",
      "20313                6  11/22/16 00:00:00  1434931200  \n",
      "20314                6  11/22/16 00:00:00  1435017600  \n",
      "20315                2  11/22/16 00:00:00  1435017600  \n",
      "20316                2  11/22/16 00:00:00  1435104000  \n",
      "20317                2  11/22/16 00:00:00  1435104000  \n",
      "\n",
      "[19824 rows x 28 columns], 'sediment':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg   ERROR%_kg  \\\n",
      "0      SKRIL2012048   ra226     NaN           NaN        35.00    3.185000   \n",
      "1      SKRIL2012049   ra226     NaN           NaN        36.00    2.851200   \n",
      "2      SKRIL2012050   ra226     NaN           NaN        38.00    3.465600   \n",
      "3      SKRIL2012051   ra226     NaN           NaN        36.00    3.240000   \n",
      "4      SKRIL2012052   ra226     NaN           NaN        30.00    2.070000   \n",
      "...             ...     ...     ...           ...          ...         ...   \n",
      "37342  SSTUK2016044   cs137  STUK01           NaN         1.20    0.001728   \n",
      "37343  SSTUK2016045   cs137  STUK01           NaN         0.79    0.001248   \n",
      "37344  SSTUK2016050   cs137  STUK01           NaN       512.00  288.358400   \n",
      "37345  SSTUK2016051   cs137  STUK01           NaN       527.00  174.969270   \n",
      "37346  SSTUK2016052   cs137  STUK01           NaN       684.00  233.928000   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  SEDI  \\\n",
      "0               NaN          NaN        NaN  08/20/14 00:00:00  ...   -99   \n",
      "1               NaN          NaN        NaN  08/20/14 00:00:00  ...   -99   \n",
      "2               NaN          NaN        NaN  08/20/14 00:00:00  ...   -99   \n",
      "3               NaN          NaN        NaN  08/20/14 00:00:00  ...   -99   \n",
      "4               NaN          NaN        NaN  08/20/14 00:00:00  ...   -99   \n",
      "...             ...          ...        ...                ...  ...   ...   \n",
      "37342           NaN     8.916443       15.0                NaN  ...    46   \n",
      "37343           NaN     5.992930       23.0                NaN  ...    46   \n",
      "37344           NaN  2164.945699       14.0                NaN  ...    57   \n",
      "37345           NaN  2523.279045        9.3                NaN  ...    47   \n",
      "37346           NaN  3929.780107        8.0                NaN  ...    46   \n",
      "\n",
      "      OXIC  DW% LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "0      NaN  NaN  NaN           11.0             11.0       NaN   \n",
      "1      NaN  NaN  NaN           11.0             11.0       NaN   \n",
      "2      NaN  NaN  NaN           11.0             11.0       NaN   \n",
      "3      NaN  NaN  NaN           11.0             11.0       NaN   \n",
      "4      NaN  NaN  NaN           11.0             11.0       NaN   \n",
      "...    ...  ...  ...            ...              ...       ...   \n",
      "37342  NaN  NaN  NaN            3.0              3.0       NaN   \n",
      "37343  NaN  NaN  NaN            3.0              3.0       NaN   \n",
      "37344  NaN  NaN  NaN            8.0              8.0       NaN   \n",
      "37345  NaN  NaN  NaN            8.0              8.0       NaN   \n",
      "37346  NaN  NaN  NaN            8.0              8.0       NaN   \n",
      "\n",
      "         DATE_OF_ENTRY_y        time  sed_type  \n",
      "0      08/20/14 00:00:00  1339891200         0  \n",
      "1      08/20/14 00:00:00  1339891200         0  \n",
      "2      08/20/14 00:00:00  1344556800         0  \n",
      "3      08/20/14 00:00:00  1344556800         0  \n",
      "4      08/20/14 00:00:00  1344556800         0  \n",
      "...                  ...         ...       ...  \n",
      "37342                NaN  1465430400        50  \n",
      "37343                NaN  1465430400        50  \n",
      "37344                NaN  1464480000        59  \n",
      "37345                NaN  1464480000        51  \n",
      "37346                NaN  1464480000        50  \n",
      "\n",
      "[36606 rows x 37 columns], 'biota':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  \\\n",
      "0      BVTIG2012041   cs134  VTIG01             <     0.010140     W   \n",
      "1      BVTIG2012041     k40  VTIG01                 135.300000     W   \n",
      "2      BVTIG2012041    co60  VTIG01             <     0.013980     W   \n",
      "3      BVTIG2012041   cs137  VTIG01                   4.338000     W   \n",
      "4      BVTIG2012040   cs134  VTIG01             <     0.009614     W   \n",
      "...             ...     ...     ...           ...          ...   ...   \n",
      "14822  BSSSM2018014   cs137      42           NaN     6.500000     D   \n",
      "14823  BSSSM2018015     k40      42           NaN   780.000000     D   \n",
      "14824  BSSSM2018015   cs137      42           NaN    12.000000     D   \n",
      "14825  BSSSM2018015     be7      42           NaN   110.000000     D   \n",
      "14892  BIMGW2018011   cs137  IMGW03           NaN     0.830000     W   \n",
      "\n",
      "           ERROR%  NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... LENGTH  WEIGHT  \\\n",
      "0             NaN     NaN  02/27/14 00:00:00      6.0  ...   45.7   948.0   \n",
      "1        6.535274     NaN  02/27/14 00:00:00      6.0  ...   45.7   948.0   \n",
      "2             NaN     NaN  02/27/14 00:00:00      6.0  ...   45.7   948.0   \n",
      "3        0.006549     NaN  02/27/14 00:00:00      6.0  ...   45.7   948.0   \n",
      "4             NaN     NaN  02/27/14 00:00:00      6.0  ...   45.9   964.0   \n",
      "...           ...     ...                ...      ...  ...    ...     ...   \n",
      "14822    0.040982     NaN  04/29/20 00:00:00      NaN  ...    NaN     NaN   \n",
      "14823  109.512000     NaN  04/29/20 00:00:00      NaN  ...    NaN     NaN   \n",
      "14824    0.043200     NaN  04/29/20 00:00:00      NaN  ...    NaN     NaN   \n",
      "14825    6.776000     NaN  04/29/20 00:00:00      NaN  ...    NaN     NaN   \n",
      "14892    0.001909     NaN  04/30/20 00:00:00     67.0  ...   21.0   120.0   \n",
      "\n",
      "          DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \\\n",
      "0      18.453  92.9              2               16  02/27/14 00:00:00   \n",
      "1      18.453  92.9              2               16  02/27/14 00:00:00   \n",
      "2      18.453  92.9              2               16  02/27/14 00:00:00   \n",
      "3      18.453  92.9              2               16  02/27/14 00:00:00   \n",
      "4      18.458  92.9              2               16  02/27/14 00:00:00   \n",
      "...       ...   ...            ...              ...                ...   \n",
      "14822  34.650   0.0              1                8  04/29/20 00:00:00   \n",
      "14823  26.800   0.0              1                8  04/29/20 00:00:00   \n",
      "14824  26.800   0.0              1                8  04/29/20 00:00:00   \n",
      "14825  26.800   0.0              1                8  04/29/20 00:00:00   \n",
      "14892     NaN   NaN              4                4  04/30/20 00:00:00   \n",
      "\n",
      "             time  species  body_part  \n",
      "0      1348358400       99         52  \n",
      "1      1348358400       99         52  \n",
      "2      1348358400       99         52  \n",
      "3      1348358400       99         52  \n",
      "4      1348358400       99         52  \n",
      "...           ...      ...        ...  \n",
      "14822  1536019200      122          1  \n",
      "14823  1536796800       96         54  \n",
      "14824  1536796800       96         54  \n",
      "14825  1536796800       96         54  \n",
      "14892  1538524800      247         52  \n",
      "\n",
      "[14809 rows x 36 columns]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['sediment'][['SEDI', 'sed_type']][:5])\n",
    "print(tfm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d5871",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "#### Lookup : Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a777c3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebee28",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "Create `renaming_unit_rules` to rename the units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "a287e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['biota']['BASIS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "b80a7e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "ea7fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {'seawater' : 1, #  'Bq/m3'\n",
    "                       'sediment' : 4, # 'Bq/kgd' for sediment (see https://maps.helcom.fi/website/download/MORS_ENVIRONMENT_Reporting_form.xlsx)\n",
    "                       'biota': {'D' : 4, # 'Bq/kgd'\n",
    "                                 'W' : 5, # 'Bq/kgw'\n",
    "                                 'F' : 5 # 'Bq/kgw' !assumed to be 'Fresh' so set to wet. .  \n",
    "                                 } } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12793b79",
   "metadata": {},
   "source": [
    "`LookupUnitCB` defines a `unit` column each dataframe based on the units provided in the value (`VALUE_Bq/m³` or `VALUE_Bq/kg`) column of the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "2f5f22fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x in renaming_unit_rules['biota'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    def __init__(self,\n",
    "                 renaming_unit_rules=renaming_unit_rules):\n",
    "        fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            \n",
    "            if grp == 'biota':\n",
    "                lut=renaming_unit_rules[grp]\n",
    "                # lookup value in the 'BASIS' column to determine the unit. \n",
    "                tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut[x] if x in lut.keys() else 0 )\n",
    "            else:                 \n",
    "                tfm.dfs[grp]['unit'] = renaming_unit_rules[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` and `LookupUnitCB()`. Then, print the unique `unit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB()])\n",
    "\n",
    "print(tfm()['biota']['unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422eeb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "#### Lookup : Detection limit or Value type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c95ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``detection_limit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fd987",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine foramt variable: ``Value type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3a699",
   "metadata": {},
   "source": [
    "Create `coi_dl` to define the column names related to Value type for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "9c6e542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_dl = {'seawater' : { 'val' : 'VALUE_Bq/m³',\n",
    "                        'unc' : 'ERROR%_m³',\n",
    "                        'dl' : '< VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg',\n",
    "                            'unc' : 'ERROR%',\n",
    "                            'dl' : '< VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg',\n",
    "                              'unc' : 'ERROR%_kg',\n",
    "                              'dl' : '< VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290b3fa",
   "metadata": {},
   "source": [
    "`get_detectionlimit_lut` reads the file at `detection_limit_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`.\n",
    "| id | name | name_sanitized |\n",
    "| :-: | :-: | :-: |\n",
    "|-1|Not applicable|Not applicable|\n",
    "|0|Not Available|Not available|\n",
    "|1|=|Detected value|\n",
    "|2|<|Detection limit|\n",
    "|3|ND|Not detected|\n",
    "|4|DE|Derived|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "3dfce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_detectionlimit_lut():\n",
    "    df = pd.read_excel(detection_limit_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`LookupDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or detection limit) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg>` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    \"Remamp value type to MARIS format.\"\n",
    "    def __init__(self ,\n",
    "                 coi=coi_dl,\n",
    "                 fn_lut=get_detectionlimit_lut\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # Copy dl col \n",
    "            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp][self.coi[grp]['dl']]\n",
    "            # Fill values with '=' if both a value and uncertainty are not nan and detection_limit is not in the list of keys returned from lut.\n",
    "            condition = ((tfm.dfs[grp][self.coi[grp]['val']].notna()) & (tfm.dfs[grp][self.coi[grp]['unc']].notna())) & (~tfm.dfs[grp][\"detection_limit\"].isin(list(lut.keys())))\n",
    "            tfm.dfs[grp].loc[condition, 'detection_limit']= '='\n",
    "            # Fill values that are not in the lut with 'Not Available'.\n",
    "            tfm.dfs[grp].loc[~tfm.dfs[grp][\"detection_limit\"].isin(list(lut.keys())), \"detection_limit\"] = 'Not Available'\n",
    "            # Perform lookup\n",
    "            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp]['detection_limit'].apply(lambda x: lut[x])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66db5cf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()` and `LookupDetectionLimitCB`. Then, print the unique `detection_limit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB()])\n",
    "\n",
    "print(tfm()['seawater']['detection_limit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb3b44",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9114d",
   "metadata": {},
   "source": [
    "#### Lookup : METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef2b9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *NetCDF4 format variables: ``counting_method``, ``sampling_method`` and ``preparation_method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200156a7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sampling method``,\t``Preparation method`` and ``Counting method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4052e59",
   "metadata": {},
   "source": [
    "> 'Method' is provided in the HELCOM data but some work is required to link it to MARIS 'counting_method', 'sampling_method' and 'preparation_method'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084de15c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "#### Data provider sample id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7b8a4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``data_provider_sample_id``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018492bf",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3238f",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format for variable type ``data_provider_sample_id`` does not support vlen strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemampDataProviderSampleIdCB(Callback):\n",
    "    \"Remamp key to MARIS data_provider_sample_id format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # data_provider_sample_id\n",
    "            tfm.dfs[grp]['data_provider_sample_id'] = tfm.dfs[grp]['KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WKRIL2012003' 'WKRIL2012004' 'WKRIL2012005' ... 'WSSSM2018006'\n",
      " 'WSSSM2018007' 'WSSSM2018008']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemampDataProviderSampleIdCB()])\n",
    "\n",
    "print(tfm()['seawater']['data_provider_sample_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf5780",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "#### Lookup : FILT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c3ba",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13e4ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84079a35",
   "metadata": {},
   "source": [
    "`get_filtered_lut` reads the file at `filtered_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ceab5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_filtered_lut():\n",
    "    df = pd.read_excel(filtered_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70453b9",
   "metadata": {},
   "source": [
    "Create  `renaming_rules` to rename the HELCOM data to the MARIS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2d1c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_rules = {'N': 'No',\n",
    "                  'n': 'No',\n",
    "                  'F': 'Yes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`LookupFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupFiltCB(Callback):\n",
    "    \"Remamp value type to MARIS format.\"\n",
    "    def __init__(self ,\n",
    "                 rules=renaming_rules,\n",
    "                 fn_lut=get_filtered_lut\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        rules = self.rules\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if \"FILT\" in tfm.dfs[grp].columns:\n",
    "                # Fill values that are not in the renaming rules with 'Not Available'.\n",
    "                tfm.dfs[grp].loc[~tfm.dfs[grp][\"FILT\"].isin(list(rules.keys())), \"FILT\"] = 'Not available'\n",
    "                # Rename HELCOM format with MARIS format. \n",
    "                tfm.dfs[grp]['FILT'] = tfm.dfs[grp]['FILT'].apply(lambda x : rules[x] if x != 'Not available' else 'Not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625063c",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()`,  `LookupDetectionLimitCB` and `LookupFiltCB()`. Then, print the unique `FILT` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not available' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemampDataProviderSampleIdCB(),\n",
    "                            LookupFiltCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['FILT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0502e9d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfe106",
   "metadata": {},
   "source": [
    "#### ~~Lookup : Area~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b0d3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``area``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e60cf4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Area is not included*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59862b",
   "metadata": {},
   "source": [
    "TODO : Write callback for area. Will I use the marineregions.org API to complete lookup? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5cfac24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#| export \\ndef get_area_lut():\\n    df = pd.read_excel(area_lut_path(), usecols=['displayName','areaId'])\\n    return df.set_index('displayName').to_dict()['areaId']\\n\""
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#| export \n",
    "def get_area_lut():\n",
    "    df = pd.read_excel(area_lut_path(), usecols=['displayName','areaId'])\n",
    "    return df.set_index('displayName').to_dict()['areaId']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81152cc4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85a9ac",
   "metadata": {},
   "source": [
    "### ~~Sample Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a021f2a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sample_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba363cb2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample notes\n",
    "``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a3e6",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``sample_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64d446",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247b50a",
   "metadata": {},
   "source": [
    "### ~~Measurement Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93974d7e",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``measurement_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819c1f2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Measurement notes``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d993a77",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``measurement_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d452362",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa59a",
   "metadata": {},
   "source": [
    "### Station ID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e08cc9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Station ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ba42",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Station ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c799173",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Station ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "768db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemampStationIdCB(Callback):\n",
    "    \"Remamp Station ID to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['station_id'] = tfm.dfs[grp]['STATION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "0ccb2604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RU10' 'RU11' 'RU19' 'RU20' 'RU23' 'RU25' 'RU32' 'RU52' 'RU89' 'RU94*'\n",
      " 'RU99' 'RU141' 'RU156' 'B6' 'B50' 'BY15' 'BY28' 'L6' 'L7' 'L8' 'LА-11'\n",
      " 'L13' 'Т1' 'RU5' 'B46' 'P16' 'Z1' 'SM1' 'SM2' 'SM5' 'P116' 'K11' 'P110'\n",
      " '2N2' 'ZN2' 'P14' 'P63' 'P140' 'P2' 'P3' 'P5' 'P39' 'B12' 'B13' 'B15'\n",
      " 'K3' 'M3' 'R4' 'P1' 'P40' 'A' 'GDR250' 'Z' 'K6' 'P127' 'P104' 'NP' '4P7'\n",
      " 'MW4' 'ZN4' 'EDC19' 'STOLGR' 'SCHLEI' 'KALKGR' 'KLBELT' 'KN' 'EDC20'\n",
      " 'GBELT2' 'EDC38' 'EDC42' 'EDC32' 'EDC46' 'EDC47' 'KATT1' 'EDC55' 'SOUNDA'\n",
      " 'SUND2' 'EDC58' 'ARKO1' 'BY2' 'EDC65' 'EDC68' 'GDR213' 'EDC80' 'EDC101'\n",
      " 'EDC88' '2' 'EDC73' 'BHOLM3' 'EDC63' '18' 'DARSS' 'KOTN11' 'KFOTN6'\n",
      " 'EDC35' 'EDC16' 'EDC7' 'EDC148' 'FBELT1' 'EDC92' '87/21' 'EDC70' 'EDC66'\n",
      " 'GDR109' 'GDR069' 'EDC18' 'EDC17' 'EDC39' 'ZZZ' 'EDC93' 'EDC81' 'GBELT1'\n",
      " 'EDC40' '8' 'EDC145' 'EDC36' '11' 'EDC54' 'EDC53' 'SUND4' 'SUND3' 'SUND1'\n",
      " 'BHOLM2' 'EDC75' '22' '29' 'EDC821' 'EDC82' 'EDC89' 'EDC98' 'EDC119'\n",
      " 'EDC114' '33' 'EDC96' 'EDC118' 'EDC109' '37' 'EDC100' '39' 'EDC84'\n",
      " 'EDC85' '42' 'EDC90' '45' 'EDC107' 'EDC120' '46' 'EDC134' '50' 'EDC136'\n",
      " '52' 'GA51' '54' 'EDC138' 'EDC140' '57' 'GA56' 'EDC124' 'EDC150' 'EDC149'\n",
      " 'EDC130' 'EDC126' 'EDC110' 'GA63' 'EDC122' 'EDC113' '68' 'TEILI1'\n",
      " 'EDC139' 'GA73' '74' 'EDC135' 'EDC125' 'EDC83' 'EDC23' '88' 'EDC78'\n",
      " 'EDC27' '91' 'EDC69' '93' 'BHOLM5' '95' 'ARKO2' 'EDC59' 'NEUBU' 'EDC15'\n",
      " 'ECKFBU' 'EDC24' 'KIBU1' 'KIBU2' 'FBELT2' 'EDC10' 'MEBU2' 'EDC11'\n",
      " 'HOWABU' 'EDC14' 'EDC146' 'EDC51' 'EDC74' 'EDC91' 'EDC94' 'EDC99' '63'\n",
      " 'EDC129' '48' '76' 'EDC142' '73' 'EDC137' 'EDC133' 'EDC131' '79' 'EDC29'\n",
      " '82' 'EDC28' 'EDC116' 'EDC121' '86' 'EDC106' 'EDC147' '102' 'L.MDGR'\n",
      " 'EDC52' 'EDC64' 'EDC48' 'EDC103' 'GDR245' 'EDC104' 'SR5' 'EDC115' 'BO3'\n",
      " 'LL7' 'EDC105' 'EDC45' 'EDC33' 'EDC34' 'EDC49' 'EDC57' 'EDC86' 'GDR284'\n",
      " 'EDC112' 'EDC117' 'EDC102' 'USSR50' 'GDR113' 'WGER031' 'EDC8' 'WGER030'\n",
      " 'EDC5' 'GDR160' 'EDC44' 'EDC43' 'EDC21' 'GDR023' 'ARKO3' 'EDC56' 'TROLGR'\n",
      " 'GBELT3' 'EDC41' 'EDC13' 'EDC37' 'EDC50' 'EDC3' 'EDC6' 'EDC22' 'WARNEM'\n",
      " 'MEBU1' 'ARKO4' 'USEDOM' 'EDC123' 'EDC127' 'EDC128' 'XV1' 'LL3A' 'EDC141'\n",
      " 'EDC30' 'EB1' 'LTKIEL' 'GTBEL3' 'BHOLM1' 'BHOLM4' 'EDC87' 'EDC97'\n",
      " 'EDC108' 'F81' 'EDC111' 'EDC95' 'EDC31' 'EDC79' 'EDC76' 'EDC77' 'EDC67'\n",
      " 'EDC62' 'LUEBU' 'WGER004' 'WGER047' 'WGER007' 'WGER059' 'BY31' 'WGER066'\n",
      " 'WGER068' 'WGER072' 'WGER077' 'WGER079' 'WGER081' 'WGER083' 'WGER089'\n",
      " 'WGER091' 'WGER086' 'WGER085' 'WGER078' 'WGER069' 'WGER065' 'WGER061'\n",
      " 'WGER058' 'WGER045' 'WGER041' 'WGER044' 'WGER039' 'WGER033' 'WGER032'\n",
      " 'WGER053' 'WGER075' 'WGER090' 'WGER095' 'WGER097' 'WGER099' 'WGER100'\n",
      " 'WGER098' 'WGER096' 'WGER092' 'WGER087' 'WGER084' 'WGER082' 'WGER080'\n",
      " 'WGER067' 'WGER070' 'WGER074' 'WGER071' 'WGER064' 'WGER038' 'WGER034'\n",
      " 'WGER036' 'WGER055' 'WGER054' 'WGER049' 'WGER048' 'WGER043' 'WGER037'\n",
      " 'PE' 'PW' 'EE22' 'N8' 'EE17' 'B18R' 'B12R' 'K' 'M' 'SW3' '46a' '65' 'LT4'\n",
      " 'LT7' '46A' 'LT10' 'LT12A' 'EDC132' 'USSR06' 'BY15B' 'USSR46' 'USSR03'\n",
      " 'USSR12' 'USSR13' 'USSR14' 'USSR15' 'USSR18' 'USSR19' 'EDC143' 'USSR05'\n",
      " 'USSR08' 'USSR24' 'EDC144' 'USSR10' 'USSR11' 'USSR27' 'USSR28' 'USSR32'\n",
      " 'USSRK1' 'USSRR1' 'USSRR6' 'USSR45' 'USSR25' 'USSR16' 'USSR22' 'USSR23'\n",
      " 'USSR31' 'USSR33' 'USSR34' 'USSR35' 'RU06' 'RU46' 'RU50' 'RU27' 'RU28'\n",
      " 'RU31' 'RU33' 'RU34' 'RU35' 'RU3' 'RU12' 'RU13' 'LV119' 'BMP61' '40A'\n",
      " '45A' '23' '24' 'Kullen' 'Hesselö' 'Kattegat SW' 'Asnaes rev'\n",
      " 'Halskov rev' 'Langeland belt' 'Femern belt' 'GEDSER ODDE' 'Möen'\n",
      " 'SOUND-S' 'SOUNDB' 'BORNHOLM' 'KLINT' 'Kattegat-413' 'GDR012' 'GDR030'\n",
      " 'GDR152' 'GDR162' 'GDR-OB' 'F64' 'US5B' 'BS' 'F2' 'LL11' 'GDR271'\n",
      " 'BCS315' 'GDR010' 'GNIBEN' 'S.MDGR' 'FLADEN' 'GF6' 'GDR046' 'GDR140'\n",
      " 'GDR355' 'GDR357' 'GDR350' 'GDR033' 'GDR041' 'GDR121' 'GDR200' 'GDR202'\n",
      " 'GDR220' 'GDR233' 'GDR260' 'GDR282' 'GDR285' '3' '25' '71' '00076A'\n",
      " 'GDR001' 'GDR034' 'GDR242' 'GDR253' 'GDR280' 'GDR302' 'KB' 'OLK2' 'LOV3'\n",
      " 'LOVR1' 'F75' 'CVI' 'W19A' 'LAV4' 'F16' 'LOV2' 'F45A' 'F45B' 'F44' 'F41'\n",
      " 'F40' 'LEDAM1' 'LL17' 'WGER040' 'WGER042' 'WGER003' 'WGER046' 'WGER062'\n",
      " 'WGER063' 'WGER057' 'OKG34' 'WGER035' 'WGER006' 'WGER056' 'WGER050'\n",
      " 'BODDEN' 'WGER001' 'WGER002' 'RUDEN' 'WGER052' 'WGER005' 'WGER051'\n",
      " 'WGER060' 'WGER073' 'WGER076' 'WGER094' 'WGER093' 'WGER088' 'KATT4' nan\n",
      " 'BHOLM1/B' 'KATT6' 'KATT5' 'LT46A' 'LT65' 'LK7' 'BY9' 'LV120'\n",
      " 'THE SOUND-S' 'The Sound-N A' '?7' 'KOTN12' 'DARSS2' 'N5' 'JML' 'LT7R'\n",
      " 'RU16' '45-A' 'RU102' 'RU150' 'RU307' 'RU310' 'RU311' 'Ru313' 'RU210'\n",
      " 'RU211' 'RU201' 'RU205' 'RU207' 'RU208' 'RU209' 'LT6' 'MYREFJ' 'SWR36'\n",
      " 'SWR35' 'SWF135' 'C14' 'A5' '23b' 'LOV02' 'ODER' 'EE38' 'EE23' 'LT 65'\n",
      " 'SWS36' 'SWF101' 'SWR3' 'SWS2' 'SWB2' 'OBANK' 'ADLERG' 'K4' 'BSH4A'\n",
      " 'LT6B' 'RU' 'The Sound-S' 'LT20' 'LT64A1' 'Asnæs Rev' 'Femern bælt '\n",
      " 'Gedser odde' 'Hesselø' 'Kattegat SW ' 'CV1' 'Langeland bælt' 'Møen'\n",
      " 'SW7' 'TROLGR16' 'WITTOW' 'LTKIEL2' 'P140 ' 'P2 ' 'P3 ' 'P5 ' 'P39 '\n",
      " 'B15 ' 'SW3 ' 'B13 ' 'K6 ' 'M3 ' 'P16 ' 'Ł7 ' 'ZN4 ' 'P1 ' 'P116 '\n",
      " 'P110 ' 'ZN2 ' 'LT64A2' 'BMPK4']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemampDataProviderSampleIdCB(),\n",
    "                            RemampStationIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['station_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548633f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb378b1",
   "metadata": {},
   "source": [
    "### Profile ID, Transect ID or Sequence ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23069215",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Profile ID, Transect ID or Sequence ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abe1c5",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Profile or transect ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a497c",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Profile ID, Transect ID or Sequence ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "433cdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapProfileIdCB(Callback):\n",
    "    \"Remamp Profile ID to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['profile_or_transect_id'] = tfm.dfs[grp]['SEQUENCE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "95f09821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2012003 2012004 2012005 ...  201806  201807  201808]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemampDataProviderSampleIdCB(),\n",
    "                            RemampStationIdCB(),\n",
    "                            RemapProfileIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['profile_or_transect_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "d6bc0f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.006000\n",
       "1        0.006000\n",
       "2        0.006000\n",
       "3        0.006000\n",
       "4        0.006000\n",
       "           ...   \n",
       "37342    0.006362\n",
       "37343    0.006362\n",
       "37344    0.006362\n",
       "37345    0.006362\n",
       "37346    0.006362\n",
       "Name: AREA, Length: 36606, dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['sediment']['AREA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb97f00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "### Sediment slice top and bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb47624",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Top and Bottom is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533568d8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Top`` and ``Bottom``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3358f02",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include sediment slice top and bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remamp Sediment slice top and bottom to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs['sediment']['bottom'] = tfm.dfs['sediment']['LOWSLI']\n",
    "        tfm.dfs['sediment']['top'] = tfm.dfs['sediment']['UPPSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15.0\n",
      "1    20.0\n",
      "2     0.0\n",
      "3     2.0\n",
      "4     4.0\n",
      "Name: top, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemampDataProviderSampleIdCB(),\n",
    "                            RemampStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['sediment']['top'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96b18f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e9e61",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "ad9a9aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
       "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
       "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
       "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
       "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
       "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
       "       'DATE_OF_ENTRY_y', 'time', 'species', 'body_part', 'bio_group', 'unit',\n",
       "       'detection_limit', 'data_provider_sample_id', 'station_id',\n",
       "       'profile_or_transect_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['biota'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "77f6872e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
       "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
       "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
       "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
       "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
       "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
       "       'DATE_OF_ENTRY_y', 'time', 'species', 'body_part', 'bio_group', 'unit',\n",
       "       'detection_limit', 'data_provider_sample_id', 'station_id',\n",
       "       'profile_or_transect_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['biota'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "e0a65efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y',\n",
       "       'time', 'sed_type', 'unit', 'detection_limit',\n",
       "       'data_provider_sample_id', 'station_id', 'profile_or_transect_id',\n",
       "       'bottom', 'top'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['sediment'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "c8f6f551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          RU10\n",
       "1          RU10\n",
       "2          RU11\n",
       "3          RU19\n",
       "4          RU19\n",
       "          ...  \n",
       "20313      ODER\n",
       "20314     OBANK\n",
       "20315    ADLERG\n",
       "20316     ARKO2\n",
       "20317     ARKO2\n",
       "Name: STATION, Length: 19824, dtype: object"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater']['STATION']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f6685",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "7c761563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uncertainty', 'detection_limit', 'volume', 'salinity', 'temperature', 'filtered', 'counting_method', 'sampling_method', 'preparation_method', 'unit'])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['suffixes'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "feb7e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sed_type'])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['sed'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "1a7d63f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bio_group', 'species', 'body_part'])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['bio'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "23653799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).+\n",
    "def get_renaming_rules():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    return {('seawater','biota', 'sediment') : {    \n",
    "                                                        ## DEFAULT\n",
    "                                                        'LATITUDE (dddddd)' : vars['defaults']['lat']['name'] ,\n",
    "                                                        'LONGITUDE (dddddd)' : vars['defaults']['lon']['name'] ,\n",
    "                                                        'time': vars['defaults']['time']['name'],\n",
    "                                                        'NUCLIDE': 'nuclide',\n",
    "                                                        'unit': vars['suffixes']['unit']['name'],\n",
    "                                                        'Station ID' : 'data_provider_station_id ',\n",
    "                                                        'Sample ID' : vars['defaults']['data_provider_sample_id']['name'],\n",
    "                                                        'Profile or transect ID' : 'profile_id',\n",
    "                                                        'detection_limit' : vars['suffixes']['detection_limit']['name']\n",
    "                                                        #'Sampling method' : 'Sampling method'\n",
    "                                                        #'Preparation method' : 'Preparation method'\n",
    "                                                        #'Counting method' : 'Counting method'\n",
    "                                                        #'Sample notes' : 'Sample notes'\n",
    "                                                        #'Measurement notes' : 'Measurement notes'\n",
    "                                                    },\n",
    "                  ('seawater',) : {\n",
    "                                ## SEAWATER\n",
    "                                'VALUE_Bq/m³': 'value',\n",
    "                                'ERROR%_m³': vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "                                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                                'SALIN' : vars['suffixes']['salinity']['name'],\n",
    "                                'TTEMP' :vars['suffixes']['temperature']['name'],\n",
    "                                'FILT' : vars['suffixes']['filtered']['name']\n",
    "                                },\n",
    "                  ('biota',) : { \n",
    "                                ## BIOTA\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%': vars['suffixes']['uncertainty']['name'],\n",
    "                                'Species' : vars['bio']['species']['name'],\n",
    "                                'Body part' : vars['bio']['body_part']['name'],\n",
    "                                'bio_group' : vars['bio']['bio_group']['name'],\n",
    "                                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                                #'WEIGHT': 'dry_weight' # assuming weight is 'fresh weight' \n",
    "                                HERE Working on evaluating weight\n",
    "                                Note that weight definiton might be different. \n",
    "                                \n",
    "                                },\n",
    "                  ('sediment',) : {\n",
    "                                ## SEDIMENT\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%_kg': vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "                                'sed_type': vars['sed']['sed_type']['name'],\n",
    "                                'top' : 'top',\n",
    "                                'bottom' : 'bottom'\n",
    "                                }\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ee1762df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest by sample type\n",
    "coi_grp = {'seawater': ['NUCLIDE', 'VALUE_Bq/m³', 'ERROR%_m³', 'time',\n",
    "                        'TDEPTH', 'SDEPTH', 'LATITUDE (dddddd)', 'LONGITUDE (dddddd)','unit', 'SALIN', 'TTEMP'],\n",
    "           'sediment': ['NUCLIDE', 'VALUE_Bq/kg', 'ERROR%_kg', 'time',\n",
    "                        'TDEPTH', 'LATITUDE (dddddd)', 'LONGITUDE (dddddd)',\n",
    "                        'sed_type','unit'],\n",
    "           'biota': ['NUCLIDE', 'VALUE_Bq/kg', 'ERROR%', 'time',\n",
    "                     'SDEPTH', 'LATITUDE ddmmmm', 'LONGITUDE ddmmmm',\n",
    "                     'species', 'body_part','unit', 'bio_group']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "8eb4fd2f-dc43-4266-a09b-babad4453249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_renaming_rules():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    # Define column names renaming rules\n",
    "    return {\n",
    "        'NUCLIDE': 'nuclide',\n",
    "        'VALUE_Bq/m³': 'value',\n",
    "        'VALUE_Bq/kg': 'value',\n",
    "        'ERROR%_m³': vars['suffixes']['uncertainty']['name'],\n",
    "        'ERROR%_kg': vars['suffixes']['uncertainty']['name'],\n",
    "        'ERROR%': vars['suffixes']['uncertainty']['name'],\n",
    "        'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "        'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "        'LATITUDE (dddddd)': vars['defaults']['lat']['name'],\n",
    "        'LATITUDE ddmmmm': vars['defaults']['lat']['name'],\n",
    "        'LONGITUDE (dddddd)': vars['defaults']['lon']['name'],\n",
    "        'LONGITUDE ddmmmm': vars['defaults']['lon']['name'],\n",
    "        'SALIN': vars['suffixes']['salinity']['name'],\n",
    "        'TTEMP': vars['suffixes']['temperature']['name'],\n",
    "        'unit': vars['suffixes']['unit']['name']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "bb1091d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define column names renaming rules\n",
    "#renaming_rules = {\n",
    "#    'NUCLIDE': 'nuclide',\n",
    "#    'VALUE_Bq/m³': 'value',\n",
    "#    'VALUE_Bq/kg': 'value',\n",
    "#    'ERROR%_m³': vars['suffixes']['uncertainty']['name'],\n",
    "#    'ERROR%_kg': vars['suffixes']['uncertainty']['name'],\n",
    "#    #'ERROR%': 'vars['suffixes']['uncertainty']['name'],\n",
    "#    'SDEPTH': vars['defaults']['depth']['name'],\n",
    "#    'LATITUDE (dddddd)': vars['defaults']['lat']['name'],\n",
    "#    'LATITUDE ddmmmm': vars['defaults']['lat']['name'],\n",
    "#    'LONGITUDE (dddddd)': vars['defaults']['lon']['name'],\n",
    "#    'LONGITUDE ddmmmm': vars['defaults']['lon']['name'],\n",
    "#    'SALIN': vars['suffixes']['salinity']['name'],\n",
    "#    'TTEMP': vars['suffixes']['temperature']['name'],\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "e41f13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RenameColumnCB(Callback):\n",
    "    def __init__(self,\n",
    "                 coi,\n",
    "                 fn_renaming_rules,\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            # Select cols of interest\n",
    "            tfm.dfs[k] = tfm.dfs[k].loc[:, self.coi[k]]\n",
    "\n",
    "            # Rename cols\n",
    "            tfm.dfs[k].rename(columns=self.fn_renaming_rules(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "9a4a8682-672f-4188-9091-821b727b4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nuclide  value  _unc       time  tot_depth  smp_depth      lat      lon  \\\n",
      "0   cs137    5.3  32.0 2012-05-23        NaN        0.0  60.0833  29.3333   \n",
      "1   cs137   19.9  20.0 2012-05-23        NaN       29.0  60.0833  29.3333   \n",
      "2   cs137   25.5  20.0 2012-06-17        NaN        0.0  59.4333  23.1500   \n",
      "3   cs137   17.0  29.0 2012-05-24        NaN        0.0  60.2500  27.9833   \n",
      "4   cs137   22.2  18.0 2012-05-24        NaN       39.0  60.2500  27.9833   \n",
      "\n",
      "   _unit  _sal  _temp  \n",
      "0      1   NaN    NaN  \n",
      "1      1   NaN    NaN  \n",
      "2      1   NaN    NaN  \n",
      "3      1   NaN    NaN  \n",
      "4      1   NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f7682",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f85a8d",
   "metadata": {},
   "source": [
    "### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a982a",
   "metadata": {},
   "source": [
    "*NetCDF4 variables: lon, lat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "0bfdf35d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/mariscoDev/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lon'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[482], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m dfs \u001b[38;5;241m=\u001b[39m load_data(fname_in)\n\u001b[1;32m      3\u001b[0m tfm \u001b[38;5;241m=\u001b[39m Transformer(dfs, cbs\u001b[38;5;241m=\u001b[39m[LowerStripRdnNameCB(),\n\u001b[1;32m      4\u001b[0m                             RemapRdnNameCB(),\n\u001b[1;32m      5\u001b[0m                             ParseTimeCB(),\n\u001b[1;32m      6\u001b[0m                             EncodeTimeCB(cfg()),                             \n\u001b[1;32m      7\u001b[0m                             SanitizeLonLatCB()\n\u001b[1;32m      8\u001b[0m                             ])\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiota\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/downloads/marisco/marisco/callbacks.py:50\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfs\n",
      "File \u001b[0;32m~/downloads/marisco/marisco/callbacks.py:41\u001b[0m, in \u001b[0;36mTransformer.callback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mrun_cbs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/downloads/marisco/marisco/callbacks.py:22\u001b[0m, in \u001b[0;36mrun_cbs\u001b[0;34m(cbs, obj)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(cbs, key\u001b[38;5;241m=\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m: obj\u001b[38;5;241m.\u001b[39mlogs\u001b[38;5;241m.\u001b[39mappend(cb\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/downloads/marisco/marisco/callbacks.py:84\u001b[0m, in \u001b[0;36mSanitizeLonLatCB.__call__\u001b[0;34m(self, tfm)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grp, df \u001b[38;5;129;01min\u001b[39;00m tfm\u001b[38;5;241m.\u001b[39mdfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Convert `,` separator to `.` separator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 84\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     85\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# mask zero values\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/mariscoDev/lib/python3.9/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/mambaforge/envs/mariscoDev/lib/python3.9/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lon'"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            SanitizeLonLatCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5465a4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7efe2d",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ee54c-19aa-4f21-b2a7-8f3f182f3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns='nuclide', values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        \n",
    "        df.reset_index(names='sample', inplace=True)\n",
    "        \n",
    "        idx = list(set(df.columns) - set([self.columns] + derived_coi + self.values))\n",
    "        return df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k] = self.pivot(tfm.dfs[k])\n",
    "            tfm.dfs[k].columns = self.renamed_cols(tfm.dfs[k].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lon       time  species  body_part  bio_group  sample    lat  smp_depth  \\\n",
      "0   9.41 2011-12-11       50         52          4     192  54.31        2.0   \n",
      "1   9.41 2011-12-11       50         52          4     193  54.31        2.0   \n",
      "2   9.41 2011-12-11       50         52          4     194  54.31        2.0   \n",
      "3   9.41 2011-12-11       50         52          4     195  54.31        2.0   \n",
      "4  10.00 2011-12-13       99         52          4     184  54.45        4.0   \n",
      "\n",
      "   ac228_unc  ag108m_unc  ...  sr89  sr90  tc99  te129m  th228  th232  tl208  \\\n",
      "0        NaN         NaN  ...   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
      "1        NaN         NaN  ...   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
      "2        NaN         NaN  ...   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
      "3        NaN         NaN  ...   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
      "4        NaN         NaN  ...   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
      "\n",
      "   u235  zn65  zr95  \n",
      "0   NaN   NaN   NaN  \n",
      "1   NaN   NaN   NaN  \n",
      "2   NaN   NaN   NaN  \n",
      "3   NaN   NaN   NaN  \n",
      "4   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 160 columns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                            ReshapeLongToWide()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Convert nuclide names to lowercase & strip any trailing space(s)',\n",
       " 'Remap to MARIS radionuclide names.',\n",
       " '\\n    Biota species remapped to MARIS db:\\n        CARD EDU: Cerastoderma edule\\n        LAMI SAC: Saccharina latissima\\n        PSET MAX: Scophthalmus maximus\\n        STIZ LUC: Sander luciopercas\\n    ',\n",
       " \"\\n    Update bodypart id based on MARIS dbo_bodypar.xlsx:\\n        - 3: 'Whole animal eviscerated without head',\\n        - 12: 'Viscera',\\n        - 8: 'Skin'\\n    \",\n",
       " \"\\n    Update sediment id  based on MARIS dbo_sedtype.xlsx\\n        -99: '(Not available)'\\n        - na: '(Not available)'\\n        - 56: '(Not available)'\\n        - 73: '(Not available)'\\n    \",\n",
       " '\\n    Update biogroup id  based on MARIS dbo_species.xlsx\\n    ',\n",
       " 'Convert data from long to wide with renamed columns.',\n",
       " 'Encode time as `int` representing seconds since xxx',\n",
       " 'Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                            ReshapeLongToWide(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            SanitizeLonLatCB()\n",
    "                            ])\n",
    "\n",
    "# Transform\n",
    "tfm()\n",
    "\n",
    "# Check transformation logs\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.1667',\n",
       " 'geospatial_lat_max': '65.6347',\n",
       " 'geospatial_lon_min': '9.41',\n",
       " 'geospatial_lon_max': '53.458',\n",
       " 'geospatial_bounds': 'POLYGON ((9.41 53.458, 31.1667 53.458, 31.1667 65.6347, 9.41 65.6347, 9.41 53.458))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2021-12-06T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert nuclide names to lowercase & strip any trailing space(s), Remap to MARIS radionuclide names., \\n    Biota species remapped to MARIS db:\\n        CARD EDU: Cerastoderma edule\\n        LAMI SAC: Saccharina latissima\\n        PSET MAX: Scophthalmus maximus\\n        STIZ LUC: Sander luciopercas\\n    , \\n    Update bodypart id based on MARIS dbo_bodypar.xlsx:\\n        - 3: 'Whole animal eviscerated without head',\\n        - 12: 'Viscera',\\n        - 8: 'Skin'\\n    , \\n    Update sediment id  based on MARIS dbo_sedtype.xlsx\\n        -99: '(Not available)'\\n        - na: '(Not available)'\\n        - 56: '(Not available)'\\n        - 73: '(Not available)'\\n    , \\n    Update biogroup id  based on MARIS dbo_species.xlsx\\n    , Convert data from long to wide with renamed columns., Encode time as `int` representing seconds since xxx, Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ebcce-b8c8-4963-8c1c-f32e820f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupUnitCB(),\n",
    "                                RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                                ReshapeLongToWide(),\n",
    "                                EncodeTimeCB(cfg()),                    \n",
    "                                SanitizeLonLatCB()\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, fname_out, nc_tpl_path(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33549327",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e715e",
   "metadata": {},
   "source": [
    "TODO : METHOD, FILT (seawater)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0be1f5",
   "metadata": {},
   "source": [
    "TODO : Do we want to include laboratory code in NetCDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546b95b",
   "metadata": {},
   "source": [
    "TODO: Should we rename the columns as soon as we can? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "> Data pipeline (handler) to convert HELCOM data ([source](https://helcom.fi/about-us)) to `NetCDF` format or `Open Refine` format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b3aaf",
   "metadata": {},
   "source": [
    "## Processing HELCOM MORS Environment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5eece",
   "metadata": {},
   "source": [
    "<!-- ## HELCOM MORS Environment database -->\n",
    "\n",
    "[Helcom MORS data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "Example steps:\n",
    "1. Download data (e.g. https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24). \n",
    "2. Install mdbtools via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In VS code terminal, navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip MORS_ENVIRONMENT.zip \n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run preprocess.sh to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ````\n",
    "7. Content of 'preprocess.sh' script.\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple\n",
    "from math import modf\n",
    "from collections import OrderedDict\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, match_maris_lut, Match)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, \n",
    "                               SanitizeLonLatCB, ReshapeLongToWide, CompareDfsAndTfmCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, \n",
    "                              TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (nuc_lut_path, nc_tpl_path, cfg, cache_path, \n",
    "                             cdl_cfg, Enums, lut_path, species_lut_path, \n",
    "                             sediments_lut_path, bodyparts_lut_path, \n",
    "                             detection_limit_lut_path, filtered_lut_path, area_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder,  OpenRefineCsvEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration and file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **fname_in**: path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_csv**: path and filename for the Open Refine csv output.The path can be defined as a relative path.\n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "- **ref_id**: refers to the location in Archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "fname_out_csv = '../../_data/output/100-HELCOM-MORS-2024.csv'\n",
    "zotero_key ='26VMZZ2Q'\n",
    "ref_id = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd04abcd",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e791e6",
   "metadata": {},
   "source": [
    "Load HELCOM data and return the data in a Python dictionary of dataframes with the dictionary key as the sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bafa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = [('SEA', 'seawater'), ('SED', 'sediment'), ('BIO', 'biota')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir: str | Path, # The directory where the source CSV files are located\n",
    "              smp_types: List = default_smp_types # A list of tuples, each containing the file prefix and the corresponding sample type name\n",
    "             ) -> Dict[str, pd.DataFrame]: # A dictionary with sample types as keys and their corresponding dataframes as values\n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df_meas = pd.read_csv(src_path / f'{file_prefix}02.csv')\n",
    "            df_smp = pd.read_csv(src_path / f'{file_prefix}01.csv')\n",
    "            return pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files for {file_prefix}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if files are not found\n",
    "    \n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e534545",
   "metadata": {},
   "source": [
    "## Transformation pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['seawater', 'sediment', 'biota'])\n",
      "Seawater cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Sediment cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Biota cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print(dfs.keys())\n",
    "print(f\"Seawater cols: {dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785805a",
   "metadata": {},
   "source": [
    "Show the structure of the `seawater` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9aeb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "0  08/20/14 00:00:00     90.0       KRIL  2012003.0  ...              29.20   \n",
       "1  08/20/14 00:00:00     90.0       KRIL  2012004.0  ...              29.20   \n",
       "2  08/20/14 00:00:00     90.0       KRIL  2012005.0  ...              23.09   \n",
       "3  08/20/14 00:00:00     90.0       KRIL  2012006.0  ...              27.59   \n",
       "4  08/20/14 00:00:00     90.0       KRIL  2012007.0  ...              27.59   \n",
       "\n",
       "   LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "0             29.3333     NaN     0.0   NaN    NaN   NaN           11.0   \n",
       "1             29.3333     NaN    29.0   NaN    NaN   NaN           11.0   \n",
       "2             23.1500     NaN     0.0   NaN    NaN   NaN           11.0   \n",
       "3             27.9833     NaN     0.0   NaN    NaN   NaN           11.0   \n",
       "4             27.9833     NaN    39.0   NaN    NaN   NaN           11.0   \n",
       "\n",
       "   HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0             11.0  08/20/14 00:00:00  \n",
       "1             11.0  08/20/14 00:00:00  \n",
       "2              3.0  08/20/14 00:00:00  \n",
       "3             11.0  08/20/14 00:00:00  \n",
       "4             11.0  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423d697",
   "metadata": {},
   "source": [
    "Show the structure of the `biota` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac781a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>BIOTATYPE</th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>NO</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>135.300000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CO60</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS137</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>4.338000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BVTIG2012040</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.9</td>\n",
       "      <td>964.0</td>\n",
       "      <td>18.458</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY   NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "0  BVTIG2012041  CS134     VTIG01             <     0.010140     W     NaN   \n",
       "1  BVTIG2012041  K40       VTIG01                 135.300000     W    3.57   \n",
       "2  BVTIG2012041  CO60      VTIG01             <     0.013980     W     NaN   \n",
       "3  BVTIG2012041  CS137     VTIG01                   4.338000     W    3.48   \n",
       "4  BVTIG2012040  CS134     VTIG01             <     0.009614     W     NaN   \n",
       "\n",
       "   NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE    NO  LENGTH  \\\n",
       "0     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "1     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "2     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "3     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "4     NaN  02/27/14 00:00:00      6.0  ...         F       5  17.0    45.9   \n",
       "\n",
       "   WEIGHT     DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0   948.0  18.453  92.9            2.0               16  02/27/14 00:00:00  \n",
       "1   948.0  18.453  92.9            2.0               16  02/27/14 00:00:00  \n",
       "2   948.0  18.453  92.9            2.0               16  02/27/14 00:00:00  \n",
       "3   948.0  18.453  92.9            2.0               16  02/27/14 00:00:00  \n",
       "4   964.0  18.458  92.9            2.0               16  02/27/14 00:00:00  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['biota'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840141d5",
   "metadata": {},
   "source": [
    "Show the structure of the `sediment` dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6013611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0  SKRIL2012048   RA226    NaN           NaN         35.0       26.0   \n",
       "1  SKRIL2012049   RA226    NaN           NaN         36.0       22.0   \n",
       "2  SKRIL2012050   RA226    NaN           NaN         38.0       24.0   \n",
       "3  SKRIL2012051   RA226    NaN           NaN         36.0       25.0   \n",
       "4  SKRIL2012052   RA226    NaN           NaN         30.0       23.0   \n",
       "\n",
       "  < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00  ...    20.0   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00  ...    27.0   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00  ...     2.0   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00  ...     4.0   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00  ...     6.0   \n",
       "\n",
       "    AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "0  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "1  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "2  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "3  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "4  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "\n",
       "     DATE_OF_ENTRY_y  \n",
       "0  08/20/14 00:00:00  \n",
       "1  08/20/14 00:00:00  \n",
       "2  08/20/14 00:00:00  \n",
       "3  08/20/14 00:00:00  \n",
       "4  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['sediment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687eade",
   "metadata": {},
   "source": [
    "### Define Sample Type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9e22e",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Included as netcdf.group*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e110b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``type``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "type_lut = {\n",
    "    'SEAWATER' : 1,\n",
    "    'BIOTA' : 2,\n",
    "    'SEDIMENT' : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class GetSampleTypeCB(Callback):\n",
    "    def __init__(self, type_lut: Dict[str, int]):\n",
    "        \"Set the sample type column in the DataFrames based on a lookup table.\"\n",
    "        self.type_lut = type_lut\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Apply the sample type lookup to DataFrames in the transformer.\"\n",
    "        for key, df in tfm.dfs.items():\n",
    "            df['samptype_id'] = self._get_sample_type(key)\n",
    "\n",
    "    def _get_sample_type(self, group_name: str) -> int:\n",
    "        \"Determine the sample type for a given group name using the lookup table.\"\n",
    "        return self.type_lut.get(group_name.upper(), 0)  # Default to 0 if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb34f6",
   "metadata": {},
   "source": [
    "Here we call a transformer, which applies the callback (e.g. `GetSampleTypeCB`) to the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
      "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
      "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
      "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
      "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
      "\n",
      "     DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ... LONGITUDE (dddddd)  \\\n",
      "0  08/20/14 00:00:00     90.0       KRIL  2012003.0  ...            29.3333   \n",
      "1  08/20/14 00:00:00     90.0       KRIL  2012004.0  ...            29.3333   \n",
      "2  08/20/14 00:00:00     90.0       KRIL  2012005.0  ...            23.1500   \n",
      "3  08/20/14 00:00:00     90.0       KRIL  2012006.0  ...            27.9833   \n",
      "4  08/20/14 00:00:00     90.0       KRIL  2012007.0  ...            27.9833   \n",
      "\n",
      "   TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
      "0     NaN     0.0    NaN   NaN   NaN           11.0             11.0   \n",
      "1     NaN    29.0    NaN   NaN   NaN           11.0             11.0   \n",
      "2     NaN     0.0    NaN   NaN   NaN           11.0              3.0   \n",
      "3     NaN     0.0    NaN   NaN   NaN           11.0             11.0   \n",
      "4     NaN    39.0    NaN   NaN   NaN           11.0             11.0   \n",
      "\n",
      "     DATE_OF_ENTRY_y  samptype_id  \n",
      "0  08/20/14 00:00:00            1  \n",
      "1  08/20/14 00:00:00            1  \n",
      "2  08/20/14 00:00:00            1  \n",
      "3  08/20/14 00:00:00            1  \n",
      "4  08/20/14 00:00:00            1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[GetSampleTypeCB(type_lut),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater'].head())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b690d9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``nuclide``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b23c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``nuclide_id``.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "#### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "Create a callback function, `LowerStripRdnNameCB`, that receives a dictionary of dataframes. For each dataframe in the dictionary, it converts the contents of the `Nuclides` column to lowercase and removes any leading or trailing whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LowerStripRdnNameCB(Callback):\n",
    "    \"Convert nuclide names to lowercase and strip any trailing spaces.\"\n",
    "    def __call__(self, tfm):\n",
    "        for key in tfm.dfs.keys():\n",
    "            self._process_nuclide_column(tfm.dfs[key])\n",
    "\n",
    "    def _process_nuclide_column(self, df):\n",
    "        \"Apply transformation to the 'NUCLIDE' column of the given DataFrame.\"\n",
    "        df['NUCLIDE'] = df['NUCLIDE'].apply(self._transform_nuclide)\n",
    "\n",
    "    def _transform_nuclide(self, nuclide):\n",
    "        \"Convert nuclide name to lowercase and strip trailing spaces.\"\n",
    "        return nuclide.lower().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb73d9",
   "metadata": {},
   "source": [
    "Here we call a transformer, which applies the callback (e.g. `LowerStripRdnNameCB`) to the dictionary of dataframes, `dfs`. We then print the unique entries of the transformed `NUCLIDE` column for each dataframe included in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB()])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm()['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "#### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9905c7",
   "metadata": {},
   "source": [
    "The `maris-template.nc` file, which  is created from the `cdl.toml` on installation of the Marisco package, provides details of the nuclides permitted in the  MARIS NetCDF file. Here we define a function  `get_unique_nuclides()` which creates a list of the unique nuclides from each dataframe in the dictionary of dataframes `dfs`. The function `has_valid_varname` checks that each nuclide in this list is included in the `maris-template.nc` (i.e. the `cdl.toml`). `has_valid_varname` returns all variables in the list that are not in the `maris-template.nc` or returns `True`. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686a0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.2000</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.2000</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0900</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5900</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5900</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21211</th>\n",
       "      <td>WSSSM2021005</td>\n",
       "      <td>H3</td>\n",
       "      <td>SSM45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>93.203883</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>202105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2143</td>\n",
       "      <td>18.3572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21212</th>\n",
       "      <td>WSSSM2021006</td>\n",
       "      <td>H3</td>\n",
       "      <td>SSM45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>43.303571</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>202106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21213</th>\n",
       "      <td>WSSSM2021007</td>\n",
       "      <td>H3</td>\n",
       "      <td>SSM45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>47.087379</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>202107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5671</td>\n",
       "      <td>11.9452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21214</th>\n",
       "      <td>WSSSM2021008</td>\n",
       "      <td>H3</td>\n",
       "      <td>SSM45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>202108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5671</td>\n",
       "      <td>11.9452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21215</th>\n",
       "      <td>WSSSM2021004</td>\n",
       "      <td>H3</td>\n",
       "      <td>SSM45</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>202104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1470</td>\n",
       "      <td>11.2450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21216 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0      WKRIL2012003   CS137    NaN           NaN          5.3  32.000000   \n",
       "1      WKRIL2012004   CS137    NaN           NaN         19.9  20.000000   \n",
       "2      WKRIL2012005   CS137    NaN           NaN         25.5  20.000000   \n",
       "3      WKRIL2012006   CS137    NaN           NaN         17.0  29.000000   \n",
       "4      WKRIL2012007   CS137    NaN           NaN         22.2  18.000000   \n",
       "...             ...     ...    ...           ...          ...        ...   \n",
       "21211  WSSSM2021005      H3  SSM45           NaN       1030.0  93.203883   \n",
       "21212  WSSSM2021006      H3  SSM45           NaN       2240.0  43.303571   \n",
       "21213  WSSSM2021007      H3  SSM45           NaN       2060.0  47.087379   \n",
       "21214  WSSSM2021008      H3  SSM45           NaN       2300.0  43.478261   \n",
       "21215  WSSSM2021004      H3  SSM45             <          NaN        NaN   \n",
       "\n",
       "         DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ...  \\\n",
       "0      08/20/14 00:00:00     90.0       KRIL  2012003.0  ...   \n",
       "1      08/20/14 00:00:00     90.0       KRIL  2012004.0  ...   \n",
       "2      08/20/14 00:00:00     90.0       KRIL  2012005.0  ...   \n",
       "3      08/20/14 00:00:00     90.0       KRIL  2012006.0  ...   \n",
       "4      08/20/14 00:00:00     90.0       KRIL  2012007.0  ...   \n",
       "...                  ...      ...        ...        ...  ...   \n",
       "21211  09/06/22 00:00:00     77.0       SSSM   202105.0  ...   \n",
       "21212  09/06/22 00:00:00     77.0       SSSM   202106.0  ...   \n",
       "21213  09/06/22 00:00:00     77.0       SSSM   202107.0  ...   \n",
       "21214  09/06/22 00:00:00     77.0       SSSM   202108.0  ...   \n",
       "21215  09/06/22 00:00:00     77.0       SSSM   202104.0  ...   \n",
       "\n",
       "      LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
       "0                29.2000             29.3333     NaN     0.0   NaN    NaN   \n",
       "1                29.2000             29.3333     NaN    29.0   NaN    NaN   \n",
       "2                23.0900             23.1500     NaN     0.0   NaN    NaN   \n",
       "3                27.5900             27.9833     NaN     0.0   NaN    NaN   \n",
       "4                27.5900             27.9833     NaN    39.0   NaN    NaN   \n",
       "...                  ...                 ...     ...     ...   ...    ...   \n",
       "21211            18.2143             18.3572     NaN     1.0   NaN    NaN   \n",
       "21212            17.0000             17.0000     NaN     1.0   NaN    NaN   \n",
       "21213            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       "21214            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       "21215            11.1470             11.2450     NaN     1.0   NaN    NaN   \n",
       "\n",
       "       FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       "1       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       "2       NaN           11.0              3.0  08/20/14 00:00:00  \n",
       "3       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       "4       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       "...     ...            ...              ...                ...  \n",
       "21211     N            1.0              8.0  09/06/22 00:00:00  \n",
       "21212     N           10.0             10.0  09/06/22 00:00:00  \n",
       "21213     N           12.0             12.0  09/06/22 00:00:00  \n",
       "21214     N           12.0             12.0  09/06/22 00:00:00  \n",
       "21215     N           15.0             18.0  09/06/22 00:00:00  \n",
       "\n",
       "[21216 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['seawater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd798f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unique_nuclides(dfs: Dict[str, pd.DataFrame]) -> List[str]:\n",
    "    \"Get a list of unique radionuclide types measured across samples.\"\n",
    "    nuclides = set()\n",
    "    for df in dfs.values(): nuclides.update(df['NUCLIDE'].unique())\n",
    "    return list(nuclides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68dacd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cs139\" variable name not found in MARIS CDL\n",
      "\"cs134137\" variable name not found in MARIS CDL\n",
      "\"cs138\" variable name not found in MARIS CDL\n",
      "\"cs143\" variable name not found in MARIS CDL\n",
      "\"cs142\" variable name not found in MARIS CDL\n",
      "\"cs144\" variable name not found in MARIS CDL\n",
      "\"pu238240\" variable name not found in MARIS CDL\n",
      "\"pu239240\" variable name not found in MARIS CDL\n",
      "\"cs146\" variable name not found in MARIS CDL\n",
      "\"cs141\" variable name not found in MARIS CDL\n",
      "\"cm243244\" variable name not found in MARIS CDL\n",
      "\"k-40\" variable name not found in MARIS CDL\n",
      "\"cs145\" variable name not found in MARIS CDL\n",
      "\"cs140\" variable name not found in MARIS CDL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Check if these variable names are consistent with MARIS CDL\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501bd59",
   "metadata": {},
   "source": [
    "Many nuclide names are not listed in the `maris-template.nc`. Here we create a look up table, `varnames_lut_updates`, which will be used to correct the nuclide names in the dictionary of dataframes (i.e. dfs) that are not compatible with the `maris-template.nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "varnames_lut_updates = {\n",
    "    'k-40': 'k40',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs138': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs140': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs143': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs146': 'cs137'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b877d3d",
   "metadata": {},
   "source": [
    "Function `get_varnames_lut` returns a dictionary of nuclide names. This dictionary includes the `NUCLIDE` names from the dataframes in dfs, along with corrections specified in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f89931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_varnames_lut(\n",
    "    dfs:dict, # Data to transform\n",
    "    lut:dict=varnames_lut_updates # Lut to fix not found nuclide names\n",
    ") -> dict: \n",
    "    \"Generate a lookup table for radionuclide names, updating with provided mappings.\"\n",
    "    unique_nuclides = get_unique_nuclides(dfs)\n",
    "    base_lut = {name: name for name in unique_nuclides}\n",
    "    base_lut.update(lut)\n",
    "    return base_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad93425",
   "metadata": {},
   "source": [
    "The ``get_nuc_id_lut`` function creates a lookup table to map nuclide names to their IDs. In the MARIS Open Refine data format, each nuclide has a unique nuclide_id. This function reads an Excel file that lists nuclide names and their IDs, and then returns a dictionary. In this dictionary, the nuclide names are the keys, and their corresponding IDs are the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd062a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_nuc_id_lut():\n",
    "    df = pd.read_excel(nuc_lut_path(), usecols=['nc_name','nuclide_id'])\n",
    "    return df.set_index('nc_name').to_dict()['nuclide_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d2ea0",
   "metadata": {},
   "source": [
    "Create a callback that remaps the nuclide names in the dataframes to the updated names in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapRdnNameCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable=partial(get_varnames_lut, lut=varnames_lut_updates), # Function remapping radionuclide names\n",
    "                 nuc_id_lut:Callable=get_nuc_id_lut # Function that returns a lookup table for nuclide IDs\n",
    "                ):\n",
    "        \"Remap and standardize radionuclide names to MARIS radionuclide names and define nuclide ids.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Apply lookup tables to remap radionuclide names and obtain nuclide IDs in DataFrames.\"\n",
    "        lut = self.fn_lut(tfm.dfs)\n",
    "        nuc_id_lut = self.nuc_id_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._remap_nuclide_names(df, lut)\n",
    "            self._apply_nuclide_ids(df, nuc_id_lut)\n",
    "\n",
    "    def _remap_nuclide_names(self, \n",
    "                             df:pd.DataFrame, # DataFrame containing the 'NUCLIDE' column\n",
    "                             lut: Dict[str, str] # Lookup table for remapping radionuclide names\n",
    "                            ):\n",
    "        \"Remap radionuclide names in the 'NUCLIDE' column of the DataFrame using the provided lookup table.\"\n",
    "        if 'NUCLIDE' in df.columns:\n",
    "            df['NUCLIDE'] = df['NUCLIDE'].replace(lut)\n",
    "        else:\n",
    "            print(f\"No 'NUCLIDE' column found in DataFrame of group {df.name}\")\n",
    "\n",
    "    def _apply_nuclide_ids(self, \n",
    "                           df:pd.DataFrame, # DataFrame containing the `NUCLIDE` column\n",
    "                           nuc_id_lut:Dict[str, str] # Lookup table for nuclide IDs\n",
    "                          ):\n",
    "        \"Apply nuclide IDs to the 'NUCLIDE' column using the provided nuclide ID lookup table.\"\n",
    "        if 'NUCLIDE' in df.columns:\n",
    "            df['nuclide_id'] = df['NUCLIDE'].map(nuc_id_lut)\n",
    "        else:\n",
    "            print(f\"No 'NUCLIDE' column found in DataFrame of group {df.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa0d93",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB` and `RemapRdnNameCB`. Then, print the unique nuclides for each dataframe in the dictionary dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c075d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "          NUCLIDE  nuclide_id\n",
      "0           cs137          33\n",
      "1            sr90          12\n",
      "2              h3           1\n",
      "3           cs134          31\n",
      "4           pu238          67\n",
      "5   pu239_240_tot          77\n",
      "6           am241          72\n",
      "7           cm242          73\n",
      "8           cm244          75\n",
      "9            tc99          15\n",
      "10            k40           4\n",
      "11          ru103          16\n",
      "12           sr89          11\n",
      "13          sb125          24\n",
      "14           nb95          14\n",
      "15          ru106          17\n",
      "16           zr95          13\n",
      "17         ag110m          22\n",
      "18  cm243_244_tot          80\n",
      "19          ba140          34\n",
      "20          ce144          37\n",
      "21           u234          62\n",
      "22           u238          64\n",
      "23           co60           9\n",
      "24          pu239          68\n",
      "25          pb210          41\n",
      "26          po210          47\n",
      "27          np237          65\n",
      "28          pu240          69\n",
      "29           mn54           6\n",
      "biota nuclides: \n",
      "          NUCLIDE  nuclide_id\n",
      "0           cs134          31\n",
      "1             k40           4\n",
      "2            co60           9\n",
      "3           cs137          33\n",
      "4            sr90          12\n",
      "5          ag108m          21\n",
      "6            mn54           6\n",
      "7            co58           8\n",
      "8          ag110m          22\n",
      "9            zn65          10\n",
      "10          sb125          24\n",
      "11  pu239_240_tot          77\n",
      "12          ru106          17\n",
      "13            be7           2\n",
      "14          ce144          37\n",
      "15          pb210          41\n",
      "16          po210          47\n",
      "17          sb124          23\n",
      "18           sr89          11\n",
      "19           zr95          13\n",
      "20         te129m          25\n",
      "21          ru103          16\n",
      "22           nb95          14\n",
      "23          ce141          36\n",
      "24          la140          35\n",
      "25           i131          29\n",
      "26          ba140          34\n",
      "27          pu238          67\n",
      "28           u235          63\n",
      "29          bi214          46\n",
      "30          pb214          43\n",
      "31          pb212          42\n",
      "32          tl208          94\n",
      "33          ac228          55\n",
      "34          ra223          50\n",
      "35          eu155          40\n",
      "36          ra226          53\n",
      "37          gd153          87\n",
      "38          sn113          92\n",
      "39           fe59          86\n",
      "40           tc99          15\n",
      "41           co57           7\n",
      "42         sn117m          93\n",
      "43          eu152          85\n",
      "44           sc46          91\n",
      "45           rb86          90\n",
      "46          ra224          51\n",
      "47          th232          59\n",
      "48  cs134_137_tot          76\n",
      "49          am241          72\n",
      "50          ra228          54\n",
      "51          th228          57\n",
      "sediment nuclides: \n",
      "          NUCLIDE  nuclide_id\n",
      "0           ra226          53\n",
      "1           cs137          33\n",
      "2           ra228          54\n",
      "3             k40           4\n",
      "4            sr90          12\n",
      "5   cs134_137_tot          76\n",
      "6           cs134          31\n",
      "7   pu239_240_tot          77\n",
      "8           pu238          67\n",
      "9            co60           9\n",
      "10          ru103          16\n",
      "11          ru106          17\n",
      "12          sb125          24\n",
      "13         ag110m          22\n",
      "14          ce144          37\n",
      "15          am241          72\n",
      "16            be7           2\n",
      "17          th228          57\n",
      "18          pb210          41\n",
      "19           co58           8\n",
      "20           mn54           6\n",
      "21           zr95          13\n",
      "22          ba140          34\n",
      "23          po210          47\n",
      "24          ra224          51\n",
      "25           nb95          14\n",
      "26  pu238_240_tot          89\n",
      "27          pu241          70\n",
      "28          pu239          68\n",
      "29          eu155          40\n",
      "30          ir192          88\n",
      "31          th232          59\n",
      "32          cd109          84\n",
      "33          sb124          23\n",
      "34           zn65          10\n",
      "35          th234          60\n",
      "36          tl208          94\n",
      "37          pb212          42\n",
      "38          pb214          43\n",
      "39          bi214          46\n",
      "40          ac228          55\n",
      "41          ra223          50\n",
      "42           u235          63\n",
      "43          bi212         130\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            #CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "\n",
    "#print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('seawater nuclides: ')\n",
    "print(tfm.dfs['seawater'][['NUCLIDE', 'nuclide_id']].drop_duplicates().reset_index(drop=True))\n",
    "print('biota nuclides: ')\n",
    "print(tfm.dfs['biota'][['NUCLIDE', 'nuclide_id']].drop_duplicates().reset_index(drop=True))\n",
    "print('sediment nuclides: ')\n",
    "print(tfm.dfs['sediment'][['NUCLIDE', 'nuclide_id']].drop_duplicates().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9359a",
   "metadata": {},
   "source": [
    "After applying correction to the nuclide names we check that all nuclide in the dictionary of dataframes are valid. Returns `True` if all are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c644322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "### Standardize Time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "#### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23281e3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: `time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691210e1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Open Refine format variables: `begperiod` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83309a2",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04817201-8c26-43d3-a769-9fd83d72751c",
   "metadata": {},
   "source": [
    "**Comment (FA)**: Can be simplified I think (TBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    def __init__(self): \n",
    "        fc.store_attr()\n",
    "            \n",
    "    def __call__(self, \n",
    "                 tfm # The transformer object containing DataFrames\n",
    "                ):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            df = tfm.dfs[grp]\n",
    "            self._process_dates(df)\n",
    "            self._define_beg_period(df)\n",
    "\n",
    "    def _process_dates(self, \n",
    "                       df:pd.DataFrame # DataFrame containing the `DATE`, `YEAR`, `MONTH`, and `DAY` columns\n",
    "                      ):\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['time'] = pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S')\n",
    "        # if 'DATE' column is nan, get 'time' from 'YEAR','MONTH' and 'DAY' column. \n",
    "        # if 'DAY' or 'MONTH' is 0 then set it to 1. \n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        # if 'DAY' and 'MONTH' is nan but YEAR is not nan then set 'DAY' and 'MONTH' both to 1. \n",
    "        condition = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[condition, \"DAY\"] = 1\n",
    "        df.loc[condition, \"MONTH\"] = 1\n",
    "        \n",
    "        condition = df['DATE'].isna() # if 'DATE' is nan. \n",
    "        df['time']  = np.where(condition,\n",
    "                                            # 'coerce', then invalid parsing will be set as NaT. NaT will result if the number of days are not valid for the month.\n",
    "                                        pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']], format='%y%m%d', errors='coerce'),  \n",
    "                                        pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S'))\n",
    "        \n",
    "    def _define_beg_period(self, \n",
    "                           df: pd.DataFrame # DataFrame containing the `time` column\n",
    "                          ):\n",
    "        \"Create a standardized date representation for Open Refine.\"\n",
    "        df['begperiod'] = df['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the ``begperiod`` and `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "       begperiod       time\n",
      "0     2012-05-23 2012-05-23\n",
      "1     2012-05-23 2012-05-23\n",
      "2     2012-06-17 2012-06-17\n",
      "3     2012-05-24 2012-05-24\n",
      "4     2012-05-24 2012-05-24\n",
      "...          ...        ...\n",
      "21211 2021-10-15 2021-10-15\n",
      "21212 2021-11-04 2021-11-04\n",
      "21213 2021-10-15 2021-10-15\n",
      "21214 2021-05-17 2021-05-17\n",
      "21215 2021-05-13 2021-05-13\n",
      "\n",
      "[21216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['seawater'][['begperiod','time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "#### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2c925",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``time``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e7277",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: No encoding for Open Refine.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 of 21216 entries for `time` are invalid for seawater.\n",
      "1 of 39817 entries for `time` are invalid for sediment.\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg(), verbose = True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7099e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20563</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MONTH  DAY DATE\n",
       "20556   NaN    NaN  NaN  NaN\n",
       "20557   NaN    NaN  NaN  NaN\n",
       "20558   NaN    NaN  NaN  NaN\n",
       "20559   NaN    NaN  NaN  NaN\n",
       "20560   NaN    NaN  NaN  NaN\n",
       "20561   NaN    NaN  NaN  NaN\n",
       "20562   NaN    NaN  NaN  NaN\n",
       "20563   NaN    NaN  NaN  NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs_dropped['seawater'][['YEAR', 'MONTH', 'DAY', 'DATE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "### Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42f151",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``value``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e99464",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``activity``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_val = {'seawater' : {'val': 'VALUE_Bq/m³'},\n",
    "           'biota':  {'val': 'VALUE_Bq/kg'},\n",
    "           'sediment': {'val': 'VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c59ae1-c523-4aa6-bc04-e824390bf06d",
   "metadata": {},
   "source": [
    "**Comment (FA)**: Those lines can be simplified I think:\n",
    "```\n",
    "value_col = self.coi.get(grp, {}).get('val')\n",
    "if value_col and value_col in df.columns:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981121ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class SanitizeValue(Callback):\n",
    "    def __init__(self, \n",
    "                 coi:dict # Dictionary containing column names for values based on group\n",
    "                ):\n",
    "        \"Sanitize value by removing blank entries and ensuring the 'value' column is retained.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, \n",
    "                 tfm # The transformer object containing DataFrames\n",
    "                ):\n",
    "        \"Sanitize the DataFrames in the transformer by removing rows with blank values in specified columns.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._sanitize_dataframe(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _sanitize_dataframe(self, \n",
    "                            df:pd.DataFrame, # DataFrame to sanitize\n",
    "                            grp:str # Group name to determine column names\n",
    "                           ):\n",
    "        \"Remove rows where specified value columns are blank and ensure the 'value' column is included.\"\n",
    "        value_col = self.coi.get(grp, {}).get('val')\n",
    "        if value_col and value_col in df.columns:\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            # Ensure 'value' column is retained\n",
    "            if 'value' not in df.columns:\n",
    "                df['value'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21122     39532  15798\n",
      "Number of dropped rows                                    94       285     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "### Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12185ee",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``uncertainty``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b02a81",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Uncertainty`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df:pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col:str, # Name of the column with measurement values\n",
    "    unc_col:str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the uncertainty is given as a relative uncertainty. The column names for both the value and the uncertainty vary by sample type. The coi_units_unc dictionary defines the column names for the Value and Uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the uncertainty by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc:Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi:List=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        \"Convert from relative error % to uncertainty of activity unit.\"\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['uncertainty'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback NormalizeUncCB(). Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value  uncertainty\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        value  uncertainty\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   value  uncertainty\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                         \n",
    "                            NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val)])\n",
    "\n",
    "print(tfm()['seawater'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['biota'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['sediment'][['value', 'uncertainty']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "### Lookup transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f44637",
   "metadata": {},
   "source": [
    "#### Lookup MARIS function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6e294",
   "metadata": {},
   "source": [
    "`get_maris_lut` performs a lookup of data provided in `data_provider_lut` against the MARIS lookup (`maris_lut`) using a fuzzy matching algorithm based on Levenshtein distance. The `get_maris_lut` is used to correct the HELCOM data to a standard format for MARIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f0c03-7666-461d-a5ce-d0021bc9e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_maris_lut(fname_in, \n",
    "                  fname_cache, # For instance 'species_helcom.pkl'\n",
    "                  data_provider_lut: str, # Data provider lookup table name\n",
    "                  data_provider_id_col: str, # Data provider lookup column id of interest\n",
    "                  data_provider_name_col: str, # Data provider lookup column name of interest\n",
    "                  maris_lut: Callable, # Function retrieving MARIS source lookup table\n",
    "                  maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "                  maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "                  unmatched_fixes: dict = {},\n",
    "                  as_dataframe: bool = False,\n",
    "                  overwrite: bool = False\n",
    "                 ):\n",
    "    \"Try to match a look up table provided by the data provider with MARIS one.\"\n",
    "    cache_file = cache_path() / fname_cache\n",
    "    lut = {}\n",
    "    maris_lut = maris_lut()\n",
    "    df = pd.read_csv(Path(fname_in) / data_provider_lut)\n",
    "    \n",
    "    if overwrite or (not cache_file.exists()):\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
    "            # Fix if unmatched\n",
    "            has_to_be_fixed = row[data_provider_id_col] in unmatched_fixes            \n",
    "            name_to_match = unmatched_fixes[row[data_provider_id_col]] if has_to_be_fixed else row[data_provider_name_col]\n",
    "\n",
    "            # Match\n",
    "            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)\n",
    "            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], \n",
    "                          row[data_provider_name_col], result.iloc[0]['score'])\n",
    "            \n",
    "            lut[row[data_provider_id_col]] = match\n",
    "        \n",
    "        fc.save_pickle(cache_file, lut)\n",
    "    else:\n",
    "        lut = fc.load_pickle(cache_file)\n",
    "\n",
    "    if as_dataframe:\n",
    "        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()\n",
    "        df_lut.index.name = 'source_id'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)\n",
    "    else:\n",
    "        return lut\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5868c16b",
   "metadata": {},
   "source": [
    "#### Lookup : Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2bbb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``species``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19098ae",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Species`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40671f8f",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `RUBIN_NAME.csv` file for biota species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_rubin = pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')\n",
    "df_rubin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa8871",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_species` to correct the spelling of names that are unmatched in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acca89-169a-45eb-98fe-cf7c7b2ee0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "unmatched_fixes_biota_species = {\n",
    "    'CARD EDU': 'Cerastoderma edule',\n",
    "    'LAMI SAC': 'Saccharina latissima',\n",
    "    'PSET MAX': 'Scophthalmus maximus',\n",
    "    'STIZ LUC': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adaa417-6b01-45d8-80d7-2e3d97cb0f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 46/46 [00:06<00:00,  6.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "species_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='species_helcom.pkl', \n",
    "                               data_provider_lut='RUBIN_NAME.csv',\n",
    "                               data_provider_id_col='RUBIN',\n",
    "                               data_provider_name_col='SCIENTIFIC NAME',\n",
    "                               maris_lut=species_lut_path,\n",
    "                               maris_id='species_id',\n",
    "                               maris_name='species',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915a7fc",
   "metadata": {},
   "source": [
    "Display `species_lut_df`. The `match_score` represents the number insertions, deletions, or substitutions needed to transform from the HECOM source name (`source_name`) to the maris name, (`matched_maris_name`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341f814-3343-47b7-958c-5df7d34a683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABRA BRA</th>\n",
       "      <td>271</td>\n",
       "      <td>Abramis brama</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id   matched_maris_name              source_name match_score\n",
       "source_id                                                                     \n",
       "ENCH CIM         276        Echinodermata       ENCHINODERMATA CIM           5\n",
       "MACO BAL         122      Macoma balthica           MACOMA BALTICA           1\n",
       "STUC PEC         704  Stuckenia pectinata      STUCKENIA PECTINATE           1\n",
       "STIZ LUC         285    Sander lucioperca  STIZOSTEDION LUCIOPERCA           1\n",
       "ABRA BRA         271        Abramis brama            ABRAMIS BRAMA           0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "species_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557931bd",
   "metadata": {},
   "source": [
    "Show `species_lut_df` where `match_type` is not a perfect match ( i.e. not equal 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id   matched_maris_name              source_name match_score\n",
       "source_id                                                                     \n",
       "ENCH CIM         276        Echinodermata       ENCHINODERMATA CIM           5\n",
       "MACO BAL         122      Macoma balthica           MACOMA BALTICA           1\n",
       "STUC PEC         704  Stuckenia pectinata      STUCKENIA PECTINATE           1\n",
       "STIZ LUC         285    Sander lucioperca  STIZOSTEDION LUCIOPERCA           1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_lut_df[species_lut_df['match_score'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900eb6",
   "metadata": {},
   "source": [
    "`LookupBiotaSpeciesCB` applies the corrected `biota` `species` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2798566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupBiotaSpeciesCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Biota species standardized to MARIS format.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap biota species names in the DataFrame using the lookup table and print unmatched RUBIN values.\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: self._get_species(x, lut))\n",
    "\n",
    "    def _get_species(self, \n",
    "                     rubin_value:str, # The RUBIN value from the DataFrame\n",
    "                     lut:dict # The lookup table dictionary\n",
    "                    ):\n",
    "        \"Get the matched_id from the lookup table and print RUBIN if the matched_id is -1.\"\n",
    "        match = lut.get(rubin_value.strip(), Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self.print_unmatched_rubin(rubin_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_rubin(self, \n",
    "                              rubin_value: str # The RUBIN value from the DataFrame\n",
    "                             ):\n",
    "        \"Print the RUBIN value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched RUBIN: {rubin_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98d51",
   "metadata": {},
   "source": [
    "`get_maris_species` defines a partial function of `get_maris_lut`, with predefined arguments  for species lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddf185-8ee8-4cb0-abd6-427fe4e52c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "get_maris_species = partial(get_maris_lut,\n",
    "                            fname_in, fname_cache='species_helcom.pkl', \n",
    "                            data_provider_lut='RUBIN_NAME.csv',\n",
    "                            data_provider_id_col='RUBIN',\n",
    "                            data_provider_name_col='SCIENTIFIC NAME',\n",
    "                            maris_lut=species_lut_path,\n",
    "                            maris_id='species_id',\n",
    "                            maris_name='species',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18132f3",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `LookupBiotaSpeciesCB(get_maris_species)`. Then, print the unique `species` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ffe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524  703\n",
      " 1611  621   60]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                     \n",
    "                            LookupBiotaSpeciesCB(get_maris_species)\n",
    "                            ])\n",
    "\n",
    "#print(tfm()['biota'][['RUBIN', 'species']][:10])\n",
    "print(tfm()['biota']['species'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "#### Lookup : Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92384b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``body_part``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7388fd",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Body part`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31449525",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `TISSUE.csv` file for biota tissues. Biota tissue is known as `body part` in the maris data set.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6a4e9",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_tissues` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "unmatched_fixes_biota_tissues = {\n",
    "    3: 'Whole animal eviscerated without head',\n",
    "    12: 'Viscera',\n",
    "    8: 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a502e-3826-404c-84e1-0d60b4be0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 141.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "tissues_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='tissues_helcom.pkl', \n",
    "                               data_provider_lut='TISSUE.csv',\n",
    "                               data_provider_id_col='TISSUE',\n",
    "                               data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                               maris_lut=bodyparts_lut_path,\n",
    "                               maris_id='bodypar_id',\n",
    "                               maris_name='bodypar',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c1a7d-ba91-4400-ba0a-bad180eee1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id     matched_maris_name                   source_name  \\\n",
       "source_id                                                                   \n",
       "2                 52    Flesh without bones   WHOLE FISH WITHOUT ENTRAILS   \n",
       "5                 52    Flesh without bones  FLESH WITHOUT BONES (FILETS)   \n",
       "1                  1           Whole animal                    WHOLE FISH   \n",
       "15                53  Stomach and intestine           STOMACH + INTESTINE   \n",
       "41                 1           Whole animal                 WHOLE ANIMALS   \n",
       "\n",
       "          match_score  \n",
       "source_id              \n",
       "2                  13  \n",
       "5                   9  \n",
       "1                   5  \n",
       "15                  3  \n",
       "41                  1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissues_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811aa06",
   "metadata": {},
   "source": [
    "`LookupBiotaBodyPartCB` applies the corrected `biota` `TISSUE` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Update bodypart id based on MARIS body part LUT (dbo_bodypar.xlsx).\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap biota body parts in the DataFrame using the lookup table and print unmatched TISSUE values.\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: self._get_body_part(x, lut))\n",
    "\n",
    "    def _get_body_part(self, \n",
    "                       tissue_value:str, # The TISSUE value from the DataFrame\n",
    "                       lut:dict # The lookup table dictionary\n",
    "                      ):\n",
    "        \"Get the matched_id from the lookup table and print TISSUE if the matched_id is -1.\"\n",
    "        match = lut.get(tissue_value, Match(-1, None, None, None))\n",
    "        if match.matched_id == -1: \n",
    "            self.print_unmatched_tissue(tissue_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_tissue(self, \n",
    "                               tissue_value:str # The TISSUE value from the DataFrame\n",
    "                              ):\n",
    "        \"Print the TISSUE value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched TISSUE: {tissue_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a3904",
   "metadata": {},
   "source": [
    "`get_maris_bodypart` defines a partial function of `get_maris_lut`, with predefined arguments  for  `TISSUE` (or `bodypar`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460dc4c-6927-460f-924f-322606ad903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "get_maris_bodypart = partial(get_maris_lut,\n",
    "                             fname_in,\n",
    "                             fname_cache='tissues_helcom.pkl', \n",
    "                             data_provider_lut='TISSUE.csv',\n",
    "                             data_provider_id_col='TISSUE',\n",
    "                             data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                             maris_lut=bodyparts_lut_path,\n",
    "                             maris_id='bodypar_id',\n",
    "                             maris_name='bodypar',\n",
    "                             unmatched_fixes=unmatched_fixes_biota_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877064bf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LookupBiotaSpeciesCB(get_maris_species)` and `LookupBiotaBodyPartCB(get_maris_bodypart)`. Then, print the `TISSUE` and `body_part` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a195f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  body_part\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                 \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'][['TISSUE', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "#### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513576a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``bio_group``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421826",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Biogroup is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_biogroup_lut(maris_lut:str # Path to the MARIS lookup table (Excel file)\n",
    "                    ) -> dict: # A dictionary mapping species_id to biogroup_id\n",
    "    \"Retrieve a lookup table for biogroup ids from a MARIS lookup table.\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291637e",
   "metadata": {},
   "source": [
    "`LookupBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupBiogroupCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Update biogroup id based on MARIS species LUT (dbo_species.xlsx).\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Update the 'bio_group' column in the DataFrame using the lookup table and print unmatched species values.\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: self._get_biogroup(x, lut))\n",
    "\n",
    "    def _get_biogroup(self, \n",
    "                      species_value:str, # The species value from the DataFrame\n",
    "                      lut: dict # The lookup table dictionary\n",
    "                     ) -> int: # The biogroup id from the lookup table\n",
    "        \"Get the biogroup id from the lookup table and print species if the biogroup id is not found.\"\n",
    "        biogroup_id = lut.get(species_value, -1)\n",
    "        if biogroup_id == -1:\n",
    "            self.print_unmatched_species(species_value)\n",
    "        return biogroup_id\n",
    "\n",
    "    def print_unmatched_species(self, \n",
    "                                species_value:str # The species value from the DataFrame\n",
    "                               ):\n",
    "        \"Print the species value if the biogroup id is not found.\"\n",
    "        print(f\"Unmatched species: {species_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f2d40",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)` and `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` . Then, print the `bio_group` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                      \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea8647",
   "metadata": {},
   "source": [
    "#### Lookup : Taxon Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99146b7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Not included`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b120b1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Taxonname`` , ``TaxonRepName``, ``Taxonrank``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf19160",
   "metadata": {},
   "source": [
    "`get_taxonname_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `Taxonname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_taxon_info_lut(\n",
    "    maris_lut:str # Path to the MARIS lookup table (Excel file)\n",
    ") -> dict: # A dictionary mapping species_id to biogroup_id\n",
    "    \"Retrieve a lookup table for Taxonname from a MARIS lookup table.\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].set_index('species_id').to_dict()\n",
    "\n",
    "# TODO include Commonname field after next MARIS data reconciling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b76fe-5a6f-42a3-9361-1403298b2d6a",
   "metadata": {},
   "source": [
    "**Comment (FA)**: Above class should be simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class LookupTaxonInformationCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Update taxon names based on MARIS species LUT (dbo_species.xlsx).\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Update the 'taxon_name' column in the DataFrame using the lookup table and print unmatched species IDs.\"\n",
    "        lut = self.fn_lut()\n",
    "        self._set_taxon_rep_name(tfm.dfs['biota'])\n",
    "        tfm.dfs['biota']['Taxonname'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Taxonname']))\n",
    "        #df['Commonname'] = df['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Commonname']))\n",
    "        tfm.dfs['biota']['Taxonrank'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['Taxonrank']))\n",
    "        tfm.dfs['biota']['TaxonDB'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDB']))\n",
    "        tfm.dfs['biota']['TaxonDBID'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDBID']))\n",
    "        tfm.dfs['biota']['TaxonDBURL'] =  tfm.dfs['biota']['species'].apply(lambda x: self._get_name_by_species_id(x, lut['TaxonDBURL']))\n",
    "\n",
    "    def _set_taxon_rep_name(self, \n",
    "                            df:pd.DataFrame # The DataFrame to modify\n",
    "                           ):\n",
    "        \"Remap the `TaxonRepName` column to the `RUBIN` column values.\"\n",
    "        # Ensure both columns exist before attempting to remap\n",
    "        if 'RUBIN' in df.columns:\n",
    "            df['TaxonRepName'] = df['RUBIN']\n",
    "        else:\n",
    "            print(\"Warning: 'RUBIN' column not found in DataFrame.\")\n",
    "            \n",
    "    def _get_name_by_species_id(self, \n",
    "                                species_id:str, # The species ID from the DataFrame\n",
    "                                lut: dict # The lookup table dictionary\n",
    "                               ) -> str: # The name from the lookup table\n",
    "        \"Get the  name from the lookup table and print species ID if the taxon name is not found.\"\n",
    "        name = lut.get(species_id, 'Unknown')  # Default to 'Unknown' if not found\n",
    "        if name == 'Unknown':\n",
    "            print(f\"Unmatched species ID: {species_id} for {lut.keys()[0]}\")\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Taxonname Taxonrank   TaxonDB TaxonDBID  \\\n",
      "0           Gadus morhua   species  Wikidata   Q199788   \n",
      "40     Sprattus sprattus   species  Wikidata   Q506823   \n",
      "44       Clupea harengus   species  Wikidata  Q2396858   \n",
      "77  Merlangius merlangus   species  Wikidata   Q273083   \n",
      "78       Limanda limanda   species  Wikidata  Q1135526   \n",
      "\n",
      "                                TaxonDBURL  \n",
      "0    https://www.wikidata.org/wiki/Q199788  \n",
      "40   https://www.wikidata.org/wiki/Q506823  \n",
      "44  https://www.wikidata.org/wiki/Q2396858  \n",
      "77   https://www.wikidata.org/wiki/Q273083  \n",
      "78  https://www.wikidata.org/wiki/Q1135526  \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                      \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path()))\n",
    "                            ])\n",
    "tfm()\n",
    "print(tfm.dfs['biota'][['Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "#### Lookup : Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1fe91",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `SEDIMENT_TYPE.csv` file for Sediment types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169727",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``sed_type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be172080",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Sediment type`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7665a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>SILT</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99       NO DATA                    NaN\n",
       "1     0        GRAVEL                    YES\n",
       "2     1          SAND                    YES\n",
       "3     2     FINE SAND                     NO\n",
       "4     3          SILT                    YES"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_sediment = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "df_sediment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dba05",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_sediments` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553b9bf-d305-456f-9bf1-620f2804637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "unmatched_fixes_sediments = {\n",
    "    #np.nan: 'Not applicable',\n",
    "    -99: '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c716f-d2de-455f-b58f-22af28ca01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 142.98it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "sediments_lut_df = get_maris_lut(\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments,\n",
    "    as_dataframe=True,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17cfe1",
   "metadata": {},
   "source": [
    "`get_maris_sediments` defines a partial function of `get_maris_lut`, with predefined arguments  for  `SEDI` (or `sedtype`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053bfbb-8f04-434c-a8a1-35b4d58dd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "get_maris_sediments = partial(\n",
    "    get_maris_lut,\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528f164",
   "metadata": {},
   "source": [
    "`LookupSedimentCB` applies the corrected `sediment` `SEDI` data obtained from the `get_maris_lut` function to the `sediment` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5c4e9-e6ac-4e3a-a267-4ee7a0b820cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def preprocess_sedi(df:pd.DataFrame, column_name:str='SEDI'):\n",
    "    \"Preprocess the 'SEDI' column in the DataFrame by handling missing values and specific replacements.\"\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].fillna(-99).astype('int')\n",
    "        df[column_name].replace([56, 73], -99, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad7ec2-97fd-43a8-83cb-c965ae89efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupSedimentCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable, # Function that returns the lookup table dictionary\n",
    "                 preprocess_fn:Callable=preprocess_sedi # Function to preprocess the sediment DataFrame\n",
    "                ):\n",
    "        \"Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).\"\n",
    "        fc.store_attr()\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Set SedRepName\n",
    "        tfm.dfs['sediment']['SedRepName']  = tfm.dfs['sediment']['SEDI'] \n",
    "\n",
    "        # Apply preprocessing to the 'SEDI' column\n",
    "        tfm.dfs['sediment'] = self.preprocess_fn(tfm.dfs['sediment'])\n",
    "        \n",
    "        # Apply the lookup function\n",
    "        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: self._get_sediment_type(x, lut))\n",
    "\n",
    "    def _get_sediment_type(self, \n",
    "                           sedi_value:int, # The `SEDI` value from the DataFrame\n",
    "                           lut: dict # The lookup table dictionary\n",
    "                          ): \n",
    "        \"Get the matched_id from the lookup table and print SEDI if the matched_id is -1.\"\n",
    "        match = lut.get(sedi_value, Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self._print_unmatched_sedi(sedi_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def _print_unmatched_sedi(self, \n",
    "                              sedi_value:int # The `SEDI` value from the DataFram\n",
    "                             ):\n",
    "        \"Print the SEDI value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131e929",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LookupSedimentCB(get_maris_sediments)`. Then, print the `SEDI` and `sed_type` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d42cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SedRepName  SEDI  sed_type\n",
      "0         NaN   -99         0\n",
      "1         NaN   -99         0\n",
      "2         NaN   -99         0\n",
      "3         NaN   -99         0\n",
      "4         NaN   -99         0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LookupSedimentCB(get_maris_sediments)])\n",
    "\n",
    "tfm()\n",
    "print(tfm.dfs['sediment'][['SedRepName', 'SEDI', 'sed_type']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "#### Lookup : Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a777c3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebee28",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "Create `renaming_unit_rules` to rename the units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {\n",
    "    'seawater': 1,  # 'Bq/m3'\n",
    "    'sediment': 4,  # 'Bq/kgd' for sediment\n",
    "    'biota': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12793b79",
   "metadata": {},
   "source": [
    "`LookupUnitCB` defines a `unit` column each dataframe based on the units provided in the value (`VALUE_Bq/m³` or `VALUE_Bq/kg`) column of the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    def __init__(self, \n",
    "                 renaming_unit_rules:dict=renaming_unit_rules # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        \"Set the 'unit' id column in the DataFrames based on a lookup table.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Apply unit renaming rules to DataFrames within the transformer.\"\n",
    "        for grp in tfm.dfs:\n",
    "            rules = renaming_unit_rules.get(grp)\n",
    "            if rules is not None:\n",
    "                # if group tules include a dictionary, apply the dictionay. \n",
    "                if isinstance(rules, dict):\n",
    "                    # Apply rules based on the 'BASIS' column\n",
    "                    tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: rules.get(x, 0))\n",
    "                else:\n",
    "                    # Apply a single rule to the entire DataFrame\n",
    "                    tfm.dfs[grp]['unit'] = rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `LookupUnitCB()`. Then, print the unique `unit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupUnitCB()])\n",
    "\n",
    "print(tfm()['biota']['unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "#### Lookup : Detection limit or Value type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c95ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``detection_limit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fd987",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine foramt variable: ``Value type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3a699",
   "metadata": {},
   "source": [
    "Create `coi_dl` to define the column names related to Value type for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_dl = {'seawater' : { 'val' : 'VALUE_Bq/m³',\n",
    "                        'unc' : 'ERROR%_m³',\n",
    "                        'dl' : '< VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg',\n",
    "                            'unc' : 'ERROR%',\n",
    "                            'dl' : '< VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg',\n",
    "                              'unc' : 'ERROR%_kg',\n",
    "                              'dl' : '< VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290b3fa",
   "metadata": {},
   "source": [
    "`get_detectionlimit_lut` reads the file at `detection_limit_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`.\n",
    "| id | name | name_sanitized |\n",
    "| :-: | :-: | :-: |\n",
    "|-1|Not applicable|Not applicable|\n",
    "|0|Not Available|Not available|\n",
    "|1|=|Detected value|\n",
    "|2|<|Detection limit|\n",
    "|3|ND|Not detected|\n",
    "|4|DE|Derived|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_detectionlimit_lut():\n",
    "    df = pd.read_excel(detection_limit_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`LookupDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or detection limit) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg>` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    def __init__(self, \n",
    "                 coi:dict=coi_dl, # Configuration options for column names\n",
    "                 fn_lut:Callable=get_detectionlimit_lut # Function that returns a lookup table\n",
    "                ):\n",
    "        \"Remap value type to MARIS format.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "    \n",
    "    def _update_detection_limit(self, \n",
    "                                df:pd.DataFrame, # The DataFrame to modify\n",
    "                                grp:str, # The group name to get the column configuration\n",
    "                                lut:dict # The lookup table dictionary\n",
    "                               ):\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        detection_col = self.coi[grp]['dl']\n",
    "        value_col = self.coi[grp]['val']\n",
    "        uncertainty_col = self.coi[grp]['unc']\n",
    "        \n",
    "        # Copy detection limit column\n",
    "        df['detection_limit'] = df[detection_col]\n",
    "        \n",
    "        # Fill values with '=' or 'Not Available'\n",
    "        condition = ((df[value_col].notna()) & (df[uncertainty_col].notna()) &\n",
    "                     (~df['detection_limit'].isin(lut.keys())))\n",
    "        df.loc[condition, 'detection_limit'] = '='\n",
    "        df.loc[~df['detection_limit'].isin(lut.keys()), 'detection_limit'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup\n",
    "        df['detection_limit'] = df['detection_limit'].map(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66db5cf",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `LookupDetectionLimitCB`. Then, print the unique `detection_limit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB()])\n",
    "\n",
    "print(tfm()['seawater']['detection_limit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "### Include Sample Laboratory code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7b8a4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Sample Laboratory code is not included.*`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018492bf",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``samplabcode``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3238f",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF format does not include Sample Laboratory code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDataProviderSampleIdCB(Callback):\n",
    "    \"Remap `KEY` column to `samplabcode` in each DataFrame.\"\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp])\n",
    "    \n",
    "    def _remap_sample_id(self, df:pd.DataFrame):\n",
    "        df['samplabcode'] = df['KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WKRIL2012003' 'WKRIL2012004' 'WKRIL2012005' ... 'WSSSM2021006'\n",
      " 'WSSSM2021007' 'WSSSM2021008']\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['samplabcode'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "### Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c3ba",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13e4ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84079a35",
   "metadata": {},
   "source": [
    "`get_filtered_lut` reads the file at `filtered_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_filtered_lut() -> dict: # A dictionary mapping names to IDs\n",
    "    \"Retrieve a filtered lookup table from an Excel file.\"\n",
    "    df = pd.read_excel(filtered_lut_path(), usecols=['name', 'id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70453b9",
   "metadata": {},
   "source": [
    "Create  `renaming_rules` to rename the HELCOM data to the MARIS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "renaming_rules = {'N': 'No',\n",
    "                  'n': 'No',\n",
    "                  'F': 'Yes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`LookupFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupFiltCB(Callback):\n",
    "    def __init__(self,\n",
    "                 rules=renaming_rules, # Dictionary mapping FILT codes to their corresponding names\n",
    "                 fn_lut=get_filtered_lut # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Lookup FILT value.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Update the FILT column in the DataFrames using the renaming rules and lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        rules = self.rules\n",
    "        \n",
    "        for grp in tfm.dfs.keys():\n",
    "            if \"FILT\" in tfm.dfs[grp].columns:\n",
    "                self._update_filt_column(tfm.dfs[grp], rules, lut)\n",
    "\n",
    "    def _update_filt_column(self, \n",
    "                            df:pd.DataFrame, # The DataFrame to modify\n",
    "                            rules:dict, # Dictionary mapping `FILT` codes to their corresponding names\n",
    "                            lut:dict # Dictionary for lookup values\n",
    "                           ):\n",
    "        \"Update the FILT column based on renaming rules and lookup table.\"\n",
    "        # Fill values that are not in the renaming rules with 'Not available'.\n",
    "        df['FILT'] = df['FILT'].apply(lambda x: rules.get(x, 'Not available'))\n",
    "        \n",
    "        # Perform lookup\n",
    "        df['FILT'] = df['FILT'].map(lambda x: lut.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625063c",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `LookupFiltCB()`. Then, print the unique `FILT` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupFiltCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['FILT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0fb210",
   "metadata": {},
   "source": [
    "### Measurement note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d92871",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: Not included in NetCDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1296194",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: ``measurenote``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05383c",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up at ``ANALYSIS_METHOD.csv``. This look-up was used to capture the method used as described by HELCOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_helcom_method_desc():\n",
    "    df = pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv')\n",
    "    return df.set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RecordMeasurementNoteCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable # Function that returns the lookup dictionary with `METHOD` as key and `DESCRIPTION` as value\n",
    "                ):\n",
    "        \"Record measurement notes by adding a 'measurenote' column to DataFrames.\"\n",
    "        self.fn_lut = fn_lut\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Apply the lookup table to add 'measurenote' to DataFrames in the transformer.\"\n",
    "        lut = self.fn_lut()\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            if 'METHOD' in df.columns:\n",
    "                self._add_measurementnote(df, lut)\n",
    "            else:\n",
    "                print(f\"Warning: 'METHOD' column not found in DataFrame for group '{grp}'\")\n",
    "\n",
    "    def _add_measurementnote(self, \n",
    "                             df:pd.DataFrame, # DataFrame containing the `METHOD` column\n",
    "                             lut:Dict # Lookup table dictionary mapping `METHOD` to `DESCRIPTION`\n",
    "                            ):\n",
    "        \"Map 'METHOD' values to `measurenote` using the provided lookup table.\"\n",
    "        df['measurenote'] = df['METHOD'].map(lut)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71191b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,\n",
       "       'Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.',\n",
       "       'Radiochem. meth of Sr90. Precipation with oxalate and separation of calcium, barium, radium and ytrium couting with low background anticoincidence beta counter. 1982-1994',\n",
       "       'For tritium liquid scintialtion counting, combined with electrolytic enrichment of analysed water samples, double distilled, before and after electrolysis in cells. Liquid Scintillation spectrometer LKB Wallac model 1410',\n",
       "       'Pretreatment drying (sediment, biota samples) and ashing (biota samples)or vaporization to 1000 ml (sea water samples), measured by gamma-spectrometry using HPGe detectors sediment, biota, sea water /Cs-137, Cs-134, K-40',\n",
       "       'Radiochemical method. acidified samples are pre-concentrated using NH4-Pmo separation on Bio rex 40 resin and preparation of Cs Cloropaltinate for beta counter',\n",
       "       'Classic nitric acid method, Equipment: Llow level beta counter FHT 770T (ESM Eberline)',\n",
       "       'Pretreatment concerning Cs-137 (together with Sr-90) from 20 L of water with HCl, SrCl2, FeCl3, CaCl2K4Fe(CN)6, Na2CO3. Drying of precipitate. Measured by gamma spectrometry using lead-shielded Ge-detectors for seawater/Cs137',\n",
       "       'Pretreatment concentration of Sr-90 (together with Cs-137) from 20 L of water with HCl, SrCl2, FeCl3, CaCl2K4Fe(CN)6, Na2CO3, adding of stable Sr as carrier.Extraction of Y-90 as in LEPA04 for seawater/Sr-90',\n",
       "       'Radiocaesium filtered through Cu2Fe(CN)6 impregnated cartridges, measured by gamma spectormetry using lead-shielded Ge detectors for sewawater/Cs137',\n",
       "       'Precipitation of radioCs on K4(Fe(CN)6)  together  with precipitation of radioSr on Na2CO3,stable Cs and Sr used as yield tracers, isolated radioCs is measured by gamma spectrometry using lead-shielded Ge detectors, isolated….seawater / Cs134, Cs137, Sr90',\n",
       "       'Radiocaesium absorbed on AMP (NH4 - MoPO4), Cs-134 used as yield tracer, measured by gamma spectrometry using lead-shielded Ge detectors - seawater / Cs134, Cs137',\n",
       "       'Radiostrontium isolated (classic nitric acid method) and Y-90 separated after ingrowth and measured by gross beta counting, Sr-85 used as yield tracer, Gross beta counting using low-level GM counters - seawater / Sr90',\n",
       "       'Pretreatment drying, freeze drying, Tc-99 isolated by chemical procedures and measured by gross beta counting, Tc-99m used as yield tracer, Gross beta counting using low-level GM counters - biota, seawater / Tc99',\n",
       "       'Gamma-spectrometric analysis (Pretreatment drying and ashing (450 deg C, Biota samples) or freeze drying (sediment samples) or vaporization to 500 ml (sea water samples), measured by gamma spectrometry using lead-shielded HPGe detectors)',\n",
       "       'Updated tritium analysis (Sea water samples distilled twice with AgNO3 and tritium measured with liquid scintillation counter)',\n",
       "       'Strontium analysis (Radiostrontium isolated (classic nitric acid method) and Y-90 separated after ingrowth and measured by gross beta counting, Stable strontium used as yield tracer, Gross beta counting using low-level GM counters)',\n",
       "       'Transuranic anal. (Pretreatm. drying, freeze drying and ashing (450 d C), Pu isotopes and Am-241 isolated (anion exchange) & determ. by alpha spectrometry,Pu-242 & Am-243 used as yield tracers,alpha spectromet.using Si detectrs, (transuranics, polonium).',\n",
       "       'Modified (-97) from STUK02; Radiostrontium isolated (Sr.Spec-resin) & Y-90 separated after ingrowth & measured by gross beta counting, Stable strontium used as yield tracer, Gross beta counting using low-level GM counters or liquid scintillation counter',\n",
       "       'Radiocaseium filtered through Cu2Fe(CN)6 impregnated cartridges, measured by gamma spectormetry using lead-shielded Ge detectors for sewawater/Cs137',\n",
       "       'not defined',\n",
       "       '137Cs activity concentrations are determined by gamma spectrometry with high purity Germanium detector with energy resolution 1.8 keV for 60Co (1332 keV) and relative efficiency of 18%.',\n",
       "       'Pretreatment drying (sediment, biota samples) and ashing (biota samples)or vaporization to 1000 ml (sea water samples), measured by gamma-spectrometry using HPGe detectors / SEDIMENT, BIOTA and SEAWATER Cs137, Cs134, K40',\n",
       "       'absorption of radiocaesium on KNiFC-PAN, gamma spectrometry of KNiFC-PAN afterwards',\n",
       "       'determination of Sr-90 via Y-90: after several purification steps Y-90 is measured as yttrium oxide in a low level beta gas flow counter',\n",
       "       'determination of Pu-238, Pu-239/240 and Am-241: after several purification steps the transuranic elements are electrolytically deposited on a stainless steel disk and measured by alpha spectrometry',\n",
       "       'Seawater analysis: concentrate Cs in water sample by use of Cu2Fe(CN)6 filters spiked with Cs-134 as tracer, followed by gammaspectrometric measurement of filters',\n",
       "       'Transuranics determined by mass spectrometry, ICPMS, after chemical separation, seawater',\n",
       "       'determination of H-3: distillation of seawater at reduced pressure, electrolytical enrichment of H-3 followed by another distillation at reduced pressure, measurement of distilled sample aliquot in a low level scintillation counter',\n",
       "       'direct gamma counting using HPGe-detectors; sediment and suspended matter undergo freeze-drying beforehand',\n",
       "       'Pretreatment drying (sediment samples) or vaporization to 500 ml (sea water samples), measured by gamma-spectrometry using HPGe detectors/SEDIMENT and SEAWATER: Cs137',\n",
       "       'Cesium analysis of a water sample. The water is shaken with ion exchangers, then the sample is filtrated and scintillation solution is added.',\n",
       "       'Pretreatment concentration of Sr-90 from 20 L of water with HCl, SrCl2, Na2CO3, adding of stable Sr as carrier. Extraction of Y-90 (with 10% HDEP solution) in n-heptane toluene from dissolved ashed samples. Sr-90 measured as Y-90 by proportional low level counter/SEAWATER:Sr-90',\n",
       "       'Preatreatment drying (sediments) or evaporation (water) to 500 ml.  Measuring by gamma spectrometry using HPGe detectors /sediments and seawater/Cs-137',\n",
       "       'Pretreatment evaporation to 500 ml. Extraction of Y-90 with 10% HDEHP solution in toluene. Sr-90 measuring by Cherenkov counting, using liquid scintillation counter /seawater/ Sr-90.',\n",
       "       'Tritium analysis of a water sample. The water is shaken with ion exchangers, then the sample is filtrated and scintillation solution is added. The contents of β-radiation from tritium is measured with a liquid scintillation spectrometer.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater']['measurenote'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa59a",
   "metadata": {},
   "source": [
    "### Include Station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e08cc9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Station ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ba42",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Station``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c799173",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF format does not include Station ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapStationIdCB(Callback):\n",
    "    def __init__(self):\n",
    "        \"Remap Station ID to MARIS format.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap `STATION` to `station_id`.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._remap_station_id(tfm.dfs[grp])\n",
    "\n",
    "    def _remap_station_id(self, \n",
    "                          df:pd.DataFrame # The DataFrame to modify\n",
    "                         ):\n",
    "        \"Remap `STATION` column to `station_id` in the given DataFrame.\"\n",
    "        df['station'] = df['STATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb2604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapStationIdCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "#print(tfm.dfs['seawater']['station'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "### Sediment slice position (top and bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb47624",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: Top and Bottom is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533568d8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Top`` and ``Bottom``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e634d8",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF format does not include sediment slice top and bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    def __init__(self):\n",
    "        \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        if 'sediment' in tfm.dfs:\n",
    "            self._remap_sediment_slice(tfm.dfs['sediment'])\n",
    "\n",
    "    def _remap_sediment_slice(self, \n",
    "                              df:pd.DataFrame # The DataFrame to modify\n",
    "                             ):\n",
    "        \"Remap `LOWSLI` column to `bottom` and `UPPSLI` column to `top` in the given DataFrame.\"\n",
    "        df['bottom'] = df['LOWSLI']\n",
    "        df['top'] = df['UPPSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15.0\n",
      "1    20.0\n",
      "2     0.0\n",
      "3     2.0\n",
      "4     4.0\n",
      "Name: top, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapSedSliceTopBottomCB()\n",
    "                            ])\n",
    "tfm()\n",
    "print(tfm.dfs['sediment']['top'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "### Dry to wet ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64f432",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variable: DW% is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0fd19",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Dry/wet ratio``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735dd22",
   "metadata": {},
   "source": [
    "HELCOM Description:\n",
    "\n",
    "**Sediment:**\n",
    "1. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "2. VALUE_Bq/kg: Measured radioactivity concentration in Bq/kg dry wt. in scientific format(e.g. 123 = 1.23E+02, 0.076 = 7.6E-02)\n",
    "\n",
    "**Biota:**\n",
    "1. WEIGHT: Average weight (in g) of specimen in the sample\n",
    "2. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetRatio(Callback):\n",
    "    def __init__(self):\n",
    "        \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame):\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['dry_wet_ratio'] = df['DW%']\n",
    "        # Convert 'DW%' = 0% to NaN.\n",
    "        df.loc[df['dry_wet_ratio'] == 0, 'dry_wet_ratio'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "0    18.453\n",
      "1    18.453\n",
      "2    18.453\n",
      "3    18.453\n",
      "4    18.458\n",
      "Name: dry_wet_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetRatio(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                    \n",
    "\n",
    "print(tfm.dfs['biota']['dry_wet_ratio'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b9aa0",
   "metadata": {},
   "source": [
    "### Standardize Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3541d",
   "metadata": {},
   "source": [
    "#### Capture Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c1fb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a07ea",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude`` and ``Latitude``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd85aa4",
   "metadata": {},
   "source": [
    "Use decimal degree coordinates if available; otherwise, convert from degree-minute format to decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00410917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_coordinates = {\n",
    "    'seawater': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    },\n",
    "    'biota': {\n",
    "        'lon_d': 'LONGITUDE dddddd',\n",
    "        'lat_d': 'LATITUDE dddddd',\n",
    "        'lon_m': 'LONGITUDE ddmmmm',\n",
    "        'lat_m': 'LATITUDE ddmmmm'\n",
    "    },\n",
    "    'sediment': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def ddmmmm2dddddd(\n",
    "    ddmmmm:float # Coordinates in `ddmmmm` format where `dd` are degrees and `mmmm`` are minutes\n",
    "    ) -> float: # Coordinates in `dddddd`` format\n",
    "    # Split into degrees and minutes\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    # Convert minutes to decimal\n",
    "    mins = mins * 100\n",
    "    # Convert to 'dddddd' format\n",
    "    return round(int(degs) + (mins / 60), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class FormatCoordinates(Callback):\n",
    "    def __init__(self, \n",
    "                 coi:dict, # Column names mapping for coordinates\n",
    "                 fn_convert_cor:Callable # Function to convert coordinates\n",
    "                 ):\n",
    "        \"Format coordinates for MARIS. Converts coordinates from 'ddmmmm' to 'dddddd' format if needed.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Apply formatting to coordinates in the DataFrame.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._format_coordinates(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _format_coordinates(self, \n",
    "                            df:pd.DataFrame, # DataFrame to modify\n",
    "                            grp: str # Group name to determine column names\n",
    "                            ):\n",
    "        \"Format coordinates in the DataFrame for a specific group.\"\n",
    "        lon_col_d = self.coi[grp]['lon_d']\n",
    "        lat_col_d = self.coi[grp]['lat_d']\n",
    "        lon_col_m = self.coi[grp]['lon_m']\n",
    "        lat_col_m = self.coi[grp]['lat_m']\n",
    "        \n",
    "        # Define condition where 'dddddd' format is not available or is zero\n",
    "        condition = (\n",
    "            (df[lon_col_d].isna() | (df[lon_col_d] == 0)) |\n",
    "            (df[lat_col_d].isna() | (df[lat_col_d] == 0))\n",
    "        )\n",
    "        \n",
    "        # Apply conversion function only to non-null and non-zero values\n",
    "        df['lon'] = np.where(\n",
    "            condition,\n",
    "            df[lon_col_m].apply(lambda x: self._safe_convert(x)),\n",
    "            df[lon_col_d]\n",
    "        )\n",
    "        \n",
    "        df['lat'] = np.where(\n",
    "            condition,\n",
    "            df[lat_col_m].apply(lambda x: self._safe_convert(x)),\n",
    "            df[lat_col_d]\n",
    "        )\n",
    "        \n",
    "        # Drop rows where coordinate columns contain NaN values\n",
    "        df.dropna(subset=['lat', 'lon'], inplace=True)\n",
    "\n",
    "    def _safe_convert(self, \n",
    "                      value:float # Coordinate value to convert\n",
    "                      ):\n",
    "        \"Convert coordinate value safely, handling NaN values.\"\n",
    "        if pd.isna(value):\n",
    "            return value  # Return NaN if value is NaN\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value  # Return original value if an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "15822  60.373333  18.395667\n",
      "15823  60.373333  18.395667\n",
      "15824  60.503333  18.366667\n",
      "15825  60.503333  18.366667\n",
      "15826  60.503333  18.366667\n",
      "\n",
      "[15827 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754289f1",
   "metadata": {},
   "source": [
    "#### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e413",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f808d23",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "15822  60.373333  18.395667\n",
      "15823  60.373333  18.395667\n",
      "15824  60.503333  18.366667\n",
      "15825  60.503333  18.366667\n",
      "15826  60.503333  18.366667\n",
      "\n",
      "[15827 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "### Combine Callbacks and review DFS and TFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21114     39531  15798\n",
      "Number of dropped rows                                   102       286     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d4798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
       "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
       "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
       "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y',\n",
       "       'samptype_id', 'nuclide_id', 'time', 'begperiod', 'value',\n",
       "       'uncertainty', 'unit', 'detection_limit', 'samplabcode', 'station',\n",
       "       'lon', 'lat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_dfs_dropped_review=tfm.dfs_dropped['seawater']\n",
    "biota_dfs_dropped_review=tfm.dfs_dropped['biota']\n",
    "sediment_dfs_dropped_review=tfm.dfs_dropped['sediment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f6685",
   "metadata": {},
   "source": [
    "### Rename columns of interest for NetCDF or Open Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af441203",
   "metadata": {},
   "source": [
    "> Column names are standardized to MARIS NetCDF format (i.e. PEP8 ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23653799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TO BE REFACTORED\n",
    "def get_renaming_rules(encoding_type='netcdf'):\n",
    "    \"Define columns of interest (keys) and renaming rules (values).\"\n",
    "    vars = cdl_cfg()['vars']\n",
    "    if encoding_type == 'netcdf':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'lat': vars['defaults']['lat']['name'],\n",
    "                'lon': vars['defaults']['lon']['name'],\n",
    "                'time': vars['defaults']['time']['name'],\n",
    "                'NUCLIDE': 'nuclide',\n",
    "                'detection_limit': vars['suffixes']['detection_limit']['name'],\n",
    "                'unit': vars['suffixes']['unit']['name'],\n",
    "                'value': 'value',\n",
    "                'uncertainty': vars['suffixes']['uncertainty']['name'],\n",
    "                'counting_method': vars['suffixes']['counting_method']['name'],\n",
    "                'sampling_method': vars['suffixes']['sampling_method']['name'],\n",
    "                'preparation_method': vars['suffixes']['preparation_method']['name']\n",
    "            },\n",
    "            ('seawater',): {\n",
    "                # SEAWATER\n",
    "                'SALIN': vars['suffixes']['salinity']['name'],\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                #'FILT': vars['suffixes']['filtered']['name'], Need to fix\n",
    "                'TTEMP': vars['suffixes']['temperature']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "\n",
    "            },\n",
    "            ('biota',): {\n",
    "                # BIOTA\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                'species': vars['bio']['species']['name'],\n",
    "                'body_part': vars['bio']['body_part']['name'],\n",
    "                'bio_group': vars['bio']['bio_group']['name']\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sed_type': vars['sed']['sed_type']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif encoding_type == 'openrefine':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'samptype_id': 'samptype_id',\n",
    "                'lat': 'latitude',\n",
    "                'lon': 'longitude',\n",
    "                'station': 'station',\n",
    "                'begperiod': 'begperiod',\n",
    "                'samplabcode': 'samplabcode',\n",
    "                #'endperiod': 'endperiod',\n",
    "                'nuclide_id': 'nuclide_id',\n",
    "                'detection_limit': 'detection',\n",
    "                'unit': 'unit_id',\n",
    "                'value': 'activity',\n",
    "                'uncertainty': 'uncertaint',\n",
    "                #'vartype': 'vartype',\n",
    "                #'rangelow': 'rangelow',\n",
    "                #'rangeupp': 'rangeupp',\n",
    "                #'rl_detection': 'rl_detection',\n",
    "                #'ru_detection': 'ru_detection',\n",
    "                #'freq': 'freq',\n",
    "                'SDEPTH': 'sampdepth',\n",
    "                #'samparea': 'samparea',\n",
    "                'SALIN': 'salinity',\n",
    "                'TTEMP': 'temperatur',\n",
    "                'FILT': 'filtered',\n",
    "                #'oxygen': 'oxygen',\n",
    "                #'sampquality': 'sampquality',\n",
    "                #'station': 'station',\n",
    "                #'samplabcode': 'samplabcode',\n",
    "                #'profile': 'profile',\n",
    "                #'transect': 'transect',\n",
    "                #'IODE_QualityFlag': 'IODE_QualityFlag',\n",
    "                'TDEPTH': 'totdepth',\n",
    "                #'counmet_id': 'counting_method',\n",
    "                #'sampmet_id': 'sampling_method',\n",
    "                #'prepmet_id': 'preparation_method',\n",
    "                'sampnote': 'sampnote',\n",
    "                'measurenote': 'measurenote'\n",
    "            },\n",
    "            ('seawater',) : {\n",
    "                # SEAWATER\n",
    "                #'volume': 'volume',\n",
    "                #'filtpore': 'filtpore',\n",
    "                #'acid': 'acid'\n",
    "            },\n",
    "            ('biota',) : {\n",
    "                # BIOTA\n",
    "                'species': 'species_id',\n",
    "                'Taxonname': 'Taxonname',\n",
    "                'TaxonRepName': 'TaxonRepName',\n",
    "                #'Commonname': 'Commonname',\n",
    "                'Taxonrank': 'Taxonrank',\n",
    "                'TaxonDB': 'TaxonDB',\n",
    "                'TaxonDBID': 'TaxonDBID',\n",
    "                'TaxonDBURL': 'TaxonDBURL',\n",
    "                'body_part': 'bodypar_id',\n",
    "                #'drywt': 'drywt',\n",
    "                #'wetwt': 'wetwt',\n",
    "                'dry_wet_ratio': 'percentwt',\n",
    "                #'drymet_id': 'drymet_id'\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sed_type': 'sedtype_id',\n",
    "                #'sedtrap': 'sedtrap',\n",
    "                'top': 'sliceup',\n",
    "                'bottom': 'slicedown',\n",
    "                'SedRepName': 'SedRepName',\n",
    "                #'drywt': 'drywt',\n",
    "                #'wetwt': 'wetwt',\n",
    "                'dry_wet_ratio': 'percentwt',\n",
    "                #'drymet_id': 'drymet_id'\n",
    "                \n",
    "            }\n",
    "        })\n",
    "    else:\n",
    "        print(\"Invalid encoding_type provided. Please use 'netcdf' or 'openrefine'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SelectAndRenameColumnCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_renaming_rules:Callable, # A function that returns an OrderedDict of renaming rules \n",
    "                 encoding_type:str='netcdf', # The encoding type (`netcdf` or `openrefine`) to determine which renaming rules to use\n",
    "                 verbose:bool=False # Whether to print out renaming rules that were not applied\n",
    "                 ):\n",
    "        \"Select and rename columns in a DataFrame based on renaming rules for a specified encoding type.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Apply column selection and renaming to DataFrames in the transformer, and identify unused rules.\"\n",
    "        try:\n",
    "            renaming_rules = self.fn_renaming_rules(self.encoding_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fetching renaming rules: {e}\")\n",
    "            return\n",
    "\n",
    "        for group in tfm.dfs.keys():\n",
    "            # Get relevant renaming rules for the current group\n",
    "            group_rules = self._get_group_rules(renaming_rules, group)\n",
    "\n",
    "            if not group_rules:\n",
    "                continue\n",
    "\n",
    "            # Apply renaming rules and track keys not found in the DataFrame\n",
    "            df = tfm.dfs[group]\n",
    "            df, not_found_keys = self._apply_renaming(df, group_rules)\n",
    "            tfm.dfs[group] = df\n",
    "            \n",
    "            # Print any renaming rules that were not used\n",
    "            if not_found_keys and self.verbose:\n",
    "                print(f\"\\nGroup '{group}' has the following renaming rules not applied:\")\n",
    "                for old_col in not_found_keys:\n",
    "                    print(f\"Key '{old_col}' from renaming rules was not found in the DataFrame.\")\n",
    "\n",
    "    def _get_group_rules(self, \n",
    "                         renaming_rules:OrderedDict, # Renaming rules\n",
    "                         group:str # Group name to filter rules\n",
    "                         ) -> OrderedDict: # Renaming rules applicable to the specified group\n",
    "        \"Retrieve and merge renaming rules for the specified group based on the encoding type.\"\n",
    "        relevant_rules = [rules for key, rules in renaming_rules.items() if group in key]\n",
    "        merged_rules = OrderedDict()\n",
    "        for rules in relevant_rules:\n",
    "            merged_rules.update(rules)\n",
    "        return merged_rules\n",
    "\n",
    "    def _apply_renaming(self, \n",
    "                        df:pd.DataFrame, # DataFrame to modify\n",
    "                        rename_rules:OrderedDict # Renaming rules\n",
    "                        ) -> tuple: # (Renamed and filtered df, Column names from renaming rules that were not found in the DataFrame)\n",
    "        \"\"\"\n",
    "        Select columns based on renaming rules and apply renaming, only for existing columns\n",
    "        while maintaining the order of the dictionary columns.\"\"\"\n",
    "        existing_columns = set(df.columns)\n",
    "        valid_rules = OrderedDict((old_col, new_col) for old_col, new_col in rename_rules.items() if old_col in existing_columns)\n",
    "\n",
    "        # Create a list to maintain the order of columns\n",
    "        columns_to_keep = [col for col in rename_rules.keys() if col in existing_columns]\n",
    "        columns_to_keep += [new_col for old_col, new_col in valid_rules.items() if new_col in df.columns]\n",
    "\n",
    "        df = df[list(OrderedDict.fromkeys(columns_to_keep))]\n",
    "\n",
    "        # Apply renaming\n",
    "        df.rename(columns=valid_rules, inplace=True)\n",
    "\n",
    "        # Determine which keys were not found\n",
    "        not_found_keys = set(rename_rules.keys()) - existing_columns\n",
    "        return df, not_found_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a8682-672f-4188-9091-821b727b4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       '_sal', 'smp_depth', '_temp', 'tot_depth'],\n",
      "      dtype='object')\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       'smp_depth', 'species', 'body_part', 'bio_group'],\n",
      "      dtype='object')\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       'sed_type', 'tot_depth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(tfm.dfs['seawater'].columns)\n",
    "print(tfm.dfs['biota'].columns)\n",
    "print(tfm.dfs['sediment'].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7efe2d",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59b263",
   "metadata": {},
   "source": [
    "Convert data from long to wide and rename columns to comply with NetCDF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21114     39531  15798\n",
      "Number of dropped rows                                   102       286     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab81ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seawater_dfs_review=tfm.dfs['seawater']\n",
    "# biota_dfs_review=tfm.dfs['biota']\n",
    "# sediment_dfs_review=tfm.dfs['sediment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Convert nuclide names to lowercase and strip any trailing spaces.',\n",
       " 'Encode time as `int` representing seconds since xxx',\n",
       " 'Remap `KEY` column to `samplabcode` in each DataFrame.',\n",
       " 'Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                         \n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "# Transform\n",
    "tfm()\n",
    "# Check transformation logs\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2021-12-15T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': 'Convert nuclide names to lowercase and strip any trailing spaces., Encode time as `int` representing seconds since xxx, Remap `KEY` column to `samplabcode` in each DataFrame., Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ebcce-b8c8-4963-8c1c-f32e820f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as `species_t` for instance.\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### Encoding NETCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                                GetSampleTypeCB(type_lut),\n",
    "                                LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),        \n",
    "                                SanitizeValue(coi_val),                       \n",
    "                                NormalizeUncCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),    \n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                                LookupFiltCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                                ReshapeLongToWide()\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "encode(fname_in, fname_out_nc, nc_tpl_path(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05beed7f",
   "metadata": {},
   "source": [
    "## Open Refine Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f45970",
   "metadata": {},
   "source": [
    "### Rename columns for Open Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 'seawater' has the following renaming rules not applied:\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'sediment' has the following renaming rules not applied:\n",
      "Key 'FILT' from renaming rules was not found in the DataFrame.\n",
      "Key 'TTEMP' from renaming rules was not found in the DataFrame.\n",
      "Key 'SDEPTH' from renaming rules was not found in the DataFrame.\n",
      "Key 'SALIN' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'biota' has the following renaming rules not applied:\n",
      "Key 'TDEPTH' from renaming rules was not found in the DataFrame.\n",
      "Key 'FILT' from renaming rules was not found in the DataFrame.\n",
      "Key 'TTEMP' from renaming rules was not found in the DataFrame.\n",
      "Key 'SALIN' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21114     39531  15798\n",
      "Number of dropped rows                                   102       286     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            GetSampleTypeCB(type_lut),\n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine', verbose=True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e68ad8",
   "metadata": {},
   "source": [
    "**Example of data included in dfs_dropped.**\n",
    "\n",
    "Main reasons for data to be dropped from dfs:\n",
    "- No activity value reported (e.g. VALUE_Bq/kg)\n",
    "- No time value reported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>SLREB1998021</td>\n",
       "      <td>SR90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11824</th>\n",
       "      <td>SLVDC1997023</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>SLVDC1997031</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>SLVDC1997040</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>SLVDC1998011</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>CO60</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39774</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>RA226</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39775</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>RA223</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39777</th>\n",
       "      <td>SSSSM2021031</td>\n",
       "      <td>CS137</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.993243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39779</th>\n",
       "      <td>SSSSM2021031</td>\n",
       "      <td>CO60</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.993243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "11784  SLREB1998021    SR90       2           NaN          NaN        NaN   \n",
       "11824  SLVDC1997023   CS137       1           NaN          NaN        NaN   \n",
       "11832  SLVDC1997031   CS137       1           NaN          NaN        NaN   \n",
       "11841  SLVDC1997040   CS137       1           NaN          NaN        NaN   \n",
       "11849  SLVDC1998011   CS137       1           NaN          NaN        NaN   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "39769  SSSSM2021030    CO60  SSSM43             <          NaN        NaN   \n",
       "39774  SSSSM2021030   RA226  SSSM43             <          NaN        NaN   \n",
       "39775  SSSSM2021030   RA223  SSSM43             <          NaN        NaN   \n",
       "39777  SSSSM2021031   CS137  SSSM43             <          NaN        NaN   \n",
       "39779  SSSSM2021031    CO60  SSSM43             <          NaN        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "11784           NaN          NaN        NaN                NaN  ...    12.0   \n",
       "11824           NaN          NaN        NaN                NaN  ...    14.0   \n",
       "11832           NaN          NaN        NaN                NaN  ...    14.0   \n",
       "11841           NaN          NaN        NaN                NaN  ...    16.0   \n",
       "11849           NaN          NaN        NaN                NaN  ...    16.0   \n",
       "...             ...          ...        ...                ...  ...     ...   \n",
       "39769             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39774             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39775             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39777             <          0.0        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39779             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "\n",
       "          AREA  SEDI OXIC        DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  \\\n",
       "11784  0.02100  55.0    O        NaN   NaN           14.0            14.0   \n",
       "11824  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11832  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11841  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11849  0.02100  55.0    O        NaN   NaN           14.0            14.0   \n",
       "...        ...   ...  ...        ...   ...            ...             ...   \n",
       "39769  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39774  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39775  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39777  0.01608   NaN  NaN  31.993243   NaN           13.0            13.0   \n",
       "39779  0.01608   NaN  NaN  31.993243   NaN           13.0            13.0   \n",
       "\n",
       "       SUM_LINK    DATE_OF_ENTRY_y  \n",
       "11784         a                NaN  \n",
       "11824         a                NaN  \n",
       "11832         a                NaN  \n",
       "11841         a                NaN  \n",
       "11849         a                NaN  \n",
       "...         ...                ...  \n",
       "39769       NaN  09/06/22 00:00:00  \n",
       "39774       NaN  09/06/22 00:00:00  \n",
       "39775       NaN  09/06/22 00:00:00  \n",
       "39777       NaN  09/06/22 00:00:00  \n",
       "39779       NaN  09/06/22 00:00:00  \n",
       "\n",
       "[286 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='sediment'\n",
    "#grp='seawater'\n",
    "#grp='biota'\n",
    "\n",
    "tfm.dfs_dropped[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6241c",
   "metadata": {},
   "source": [
    "## Open Refine encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd81eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode_or(fname_in, fname_out_csv, ref_id, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                                GetSampleTypeCB(type_lut),\n",
    "                                LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),        \n",
    "                                SanitizeValue(coi_val),                       \n",
    "                                NormalizeUncCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),    \n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                                LookupFiltCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine'),\n",
    "                                CompareDfsAndTfmCB(dfs)\n",
    "                                ])\n",
    "    tfm()\n",
    "\n",
    "    encoder = OpenRefineCsvEncoder(tfm.dfs, \n",
    "                                    dest_fname=fname_out_csv, \n",
    "                                    ref_id = ref_id,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "encode_or(fname_in, fname_out_csv, ref_id, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be09695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samptype_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station</th>\n",
       "      <th>begperiod</th>\n",
       "      <th>samplabcode</th>\n",
       "      <th>nuclide_id</th>\n",
       "      <th>detection</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>uncertaint</th>\n",
       "      <th>sampdepth</th>\n",
       "      <th>salinity</th>\n",
       "      <th>temperatur</th>\n",
       "      <th>filtered</th>\n",
       "      <th>totdepth</th>\n",
       "      <th>measurenote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>RU10</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>RU10</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>3.980</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>59.4333</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>RU11</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.5</td>\n",
       "      <td>5.100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60.2500</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>RU19</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>60.2500</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>RU19</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>3.996</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21210</th>\n",
       "      <td>1</td>\n",
       "      <td>58.6033</td>\n",
       "      <td>11.2450</td>\n",
       "      <td>SW7</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>WSSSM2021003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>970.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21211</th>\n",
       "      <td>1</td>\n",
       "      <td>60.5200</td>\n",
       "      <td>18.3572</td>\n",
       "      <td>SWF135</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>WSSSM2021005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>960.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21212</th>\n",
       "      <td>1</td>\n",
       "      <td>57.4217</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>SWS36</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>WSSSM2021006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>970.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21213</th>\n",
       "      <td>1</td>\n",
       "      <td>57.2347</td>\n",
       "      <td>11.9452</td>\n",
       "      <td>SWR35</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>WSSSM2021007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>970.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21214</th>\n",
       "      <td>1</td>\n",
       "      <td>57.2347</td>\n",
       "      <td>11.9452</td>\n",
       "      <td>SWR35</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>WSSSM2021008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21114 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       samptype_id  latitude  longitude station  begperiod   samplabcode  \\\n",
       "0                1   60.0833    29.3333    RU10 2012-05-23  WKRIL2012003   \n",
       "1                1   60.0833    29.3333    RU10 2012-05-23  WKRIL2012004   \n",
       "2                1   59.4333    23.1500    RU11 2012-06-17  WKRIL2012005   \n",
       "3                1   60.2500    27.9833    RU19 2012-05-24  WKRIL2012006   \n",
       "4                1   60.2500    27.9833    RU19 2012-05-24  WKRIL2012007   \n",
       "...            ...       ...        ...     ...        ...           ...   \n",
       "21210            1   58.6033    11.2450     SW7 2021-09-28  WSSSM2021003   \n",
       "21211            1   60.5200    18.3572  SWF135 2021-10-15  WSSSM2021005   \n",
       "21212            1   57.4217    17.0000   SWS36 2021-11-04  WSSSM2021006   \n",
       "21213            1   57.2347    11.9452   SWR35 2021-10-15  WSSSM2021007   \n",
       "21214            1   57.2347    11.9452   SWR35 2021-05-17  WSSSM2021008   \n",
       "\n",
       "       nuclide_id  detection  unit_id  activity  uncertaint  sampdepth  \\\n",
       "0              33          1        1       5.3       1.696        0.0   \n",
       "1              33          1        1      19.9       3.980       29.0   \n",
       "2              33          1        1      25.5       5.100        0.0   \n",
       "3              33          1        1      17.0       4.930        0.0   \n",
       "4              33          1        1      22.2       3.996       39.0   \n",
       "...           ...        ...      ...       ...         ...        ...   \n",
       "21210           1          1        1    2370.0     970.000        1.0   \n",
       "21211           1          1        1    1030.0     960.000        1.0   \n",
       "21212           1          1        1    2240.0     970.000        1.0   \n",
       "21213           1          1        1    2060.0     970.000        1.0   \n",
       "21214           1          1        1    2300.0    1000.000        1.0   \n",
       "\n",
       "       salinity  temperatur  filtered  totdepth measurenote  \n",
       "0           NaN         NaN         0       NaN         NaN  \n",
       "1           NaN         NaN         0       NaN         NaN  \n",
       "2           NaN         NaN         0       NaN         NaN  \n",
       "3           NaN         NaN         0       NaN         NaN  \n",
       "4           NaN         NaN         0       NaN         NaN  \n",
       "...         ...         ...       ...       ...         ...  \n",
       "21210       NaN         NaN         2       NaN         NaN  \n",
       "21211       NaN         NaN         2       NaN         NaN  \n",
       "21212       NaN         NaN         2       NaN         NaN  \n",
       "21213       NaN         NaN         2       NaN         NaN  \n",
       "21214       NaN         NaN         2       NaN         NaN  \n",
       "\n",
       "[21114 rows x 17 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../_data/output/100-HELCOM-MORS-2024.csv'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_out_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d01ad",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc9e8",
   "metadata": {},
   "source": [
    "###  Open Refine Variables not included in Helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca95cc",
   "metadata": {},
   "source": [
    "| Field name      | Full name                | HELCOM     |\n",
    "|-----------------|--------------------------|------------|\n",
    "| sampquality     | Sample quality           | N          |\n",
    "| lab_id          | Laboratory ID            | N          |\n",
    "| profile_id      | Profile ID               | N          |\n",
    "| transect_id     | Transect ID              | N          |\n",
    "| endperiod       | End period               | N          |\n",
    "| vartype         | Variable type            | N          |\n",
    "| freq            | Frequency                | N          |\n",
    "| rl_detection    | Range low detection      | N          |\n",
    "| rangelow        | Range low                | N          |\n",
    "| rangeupp        | Range upper              | N          |\n",
    "| Commonname      | Common name              | N          |\n",
    "| volume          | Volume                   | N          |\n",
    "| filtpore        | Filter pore              | N          |\n",
    "| acid            | Acidified                | N          |\n",
    "| oxygen          | Oxygen                   | N          |\n",
    "| samparea        | Sample area              | N          |\n",
    "| drywt           | Dry weight               | N          |\n",
    "| wetwt           | Wet weight               | N          |\n",
    "| sampmet_id      | Sampling method ID       | N          |\n",
    "| drymet_id       | Drying method ID         | N          |\n",
    "| prepmet_id      | Preparation method ID    | N          |\n",
    "| counmet_id      | Counting method ID       | N          |\n",
    "| refnote         | Reference note           | N          |\n",
    "| sampnote        | Sample note              | N          |\n",
    "| gfe             | Good for export          | ?          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ef79f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33549327",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d9df4",
   "metadata": {},
   "source": [
    "TODO: Should we use a single encoder for both NetCDF and OpenRefine? If so, should we have a single encode function that accepts a variable 'encoding_type'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa225e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a206afa",
   "metadata": {},
   "source": [
    "TODO: Include FILT for NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d309d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44bf97",
   "metadata": {},
   "source": [
    "TODO: Check sediment 'DW%' data that is less than 1%. Is this realistic? Check the 'DW%' data that is 0%. Run below before SelectAndRenameColumnCB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002712da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seawater':                 KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       " 0      WKRIL2012003   cs137    NaN           NaN          5.3  32.000000   \n",
       " 1      WKRIL2012004   cs137    NaN           NaN         19.9  20.000000   \n",
       " 2      WKRIL2012005   cs137    NaN           NaN         25.5  20.000000   \n",
       " 3      WKRIL2012006   cs137    NaN           NaN         17.0  29.000000   \n",
       " 4      WKRIL2012007   cs137    NaN           NaN         22.2  18.000000   \n",
       " ...             ...     ...    ...           ...          ...        ...   \n",
       " 21211  WSSSM2021005      h3  SSM45           NaN       1030.0  93.203883   \n",
       " 21212  WSSSM2021006      h3  SSM45           NaN       2240.0  43.303571   \n",
       " 21213  WSSSM2021007      h3  SSM45           NaN       2060.0  47.087379   \n",
       " 21214  WSSSM2021008      h3  SSM45           NaN       2300.0  43.478261   \n",
       " 21215  WSSSM2021004      h3  SSM45             <          NaN        NaN   \n",
       " \n",
       "          DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ...  \\\n",
       " 0      08/20/14 00:00:00     90.0       KRIL  2012003.0  ...   \n",
       " 1      08/20/14 00:00:00     90.0       KRIL  2012004.0  ...   \n",
       " 2      08/20/14 00:00:00     90.0       KRIL  2012005.0  ...   \n",
       " 3      08/20/14 00:00:00     90.0       KRIL  2012006.0  ...   \n",
       " 4      08/20/14 00:00:00     90.0       KRIL  2012007.0  ...   \n",
       " ...                  ...      ...        ...        ...  ...   \n",
       " 21211  09/06/22 00:00:00     77.0       SSSM   202105.0  ...   \n",
       " 21212  09/06/22 00:00:00     77.0       SSSM   202106.0  ...   \n",
       " 21213  09/06/22 00:00:00     77.0       SSSM   202107.0  ...   \n",
       " 21214  09/06/22 00:00:00     77.0       SSSM   202108.0  ...   \n",
       " 21215  09/06/22 00:00:00     77.0       SSSM   202104.0  ...   \n",
       " \n",
       "       LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
       " 0                29.2000             29.3333     NaN     0.0   NaN    NaN   \n",
       " 1                29.2000             29.3333     NaN    29.0   NaN    NaN   \n",
       " 2                23.0900             23.1500     NaN     0.0   NaN    NaN   \n",
       " 3                27.5900             27.9833     NaN     0.0   NaN    NaN   \n",
       " 4                27.5900             27.9833     NaN    39.0   NaN    NaN   \n",
       " ...                  ...                 ...     ...     ...   ...    ...   \n",
       " 21211            18.2143             18.3572     NaN     1.0   NaN    NaN   \n",
       " 21212            17.0000             17.0000     NaN     1.0   NaN    NaN   \n",
       " 21213            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       " 21214            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       " 21215            11.1470             11.2450     NaN     1.0   NaN    NaN   \n",
       " \n",
       "        FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       " 0       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 1       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 2       NaN           11.0              3.0  08/20/14 00:00:00  \n",
       " 3       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 4       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " ...     ...            ...              ...                ...  \n",
       " 21211     N            1.0              8.0  09/06/22 00:00:00  \n",
       " 21212     N           10.0             10.0  09/06/22 00:00:00  \n",
       " 21213     N           12.0             12.0  09/06/22 00:00:00  \n",
       " 21214     N           12.0             12.0  09/06/22 00:00:00  \n",
       " 21215     N           15.0             18.0  09/06/22 00:00:00  \n",
       " \n",
       " [21216 rows x 27 columns],\n",
       " 'sediment':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       " 0      SKRIL2012048   ra226     NaN           NaN         35.0      26.00   \n",
       " 1      SKRIL2012049   ra226     NaN           NaN         36.0      22.00   \n",
       " 2      SKRIL2012050   ra226     NaN           NaN         38.0      24.00   \n",
       " 3      SKRIL2012051   ra226     NaN           NaN         36.0      25.00   \n",
       " 4      SKRIL2012052   ra226     NaN           NaN         30.0      23.00   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 39812  SSSSM2020029   ac228  SSSM43           NaN         37.5       5.00   \n",
       " 39813  SSSSM2020030     k40  SSSM43           NaN        526.0       1.72   \n",
       " 39814  SSSSM2020030   cs137  SSSM43           NaN         17.2       2.21   \n",
       " 39815  SSSSM2020031     k40  SSSM43           NaN       1000.0       1.80   \n",
       " 39816  SSSSM2020031   cs137  SSSM43           NaN         64.0       1.20   \n",
       " \n",
       "       < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       " 0               NaN          NaN        NaN  08/20/14 00:00:00  ...    20.0   \n",
       " 1               NaN          NaN        NaN  08/20/14 00:00:00  ...    27.0   \n",
       " 2               NaN          NaN        NaN  08/20/14 00:00:00  ...     2.0   \n",
       " 3               NaN          NaN        NaN  08/20/14 00:00:00  ...     4.0   \n",
       " 4               NaN          NaN        NaN  08/20/14 00:00:00  ...     6.0   \n",
       " ...             ...          ...        ...                ...  ...     ...   \n",
       " 39812           NaN        255.0       28.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39813           NaN       5690.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39814           NaN        186.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39815           NaN      16000.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39816           NaN       1020.0        1.0  04/22/22 00:00:00  ...     2.0   \n",
       " \n",
       "         AREA  SEDI OXIC    DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       " 0      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 1      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 2      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 3      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 4      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " ...      ...   ...  ...    ...   ...            ...             ...       ...   \n",
       " 39812  0.019   0.0    O  28.73  14.0           13.0            13.0       NaN   \n",
       " 39813  0.019   0.0    O  32.03   NaN           12.0            12.0       NaN   \n",
       " 39814  0.019   0.0    O  32.03   NaN           12.0            12.0       NaN   \n",
       " 39815  0.017   0.0    O  48.77   NaN            1.0             8.0       NaN   \n",
       " 39816  0.017   0.0    O  48.77   NaN            1.0             8.0       NaN   \n",
       " \n",
       "          DATE_OF_ENTRY_y  \n",
       " 0      08/20/14 00:00:00  \n",
       " 1      08/20/14 00:00:00  \n",
       " 2      08/20/14 00:00:00  \n",
       " 3      08/20/14 00:00:00  \n",
       " 4      08/20/14 00:00:00  \n",
       " ...                  ...  \n",
       " 39812  04/22/22 00:00:00  \n",
       " 39813  04/22/22 00:00:00  \n",
       " 39814  04/22/22 00:00:00  \n",
       " 39815  04/22/22 00:00:00  \n",
       " 39816  04/22/22 00:00:00  \n",
       " \n",
       " [39817 rows x 35 columns],\n",
       " 'biota':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       " 0      BVTIG2012041   cs134  VTIG01             <     0.010140     W     NaN   \n",
       " 1      BVTIG2012041     k40  VTIG01                 135.300000     W    3.57   \n",
       " 2      BVTIG2012041    co60  VTIG01             <     0.013980     W     NaN   \n",
       " 3      BVTIG2012041   cs137  VTIG01                   4.338000     W    3.48   \n",
       " 4      BVTIG2012040   cs134  VTIG01             <     0.009614     W     NaN   \n",
       " ...             ...     ...     ...           ...          ...   ...     ...   \n",
       " 15822  BSSSM2020016     k40  SSSM42           NaN    65.000000     D   10.20   \n",
       " 15823  BSSSM2020016   cs137  SSSM42           NaN     4.500000     D    6.20   \n",
       " 15824  BSSSM2020017     be7  SSSM42           NaN    94.000000     D    3.40   \n",
       " 15825  BSSSM2020017     k40  SSSM42           NaN  1100.000000     D    1.60   \n",
       " 15826  BSSSM2020017   cs137  SSSM42           NaN    13.000000     D    2.50   \n",
       " \n",
       "        NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE     NO  \\\n",
       " 0         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 1         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 2         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 3         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 4         NaN  02/27/14 00:00:00      6.0  ...         F       5   17.0   \n",
       " ...       ...                ...      ...  ...       ...     ...    ...   \n",
       " 15822     NaN  04/22/22 00:00:00     77.0  ...         B      41  319.0   \n",
       " 15823     NaN  04/22/22 00:00:00     77.0  ...         B      41  319.0   \n",
       " 15824     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " 15825     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " 15826     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " \n",
       "        LENGTH  WEIGHT     DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
       " 0        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 1        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 2        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 3        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 4        45.9   964.0  18.458  92.9            2.0               16   \n",
       " ...       ...     ...     ...   ...            ...              ...   \n",
       " 15822     NaN     NaN  41.000   0.0            1.0                8   \n",
       " 15823     NaN     NaN  41.000   0.0            1.0                8   \n",
       " 15824     NaN     NaN  21.000   0.0            1.0                8   \n",
       " 15825     NaN     NaN  21.000   0.0            1.0                8   \n",
       " 15826     NaN     NaN  21.000   0.0            1.0                8   \n",
       " \n",
       "          DATE_OF_ENTRY_y  \n",
       " 0      02/27/14 00:00:00  \n",
       " 1      02/27/14 00:00:00  \n",
       " 2      02/27/14 00:00:00  \n",
       " 3      02/27/14 00:00:00  \n",
       " 4      02/27/14 00:00:00  \n",
       " ...                  ...  \n",
       " 15822  04/22/22 00:00:00  \n",
       " 15823  04/22/22 00:00:00  \n",
       " 15824  04/22/22 00:00:00  \n",
       " 15825  04/22/22 00:00:00  \n",
       " 15826  04/22/22 00:00:00  \n",
       " \n",
       " [15827 rows x 33 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de551778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30938</th>\n",
       "      <td>SLVEA2010001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.886</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30939</th>\n",
       "      <td>SLVEA2010002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.58</td>\n",
       "      <td>1.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.092</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30940</th>\n",
       "      <td>SLVEA2010003</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.69</td>\n",
       "      <td>1.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.390</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30941</th>\n",
       "      <td>SLVEA2010004</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.699</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30942</th>\n",
       "      <td>SLVEA2010005</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.894</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30943</th>\n",
       "      <td>SLVEA2010006</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.02</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.523</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30944</th>\n",
       "      <td>SLVEA2010007</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.946</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30945</th>\n",
       "      <td>SLVEA2010008</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.07</td>\n",
       "      <td>2.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.162</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30946</th>\n",
       "      <td>SLVEA2010009</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.70</td>\n",
       "      <td>3.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.444</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30947</th>\n",
       "      <td>SLVEA2010010</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.220</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30948</th>\n",
       "      <td>SLVEA2010011</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>12.24</td>\n",
       "      <td>3.88</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>5.035</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30949</th>\n",
       "      <td>SLVEA2010012</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.330</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30950</th>\n",
       "      <td>SLVEA2010013</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331.61</td>\n",
       "      <td>1.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.566</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30951</th>\n",
       "      <td>SLVEA2010014</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.06</td>\n",
       "      <td>1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.516</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30952</th>\n",
       "      <td>SLVEA2010015</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367.11</td>\n",
       "      <td>1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.434</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30953</th>\n",
       "      <td>SLVEA2010016</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.97</td>\n",
       "      <td>1.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.348</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30954</th>\n",
       "      <td>SLVEA2010017</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356.30</td>\n",
       "      <td>1.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.447</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30955</th>\n",
       "      <td>SLVEA2010018</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.75</td>\n",
       "      <td>1.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.765</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30956</th>\n",
       "      <td>SLVEA2010019</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.64</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.580</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30957</th>\n",
       "      <td>SLVEA2010020</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.058</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30958</th>\n",
       "      <td>SLVEA2010021</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.65</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.680</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30959</th>\n",
       "      <td>SLVEA2010022</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.36</td>\n",
       "      <td>2.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.153</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30960</th>\n",
       "      <td>SLVEA2010023</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.12</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.873</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30961</th>\n",
       "      <td>SLVEA2010024</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.864</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "30938  SLVEA2010001   cs137  LVEA01           NaN       334.25       1.57   \n",
       "30939  SLVEA2010002   cs137  LVEA01           NaN       343.58       1.49   \n",
       "30940  SLVEA2010003   cs137  LVEA01           NaN       334.69       1.56   \n",
       "30941  SLVEA2010004   cs137  LVEA01           NaN       348.50       1.56   \n",
       "30942  SLVEA2010005   cs137  LVEA01           NaN       258.67       1.73   \n",
       "30943  SLVEA2010006   cs137  LVEA01           NaN       182.02       2.05   \n",
       "30944  SLVEA2010007   cs137  LVEA01           NaN       116.34       2.79   \n",
       "30945  SLVEA2010008   cs137  LVEA01           NaN        94.07       2.61   \n",
       "30946  SLVEA2010009   cs137  LVEA01           NaN        69.70       3.12   \n",
       "30947  SLVEA2010010   cs137  LVEA01           NaN        59.63       3.40   \n",
       "30948  SLVEA2010011   cs137  LVEA01             <        12.24       3.88   \n",
       "30949  SLVEA2010012   cs137  LVEA01             <         0.83        NaN   \n",
       "30950  SLVEA2010013   cs137  LVEA01           NaN       331.61       1.40   \n",
       "30951  SLVEA2010014   cs137  LVEA01           NaN       352.06       1.33   \n",
       "30952  SLVEA2010015   cs137  LVEA01           NaN       367.11       1.36   \n",
       "30953  SLVEA2010016   cs137  LVEA01           NaN       328.97       1.42   \n",
       "30954  SLVEA2010017   cs137  LVEA01           NaN       356.30       1.37   \n",
       "30955  SLVEA2010018   cs137  LVEA01           NaN       314.75       1.42   \n",
       "30956  SLVEA2010019   cs137  LVEA01           NaN       261.64       1.52   \n",
       "30957  SLVEA2010020   cs137  LVEA01           NaN       181.00       1.76   \n",
       "30958  SLVEA2010021   cs137  LVEA01           NaN       143.65       2.02   \n",
       "30959  SLVEA2010022   cs137  LVEA01           NaN       109.36       2.15   \n",
       "30960  SLVEA2010023   cs137  LVEA01           NaN        94.12       1.39   \n",
       "30961  SLVEA2010024   cs137  LVEA01           NaN        96.63       1.35   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "30938           NaN      131.886    41179.0             NaN  ...     2.0   \n",
       "30939           NaN      132.092    41179.0             NaN  ...     4.0   \n",
       "30940           NaN      134.390    41179.0             NaN  ...     6.0   \n",
       "30941           NaN      136.699    41179.0             NaN  ...     8.0   \n",
       "30942           NaN      104.894    41179.0             NaN  ...    10.0   \n",
       "30943           NaN       77.523    41179.0             NaN  ...    12.0   \n",
       "30944           NaN       46.946    41179.0             NaN  ...    14.0   \n",
       "30945           NaN       38.162    41179.0             NaN  ...    16.0   \n",
       "30946           NaN       27.444    41179.0             NaN  ...    18.0   \n",
       "30947           NaN       24.220    41179.0             NaN  ...    20.0   \n",
       "30948             <        5.035    41179.0             NaN  ...    22.0   \n",
       "30949             <        0.330    41179.0             NaN  ...    24.0   \n",
       "30950           NaN      125.566    41179.0             NaN  ...     2.0   \n",
       "30951           NaN      144.516    41179.0             NaN  ...     4.0   \n",
       "30952           NaN      139.434    41179.0             NaN  ...     6.0   \n",
       "30953           NaN      124.348    41179.0             NaN  ...     8.0   \n",
       "30954           NaN      135.447    41179.0             NaN  ...    10.0   \n",
       "30955           NaN      118.765    41179.0             NaN  ...    12.0   \n",
       "30956           NaN      104.580    41179.0             NaN  ...    14.0   \n",
       "30957           NaN       74.058    41179.0             NaN  ...    16.0   \n",
       "30958           NaN       57.680    41179.0             NaN  ...    18.0   \n",
       "30959           NaN       42.153    41179.0             NaN  ...    20.0   \n",
       "30960           NaN       35.873    41179.0             NaN  ...    22.0   \n",
       "30961           NaN       38.864    41179.0             NaN  ...    24.0   \n",
       "\n",
       "         AREA  SEDI OXIC    DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  \\\n",
       "30938  0.0151   5.0    O  0.115   0.9           14.0            14.0   \n",
       "30939  0.0151   5.0    A  0.159   0.8           14.0            14.0   \n",
       "30940  0.0151   5.0    A  0.189   0.8           14.0            14.0   \n",
       "30941  0.0151   5.0    A  0.194   0.8           14.0            14.0   \n",
       "30942  0.0151   5.0    A  0.195   0.8           14.0            14.0   \n",
       "30943  0.0151   5.0    A  0.221   0.8           14.0            14.0   \n",
       "30944  0.0151   5.0    A  0.238   0.8           14.0            14.0   \n",
       "30945  0.0151   5.0    A  0.234   0.8           14.0            14.0   \n",
       "30946  0.0151   5.0    A  0.242   0.8           14.0            14.0   \n",
       "30947  0.0151   5.0    A  0.257   0.7           14.0            14.0   \n",
       "30948  0.0151   5.0    A  0.264   0.7           14.0            14.0   \n",
       "30949  0.0151   5.0    A  0.244   0.8           14.0            14.0   \n",
       "30950  0.0151   5.0    O  0.115   0.9           14.0            14.0   \n",
       "30951  0.0151   5.0    A  0.164   0.8           14.0            14.0   \n",
       "30952  0.0151   5.0    A  0.191   0.8           14.0            14.0   \n",
       "30953  0.0151   5.0    A  0.188   0.8           14.0            14.0   \n",
       "30954  0.0151   5.0    A  0.179   0.8           14.0            14.0   \n",
       "30955  0.0151   5.0    A  0.186   0.8           14.0            14.0   \n",
       "30956  0.0151   5.0    A  0.194   0.8           14.0            14.0   \n",
       "30957  0.0151   5.0    A  0.209   0.8           14.0            14.0   \n",
       "30958  0.0151   5.0    A  0.214   0.8           14.0            14.0   \n",
       "30959  0.0151   5.0    A  0.218   0.8           14.0            14.0   \n",
       "30960  0.0151   5.0    A  0.212   0.8           14.0            14.0   \n",
       "30961  0.0151   5.0    A  0.217   0.8           14.0            14.0   \n",
       "\n",
       "       SUM_LINK    DATE_OF_ENTRY_y  \n",
       "30938       NaN  11/11/11 00:00:00  \n",
       "30939       NaN  11/11/11 00:00:00  \n",
       "30940       NaN  11/11/11 00:00:00  \n",
       "30941       NaN  11/11/11 00:00:00  \n",
       "30942       NaN  11/11/11 00:00:00  \n",
       "30943       NaN  11/11/11 00:00:00  \n",
       "30944       NaN  11/11/11 00:00:00  \n",
       "30945       NaN  11/11/11 00:00:00  \n",
       "30946       NaN  11/11/11 00:00:00  \n",
       "30947       NaN  11/11/11 00:00:00  \n",
       "30948       NaN  11/11/11 00:00:00  \n",
       "30949       NaN  11/11/11 00:00:00  \n",
       "30950       NaN  11/11/11 00:00:00  \n",
       "30951       NaN  11/11/11 00:00:00  \n",
       "30952       NaN  11/11/11 00:00:00  \n",
       "30953       NaN  11/11/11 00:00:00  \n",
       "30954       NaN  11/11/11 00:00:00  \n",
       "30955       NaN  11/11/11 00:00:00  \n",
       "30956       NaN  11/11/11 00:00:00  \n",
       "30957       NaN  11/11/11 00:00:00  \n",
       "30958       NaN  11/11/11 00:00:00  \n",
       "30959       NaN  11/11/11 00:00:00  \n",
       "30960       NaN  11/11/11 00:00:00  \n",
       "30961       NaN  11/11/11 00:00:00  \n",
       "\n",
       "[24 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] < 1) & (tfm.dfs[grp]['DW%'] > 0.001) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe533d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9824</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9825</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.78</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9828</th>\n",
       "      <td>SERPC1997003</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15257</th>\n",
       "      <td>SKRIL1999062</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15258</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>k40</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra226</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra228</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "9824   SERPC1997001   cs134     NaN           NaN         3.80       20.0   \n",
       "9825   SERPC1997001   cs137     NaN           NaN       389.00        4.0   \n",
       "9826   SERPC1997002   cs134     NaN           NaN         4.78       13.0   \n",
       "9827   SERPC1997002   cs137     NaN           NaN       420.00        4.0   \n",
       "9828   SERPC1997003   cs134     NaN           NaN         3.12       17.0   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "15257  SKRIL1999062   th228       1           NaN        68.00        NaN   \n",
       "15258  SKRIL1999063     k40       1           NaN      1210.00        NaN   \n",
       "15259  SKRIL1999063   ra226  KRIL01           NaN        56.50        NaN   \n",
       "15260  SKRIL1999063   ra228  KRIL01           NaN        72.20        NaN   \n",
       "15261  SKRIL1999063   th228       1           NaN        74.20        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "9824            NaN         5.75        NaN             NaN  ...     2.0   \n",
       "9825            NaN       589.00        NaN             NaN  ...     2.0   \n",
       "9826            NaN        12.00        NaN             NaN  ...     4.0   \n",
       "9827            NaN      1060.00        NaN             NaN  ...     4.0   \n",
       "9828            NaN        12.00        NaN             NaN  ...     6.0   \n",
       "...             ...          ...        ...             ...  ...     ...   \n",
       "15257           NaN          NaN        NaN             NaN  ...    15.0   \n",
       "15258           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15259           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15260           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15261           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "\n",
       "        AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "9824   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9825   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9826   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9827   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9828   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "...      ...   ...  ...  ...   ...            ...             ...       ...   \n",
       "15257  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15258  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15259  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15260  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15261  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "\n",
       "      DATE_OF_ENTRY_y  \n",
       "9824              NaN  \n",
       "9825              NaN  \n",
       "9826              NaN  \n",
       "9827              NaN  \n",
       "9828              NaN  \n",
       "...               ...  \n",
       "15257             NaN  \n",
       "15258             NaN  \n",
       "15259             NaN  \n",
       "15260             NaN  \n",
       "15261             NaN  \n",
       "\n",
       "[302 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357222d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>BIOTATYPE</th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>NO</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.60</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>W</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>W</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "5971  BERPC1997002     k40    NaN           NaN       116.00     W     3.0   \n",
       "5972  BERPC1997002   cs137    NaN           NaN        12.60     W     4.0   \n",
       "5973  BERPC1997002   cs134    NaN           NaN         0.14     W    18.0   \n",
       "5974  BERPC1997001     k40    NaN           NaN       116.00     W     4.0   \n",
       "5975  BERPC1997001   cs137    NaN           NaN        12.00     W     4.0   \n",
       "5976  BERPC1997001   cs134    NaN           NaN         0.21     W    24.0   \n",
       "\n",
       "      NUMBER DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE   NO  LENGTH  \\\n",
       "5971     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5972     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5973     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5974     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5975     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5976     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "\n",
       "      WEIGHT  DW% LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \n",
       "5971     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5972     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5973     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5974     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5975     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5976     0.0  0.0  0.0           11.0               11              NaN  \n",
       "\n",
       "[6 rows x 33 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='biota'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb8c80",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b11a0",
   "metadata": {},
   "source": [
    "TODO : Should we manually extract the 'Counting method ID' from 'measurenote' (i.e. the HELCOM METHOD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785783d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50db5f6",
   "metadata": {},
   "source": [
    "TODO: : Include CompareDfsAndTfmCB Callback in Transformer Callbacks System.\n",
    "\n",
    "Description : I would like to include the  CompareDfsAndTfmCB in the Callback class. This callback will be helpful for identifying and analyzing data dropped during transformations, aiding in debugging and ensuring data integrity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213d2a0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be025c9",
   "metadata": {},
   "source": [
    "TODO: The description for the 'Sample area; variable states 'Sample surface area of sediment (cm2)'.\n",
    "In the MARIS LUT we have a 'dbo_area.xlsx' LUT which includes the IHO sea areas. \n",
    "1) What does the variable 'Sample area' represent for Open Refine and is it the same for NetCDF?\n",
    "2) The HELCOM data reports the sediment activity concentration as both Bq per mass and Bq per area. Would you like to include both entires in MARIS? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['sediment'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40a304",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

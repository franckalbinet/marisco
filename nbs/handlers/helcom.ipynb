{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "> Data pipeline (handler) to convert HELCOM data ([source](https://helcom.fi/about-us)) to `NetCDF` format or `Open Refine` format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5eece",
   "metadata": {},
   "source": [
    "<!-- ## HELCOM MORS Environment database -->\n",
    "\n",
    "[Helcom MORS data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "Example steps:\n",
    "1. Download data (e.g. https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24). \n",
    "2. Install mdbtools via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In VS code terminal, navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip MORS_ENVIRONMENT.zip \n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run preprocess.sh to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ````\n",
    "7. Conetens of 'preprocess.sh' script.\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c4c6b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd # Python package that provides fast, flexible, and expressive data structures.\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Python Progress Bar Library\n",
    "from functools import partial # Function which Return a new partial object which when called will behave like func called with the positional arguments args and keyword arguments keywords\n",
    "import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.\n",
    "from pathlib import Path # This module offers classes representing filesystem paths\n",
    "from dataclasses import asdict\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, match_maris_lut, Match)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, SanitizeLonLatCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (base_path, nc_tpl_path, cfg, cache_path, cdl_cfg, Enums, lut_path,\n",
    "                             species_lut_path, sediments_lut_path, bodyparts_lut_path, \n",
    "                             detection_limit_lut_path, filtered_lut_path, area_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder\n",
    "from collections.abc import Callable\n",
    "from math import modf\n",
    "import warnings\n",
    "from marisco.netcdf_to_csv import (LookupTimeFromEncodedTime, GetSampleTypeCB,\n",
    "                                   LookupNuclideByIdCB, ConvertLonLatCB, LookupUnitByIdCB,\n",
    "                                   LookupValueTypeByIdCB, LookupSpeciesByIdCB, \n",
    "                                   LookupBodypartByIdCB, LookupSedimentTypeByIdCB)                                  \n",
    "from marisco.serializers import OpenRefineCsvEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc705a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed39cdd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a65e9b",
   "metadata": {},
   "source": [
    "##  MARIS NetCDF \n",
    "When MARISCO is installed, it uses `cdl.toml` to create the `maris-template.nc`, which acts as a standardized template for MARIS NetCDF files. The `cdl.toml` is a configuration file listing all the variables allowed in the NetCDF4 files. The contents of the cdl.toml can be retrieved with the function `cdl_cfg()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907924b",
   "metadata": {},
   "source": [
    "Retrieving the keys of the `cdl_cfg()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50406959",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cdl_cfg()['vars'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32b0fd",
   "metadata": {},
   "source": [
    "Printing the contents of all keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cdl_cfg()['vars']['defaults'].keys())\n",
    "print (cdl_cfg()['vars']['bio'].keys())\n",
    "print (cdl_cfg()['vars']['sed'].keys())\n",
    "print (cdl_cfg()['vars']['suffixes'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5519f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78f26f",
   "metadata": {},
   "source": [
    "## MARIS Open Refine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c37687",
   "metadata": {},
   "source": [
    "Currently, updates to the MARIS database are facilitated through a standardized CSV file using Open Refine. Description of the variables included in this CSV file are provided at [Maris](https://maris.iaea.org/help/1132).\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe953fc7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f31d33",
   "metadata": {},
   "source": [
    "## MARIS Open Refine CSV & MARIS NetCDF variable relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fc4c6",
   "metadata": {},
   "source": [
    "The table below lists the MARIS variables in both MARIS Open Refine and MARIS NetCDF formats. Each variable's presence in both formats for the seawater (``sea``), biota (``bio``), and sediment (``sed``) groups is indicated with a checkmark (``✓``)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65a7c1",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "  table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse\n",
    "  }\n",
    "\n",
    "  td,\n",
    "  th {\n",
    "    border: 1px solid #000;\n",
    "    padding: 5px;\n",
    "    text-align: center\n",
    "  }\n",
    "\n",
    "  th {\n",
    "    background-color: #f2f2f2\n",
    "  }\n",
    "\n",
    "  .open-refine {\n",
    "    background-color: #fff;\n",
    "    color: black;\n",
    "    text-align: center\n",
    "\n",
    "  }\n",
    "\n",
    "  .netcdf {\n",
    "    background-color: #e6e6e6;\n",
    "    color: black;\n",
    "    text-align: center\n",
    "  }\n",
    "</style>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"open-refine\">Open Refine Variables</th>\n",
    "      <th class=\"open-refine\">sea</th>\n",
    "      <th class=\"open-refine\">bio</th>\n",
    "      <th class=\"open-refine\">sed</th>\n",
    "      <th class=\"netcdf\">sea</th>\n",
    "      <th class=\"netcdf\">bio</th>\n",
    "      <th class=\"netcdf\">sed</th>\n",
    "      <th class=\"netcdf\">NetCDF Variables</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample type</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">*Included as netcdf.group*</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Latitude decimal</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">lat</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Longitude decimal</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">lon</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling start date</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">time</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling start time</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">time</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling end date</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling end time</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Nuclide</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">nuclide</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Value type</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">detection_limit</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Unit</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">unit</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Activity or MDA</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">value</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Uncertainty</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">uncertainty</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling depth</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">smp_depth</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Top</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Bottom</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Species</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">species</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Body part</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">body_part</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">bio_group</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Salinity</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">salinity</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Temperature</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">temperature</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Filtered</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">filtered</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Mesh size</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Quality flag</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sediment type</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sed_type</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Dry weight</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Wet weight</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Dry/wet ratio</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Station ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">data_provider_sample_id</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Total depth</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">tot_depth</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Profile or transect ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sampling_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Preparation method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">preparation_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Drying method</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Counting method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">counting_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample notes</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sample_notes<sup>*1</sup></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Measurement notes</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">measurement_notes<sup>*1</sup></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcd47a",
   "metadata": {},
   "source": [
    "<sup>*1</sup> The MARIS NetCDF does not currently support strings of variable length (i.e. vlen string data type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc6103",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "1. **fname_in** - is the path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "2. **fname_out_nc** - is the path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "3. **Zotero key** - is used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "fname_out_csv = '../../_data/output/100-HELCOM-MORS-2024.csv'\n",
    "zotero_key ='26VMZZ2Q'\n",
    "ref_id = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf9628",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd04abcd",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(src_dir,\n",
    "                smp_types=['SEA', 'SED', 'BIO']):\n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type\"\n",
    "    dfs = {}\n",
    "    lut_smp_type = {'SEA': 'seawater', 'SED': 'sediment', 'BIO': 'biota'}\n",
    "    for smp_type in smp_types:\n",
    "        fname_meas = smp_type + '02.csv' # measurement (i.e. radioactivity) information.\n",
    "        fname_smp = smp_type + '01.csv' # sample information \n",
    "        df = pd.merge(pd.read_csv(Path(src_dir)/fname_meas),  # measurements\n",
    "                      pd.read_csv(Path(src_dir)/fname_smp),  # sample\n",
    "                      on='KEY', how='left')\n",
    "        dfs[lut_smp_type[smp_type]] = df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bb0fd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e534545",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print(dfs.keys())\n",
    "print(f\"Seawater cols: {dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785805a",
   "metadata": {},
   "source": [
    "Show the structure of the `seawater` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9aeb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423d697",
   "metadata": {},
   "source": [
    "Show the structure of the `biota` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac781a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['biota'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840141d5",
   "metadata": {},
   "source": [
    "Show the structure of the `sediment` dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6013611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['sediment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f3eef",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d68abc3",
   "metadata": {},
   "source": [
    "## Data transformation pipeline for NetCDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd7de4",
   "metadata": {},
   "source": [
    "### Data transformation pipeline utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ceb64d",
   "metadata": {},
   "source": [
    "``CompareDfsAndTfm`` compares the original dataframes to the transformed dataframe. A dictionary of dataframes, ``tfm.dfs_dropped``, is created to include the data present in the original dataset but absent from the transformed data. ``tfm.compare_stats`` provides a quick overview of the number of rows in both the original dataframes and the transformed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae81009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class CompareDfsAndTfm(Callback):\n",
    "    \"Create a dfs of dropped data. Data included in the DFS not in the TFM\"\n",
    "    def __init__(self, dfs_compare):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs_dropped={}\n",
    "        tfm.compare_stats={}\n",
    "        for grp in tfm.dfs.keys():\n",
    "           \n",
    "            # get the index values in dfs (i.e. dfs_compare) not in tfm.dfs. \n",
    "            index_diff=self.dfs_compare[grp].index.difference(tfm.dfs[grp].index)\n",
    "            tfm.dfs_dropped[grp] = self.dfs_compare[grp].loc[index_diff]\n",
    "\n",
    "            tfm.compare_stats[grp]= {'Number of rows in dfs :' : len(self.dfs_compare[grp].index),\n",
    "                                     'Number of rows in tfm.dfs:' : len(tfm.dfs[grp].index),\n",
    "                                     'Number of dropped rows:' : len(tfm.dfs_dropped[grp].index),\n",
    "                                     'Number of rows in tfm.dfs + Number of dropped rows:' : len(tfm.dfs[grp].index) + len(tfm.dfs_dropped[grp].index)\n",
    "                                    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b690d9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``nuclide``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b23c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Nuclide``.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "#### Lower & strip nuclide names\n",
    "\n",
    "Create a callback function, `LowerStripRdnNameCB`, that receives a dictionary of dataframes. For each dataframe in the dictionary, it converts the contents of the `Nuclides` column to lowercase and removes any leading or trailing whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LowerStripRdnNameCB(Callback):\n",
    "    \"Convert nuclide names to lowercase & strip any trailing space(s)\"\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].apply(\n",
    "                lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb73d9",
   "metadata": {},
   "source": [
    "Here we call a transformer, which applies the callback (e.g. `LowerStripRdnNameCB`) to the dictionary of dataframes, `dfs`. We then print the unique entries of the transformed `NUCLIDE` column for each dataframe included in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB()])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm()['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "#### Remap HELCOM nuclide names to MARIS nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9905c7",
   "metadata": {},
   "source": [
    "The `maris-template.nc` file, which  is created from the `cdl.toml` on installation of the Marisco package, provides details of the nuclides permitted in the  MARIS NetCDF file. Here we define a function  `get_unique_nuclides()` which creates a list of the unique nuclides from each dataframe in the dictionary of dataframes `dfs`. The function `has_valid_varname` checks that each nuclide in this list is included in the `maris-template.nc` (i.e. the `cdl.toml`). `has_valid_varname` returns all variables in the list that are not in the `maris-template.nc` or returns `True`. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf213bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unique_nuclides(dfs):\n",
    "    \"Get list of unique radionuclide types measured across samples.\"\n",
    "    nuclides = []\n",
    "    for k in dfs.keys():\n",
    "        nuclides += dfs[k]['NUCLIDE'].unique().tolist()\n",
    "    # remove duplicates from nuclides list.\n",
    "    nuclides=list(set(nuclides))\n",
    "    return nuclides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68dacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# Check if these variable names are consistent with MARIS CDL\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501bd59",
   "metadata": {},
   "source": [
    "Many nuclide names are not listed in the `maris-template.nc`. Here we create a look up table, `varnames_lut_updates`, which will be used to correct the nuclide names in the dictionary of dataframes (i.e. dfs) that are not compatible with the `maris-template.nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "varnames_lut_updates = {\n",
    "    'k-40': 'k40',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs138': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs140': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs143': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs146': 'cs137'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b877d3d",
   "metadata": {},
   "source": [
    "Function `get_varnames_lut` returns a dictionary of nuclide names. This dictionary includes the `NUCLIDE` names from the dataframes in dfs, along with corrections specified in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f89931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_varnames_lut(dfs, lut=varnames_lut_updates):\n",
    "    lut = {n: n for n in set(get_unique_nuclides(dfs))}\n",
    "    lut.update(varnames_lut_updates)\n",
    "    return lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d2ea0",
   "metadata": {},
   "source": [
    "Create a callback that remaps the nuclide names in the dataframes within dfs to the updated names in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapRdnNameCB(Callback):\n",
    "    \"Remap to MARIS radionuclide names.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=partial(get_varnames_lut, lut=varnames_lut_updates)):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut(tfm.dfs)\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['NUCLIDE'].replace(lut, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa0d93",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB` and `RemapRdnNameCB`. Then, print the unique nuclides for each dataframe in the dictionary dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c075d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            #CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "\n",
    "#print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('seawater nuclides: ')\n",
    "print(tfm.dfs['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm.dfs['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm.dfs['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9359a",
   "metadata": {},
   "source": [
    "After apply correction to the nuclide names check that all nuclide in the dictionary of dataframees are valid. Returns `True` if all are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c644322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca601fc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23281e3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: `time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691210e1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83309a2",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParseTimeCB(Callback):\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # get 'time' from 'DATE' column\n",
    "            tfm.dfs[grp]['time'] = pd.to_datetime(tfm.dfs[grp]['DATE'], format='%m/%d/%y %H:%M:%S')\n",
    "            # if 'DATE' column is nan, get 'time' from 'YEAR','MONTH' and 'DAY' column. \n",
    "            # if 'DAY' or 'MONTH' is 0 then set it to 1. \n",
    "            tfm.dfs[grp].loc[tfm.dfs[grp][\"DAY\"] == 0, \"DAY\"] = 1\n",
    "            tfm.dfs[grp].loc[tfm.dfs[grp][\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "            \n",
    "            # if 'DAY' and 'MONTH' is nan but YEAR is not nan then set 'DAY' and 'MONTH' both to 1. \n",
    "            condition = (tfm.dfs[grp][\"DAY\"].isna()) & (tfm.dfs[grp][\"MONTH\"].isna()) & (tfm.dfs[grp][\"YEAR\"].notna())\n",
    "            tfm.dfs[grp].loc[condition, \"DAY\"] = 1\n",
    "            tfm.dfs[grp].loc[condition, \"MONTH\"] = 1\n",
    "            \n",
    "            \n",
    "            condition = tfm.dfs[grp]['DATE'].isna() # if 'DATE' is nan. \n",
    "            tfm.dfs[grp]['time']  = np.where(condition,\n",
    "                                             # 'coerce', then invalid parsing will be set as NaT. NaT will result if the number of days are not valid for the month.\n",
    "                                            pd.to_datetime(tfm.dfs[grp][['YEAR', 'MONTH', 'DAY']], format='%y%m%d', errors='coerce'),  \n",
    "                                            pd.to_datetime(tfm.dfs[grp]['DATE'], format='%m/%d/%y %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB` and `ParseTimeCB`. Then, print the `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            #CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "#print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['seawater']['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e52eb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2c925",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``time``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e7277",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg(), verbose = True),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7099e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm.dfs_dropped['sediment'][['YEAR', 'MONTH', 'DAY', 'DATE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba93b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "### Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12185ee",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``uncertainty``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b02a81",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Uncertainty`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` coverts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Make measurement and uncertainty units consistent\n",
    "def unc_rel2stan(df, meas_col, unc_col):\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col]/100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the uncertainty is given as a relative uncertainty to the value (i.e., activity). The column names for both the value and the uncertainty vary by sample type. The coi_units_unc dictionary defines the column names for the Value and Uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncUnitCB callback normalizes the uncertainty by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormalizeUncUnitCB(Callback):\n",
    "    \"Convert from relative error % to uncertainty of activity unit\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc=unc_rel2stan,\n",
    "                 coi=coi_units_unc):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp, val, unc in self.coi:\n",
    "            tfm.dfs[grp][unc] = self.fn_convert_unc(tfm.dfs[grp], val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB` and `NormalizeUncUnitCB()`. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB()])\n",
    "\n",
    "print(tfm()['seawater'][['VALUE_Bq/m³', 'ERROR%_m³']][:5])\n",
    "print(tfm()['biota'][['VALUE_Bq/kg', 'ERROR%']][:5])\n",
    "print(tfm()['sediment'][['VALUE_Bq/kg', 'ERROR%_kg']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8540",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "### Lookup transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f44637",
   "metadata": {},
   "source": [
    "#### Lookup MARIS function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6e294",
   "metadata": {},
   "source": [
    "`get_maris_lut` performs a lookup of data provided in `data_provider_lut` against the MARIS lookup (`maris_lut`) using a fuzzy matching algorithm based on Levenshtein distance. The `get_maris_lut` is used to correct the HELCOM data to a standard format for MARIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f0c03-7666-461d-a5ce-d0021bc9e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_maris_lut(fname_in, \n",
    "                  fname_cache, # For instance 'species_helcom.pkl'\n",
    "                  data_provider_lut:str, # Data provider lookup table name\n",
    "                  data_provider_id_col:str, # Data provider lookup column id of interest\n",
    "                  data_provider_name_col:str, # Data provider lookup column name of interest\n",
    "                  maris_lut:Callable, # Function retrieving MARIS source lookup table\n",
    "                  maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "                  maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "                  unmatched_fixes={},\n",
    "                  as_dataframe=False,\n",
    "                  overwrite=False\n",
    "                 ):\n",
    "    fname_cache = cache_path() / fname_cache\n",
    "    lut = {}\n",
    "    maris_lut = maris_lut()\n",
    "    df = pd.read_csv(Path(fname_in) / data_provider_lut)\n",
    "    if overwrite or (not fname_cache.exists()):\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "            # Fix if unmatched\n",
    "            has_to_be_fixed = row[data_provider_id_col] in unmatched_fixes            \n",
    "            name_to_match = unmatched_fixes[row[data_provider_id_col]] if has_to_be_fixed else row[data_provider_name_col]\n",
    "\n",
    "            # Match\n",
    "            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)\n",
    "            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], \n",
    "                          row[data_provider_name_col], result.iloc[0]['score'])\n",
    "            \n",
    "            lut[row[data_provider_id_col]] = match\n",
    "        fc.save_pickle(fname_cache, lut)\n",
    "    else:\n",
    "        lut = fc.load_pickle(fname_cache)\n",
    "\n",
    "    if as_dataframe:\n",
    "        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()\n",
    "        df_lut.index.name = 'source_id'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)\n",
    "    else:\n",
    "        return lut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5868c16b",
   "metadata": {},
   "source": [
    "#### Lookup : Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2bbb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``species``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19098ae",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Species`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40671f8f",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `RUBIN_NAME.csv` file for biota species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "df_rubin = pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')\n",
    "df_rubin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa8871",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_species` to correct the spelling of names that are unmatched in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acca89-169a-45eb-98fe-cf7c7b2ee0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_species = {\n",
    "    'CARD EDU': 'Cerastoderma edule',\n",
    "    'LAMI SAC': 'Saccharina latissima',\n",
    "    'PSET MAX': 'Scophthalmus maximus',\n",
    "    'STIZ LUC': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adaa417-6b01-45d8-80d7-2e3d97cb0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "species_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='species_helcom.pkl', \n",
    "                               data_provider_lut='RUBIN_NAME.csv',\n",
    "                               data_provider_id_col='RUBIN',\n",
    "                               data_provider_name_col='SCIENTIFIC NAME',\n",
    "                               maris_lut=species_lut_path,\n",
    "                               maris_id='species_id',\n",
    "                               maris_name='species',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915a7fc",
   "metadata": {},
   "source": [
    "Display `species_lut_df`. The `match_score` represents the number insertions, deletions, or substitutions needed to transform from the HECOM source name (`source_name`) to the maris name, (`matched_maris_name`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341f814-3343-47b7-958c-5df7d34a683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "species_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557931bd",
   "metadata": {},
   "source": [
    "Show `species_lut_df` where `match_type` is not a perfect match ( i.e. not equal 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_lut_df[species_lut_df['match_score'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900eb6",
   "metadata": {},
   "source": [
    "`LookupBiotaSpeciesCB` applies the corrected `biota` `species` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2798566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaSpeciesCB(Callback):\n",
    "    \"\"\"\n",
    "    Biota species remapped to MARIS db:\n",
    "        CARD EDU: Cerastoderma edule\n",
    "        LAMI SAC: Saccharina latissima\n",
    "        PSET MAX: Scophthalmus maximus\n",
    "        STIZ LUC: Sander luciopercas\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: lut[x.strip()].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98d51",
   "metadata": {},
   "source": [
    "`get_maris_species` defines a partial function of `get_maris_lut`, with predefined arguments  for species lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddf185-8ee8-4cb0-abd6-427fe4e52c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_species = partial(get_maris_lut,\n",
    "                            fname_in, fname_cache='species_helcom.pkl', \n",
    "                            data_provider_lut='RUBIN_NAME.csv',\n",
    "                            data_provider_id_col='RUBIN',\n",
    "                            data_provider_name_col='SCIENTIFIC NAME',\n",
    "                            maris_lut=species_lut_path,\n",
    "                            maris_id='species_id',\n",
    "                            maris_name='species',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18132f3",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()` and `LookupBiotaSpeciesCB(get_maris_species)`. Then, print the unique `species` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ffe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species)\n",
    "                            ])\n",
    "\n",
    "#print(tfm()['biota'][['RUBIN', 'species']][:10])\n",
    "print(tfm()['biota']['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0faa085",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "#### Lookup : Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92384b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``body_part``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7388fd",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Body part`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31449525",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `TISSUE.csv` file for biota tissues. Biota tissue is known as `body part` in the maris data set.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6a4e9",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_tissues` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {\n",
    "    3: 'Whole animal eviscerated without head',\n",
    "    12: 'Viscera',\n",
    "    8: 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a502e-3826-404c-84e1-0d60b4be0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='tissues_helcom.pkl', \n",
    "                               data_provider_lut='TISSUE.csv',\n",
    "                               data_provider_id_col='TISSUE',\n",
    "                               data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                               maris_lut=bodyparts_lut_path,\n",
    "                               maris_id='bodypar_id',\n",
    "                               maris_name='bodypar',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c1a7d-ba91-4400-ba0a-bad180eee1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811aa06",
   "metadata": {},
   "source": [
    "`LookupBiotaBodyPartCB` applies the corrected `biota` `TISSUE` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    \"\"\"\n",
    "    Update bodypart id based on MARIS dbo_bodypar.xlsx:\n",
    "        - 3: 'Whole animal eviscerated without head',\n",
    "        - 12: 'Viscera',\n",
    "        - 8: 'Skin'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: lut[x].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a3904",
   "metadata": {},
   "source": [
    "`get_maris_bodypart` defines a partial function of `get_maris_lut`, with predefined arguments  for  `TISSUE` (or `bodypar`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460dc4c-6927-460f-924f-322606ad903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_bodypart = partial(get_maris_lut,\n",
    "                             fname_in,\n",
    "                             fname_cache='tissues_helcom.pkl', \n",
    "                             data_provider_lut='TISSUE.csv',\n",
    "                             data_provider_id_col='TISSUE',\n",
    "                             data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                             maris_lut=bodyparts_lut_path,\n",
    "                             maris_id='bodypar_id',\n",
    "                             maris_name='bodypar',\n",
    "                             unmatched_fixes=unmatched_fixes_biota_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877064bf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)` and `LookupbioooooooootaBodyPartCB(get_maris_bodypart)`. Then, print the `TISSUE` and `body_part` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a195f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'][['TISSUE', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718285f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "#### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513576a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``bio_group``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421826",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Biogroup is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_biogroup_lut(maris_lut):\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291637e",
   "metadata": {},
   "source": [
    "`LookupBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class LookupBiogroupCB(Callback):\n",
    "    \"\"\"\n",
    "    Update biogroup id  based on MARIS dbo_species.xlsx\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: lut[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f2d40",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)` and `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` . Then, print the `bio_group` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                            \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158b423",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "#### Lookup : Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1fe91",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `SEDIMENT_TYPE.csv` file for Sediment types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169727",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sed_type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be172080",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Sediment type`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7665a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "df_sediment = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "df_sediment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dba05",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_sediments` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553b9bf-d305-456f-9bf1-620f2804637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_sediments = {\n",
    "    #np.nan: 'Not applicable',\n",
    "    -99: '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c716f-d2de-455f-b58f-22af28ca01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "sediments_lut_df = get_maris_lut(\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments,\n",
    "    as_dataframe=True,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17cfe1",
   "metadata": {},
   "source": [
    "`get_maris_sediments` defines a partial function of `get_maris_lut`, with predefined arguments  for  `SEDI` (or `sedtype`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053bfbb-8f04-434c-a8a1-35b4d58dd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_sediments = partial(\n",
    "    get_maris_lut,\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528f164",
   "metadata": {},
   "source": [
    "`LookupSedimentCB` applies the corrected `sediment` `SEDI` data obtained from the `get_maris_lut` function to the `sediment` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fb63d-2459-4497-9086-bb98ccd524e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupSedimentCB(Callback):\n",
    "    \"\"\"\n",
    "    Update sediment id  based on MARIS dbo_sedtype.xlsx\n",
    "        -99: '(Not available)'\n",
    "        - na: '(Not available)'\n",
    "        - 56: '(Not available)'\n",
    "        - 73: '(Not available)'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "\n",
    "        # To check with Helcom\n",
    "        tfm.dfs['sediment']['SEDI'] = dfs['sediment']['SEDI'].fillna(-99).astype('int')\n",
    "        tfm.dfs['sediment']['SEDI'].replace(56, -99, inplace=True)\n",
    "        tfm.dfs['sediment']['SEDI'].replace(73, -99, inplace=True)\n",
    "        \n",
    "        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: lut[x].matched_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131e929",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)` and `LookupSedimentCB(get_maris_sediments)`. Then, print the `SEDI` and `sed_type` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d42cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['sediment'][['SEDI', 'sed_type']][:5])\n",
    "print(tfm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d5871",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "#### Lookup : Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a777c3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebee28",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "Create `renaming_unit_rules` to rename the units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {'seawater' : 1, #  'Bq/m3'\n",
    "                       'sediment' : 4, # 'Bq/kgd' for sediment (see https://maps.helcom.fi/website/download/MORS_ENVIRONMENT_Reporting_form.xlsx)\n",
    "                       'biota': {'D' : 4, # 'Bq/kgd'\n",
    "                                 'W' : 5, # 'Bq/kgw'\n",
    "                                 'F' : 5 # 'Bq/kgw' !assumed to be 'Fresh' so set to wet. .  \n",
    "                                 } } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12793b79",
   "metadata": {},
   "source": [
    "`LookupUnitCB` defines a `unit` column each dataframe based on the units provided in the value (`VALUE_Bq/m³` or `VALUE_Bq/kg`) column of the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    def __init__(self,\n",
    "                 renaming_unit_rules=renaming_unit_rules):\n",
    "        fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            \n",
    "            if grp == 'biota':\n",
    "                lut=renaming_unit_rules[grp]\n",
    "                # lookup value in the 'BASIS' column to determine the unit. \n",
    "                tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut[x] if x in lut.keys() else 0 )\n",
    "            else:                 \n",
    "                tfm.dfs[grp]['unit'] = renaming_unit_rules[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` and `LookupUnitCB()`. Then, print the unique `unit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB()])\n",
    "\n",
    "print(tfm()['biota']['unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422eeb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "#### Lookup : Detection limit or Value type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c95ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``detection_limit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fd987",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine foramt variable: ``Value type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3a699",
   "metadata": {},
   "source": [
    "Create `coi_dl` to define the column names related to Value type for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_dl = {'seawater' : { 'val' : 'VALUE_Bq/m³',\n",
    "                        'unc' : 'ERROR%_m³',\n",
    "                        'dl' : '< VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg',\n",
    "                            'unc' : 'ERROR%',\n",
    "                            'dl' : '< VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg',\n",
    "                              'unc' : 'ERROR%_kg',\n",
    "                              'dl' : '< VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290b3fa",
   "metadata": {},
   "source": [
    "`get_detectionlimit_lut` reads the file at `detection_limit_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`.\n",
    "| id | name | name_sanitized |\n",
    "| :-: | :-: | :-: |\n",
    "|-1|Not applicable|Not applicable|\n",
    "|0|Not Available|Not available|\n",
    "|1|=|Detected value|\n",
    "|2|<|Detection limit|\n",
    "|3|ND|Not detected|\n",
    "|4|DE|Derived|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_detectionlimit_lut():\n",
    "    df = pd.read_excel(detection_limit_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`LookupDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or detection limit) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg>` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    def __init__(self ,\n",
    "                 coi=coi_dl,\n",
    "                 fn_lut=get_detectionlimit_lut\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # Copy dl col \n",
    "            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp][self.coi[grp]['dl']]\n",
    "            # Fill values with '=' if both a value and uncertainty are not nan and detection_limit is not in the list of keys returned from lut.\n",
    "            condition = ((tfm.dfs[grp][self.coi[grp]['val']].notna()) & (tfm.dfs[grp][self.coi[grp]['unc']].notna())) & (~tfm.dfs[grp][\"detection_limit\"].isin(list(lut.keys())))\n",
    "            tfm.dfs[grp].loc[condition, 'detection_limit']= '='\n",
    "            # Fill values that are not in the lut with 'Not Available'.\n",
    "            tfm.dfs[grp].loc[~tfm.dfs[grp][\"detection_limit\"].isin(list(lut.keys())), \"detection_limit\"] = 'Not Available'\n",
    "            # Perform lookup\n",
    "            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp]['detection_limit'].apply(lambda x: lut[x])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66db5cf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()` and `LookupDetectionLimitCB`. Then, print the unique `detection_limit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB()])\n",
    "\n",
    "print(tfm()['seawater']['detection_limit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb3b44",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9114d",
   "metadata": {},
   "source": [
    "#### Lookup : Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef2b9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *NetCDF4 format variables: ``counting_method``, ``sampling_method`` and ``preparation_method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200156a7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sampling method``,\t``Preparation method`` and ``Counting method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4052e59",
   "metadata": {},
   "source": [
    "> 'Method' is provided in the HELCOM data but some work is required to link it to MARIS 'counting_method', 'sampling_method' and 'preparation_method'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084de15c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "### Data provider sample id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7b8a4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``data_provider_sample_id``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018492bf",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3238f",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format for variable type ``data_provider_sample_id`` does not support vlen strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapDataProviderSampleIdCB(Callback):\n",
    "    \"Remap key to MARIS data_provider_sample_id format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # data_provider_sample_id\n",
    "            tfm.dfs[grp]['data_provider_sample_id'] = tfm.dfs[grp]['KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['data_provider_sample_id'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf5780",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "### Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c3ba",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13e4ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84079a35",
   "metadata": {},
   "source": [
    "`get_filtered_lut` reads the file at `filtered_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_filtered_lut():\n",
    "    df = pd.read_excel(filtered_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9746673",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filtered_lut()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70453b9",
   "metadata": {},
   "source": [
    "Create  `renaming_rules` to rename the HELCOM data to the MARIS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_rules = {'N': 'No',\n",
    "                  'n': 'No',\n",
    "                  'F': 'Yes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`LookupFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupFiltCB(Callback):\n",
    "    \"Lookup FILT value.\"\n",
    "    def __init__(self ,\n",
    "                 rules=renaming_rules,\n",
    "                 fn_lut=get_filtered_lut\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        rules = self.rules\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if \"FILT\" in tfm.dfs[grp].columns:\n",
    "                # Fill values that are not in the renaming rules with 'Not Available'.\n",
    "                tfm.dfs[grp].loc[~tfm.dfs[grp][\"FILT\"].isin(list(rules.keys())), \"FILT\"] = 'Not available'\n",
    "                # Rename HELCOM format with MARIS format. \n",
    "                tfm.dfs[grp]['FILT'] = tfm.dfs[grp]['FILT'].apply(lambda x : rules[x] if x != 'Not available' else 'Not available')\n",
    "                # Perform lookup\n",
    "                tfm.dfs[grp]['FILT'] = tfm.dfs[grp]['FILT'].apply(lambda x : lut[x])                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625063c",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()`,  `LookupDetectionLimitCB` and `LookupFiltCB()`. Then, print the unique `FILT` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            LookupFiltCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['FILT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0502e9d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfe106",
   "metadata": {},
   "source": [
    "#### ~~Lookup : Area~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b0d3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``area``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e60cf4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Area is not included*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59862b",
   "metadata": {},
   "source": [
    "TODO : Write callback for area. Will I use the marineregions.org API to complete lookup? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfac24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#| export \n",
    "def get_area_lut():\n",
    "    df = pd.read_excel(area_lut_path(), usecols=['displayName','areaId'])\n",
    "    return df.set_index('displayName').to_dict()['areaId']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81152cc4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85a9ac",
   "metadata": {},
   "source": [
    "### ~~Sample Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a021f2a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sample_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba363cb2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample notes\n",
    "``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a3e6",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``sample_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64d446",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247b50a",
   "metadata": {},
   "source": [
    "### ~~Measurement Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93974d7e",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``measurement_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819c1f2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Measurement notes``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d993a77",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``measurement_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d452362",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa59a",
   "metadata": {},
   "source": [
    "### Station ID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e08cc9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Station ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ba42",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Station ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c799173",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Station ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapStationIdCB(Callback):\n",
    "    \"Remap Station ID to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['station_id'] = tfm.dfs[grp]['STATION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['station_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548633f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb378b1",
   "metadata": {},
   "source": [
    "### Profile ID, Transect ID or Sequence ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23069215",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Profile ID, Transect ID or Sequence ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abe1c5",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Profile or transect ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a497c",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Profile ID, Transect ID or Sequence ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapProfileIdCB(Callback):\n",
    "    \"Remap Profile ID to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['profile_or_transect_id'] = tfm.dfs[grp]['SEQUENCE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f09821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['profile_or_transect_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb97f00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "### Sediment slice position (top and bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb47624",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Top and Bottom is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533568d8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Top`` and ``Bottom``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3358f02",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include sediment slice top and bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs['sediment']['bottom'] = tfm.dfs['sediment']['LOWSLI']\n",
    "        tfm.dfs['sediment']['top'] = tfm.dfs['sediment']['UPPSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['sediment']['top'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96b18f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "### Dry to wet ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64f432",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: DW% is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0fd19",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Dry/wet ratio``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735dd22",
   "metadata": {},
   "source": [
    "HELCOM Description:\n",
    "\n",
    "**Sediment:**\n",
    "1. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "2. VALUE_Bq/kg: Measured radioactivity concentration in Bq/kg dry wt. in scientific format(e.g. 123 = 1.23E+02, 0.076 = 7.6E-02)\n",
    "\n",
    "**Biota:**\n",
    "1. WEIGHT: Average weight (in g) of specimen in the sample\n",
    "2. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDryWetRatio(Callback):\n",
    "    \"Lookup dry wet ratio and format for MARIS.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                tfm.dfs[grp]['dry_wet_ratio'] = tfm.dfs[grp]['DW%']\n",
    "                # Convert 'Dw%' = 0% to 'nan'.\n",
    "                tfm.dfs[grp].loc[tfm.dfs[grp]['dry_wet_ratio'] == 0, 'dry_wet_ratio'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                    \n",
    "\n",
    "print(tfm.dfs['biota']['dry_wet_ratio'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02488c00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3541d",
   "metadata": {},
   "source": [
    "### Capture Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c1fb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a07ea",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd85aa4",
   "metadata": {},
   "source": [
    "Use decimal degree coordinates if available; otherwise, convert from degree-minute format to decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00410917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest coordinates\n",
    "coi_coordinates = {'seawater' : { 'lon_d' : 'LONGITUDE (dddddd)', 'lat_d':'LATITUDE (dddddd)',\n",
    "                                 'lon_m' : 'LONGITUDE (ddmmmm)', 'lat_m':'LATITUDE (ddmmmm)'},\n",
    "                 'biota' : { 'lon_d' : 'LONGITUDE dddddd', 'lat_d':'LATITUDE dddddd',\n",
    "                                 'lon_m' : 'LONGITUDE ddmmmm', 'lat_m':'LATITUDE ddmmmm'},\n",
    "                 'sediment': { 'lon_d' : 'LONGITUDE (dddddd)', 'lat_d':'LATITUDE (dddddd)',\n",
    "                                 'lon_m' : 'LONGITUDE (ddmmmm)', 'lat_m':'LATITUDE (ddmmmm)'}\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ddmmmm2dddddd(ddmmmm):\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    # move 2 decimal place\n",
    "    mins = mins*100\n",
    "    return round((int(degs)+(float(mins)/60)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class FormatCoordinates(Callback):\n",
    "    \"Format coordinates for MARIS.\"\n",
    "    def __init__(self, \n",
    "                 coi: dict,\n",
    "                 fn_convert_cor\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # If coordinates with format dddddd (e.g. )\n",
    "            # Get coordinates from dddddd unless dddddd equals 0 or nan. \n",
    "            condition = ((tfm.dfs[grp][self.coi[grp]['lon_d']].isna()) | (tfm.dfs[grp][self.coi[grp]['lon_d']] == 0 )) | ((tfm.dfs[grp][self.coi[grp]['lat_d']].isna()) | (tfm.dfs[grp][self.coi[grp]['lat_d']] == 0 ))            \n",
    "            \n",
    "            \n",
    "            tfm.dfs[grp]['lon']  = np.where(condition,\n",
    "                                            tfm.dfs[grp][self.coi[grp]['lon_m']].apply(lambda x: self.fn_convert_cor(x)),\n",
    "                                            tfm.dfs[grp][self.coi[grp]['lon_d']])\n",
    "            \n",
    "            tfm.dfs[grp]['lat']  = np.where(condition,\n",
    "                                            tfm.dfs[grp][self.coi[grp]['lat_m']].apply(lambda x: self.fn_convert_cor(x)),\n",
    "                                            tfm.dfs[grp][self.coi[grp]['lat_d']])      \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7fc59",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754289f1",
   "metadata": {},
   "source": [
    "### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e413",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f808d23",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf2efc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320434d",
   "metadata": {},
   "source": [
    "### Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12783c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``value``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9c6e7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Activity or MDA``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ba17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_val = {'seawater' : { 'val' : 'VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SanitizeValue(Callback):\n",
    "    \"Sanitize value. Remove blank entries.\"\n",
    "    def __init__(self,\n",
    "                coi: dict):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            val = self.coi[grp]['val']\n",
    "            # Keep rows where either value (i.e. VALUE_Bq/m³ or VALUE_Bq/kg ) is not 'nan'\n",
    "            tfm.dfs[grp] = tfm.dfs[grp][tfm.dfs[grp][[val]].notna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_review=tfm.dfs_dropped['seawater']\n",
    "biota_review=tfm.dfs_dropped['biota']\n",
    "sediment_review=tfm.dfs_dropped['sediment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4485e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "### Review DFS and TFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_review=tfm.dfs_dropped['seawater']\n",
    "biota_review=tfm.dfs_dropped['biota']\n",
    "sediment_review=tfm.dfs_dropped['sediment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f6685",
   "metadata": {},
   "source": [
    "### Columns of interest and rename for NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af441203",
   "metadata": {},
   "source": [
    "> Column names are standardized to MARIS NetCDF format (i.e. PEP8 ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23653799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).\n",
    "def get_renaming_rules_netcdf():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    return {('seawater','biota', 'sediment') : {    \n",
    "                                                        ## DEFAULT\n",
    "                                                        'lat' : vars['defaults']['lat']['name'] ,\n",
    "                                                        'lon' : vars['defaults']['lon']['name'] ,\n",
    "                                                        'time' : vars['defaults']['time']['name'],\n",
    "                                                        'NUCLIDE' : 'nuclide',\n",
    "                                                        'unit' : vars['suffixes']['unit']['name'],\n",
    "                                                        #'station_id' : 'data_provider_station_id',\n",
    "                                                        #'data_provider_sample_id' : vars['defaults']['data_provider_sample_id']['name'],\n",
    "                                                        #'profile_or_transect_id' : 'profile_id',\n",
    "                                                        'detection_limit' : vars['suffixes']['detection_limit']['name']\n",
    "                                                        #'Sampling method' : 'sampling_method'\n",
    "                                                        #'Preparation method' : 'preparation_method'\n",
    "                                                        #'Counting method' : 'counting_method'\n",
    "                                                        #'Sample notes' : 'sample_notes'\n",
    "                                                        #'Measurement notes' : 'measurement_notes'\n",
    "                                                    },\n",
    "                  ('seawater',) : {\n",
    "                                ## SEAWATER\n",
    "                                'VALUE_Bq/m³': 'value',\n",
    "                                'ERROR%_m³': vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "                                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                                'SALIN' : vars['suffixes']['salinity']['name'],\n",
    "                                'TTEMP' : vars['suffixes']['temperature']['name'],\n",
    "                                #'FILT' : vars['suffixes']['filtered']['name']\n",
    "                                },\n",
    "                  ('biota',) : { \n",
    "                                ## BIOTA\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%' : vars['suffixes']['uncertainty']['name'],\n",
    "                                'species' : vars['bio']['species']['name'],\n",
    "                                'body_part' : vars['bio']['body_part']['name'],\n",
    "                                'bio_group' : vars['bio']['bio_group']['name'],\n",
    "                                'SDEPTH' : vars['defaults']['smp_depth']['name'],\n",
    "                                #'DW%' : 'dry_wet_ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                \n",
    "                                },\n",
    "                  ('sediment',) : {\n",
    "                                ## SEDIMENT\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%_kg' : vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH' : vars['defaults']['tot_depth']['name'],\n",
    "                                'sed_type' : vars['sed']['sed_type']['name'],\n",
    "                                #'top' : 'top',\n",
    "                                #'bottom' : 'bottom', \n",
    "                                #'DW%' : 'dry_wet_ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                }\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb975d9",
   "metadata": {},
   "source": [
    "Open Refine data format includes additional data that is not available in NetCDF format. Here we select columns of interest for Open Refine and standardize columns names to MARIS NetCDF format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a6d25",
   "metadata": {},
   "source": [
    "> For Open Refine CSV column names are standardized to MARIS NetCDF format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values) for encoding to open refine csv. .\n",
    "def get_renaming_rules_openrefine():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    return {('seawater','biota', 'sediment') : {    \n",
    "                                                        ## DEFAULT\n",
    "                                                        'lat' : vars['defaults']['lat']['name'] ,\n",
    "                                                        'lon' : vars['defaults']['lon']['name'] ,\n",
    "                                                        'time' : vars['defaults']['time']['name'],\n",
    "                                                        'NUCLIDE' : 'nuclide',\n",
    "                                                        'unit' : vars['suffixes']['unit']['name'],\n",
    "                                                        'station_id' : 'data_provider_station_id',\n",
    "                                                        'data_provider_sample_id' : vars['defaults']['data_provider_sample_id']['name'],\n",
    "                                                        'profile_or_transect_id' : 'profile_id',\n",
    "                                                        'detection_limit' : vars['suffixes']['detection_limit']['name']\n",
    "                                                        #'Sampling method' : 'sampling_method'\n",
    "                                                        #'Preparation method' : 'preparation_method'\n",
    "                                                        #'Counting method' : 'counting_method'\n",
    "                                                        #'Sample notes' : 'sample_notes'\n",
    "                                                        #'Measurement notes' : 'measurement_notes'\n",
    "                                                    },\n",
    "                  ('seawater',) : {\n",
    "                                ## SEAWATER\n",
    "                                'VALUE_Bq/m³': 'value',\n",
    "                                'ERROR%_m³': vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "                                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                                'SALIN' : vars['suffixes']['salinity']['name'],\n",
    "                                'TTEMP' : vars['suffixes']['temperature']['name'],\n",
    "                                'FILT' : vars['suffixes']['filtered']['name']\n",
    "                                },\n",
    "                  ('biota',) : { \n",
    "                                ## BIOTA\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%' : vars['suffixes']['uncertainty']['name'],\n",
    "                                'species' : vars['bio']['species']['name'],\n",
    "                                'body_part' : vars['bio']['body_part']['name'],\n",
    "                                'bio_group' : vars['bio']['bio_group']['name'],\n",
    "                                'SDEPTH' : vars['defaults']['smp_depth']['name'],\n",
    "                                'DW%' : 'dry_wet_ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                \n",
    "                                },\n",
    "                  ('sediment',) : {\n",
    "                                ## SEDIMENT\n",
    "                                'VALUE_Bq/kg': 'value',\n",
    "                                'ERROR%_kg' : vars['suffixes']['uncertainty']['name'],\n",
    "                                'TDEPTH' : vars['defaults']['tot_depth']['name'],\n",
    "                                'sed_type' : vars['sed']['sed_type']['name'],\n",
    "                                'top' : 'top',\n",
    "                                'bottom' : 'bottom', \n",
    "                                'DW%' : 'dry_wet_ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                }\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class SelectAndRenameColumnCB(Callback):\n",
    "    def __init__(self,\n",
    "                 fn_renaming_rules,\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        renaming = self.fn_renaming_rules()\n",
    "        for grp in tfm.dfs.keys():            \n",
    "            # get columns related to the grp (e.g. 'biota').\n",
    "            coi = [v for k, v in renaming.items() if grp in k]\n",
    "            # Join cols of interest\n",
    "            coi_rename = {}\n",
    "            for d in coi:\n",
    "                for k, v in d.items(): \n",
    "                    coi_rename[k]=v\n",
    "            # list cols\n",
    "            cols = list(coi_rename.keys()) \n",
    "            # select cols in df \n",
    "            tfm.dfs[grp] = tfm.dfs[grp].loc[:, cols]\n",
    "            # Rename cols\n",
    "            tfm.dfs[grp].rename(columns=coi_rename, inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a8682-672f-4188-9091-821b727b4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f7682",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7efe2d",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59b263",
   "metadata": {},
   "source": [
    "Convert data from long to wide and rename columns to comply with NetCDF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ee54c-19aa-4f21-b2a7-8f3f182f3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns=['nuclide'], values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        \n",
    "        df=df.reset_index()\n",
    "        \n",
    "        idx = list(set(df.columns) - set(self.columns + derived_coi + self.values))\n",
    "        \n",
    "        # Create a fill_value to replace NaN values in the columns used as the index in the pivot table.\n",
    "        # Check if num_fill_value is already in the dataframe index values. If num_fill_value already exists\n",
    "        # then increase num_fill_value by 1 until a value is found for num_fill_value that is not in the dataframe. \n",
    "        num_fill_value = 99999999999999\n",
    "        while (df[idx] == num_fill_value).any().any():\n",
    "            num_fill_value += 1\n",
    "        # Fill in nan values for each col found in idx. \n",
    "        for col in idx:   \n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                fill_value = num_fill_value\n",
    "            if pd.api.types.is_string_dtype(df[col]):\n",
    "                fill_value = 'NOT AVAILABLE'\n",
    "                \n",
    "            df[col]=df[col].fillna(fill_value)\n",
    "\n",
    "        pivot_df=df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "        \n",
    "        pivot_df.index.name = 'sample'\n",
    "        pivot_df=pivot_df.reset_index('sample')\n",
    "        \n",
    "        # Replace fill_value  with  np.nan\n",
    "        pivot_df[idx]=pivot_df[idx].replace({'NOT AVAILABLE': np.nan,\n",
    "                                             num_fill_value : np.nan})\n",
    "        return (pivot_df)\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp] = self.pivot(tfm.dfs[grp])\n",
    "            tfm.dfs[grp].columns = self.renamed_cols(tfm.dfs[grp].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfm(dfs)\n",
    "\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'].head())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c700a05",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf),\n",
    "                            ReshapeLongToWide(), \n",
    "                            #CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "# Transform\n",
    "tfm()\n",
    "# Check transformation logs\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ebcce-b8c8-4963-8c1c-f32e820f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### Encoding NETCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),                             \n",
    "                                NormalizeUncUnitCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),\n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapProfileIdCB(), \n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SanitizeValue(coi_val),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules_netcdf),\n",
    "                                ReshapeLongToWide()\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, fname_out_nc, nc_tpl_path(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac622af",
   "metadata": {},
   "source": [
    "## Data transformation pipeline for Open Refine CSV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34324b",
   "metadata": {},
   "source": [
    "Data intended for the ``Open Refine`` format is first processed using several callbacks from the ``Data transformation pipeline for NetCDF``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_openrefine), \n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(), \n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(), \n",
    "                            LookupValueTypeByIdCB(), \n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB(), \n",
    "                            LookupSedimentTypeByIdCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(f\"Seawater cols: {tfm.dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {tfm.dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {tfm.dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm.dfs['sediment'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf83afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export` is a special comment tag that is often used in code documentation or code generation tools to indicate that the following code block should be exported or made available for external use. This can be useful for generating documentation, extracting specific parts of code for reuse, or for other automated processes that require specific code sections to be identified.\n",
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).\n",
    "def get_renaming_rules_netcdf2OpenRefine():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    return {('seawater','biota', 'sediment') : {    \n",
    "                                                        ## DEFAULT\n",
    "                                                        'Sample type' : 'Sample type',\n",
    "                                                        'Latitude degrees' : 'Latitude degrees',\n",
    "                                                        'Latitude minutes' : 'Latitude minutes',\n",
    "                                                        'Latitude seconds' : 'Latitude seconds',\n",
    "                                                        'Latitude direction' : 'Latitude direction',\n",
    "                                                        'Longitude degrees' : 'Longitude degrees',\n",
    "                                                        'Longitude minutes' : 'Longitude minutes',\n",
    "                                                        'Longitude seconds' : 'Longitude seconds', \n",
    "                                                        'Longitude direction' : 'Longitude direction', \n",
    "                                                        vars['defaults']['lat']['name'] : 'Latitude decimal',\n",
    "                                                        vars['defaults']['lon']['name'] : 'Longitude decimal',\n",
    "                                                        'Sampling start date' : 'Sampling start date',\n",
    "                                                        'Sampling start time' : 'Sampling start time',\n",
    "                                                        'Nuclide' : 'Nuclide',\n",
    "                                                        'Value type': 'Value type',\n",
    "                                                        'Unit' : 'Unit',\n",
    "                                                        'value' : 'Activity or MDA',\n",
    "                                                        vars['suffixes']['uncertainty']['name'] : 'Uncertainty',\n",
    "                                                        'data_provider_station_id' : 'Station ID',\n",
    "                                                        vars['defaults']['data_provider_sample_id']['name'] :'Sample ID',\n",
    "                                                        'profile_id' : 'Profile or transect ID',                                                        \n",
    "                                                        #'Sampling method' : 'sampling_method'\n",
    "                                                        #'Preparation method' : 'preparation_method'\n",
    "                                                        #'Counting method' : 'counting_method'\n",
    "                                                        #'Sample notes' : 'sample_notes'\n",
    "                                                        #'Measurement notes' : 'measurement_notes'\n",
    "                                                    },\n",
    "                  ('seawater',) : {\n",
    "                                ## SEAWATER\n",
    "                                vars['defaults']['tot_depth']['name'] : 'Total depth',\n",
    "                                vars['defaults']['smp_depth']['name'] : 'Sampling depth' ,\n",
    "                                vars['suffixes']['salinity']['name'] : 'Salinity',\n",
    "                                vars['suffixes']['temperature']['name'] : 'Temperature',\n",
    "                                vars['suffixes']['filtered']['name'] : 'Filtered'\n",
    "                                },\n",
    "                  ('biota',) : { \n",
    "                                ## BIOTA\n",
    "                                'Species' : 'Species',\n",
    "                                'Body part' : 'Body part',\n",
    "                                #'bio_group' : vars['bio']['bio_group']['name'],\n",
    "                                #'SDEPTH' : vars['defaults']['smp_depth']['name'],\n",
    "                                'dry_wet_ratio' : 'Dry/wet ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                \n",
    "                                },\n",
    "                  ('sediment',) : {\n",
    "                                ## SEDIMENT\n",
    "                                vars['defaults']['tot_depth']['name'] : 'Total depth',\n",
    "                                'Sediment type' : 'Sediment type',\n",
    "                                'top' : 'Top',\n",
    "                                'bottom' : 'Bottom', \n",
    "                                'dry_wet_ratio' : 'Dry/wet ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                }\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_openrefine), \n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(), \n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(), \n",
    "                            LookupValueTypeByIdCB(), \n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB(), \n",
    "                            LookupSedimentTypeByIdCB(),\n",
    "                            CompareDfsAndTfm(dfs), \n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf2OpenRefine)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(f\"Seawater cols: {tfm.dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {tfm.dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {tfm.dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f90bf",
   "metadata": {},
   "source": [
    "### Encoding Open Refine CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_review=tfm.dfs['seawater']\n",
    "biota_review=tfm.dfs['biota']\n",
    "sediment_review=tfm.dfs['sediment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5de3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_open_refine_csv(fname_in, fname_out, ref_id=-1, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),                             \n",
    "                                NormalizeUncUnitCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),\n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapProfileIdCB(), \n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SanitizeValue(coi_val),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules_openrefine), \n",
    "                                LookupTimeFromEncodedTime(cfg()),\n",
    "                                GetSampleTypeCB(), \n",
    "                                LookupNuclideByIdCB(),\n",
    "                                ConvertLonLatCB(), \n",
    "                                LookupUnitByIdCB(), \n",
    "                                LookupValueTypeByIdCB(), \n",
    "                                LookupSpeciesByIdCB(),\n",
    "                                LookupBodypartByIdCB(), \n",
    "                                LookupSedimentTypeByIdCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules_netcdf2OpenRefine)\n",
    "                                ])\n",
    "    \n",
    "    encoder = OpenRefineCsvEncoder(tfm(), \n",
    "                            dest_fname=fname_out,\n",
    "                            ref_id = ref_id,\n",
    "                            **kwargs)\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83073a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_open_refine_csv(fname_in, fname_out_csv, ref_id, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33549327",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a206afa",
   "metadata": {},
   "source": [
    "TODO: Include FILT for NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0be1f5",
   "metadata": {},
   "source": [
    "TODO : Do we want to include laboratory code in NetCDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44bf97",
   "metadata": {},
   "source": [
    "TODO: Check sediment 'DW%' data that is less than 1%. Is this realistic? Check the 'DW%' data that is 0%. Run below before SelectAndRenameColumnCB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002712da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val)\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de551778",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] < 1) & (tfm.dfs[grp]['DW%'] > 0.001) ]\n",
    "#check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe533d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357222d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp='biota'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eefdfcc",
   "metadata": {},
   "source": [
    "TODO: Note weight definition in HELCOM is different than in MARIS.  HELCOM definition is 'Average weight (in g) of specimen in the sample. MARIS definition is 'dry weight of biota sample in grammes (g).' or 'wet weight of biota sample in grammes (g).'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208aa11",
   "metadata": {},
   "source": [
    "TODO :  For biota we have some entries that include a YEAR but no month and day (see tfm.dfs_dropped['biota'][['YEAR', 'MONTH', 'DAY', 'DATE']]). For these entries I have included a day and month as 1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7560d",
   "metadata": {},
   "source": [
    "TODO: Review the format of 'ddmmmm'.. Example of data '29.2000'. Assuming that this is 29 degrees. Then 20 minutes with a remainder of .00 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa5e77",
   "metadata": {},
   "source": [
    "TODO: Follow up with HELCOM on entries where the value is nan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b010f",
   "metadata": {},
   "source": [
    "TODO: Review Maris Open Refine date format. The description format is 'DD-MMM-YYYY'. The example format is '29/Sep/2008'.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

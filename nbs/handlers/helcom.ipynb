{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709cfb6",
   "metadata": {},
   "source": [
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [HELCOM data](https://helcom.fi/about-us) into `NetCDF` format. The handler processes raw HELCOM data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw HELCOM data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring HELCOM data is properly integrated into the MARIS database.\n",
    "\n",
    "\n",
    "Note: *Additionally, an optional encoder (pipeline) is provided below to process data into a `.csv` format compatible with the MARIS master database. This feature is maintained for legacy purposes, as data ingestion was previously performed using OpenRefine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/blob/main/nbs/metadata/field-definition.ipynb) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121843",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/helcom.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "#from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple, Any \n",
    "#from collections import OrderedDict, defaultdict\n",
    "import re\n",
    "#from functools import partial\n",
    "\n",
    "from marisco.utils import (\n",
    "    Remapper, \n",
    "    ddmm_to_dd,\n",
    "    Match, \n",
    "    get_unique_across_dfs\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback, \n",
    "    Transformer, \n",
    "    EncodeTimeCB, \n",
    "    AddSampleTypeIdColumnCB,\n",
    "    AddNuclideIdColumnCB, \n",
    "    LowerStripNameCB, \n",
    "    SanitizeLonLatCB, \n",
    "    CompareDfsAndTfmCB, \n",
    "    RemapCB\n",
    ")\n",
    "\n",
    "from marisco.metadata import (\n",
    "    GlobAttrsFeeder, \n",
    "    BboxCB, \n",
    "    DepthRangeCB, \n",
    "    TimeRangeCB, \n",
    "    ZoteroCB, \n",
    "    KeyValuePairCB\n",
    ")\n",
    "\n",
    "from marisco.configs import (\n",
    "    nuc_lut_path, \n",
    "    nc_tpl_path, \n",
    "    cfg, \n",
    "    species_lut_path, \n",
    "    sediments_lut_path, \n",
    "    bodyparts_lut_path, \n",
    "    detection_limit_lut_path, \n",
    "    filtered_lut_path, \n",
    "    get_lut, \n",
    "    unit_lut_path,\n",
    "    prepmet_lut_path,\n",
    "    sampmet_lut_path,\n",
    "    counmet_lut_path, \n",
    "    lab_lut_path,\n",
    "    NC_VARS\n",
    ")\n",
    "\n",
    "from marisco.encoders import (\n",
    "    NetCDFEncoder, \n",
    ")\n",
    "\n",
    "from marisco.decoders import (\n",
    "    nc_to_dfs,\n",
    "    get_netcdf_properties, \n",
    "    get_netcdf_group_properties,\n",
    "    get_netcdf_variable_properties\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration & file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **fname_in**: path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "- **ref_id**: refers to the location in Archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034b0a9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**:  Review NetCDF file name format, see (https://trello.com/c/RlB7mM8N#comment-6747489a3ef094e3520a4272)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "zotero_key ='26VMZZ2Q' # HELCOM MORS zotero key\n",
    "ref_id = 100 # HELCOM MORS reference id as defined by MARIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc83f",
   "metadata": {},
   "source": [
    "[Helcom MORS (Monitoring of Radioactive Substances in the Baltic Sea) data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "Metadata for the HELCOM MORS dataset is available [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    "**Example steps**:\n",
    "\n",
    "\n",
    "1. [Download data](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24)\n",
    "\n",
    "2. Install mdbtools via VScode Terminal: \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ```\n",
    "\n",
    "3. Install unzip via VScode Terminal:\n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ```\n",
    "\n",
    "4. In `VS Code` terminal (for instance), navigate to the marisco data folder:\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip `MORS_ENVIRONMENT.zip`:\n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run `preprocess.sh` to generate the required data files:\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ```\n",
    "\n",
    "7. Content of `preprocess.sh` script:\n",
    "\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n",
    "\n",
    "Once converted to `.csv` files, the data is ready to be loaded into a dictionary of dataframes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = {  \n",
    "    'BIO': 'BIOTA', \n",
    "    'SEA': 'SEAWATER', \n",
    "    'SED': 'SEDIMENT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir: str|Path, \n",
    "              smp_types: dict = default_smp_types \n",
    "             ) -> Dict[str, pd.DataFrame]: \n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df_meas = pd.read_csv(src_path / f'{file_prefix}02.csv')\n",
    "            df_smp = pd.read_csv(src_path / f'{file_prefix}01.csv')\n",
    "            return pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files for {file_prefix}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if files are not found\n",
    "    \n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types.items()}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys/sample types:  dict_keys(['BIOTA', 'SEAWATER', 'SEDIMENT'])\n",
      "BIOTA columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEAWATER columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEDIMENT columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('keys/sample types: ', dfs.keys())\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} columns: ', dfs[key].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4ceb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d84ed7",
   "metadata": {},
   "source": [
    "This is demonstrated below for the `NUCLIDE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      value  n_chars  stripped_chars\n",
      "1       1    SR90           7               4\n",
      "4       4  CS137            9               5\n",
      "7       7   CO60            8               4\n",
      "15     15   CS134           8               5\n",
      "28     28   AM241           8               5\n",
      "30     30   PU238           8               5\n",
      "32     32      SR90         5               4\n",
      "33     33     SR90          6               4\n",
      "40     40    TC99           7               4\n",
      "41     41   CS137           8               5\n",
      "81     81   K40             8               3\n",
      "92     92   SR90            8               4\n",
      "95     95     CS137         6               5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(fname_in), 'NUCLIDE', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA Nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "SEAWATER Nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "SEDIMENT Nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n",
      "[\"Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'NUCLIDE' column.\"]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE', col_dst='NUCLIDE')])\n",
    "tfm()\n",
    "for key, df in tfm.dfs.items():\n",
    "    print(f'{key} Nuclides: ')\n",
    "    print(df['NUCLIDE'].unique())\n",
    "    \n",
    "print(tfm.logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58baf14",
   "metadata": {},
   "source": [
    "Below, we map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures to MARIS standards is a recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "We will refer to this process as **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31bc",
   "metadata": {},
   "source": [
    "The `get_unique_across_dfs` function is a utility in MARISCO that retrieves unique values from a specified column across all DataFrames. \n",
    "Note that there is one DataFrame for each sample type, such as biota, sediment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ee8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>cs137</td>\n",
       "      <td>ra223</td>\n",
       "      <td>cs145</td>\n",
       "      <td>sn113</td>\n",
       "      <td>np237</td>\n",
       "      <td>fe59</td>\n",
       "      <td>i131</td>\n",
       "      <td>pb210</td>\n",
       "      <td>po210</td>\n",
       "      <td>cs146</td>\n",
       "      <td>...</td>\n",
       "      <td>cs140</td>\n",
       "      <td>ra228</td>\n",
       "      <td>ra224</td>\n",
       "      <td>bi214</td>\n",
       "      <td>pu240</td>\n",
       "      <td>ru106</td>\n",
       "      <td>ac228</td>\n",
       "      <td>co60</td>\n",
       "      <td>h3</td>\n",
       "      <td>k40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4     5     6      7      8      9   \\\n",
       "index      0      1      2      3      4     5     6      7      8      9   \n",
       "value  cs137  ra223  cs145  sn113  np237  fe59  i131  pb210  po210  cs146   \n",
       "\n",
       "       ...     67     68     69     70     71     72     73    74  75   76  \n",
       "index  ...     67     68     69     70     71     72     73    74  75   76  \n",
       "value  ...  cs140  ra228  ra224  bi214  pu240  ru106  ac228  co60  h3  k40  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "dfs_output = tfm()\n",
    "\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1bdf",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the nuclide names of the HELCOM dataset to the MARIS standard nuclide names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0ea0c",
   "metadata": {},
   "source": [
    "Lets try to match HELCOM nuclide names to MARIS standard nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 34.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 entries matched the criteria, while 14 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pu238240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu238240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cm243244</th>\n",
       "      <td>cm242</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu239240</th>\n",
       "      <td>pu239</td>\n",
       "      <td>pu239240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs134137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs134137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs145</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs143</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs142</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs146</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs138</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-40</th>\n",
       "      <td>k40</td>\n",
       "      <td>k-40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs139</th>\n",
       "      <td>ce139</td>\n",
       "      <td>cs139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs141</th>\n",
       "      <td>ce141</td>\n",
       "      <td>cs141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs144</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs140</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "pu238240                pu240    pu238240            3\n",
       "cm243244                cm242    cm243244            3\n",
       "pu239240                pu239    pu239240            3\n",
       "cs134137                cs137    cs134137            3\n",
       "cs145                   ce140       cs145            2\n",
       "cs143                   ce140       cs143            2\n",
       "cs142                   ce140       cs142            2\n",
       "cs146                   cs136       cs146            1\n",
       "cs138                   cs134       cs138            1\n",
       "k-40                      k40        k-40            1\n",
       "cs139                   ce139       cs139            1\n",
       "cs141                   ce141       cs141            1\n",
       "cs144                   cs134       cs144            1\n",
       "cs140                   ce140       cs140            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cb838",
   "metadata": {},
   "source": [
    "We can now manually inspect the unmatched nuclide names and create a table to correct them to the MARIS standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs143': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'k-40': 'k40',\n",
    "    'cs140': 'cs137',\n",
    "    'cs146': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs138': 'cs137'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575e7e",
   "metadata": {},
   "source": [
    "We now include the table `fixes_nuclide_names`, which applies manual corrections to the nuclide names before the remapping process. \n",
    "The `generate_lookup_table` function has an `overwrite` parameter (default is `True`), which, when set to `True`, creates a pickle file cache of the lookup table. We can now test the remapping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 entries matched the criteria, while 0 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1, verbose=True)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1276f",
   "metadata": {},
   "source": [
    "Test passes! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a189ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_helcom.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0281b22",
   "metadata": {},
   "source": [
    "We now create the callback `RemapNuclideNameCB`, which will remap the nuclide names using the `lut_nuclides` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    \"Remap data provider nuclide names to standardized MARIS nuclide names.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable, # Function that returns the lookup table dictionary\n",
    "                 col_name: str # Column name to remap\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name=self.col_name, as_df=True)\n",
    "        #lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        lut = {k: v.matched_id for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k][self.col_name].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce649d7a",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `LowerStripNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA NUCLIDE unique:  [31  4  9 33 12 21  6  8 22 10 24 77 17  2 37 41 47 23 11 13 25 16 14 36\n",
      " 35 29 34 67 63 46 43 42 94 55 50 40 53 87 92 86 15  7 93 85 91 90 51 59\n",
      " 76 72 54 57]\n",
      "SEAWATER NUCLIDE unique:  [33 12  1 31 67 77 72 73 75 15  4 16 11 24 14 17 13 22 80 34 37 62 64  9\n",
      " 68 41 47 65 69  6]\n",
      "SEDIMENT NUCLIDE unique:  [ 53  33  54   4  12  76  31  77  67   9  16  17  24  22  37  72   2  57\n",
      "  41   8   6  13  34  47  51  14  89  70  68  40  88  59  84  23  10  60\n",
      "  94  42  43  46  55  50  63 130]\n",
      "[\"Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column.\", 'Remap data provider nuclide names to standardized MARIS nuclide names.']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='NUCLIDE')\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "for key in dfs_out.keys():\n",
    "    print(f'{key} NUCLIDE unique: ', dfs_out[key]['NUCLIDE'].unique())\n",
    "    \n",
    "print(tfm.logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24856dc5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Time/date is provide in the `DATE`, `YEAR`\n",
    ", `MONTH`, `DAY` columns. Note that the `DATE` contains missing values as indicated below. When missing, we fallback on the `YEAR`, `MONTH`, `DAY` columns. Note also that sometimes `DAY` and `MONTH` contain 0. In this case we systematically set them to 1.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612873e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA DATE null values:  84\n",
      "SEAWATER DATE null values:  494\n",
      "SEDIMENT DATE null values:  741\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} DATE null values: ', dfs[key]['DATE'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Standardize time format across all dataframes.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._process_dates(df)\n",
    "\n",
    "    def _process_dates(self, df: pd.DataFrame) -> None:\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['TIME'] = self._parse_date(df)\n",
    "        self._handle_missing_dates(df)\n",
    "        self._fill_missing_time(df)\n",
    "\n",
    "    def _parse_date(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"Parse the DATE column if present.\"\n",
    "        return pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "\n",
    "    def _handle_missing_dates(self, df: pd.DataFrame):\n",
    "        \"Handle cases where DAY or MONTH is 0 or missing.\"\n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        missing_day_month = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[missing_day_month, [\"DAY\", \"MONTH\"]] = 1\n",
    "\n",
    "    def _fill_missing_time(self, df: pd.DataFrame) -> None:\n",
    "        \"Fill missing time values using YEAR, MONTH, and DAY columns.\"\n",
    "        missing_time = df['TIME'].isna()\n",
    "        df.loc[missing_time, 'TIME'] = pd.to_datetime(\n",
    "            df.loc[missing_time, ['YEAR', 'MONTH', 'DAY']], \n",
    "            format='%Y%m%d', \n",
    "            errors='coerce'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the `TIME` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "            TIME\n",
      "0     2012-05-23\n",
      "1     2012-05-23\n",
      "2     2012-06-17\n",
      "3     2012-05-24\n",
      "4     2012-05-24\n",
      "...          ...\n",
      "20313 2015-06-22\n",
      "20314 2015-06-23\n",
      "20315 2015-06-23\n",
      "20316 2015-06-24\n",
      "20317 2015-06-24\n",
      "\n",
      "[20318 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['SEAWATER'][['TIME']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "The NetCDF time format requires that time be encoded as the number of milliseconds since a specified origin. In our case, the origin is `1970-01-01`, as indicated in the `cdl.toml` file under the `[vars.defaults.time.attrs]` section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "['Standardize time format across all dataframes.', 'Encode time as seconds since epoch.', 'Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.logs)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a9aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003</td>\n",
       "      <td>...</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004</td>\n",
       "      <td>...</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1339891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006</td>\n",
       "      <td>...</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007</td>\n",
       "      <td>...</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337817600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (dddddd)  \\\n",
       "0  08/20/14 00:00:00       90       KRIL   2012003  ...            29.3333   \n",
       "1  08/20/14 00:00:00       90       KRIL   2012004  ...            29.3333   \n",
       "2  08/20/14 00:00:00       90       KRIL   2012005  ...            23.1500   \n",
       "3  08/20/14 00:00:00       90       KRIL   2012006  ...            27.9833   \n",
       "4  08/20/14 00:00:00       90       KRIL   2012007  ...            27.9833   \n",
       "\n",
       "   TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
       "0     NaN     0.0    NaN   NaN   NaN             11               11   \n",
       "1     NaN    29.0    NaN   NaN   NaN             11               11   \n",
       "2     NaN     0.0    NaN   NaN   NaN             11                3   \n",
       "3     NaN     0.0    NaN   NaN   NaN             11               11   \n",
       "4     NaN    39.0    NaN   NaN   NaN             11               11   \n",
       "\n",
       "     DATE_OF_ENTRY_y        TIME  \n",
       "0  08/20/14 00:00:00  1337731200  \n",
       "1  08/20/14 00:00:00  1337731200  \n",
       "2  08/20/14 00:00:00  1339891200  \n",
       "3  08/20/14 00:00:00  1337817600  \n",
       "4  08/20/14 00:00:00  1337817600  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['SEAWATER'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b52103",
   "metadata": {},
   "source": [
    "## Split Sediment Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51dae5",
   "metadata": {},
   "source": [
    "Helcom reports two values for the SEDIMENT sample type: `VALUE_Bq/kg` and `VALUE_Bq/m³`. We need to split this and use a single column `VALUE` for the MARIS standard. We will use the `UNIT` column to identify the reported values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102849f",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS unit lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bbf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "      <th>ordlist</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bq/m&lt;sup&gt;3&lt;/sup&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized  ordlist Unnamed: 4  Unnamed: 5  \\\n",
       "0        -1  Not applicable  Not applicable      NaN        NaN         NaN   \n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE      0.0        NaN         NaN   \n",
       "2         1           Bq/m3       Bq per m3      1.0      Bq/m3         NaN   \n",
       "3         2           Bq/m2       Bq per m2      2.0        NaN         NaN   \n",
       "4         3           Bq/kg       Bq per kg      3.0        NaN         NaN   \n",
       "5         4          Bq/kgd      Bq per kgd      4.0        NaN         NaN   \n",
       "6         5          Bq/kgw      Bq per kgw      5.0        NaN         NaN   \n",
       "7         6           kg/kg       kg per kg      6.0        NaN         NaN   \n",
       "8         7              TU              TU      7.0        NaN         NaN   \n",
       "9         8      DELTA/mill  DELTA per mill      8.0        NaN         NaN   \n",
       "10        9         atom/kg     atom per kg      9.0        NaN         NaN   \n",
       "11       10        atom/kgd    atom per kgd     10.0        NaN         NaN   \n",
       "12       11        atom/kgw    atom per kgw     11.0        NaN         NaN   \n",
       "13       12          atom/l      atom per l     12.0        NaN         NaN   \n",
       "14       13          Bq/kgC      Bq per kgC     13.0        NaN         NaN   \n",
       "\n",
       "          Unnamed: 6  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2   Bq/m<sup>3</sup>  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "5                NaN  \n",
       "6                NaN  \n",
       "7                NaN  \n",
       "8                NaN  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "11               NaN  \n",
       "12               NaN  \n",
       "13               NaN  \n",
       "14               NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel(unit_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83ec0d",
   "metadata": {},
   "source": [
    "We will define the columns of interest for the SEDIMENT measurement types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df02329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_sediment = {\n",
    "    'kg_type': {\n",
    "        'VALUE': 'VALUE_Bq/kg',\n",
    "        'UNCERTAINTY': 'ERROR%_kg',\n",
    "        'DL': '< VALUE_Bq/kg',\n",
    "        'UNIT': 3,  # Unit ID for Bq/kg\n",
    "    },\n",
    "    'm2_type': {\n",
    "        'VALUE': 'VALUE_Bq/m²',\n",
    "        'UNCERTAINTY': 'ERROR%_m²',\n",
    "        'DL': '< VALUE_Bq/m²',\n",
    "        'UNIT': 2,  # Unit ID for Bq/m²\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11202714",
   "metadata": {},
   "source": [
    "We define the `SplitSedimentValuesCB` callback to split the sediment entries into separate rows for Bq/kg and Bq/m² values. We use underscore to denote the columns are temporary columns created during the splitting process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SplitSedimentValuesCB(Callback):\n",
    "    \"Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, Any]] # Columns of interest with value, uncertainty, DL columns and units\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        if 'SEDIMENT' not in tfm.dfs:\n",
    "            return\n",
    "            \n",
    "        df = tfm.dfs['SEDIMENT']\n",
    "        dfs_to_concat = []\n",
    "        \n",
    "        # For each measurement type (kg and m2)\n",
    "        for measure_type, cols in self.coi.items():\n",
    "            # If any of value/uncertainty/DL exists, keep the row\n",
    "            has_data = (\n",
    "                df[cols['VALUE']].notna() | \n",
    "                df[cols['UNCERTAINTY']].notna() | \n",
    "                df[cols['DL']].notna()\n",
    "            )\n",
    "            \n",
    "            if has_data.any():\n",
    "                df_measure = df[has_data].copy()\n",
    "                \n",
    "                # Copy columns to standardized names\n",
    "                df_measure['_VALUE'] = df_measure[cols['VALUE']]\n",
    "                df_measure['_UNCERTAINTY'] = df_measure[cols['UNCERTAINTY']]\n",
    "                df_measure['_DL'] = df_measure[cols['DL']]\n",
    "                df_measure['_UNIT'] = cols['UNIT']\n",
    "                \n",
    "                dfs_to_concat.append(df_measure)\n",
    "        \n",
    "        # Combine all measurement type dataframes\n",
    "        if dfs_to_concat:\n",
    "            tfm.dfs['SEDIMENT'] = pd.concat(dfs_to_concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ee701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     64074\n",
      "Number of rows removed         0         0         0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>_VALUE</th>\n",
       "      <th>_UNCERTAINTY</th>\n",
       "      <th>_DL</th>\n",
       "      <th>_UNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0  SKRIL2012048   RA226    NaN           NaN         35.0       26.0   \n",
       "1  SKRIL2012049   RA226    NaN           NaN         36.0       22.0   \n",
       "2  SKRIL2012050   RA226    NaN           NaN         38.0       24.0   \n",
       "3  SKRIL2012051   RA226    NaN           NaN         36.0       25.0   \n",
       "4  SKRIL2012052   RA226    NaN           NaN         30.0       23.0   \n",
       "\n",
       "  < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  DW% LOI%  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "\n",
       "   MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK    DATE_OF_ENTRY_y  _VALUE  \\\n",
       "0           11.0            11.0       NaN  08/20/14 00:00:00    35.0   \n",
       "1           11.0            11.0       NaN  08/20/14 00:00:00    36.0   \n",
       "2           11.0            11.0       NaN  08/20/14 00:00:00    38.0   \n",
       "3           11.0            11.0       NaN  08/20/14 00:00:00    36.0   \n",
       "4           11.0            11.0       NaN  08/20/14 00:00:00    30.0   \n",
       "\n",
       "  _UNCERTAINTY  _DL  _UNIT  \n",
       "0         26.0  NaN      3  \n",
       "1         22.0  NaN      3  \n",
       "2         24.0  NaN      3  \n",
       "3         25.0  NaN      3  \n",
       "4         23.0  NaN      3  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "\n",
    "tfm.dfs['SEDIMENT'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de49e39",
   "metadata": {},
   "source": [
    "We allocate each column containing measurement values (named differently across sample types) into a single column `VALUE` and remove NA where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_val = {'SEAWATER' : {'VALUE': 'VALUE_Bq/m³'},\n",
    "           'BIOTA':  {'VALUE': 'VALUE_Bq/kg'},\n",
    "           'SEDIMENT': {'VALUE': '_VALUE'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d74eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SanitizeValueCB(Callback):\n",
    "    \"Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, str]] # Columns of interest. Format: {group_name: {'val': 'column_name'}}\n",
    "                 ): \n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            value_col = self.coi[grp]['VALUE']\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            df['VALUE'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14873     20242     63870\n",
      "Number of rows removed        20        76       112 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>_VALUE</th>\n",
       "      <th>_UNCERTAINTY</th>\n",
       "      <th>_DL</th>\n",
       "      <th>_UNIT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64069</th>\n",
       "      <td>SSTUK2016044</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.916443</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.916443</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8.916443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64070</th>\n",
       "      <td>SSTUK2016045</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.992930</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.992930</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.992930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64071</th>\n",
       "      <td>SSTUK2016050</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2164.945699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2164.945699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2164.945699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64072</th>\n",
       "      <td>SSTUK2016051</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2523.279045</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2523.279045</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2523.279045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64073</th>\n",
       "      <td>SSTUK2016052</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3929.780107</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3929.780107</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3929.780107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63870 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0      SKRIL2012048   RA226     NaN           NaN        35.00       26.0   \n",
       "1      SKRIL2012049   RA226     NaN           NaN        36.00       22.0   \n",
       "2      SKRIL2012050   RA226     NaN           NaN        38.00       24.0   \n",
       "3      SKRIL2012051   RA226     NaN           NaN        36.00       25.0   \n",
       "4      SKRIL2012052   RA226     NaN           NaN        30.00       23.0   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "64069  SSTUK2016044   CS137  STUK01           NaN         1.20       12.0   \n",
       "64070  SSTUK2016045   CS137  STUK01           NaN         0.79       20.0   \n",
       "64071  SSTUK2016050   CS137  STUK01           NaN       512.00       11.0   \n",
       "64072  SSTUK2016051   CS137  STUK01           NaN       527.00        6.3   \n",
       "64073  SSTUK2016052   CS137  STUK01           NaN       684.00        5.0   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOI%  \\\n",
       "0               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "1               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "2               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "3               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "4               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "...             ...          ...        ...                ...  ...   ...   \n",
       "64069           NaN     8.916443       15.0                NaN  ...   NaN   \n",
       "64070           NaN     5.992930       23.0                NaN  ...   NaN   \n",
       "64071           NaN  2164.945699       14.0                NaN  ...   NaN   \n",
       "64072           NaN  2523.279045        9.3                NaN  ...   NaN   \n",
       "64073           NaN  3929.780107        8.0                NaN  ...   NaN   \n",
       "\n",
       "      MORS_SUBBASIN  HELCOM_SUBBASIN SUM_LINK    DATE_OF_ENTRY_y       _VALUE  \\\n",
       "0              11.0             11.0      NaN  08/20/14 00:00:00    35.000000   \n",
       "1              11.0             11.0      NaN  08/20/14 00:00:00    36.000000   \n",
       "2              11.0             11.0      NaN  08/20/14 00:00:00    38.000000   \n",
       "3              11.0             11.0      NaN  08/20/14 00:00:00    36.000000   \n",
       "4              11.0             11.0      NaN  08/20/14 00:00:00    30.000000   \n",
       "...             ...              ...      ...                ...          ...   \n",
       "64069           3.0              3.0      NaN                NaN     8.916443   \n",
       "64070           3.0              3.0      NaN                NaN     5.992930   \n",
       "64071           8.0              8.0      NaN                NaN  2164.945699   \n",
       "64072           8.0              8.0      NaN                NaN  2523.279045   \n",
       "64073           8.0              8.0      NaN                NaN  3929.780107   \n",
       "\n",
       "       _UNCERTAINTY  _DL  _UNIT        VALUE  \n",
       "0              26.0  NaN      3    35.000000  \n",
       "1              22.0  NaN      3    36.000000  \n",
       "2              24.0  NaN      3    38.000000  \n",
       "3              25.0  NaN      3    36.000000  \n",
       "4              23.0  NaN      3    30.000000  \n",
       "...             ...  ...    ...          ...  \n",
       "64069          15.0  NaN      2     8.916443  \n",
       "64070          23.0  NaN      2     5.992930  \n",
       "64071          14.0  NaN      2  2164.945699  \n",
       "64072           9.3  NaN      2  2523.279045  \n",
       "64073           8.0  NaN      2  3929.780107  \n",
       "\n",
       "[63870 rows x 40 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_sed=tfm.dfs['SEDIMENT']\n",
    "rev_sed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df: pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col: str, # Name of the column with measurement values\n",
    "    unc_col: str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the `UNCERTAINTY` is provided as a relative uncertainty. The column names for both the `VALUE` and the `UNCERTAINTY` vary by sample type. The `coi_units_unc` dictionary defines the column names for the `VALUE` and `UNCERTAINTY` for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('SEAWATER', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('BIOTA', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('SEDIMENT', '_VALUE', '_UNCERTAINTY')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the ``UNCERTAINTY`` by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"Convert from relative error ( % ) to standard uncertainty.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc: Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi: List[Tuple[str, str, str]]=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['UNCERTAINTY'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback ``NormalizeUncCB``. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALUE  UNCERTAINTY\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        VALUE  UNCERTAINTY\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   VALUE  UNCERTAINTY\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEAWATER'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['BIOTA'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['SEDIMENT'][['VALUE', 'UNCERTAINTY']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2c077",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0226ff",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The handling of unit types varies between `biota` and `sediment` sample types. For consistency and ease of use, it would be beneficial to have dedicated unit columns for all sample types.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e264aa",
   "metadata": {},
   "source": [
    "Given the inconsistent handling of units across sample types, we need to define custom mapping rules for standardizing the units. The units available in MARIS are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e594cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized\n",
       "0        -1  Not applicable  Not applicable\n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE\n",
       "2         1           Bq/m3       Bq per m3\n",
       "3         2           Bq/m2       Bq per m2\n",
       "4         3           Bq/kg       Bq per kg\n",
       "5         4          Bq/kgd      Bq per kgd\n",
       "6         5          Bq/kgw      Bq per kgw\n",
       "7         6           kg/kg       kg per kg\n",
       "8         7              TU              TU\n",
       "9         8      DELTA/mill  DELTA per mill\n",
       "10        9         atom/kg     atom per kg\n",
       "11       10        atom/kgd    atom per kgd\n",
       "12       11        atom/kgw    atom per kgw\n",
       "13       12          atom/l      atom per l\n",
       "14       13          Bq/kgC      Bq per kgC"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())[['unit_id', 'unit', 'unit_sanitized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d34fe",
   "metadata": {},
   "source": [
    "We define unit renaming rules for HELCOM in an **ad hoc** way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_units = {\n",
    "    'SEAWATER': 1,  # 'Bq/m3'\n",
    "    'SEDIMENT': 4,  # 'Bq/kgd' for sediment\n",
    "    'BIOTA': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapUnitCB(Callback):\n",
    "    \"Set the `unit` id column in the DataFrames based on a lookup table.\"\n",
    "    def __init__(self, \n",
    "                 lut_units: dict=lut_units # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp in ['SEAWATER', 'SEDIMENT']:\n",
    "                tfm.dfs[grp]['UNIT'] = self.lut_units[grp]\n",
    "            else:\n",
    "                tfm.dfs[grp]['UNIT'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut_units[grp].get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e7771",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `RemapUnitCB()`. Then, print the unique `UNIT` for the `SEAWATER` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d546d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [5 0 4]\n",
      "SEDIMENT: [4]\n",
      "SEAWATER: [1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapUnitCB()])\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['UNIT'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa950b",
   "metadata": {},
   "source": [
    "## Remap detection limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fe0fa",
   "metadata": {},
   "source": [
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcce61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77091197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c37e8f",
   "metadata": {},
   "source": [
    "Based on columns of interest for each sample type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'SEAWATER' : {'VALUE' : 'VALUE_Bq/m³',\n",
    "                       'UNCERTAINTY' : 'ERROR%_m³',\n",
    "                       'DL' : '< VALUE_Bq/m³'},\n",
    "          'BIOTA':  {'VALUE' : 'VALUE_Bq/kg',\n",
    "                     'UNCERTAINTY' : 'ERROR%',\n",
    "                     'DL' : '< VALUE_Bq/kg'},\n",
    "          'SEDIMENT': {\n",
    "              'VALUE' : 'VALUE_Bq/kg',\n",
    "              'UNCERTAINTY' : 'ERROR%_kg',\n",
    "              'DL' : '< VALUE_Bq/kg'}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f77c59",
   "metadata": {},
   "source": [
    "We follow the following business logic to encode the detection limit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce2004",
   "metadata": {},
   "source": [
    "`RemapDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or DL) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 coi: dict,  # Configuration options for column names\n",
    "                 fn_lut: Callable  # Function that returns a lookup table\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "\n",
    "    def _update_detection_limit(self, \n",
    "                                df: pd.DataFrame,  # The DataFrame to modify\n",
    "                                grp: str,  # The group name to get the column configuration\n",
    "                                lut: dict  # The lookup table dictionary\n",
    "                               ) -> None:\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        \n",
    "        # Check if the group exists in coi_dl\n",
    "        if grp not in coi_dl:\n",
    "            raise ValueError(f\"Group '{grp}' not found in coi_dl configuration.\")\n",
    "        \n",
    "        # Access column names from coi_dl\n",
    "        value_col = coi_dl[grp]['VALUE']\n",
    "        uncertainty_col = coi_dl[grp]['UNCERTAINTY']\n",
    "        detection_col = coi_dl[grp]['DL']\n",
    "\n",
    "        # Initialize detection limit column\n",
    "        df['DL'] = df[detection_col]\n",
    "        \n",
    "        # Set detection limits based on conditions\n",
    "        self._set_detection_limits(df, value_col, uncertainty_col, lut)\n",
    "\n",
    "    def _set_detection_limits(self, df: pd.DataFrame, value_col: str, uncertainty_col: str, lut: dict) -> None:\n",
    "        \"Set detection limits based on value and uncertainty columns.\"\n",
    "        \n",
    "        # Condition for setting '='\n",
    "        # 'DL' defaults to equal (i.e. '=') if there is a value and uncertainty and 'DL' value is not \n",
    "        # in the lookup table.\n",
    "        \n",
    "        condition_eq =(df[value_col].notna() & \n",
    "                       df[uncertainty_col].notna() & \n",
    "                       ~df['DL'].isin(lut.keys())\n",
    "        )\n",
    "        \n",
    "        df.loc[condition_eq, 'DL'] = '='\n",
    "\n",
    "        # Set 'Not Available' for unmatched detection limits\n",
    "        df.loc[~df['DL'].isin(lut.keys()), 'DL'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup to map detection limits\n",
    "        df['DL'] = df['DL'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [2 1 0]\n",
      "SEDIMENT: [1 2 0]\n",
      "SEAWATER: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB(),                  \n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl)])\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['DL'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda9f9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: RUBIN contains codes that are not found in the HELCOM biota dataset. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe37ba",
   "metadata": {},
   "source": [
    "For example, 'CH HI;BA', its not in the HELCOM biota dataset. Lets return the uniue RUBIN of the HELCOM biota dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33953cd",
   "metadata": {},
   "source": [
    "Other unused RUBIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e11297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused RUBIN names: ['CH HI;BA', 'SOLE SOL']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "unique_rubin = dfs['BIOTA']['RUBIN'].unique()\n",
    "unique_rubin_set = set(unique_rubin)\n",
    "rubin_lut = list(pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')['RUBIN'])\n",
    "unused_rubins = [rune for rune in rubin_lut if rune not in unique_rubin_set]\n",
    "print(\"Unused RUBIN names:\", unused_rubins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7129a",
   "metadata": {},
   "source": [
    "We will remap the HELCOM `RUBIN` column to the MARIS `SPECIES` column using the **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply) pattern. First lets **inspect** the `RUBIN_NAME.csv` file provided by HELCOM, which describes the nomenclature of biota species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d23db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/marisco/.marisco/lut/dbo_species_2024_11_19.xlsx')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "species_lut_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1858121",
   "metadata": {},
   "source": [
    "Now we try to **MATCH** the `SCIENTIFIC NAME` column of ``HELCOM`` ``BIOTA`` dataset to the `species` column of the MARIS species lookup table, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:08<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMI SAC</th>\n",
       "      <td>Laminaria japonica</td>\n",
       "      <td>LAMINARIA SACCHARINA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD EDU</th>\n",
       "      <td>Cardiidae</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH HI;BA</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>CHARA BALTICA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSET MAX</th>\n",
       "      <td>Pinctada maxima</td>\n",
       "      <td>PSETTA MAXIMA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA           10\n",
       "LAMI SAC     Laminaria japonica     LAMINARIA SACCHARINA            7\n",
       "CARD EDU              Cardiidae            CARDIUM EDULE            6\n",
       "CH HI;BA        Macoma balthica            CHARA BALTICA            6\n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "PSET MAX        Pinctada maxima            PSETTA MAXIMA            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='SCIENTIFIC NAME',\n",
    "                    provider_col_key='RUBIN',\n",
    "                    fname_cache='species_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3b8aa",
   "metadata": {},
   "source": [
    "Below, we will correct the entries that were not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_species = {\n",
    "    'CHARA BALTICA': 'NOT AVAILABLE', # CHARA BALTICA (RUBIN: CH HI;BA) is not listed in the biota data. \n",
    "    'CARDIUM EDULE': 'Cerastoderma edule',\n",
    "    'LAMINARIA SACCHARINA': 'Saccharina latissima',\n",
    "    'PSETTA MAXIMA': 'Scophthalmus maximus',\n",
    "    'STIZOSTEDION LUCIOPERCA': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781f210",
   "metadata": {},
   "source": [
    "And give the ``remapper`` another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb07a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 1/43 [00:00<00:07,  5.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:07<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a5",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `RUBIN` column to the `species` column after having defined the lookup table `lut_biota`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='SCIENTIFIC NAME',\n",
    "                             provider_col_key='RUBIN',\n",
    "                             fname_cache='species_helcom.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA')\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "print(tfm.dfs['BIOTA']['SPECIES'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "## Remap Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae2880",
   "metadata": {},
   "source": [
    "Let's inspect the `TISSUE.csv` file provided by HELCOM describing the tissue nomenclature. Biota tissue is known as `body part` in the maris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  28%|██▊       | 8/29 [00:00<00:00, 77.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 89.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>SKIN/EPIDERMIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brain</td>\n",
       "      <td>ENTRAILS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                           source_name  \\\n",
       "source_key                                                                \n",
       "3             Flesh without bones  WHOLE FISH WITHOUT HEAD AND ENTRAILS   \n",
       "2             Flesh without bones           WHOLE FISH WITHOUT ENTRAILS   \n",
       "8                      Soft parts                        SKIN/EPIDERMIS   \n",
       "5             Flesh without bones          FLESH WITHOUT BONES (FILETS)   \n",
       "1                    Whole animal                            WHOLE FISH   \n",
       "12                          Brain                              ENTRAILS   \n",
       "15          Stomach and intestine                   STOMACH + INTESTINE   \n",
       "41                   Whole animal                         WHOLE ANIMALS   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "3                    20  \n",
       "2                    13  \n",
       "8                    10  \n",
       "5                     9  \n",
       "1                     5  \n",
       "12                    5  \n",
       "15                    3  \n",
       "41                    1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                    provider_col_key='TISSUE',\n",
    "                    fname_cache='tissues_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1bb9",
   "metadata": {},
   "source": [
    "We address several entries that were not correctly matched by the Remapper object, as detailed below:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_tissues = {\n",
    "    'WHOLE FISH WITHOUT HEAD AND ENTRAILS': 'Whole animal eviscerated without head',\n",
    "    'ENTRAILS': 'Viscera',\n",
    "    'SKIN/EPIDERMIS': 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 91.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 entries matched the criteria, while 5 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                   source_name  match_score\n",
       "source_key                                                                  \n",
       "2             Flesh without bones   WHOLE FISH WITHOUT ENTRAILS           13\n",
       "5             Flesh without bones  FLESH WITHOUT BONES (FILETS)            9\n",
       "1                    Whole animal                    WHOLE FISH            5\n",
       "15          Stomach and intestine           STOMACH + INTESTINE            3\n",
       "41                   Whole animal                 WHOLE ANIMALS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef75cb1",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `TISSUE` column to the `body_part` column after having defined the lookup table `lut_tissues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                               provider_col_key='TISSUE',\n",
    "                               fname_cache='tissues_helcom.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1887c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  BODY_PART\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA'][['TISSUE', 'BODY_PART']][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "## Remap biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f111f2",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "\n",
    "1) Is this needed in NETCDF? Can enum include the species and biogroup LUT?\n",
    "\n",
    "2) Include the `lut_biogroup_from_biota` callback in utils.ipynb. \n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`lut_biogroup_from_biota` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biogroup_from_biota = lambda: get_lut(src_dir=species_lut_path().parent, fname=species_lut_path().name, \n",
    "                               key='species_id', value='biogroup_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a37157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA')\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA']['BIO_GROUP'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "## Remap Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938d40",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `SEDI` values `56` and `73` are not found in the `SEDIMENT_TYPE.csv` lookup table provided. Note also there are many `nan` values in the `SEDIMENT_TYPE.csv` file.\n",
    "\n",
    "We reassign them to `-99` for now but should be clarified/fixed. This is demonstrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SEDI values: {56.0, 73.0, nan}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_sed_lut = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "sediment_sedi = set(dfs['SEDIMENT'].SEDI.unique())\n",
    "lookup_sedi = set(df_sed_lut['SEDI'])\n",
    "missing = sediment_sedi - lookup_sedi\n",
    "print(f\"Missing SEDI values: {missing if missing else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1b5c5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    " ``SedRepName`` is used by OpenRefine. ``SedRepName`` is not included in the NetCDF encoding. Description of the `SedRepName` from [MARIS Data Formats\n",
    "](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide); 'Name of the sediment as reported by the data provider. The sediment name should be stored exactly as provided, without any modifications'. \n",
    "\n",
    "This information will be lost with the latest workflow (creating netcdf and decoding to csv) if we do not include strings in the netcdf encoding. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffefc5",
   "metadata": {},
   "source": [
    "Once again, we employ the **IMFA** (Inspect, Match, Fix, Apply) pattern to remap the HELCOM sediment types. Let's inspect the `SEDIMENT_TYPE.csv` file provided by HELCOM describing the sediment type nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI    SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99          NO DATA                    NaN\n",
       "1    30  SILT AND GRAVEL                    YES\n",
       "2     0           GRAVEL                    YES\n",
       "3     1             SAND                    YES\n",
       "4     2        FINE SAND                     NO"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e669f",
   "metadata": {},
   "source": [
    "Let's try to match as many as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█         | 5/47 [00:00<00:00, 46.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 75.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 entries matched the criteria, while 3 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>Soft</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99                      Soft         NO DATA            5\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in)/'SEDIMENT_TYPE.csv'),\n",
    "                    maris_lut_fn=sediments_lut_path,\n",
    "                    maris_col_id='sedtype_id',\n",
    "                    maris_col_name='sedtype',\n",
    "                    provider_col_to_match='SEDIMENT TYPE',\n",
    "                    provider_col_key='SEDI',\n",
    "                    fname_cache='sediments_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a92e4",
   "metadata": {},
   "source": [
    "We address the remaining unmatched values by adding fixes_sediments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_sediments = {\n",
    "    'NO DATA': '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05728a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|█▉        | 9/47 [00:00<00:00, 82.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 90.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 entries matched the criteria, while 2 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "50             Mud and gravel  MUD AND GARVEL            2\n",
       "46               Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_sediments)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152c8c7",
   "metadata": {},
   "source": [
    "A visual inspection of the remaining values shows that they are acceptable to proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedimentCB(Callback):\n",
    "    \"Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable,  # Function that returns the lookup table dictionary\n",
    "                 sed_grp_name: str = 'SEDIMENT',  # The name of the sediment group\n",
    "                 replace_lut: dict = None  # Dictionary for replacing SEDI values\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Fix inconsistent SEDI values\n",
    "        tfm.dfs[self.sed_grp_name] = self._fix_inconsistent_sedi(tfm.dfs[self.sed_grp_name], self.replace_lut)\n",
    "        \n",
    "        # Get unique SEDI values\n",
    "        unique_sedi = tfm.dfs[self.sed_grp_name]['SEDI'].unique()\n",
    "        \n",
    "        # Get sediment types for unique SEDI values\n",
    "        sediment_mapping = self._get_sediment_types(unique_sedi, lut)\n",
    "        \n",
    "        # Replace SEDI values in the DataFrame using the mapping\n",
    "        tfm.dfs[self.sed_grp_name]['SED_TYPE'] = tfm.dfs[self.sed_grp_name]['SEDI'].map(sediment_mapping)\n",
    "\n",
    "    def _fix_inconsistent_sedi(self, df: pd.DataFrame, replace_lut: dict) -> pd.DataFrame:\n",
    "        \"Temporary fix for inconsistent SEDI values. Data provider to confirm and clarify.\"\n",
    "        df['SEDI'] = df['SEDI'].replace(replace_lut)\n",
    "        return df\n",
    "\n",
    "    def _get_sediment_types(self, unique_sedi: np.ndarray, lut: dict) -> dict:\n",
    "        \"Get sediment types for unique SEDI values and return a mapping dictionary.\"\n",
    "        sediment_mapping = {}\n",
    "        \n",
    "        for sedi_value in unique_sedi:\n",
    "            match = lut.get(sedi_value, Match(0, None, None, None))\n",
    "            if match.matched_id == 0:\n",
    "                self._print_unmatched_sedi(sedi_value)\n",
    "            sediment_mapping[sedi_value] = match.matched_id\n",
    "        \n",
    "        return sediment_mapping\n",
    "\n",
    "    def _print_unmatched_sedi(self, \n",
    "                              sedi_value: int,  # The `SEDI` value from the DataFrame\n",
    "                             ) -> None:\n",
    "        \"Print the SEDI value if the matched_id is 0 (i.e. Not available).\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_sediments = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv'),\n",
    "                                 maris_lut_fn=sediments_lut_path,\n",
    "                                 maris_col_id='sedtype_id',\n",
    "                                 maris_col_name='sedtype',\n",
    "                                 provider_col_to_match='SEDIMENT TYPE',\n",
    "                                 provider_col_key='SEDI',\n",
    "                                 fname_cache='sediments_helcom.pkl'\n",
    "                                 ).generate_lookup_table(fixes=fixes_sediments, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e7e02",
   "metadata": {},
   "source": [
    "Reassign the `SEDI` values of `56`, `73`, and `nan` to `-99`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63482233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "sed_replace_lut = {\n",
    "    56: -99,\n",
    "    73: -99,\n",
    "    np.nan: -99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d334ac",
   "metadata": {},
   "source": [
    "Utilize the RemapSedimentCB callback to remap the SEDI values in the HELCOM dataset to the corresponding MARIS standard sediment type, referred to as SED_TYPE. After the remapping process, display the SEDI and SED_TYPE columns from the SEDIMENT DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25495b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 58, 30, 59, 55, 56, 36, 29, 47,  4, 54, 33,  6, 44, 42, 48,\n",
       "       61, 57, 28, 49, 32, 45, 39, 46, 38, 31, 60, 62, 26, 53, 52,  1, 51,\n",
       "       37, 34, 50,  7, 10, 41, 43, 35])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut)])\n",
    "\n",
    "tfm()\n",
    "\n",
    "tfm.dfs['SEDIMENT']['SED_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "## Remap filtering status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea63f3",
   "metadata": {},
   "source": [
    "HELCOM filtered status is encoded as follows in the `FILT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index value\n",
       "0      0     F\n",
       "1      1     n\n",
       "2      2     N\n",
       "3      3   NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "get_unique_across_dfs(dfs, col_name='FILT', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee067",
   "metadata": {},
   "source": [
    "MARIS uses a different encoding for filtered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(filtered_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf457",
   "metadata": {},
   "source": [
    "For only four categories to remap, the `Remapper` is an overkill. We can use a simple dictionary to map the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_filtered = {\n",
    "    'N': 2, # No\n",
    "    'n': 2, # No\n",
    "    'F': 1 # Yes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`RemapFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapFiltCB(Callback):\n",
    "    \"Lookup FILT value in dataframe using the lookup table.\"\n",
    "    def __init__(self,\n",
    "                 lut_filtered: dict=lut_filtered, # Dictionary mapping FILT codes to their corresponding names\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'FILT' in df.columns:\n",
    "                df['FILT'] = df['FILT'].map(lambda x: self.lut_filtered.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719feb2c",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapFiltCB(lut_filtered)])\n",
    "\n",
    "print(tfm()['SEAWATER']['FILT'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1762e",
   "metadata": {},
   "source": [
    "## Add Laboratory ID (REVIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa8601",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**:  Review the inclusion of LAB in the NetCDF output, note with minor updates to dbo_lab.xlsx it would offer a way to obtain a `SMP_ID`\n",
    "\n",
    "This section could be simplified by including all Helcom 'LABORATORY' names in the MARIS standard laboratory names lookup table (dbo_lab.xlsx). For example STUK, KRIL, RISO, etc. are absent from the MARIS standard laboratory names lookup table lab_abb column.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fd6c2",
   "metadata": {},
   "source": [
    "Lets use the utility `get_unique_across_dfs` function to review the unique laboratory IDs in the HELCOM dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>LVDC</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>RISO</td>\n",
       "      <td>LVEA</td>\n",
       "      <td>ERPC</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>EBRS</td>\n",
       "      <td>STUK</td>\n",
       "      <td>NCRS</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>LREB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JORC</td>\n",
       "      <td>SSSI</td>\n",
       "      <td>CLOR</td>\n",
       "      <td>BFFG</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>SAAS</td>\n",
       "      <td>IMGW</td>\n",
       "      <td>SSSM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3     4     5     6     7     8     9     10   11  \\\n",
       "index     0     1     2     3     4     5     6     7     8     9    10   11   \n",
       "value  LVDC  KRIL  RISO  LVEA  ERPC  VTIG  EBRS  STUK  NCRS  LEPA  LREB  NaN   \n",
       "\n",
       "         12    13    14    15    16    17    18    19  \n",
       "index    12    13    14    15    16    17    18    19  \n",
       "value  JORC  SSSI  CLOR  BFFG  DHIG  SAAS  IMGW  SSSM  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(tfm.dfs, col_name='LABORATORY', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20d826",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a lookup table `LABORATORY_NAME.csv` which captures the laboratory names and codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>LABORATORY_NAME</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG</td>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY</td>\n",
       "      <td>01/01/86 00:00:00</td>\n",
       "      <td>12/31/07 00:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLOR</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>01/01/84 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DHIG</td>\n",
       "      <td>FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY</td>\n",
       "      <td>01/01/84 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBRS</td>\n",
       "      <td>RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA</td>\n",
       "      <td>01/01/10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMHI</td>\n",
       "      <td>ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABORATORY                                              LABORATORY_NAME  \\\n",
       "0       BFFG                BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY   \n",
       "1       CLOR    CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "2       DHIG            FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY   \n",
       "3       EBRS     RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA   \n",
       "4       EMHI  ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA   \n",
       "\n",
       "          START_DATE           END_DATE  COUNTRY  \n",
       "0  01/01/86 00:00:00  12/31/07 00:00:00        6  \n",
       "1  01/01/84 00:00:00                NaN       67  \n",
       "2  01/01/84 00:00:00                NaN        6  \n",
       "3  01/01/10 00:00:00                NaN       91  \n",
       "4                NaN                NaN       91  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af592d43",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS standard laboratory names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f95bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_abb</th>\n",
       "      <th>lab</th>\n",
       "      <th>addr_1</th>\n",
       "      <th>addr_2</th>\n",
       "      <th>twn_zip</th>\n",
       "      <th>country</th>\n",
       "      <th>tel</th>\n",
       "      <th>e_mail</th>\n",
       "      <th>fax</th>\n",
       "      <th>note</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IAEA-EL</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P.O. Box No. 800</td>\n",
       "      <td>MC-98012 Monaco Cedex</td>\n",
       "      <td>Principality of Monaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab =  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ , country =    where lab_id = 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>INPAS</td>\n",
       "      <td>Institute of Nuclear Physics - Academy of Sciences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab =  Institute of Nuclear Physics - Academy of Sciences , country =    where lab_id = 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_id         lab_abb  \\\n",
       "0      -1  Not applicable   \n",
       "1       0   Not available   \n",
       "2       1         IAEA-EL   \n",
       "3       2           INPAS   \n",
       "\n",
       "                                                                                                  lab  \\\n",
       "0                                                                                      Not applicable   \n",
       "1                                                                                       Not available   \n",
       "2  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_   \n",
       "3                                                  Institute of Nuclear Physics - Academy of Sciences   \n",
       "\n",
       "  addr_1            addr_2                twn_zip                 country  \\\n",
       "0    NaN               NaN                    NaN                     NaN   \n",
       "1    NaN               NaN                    NaN           Not available   \n",
       "2    NaN  P.O. Box No. 800  MC-98012 Monaco Cedex  Principality of Monaco   \n",
       "3    NaN               NaN                 Tirana                 Albania   \n",
       "\n",
       "   tel e_mail  fax note  Unnamed: 11  Unnamed: 12  \\\n",
       "0  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "1  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "2  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "3  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "\n",
       "                                                                                                                                                Unnamed: 13  \n",
       "0                                                                                                                                                       NaN  \n",
       "1                                                                                                                                                       NaN  \n",
       "2  update lab set lab =  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ , country =    where lab_id = 1  \n",
       "3                                                  update lab set lab =  Institute of Nuclear Physics - Academy of Sciences , country =    where lab_id = 2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "maris_lab_lut=pd.read_excel(lab_lut_path())\n",
    "maris_lab_lut.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e993fd1",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR DATA PROVIDER**: \n",
    "One entry for the `LABORATORY` column includes a 'NaN', see below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with NaN in the `LABORATORY` column:\n",
      "SEDIMENT: \n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def find_nan_entries(dfs, columns=None):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of DataFrames, each containing the complete rows where any of the specified columns have NaN values from the original DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "        dfs (dict): A dictionary where keys are dataset names and values are pandas DataFrames.\n",
    "        columns (list, optional): A list of column names to check for NaN values. If None, all columns are checked.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where each key is the dataset name and the value is a DataFrame of complete rows that have NaN entries in the specified columns.\n",
    "    \"\"\"\n",
    "    nan_entries = {}\n",
    "    for key, df in dfs.items():\n",
    "        # If columns are specified, check these columns for NaN values\n",
    "        if columns is not None:\n",
    "            # Find rows with NaN values in the specified columns\n",
    "            nan_rows = df[columns].isnull().any(axis=1)\n",
    "        else:\n",
    "            # Find rows with any NaN values across all columns\n",
    "            nan_rows = df.isnull().any(axis=1)\n",
    "        \n",
    "        # Use the boolean index to select the complete rows from the original DataFrame\n",
    "        complete_nan_rows = df[nan_rows]\n",
    "        \n",
    "        if not complete_nan_rows.empty:\n",
    "            nan_entries[key] = complete_nan_rows\n",
    "    return nan_entries\n",
    "\n",
    "nan_lab_df = find_nan_entries(dfs, columns=['LABORATORY'])\n",
    "\n",
    "print ('Entries with NaN in the `LABORATORY` column:')\n",
    "for key, df in nan_lab_df.items():\n",
    "    print(f\"{key}: \\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cedd8",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Consider integrating combine_lut_columns into utils.ipynb. I've updated the remapper and match_maris_lut functions to accept either a lut_path or a DataFrame. This code could be further simplified by handling the file opening (e.g., pd.read_excel) directly within the remapper function, thereby always passing a DataFrame to match_maris_lut. Refer to the implementation in utils.ipynb for details.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8717d2",
   "metadata": {},
   "source": [
    "The HELCOM description of laboratory includes both the laboratory name and country. Lets update the ``maris_lab_lut`` to include the laboratory name and country in the same column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c3703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def combine_lut_columns(lut_path: Callable, combine_cols: List[str] = []):\n",
    "    if lut_path:\n",
    "        df_lut = pd.read_excel(lut_path()) \n",
    "        if combine_cols:\n",
    "            # Combine the specified columns into a single column with space as separator\n",
    "            df_lut['combined'] = df_lut[combine_cols].astype(str).agg(' '.join, axis=1)\n",
    "            # Create a column name by joining column names with '_'\n",
    "            combined_col_name = '_'.join(combine_cols)\n",
    "            df_lut.rename(columns={'combined': combined_col_name}, inplace=True)\n",
    "        return df_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9418a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_abb</th>\n",
       "      <th>lab</th>\n",
       "      <th>addr_1</th>\n",
       "      <th>addr_2</th>\n",
       "      <th>twn_zip</th>\n",
       "      <th>country</th>\n",
       "      <th>tel</th>\n",
       "      <th>e_mail</th>\n",
       "      <th>fax</th>\n",
       "      <th>note</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>lab_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not applicable nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IAEA-EL</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P.O. Box No. 800</td>\n",
       "      <td>MC-98012 Monaco Cedex</td>\n",
       "      <td>Principality of Monaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab =  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ , country =    where lab_id = 1</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ Principality of Monaco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_id         lab_abb  \\\n",
       "0      -1  Not applicable   \n",
       "1       0   Not available   \n",
       "2       1         IAEA-EL   \n",
       "\n",
       "                                                                                                  lab  \\\n",
       "0                                                                                      Not applicable   \n",
       "1                                                                                       Not available   \n",
       "2  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_   \n",
       "\n",
       "  addr_1            addr_2                twn_zip                 country  \\\n",
       "0    NaN               NaN                    NaN                     NaN   \n",
       "1    NaN               NaN                    NaN           Not available   \n",
       "2    NaN  P.O. Box No. 800  MC-98012 Monaco Cedex  Principality of Monaco   \n",
       "\n",
       "   tel e_mail  fax note  Unnamed: 11  Unnamed: 12  \\\n",
       "0  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "1  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "2  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "\n",
       "                                                                                                                                                Unnamed: 13  \\\n",
       "0                                                                                                                                                       NaN   \n",
       "1                                                                                                                                                       NaN   \n",
       "2  update lab set lab =  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ , country =    where lab_id = 1   \n",
       "\n",
       "                                                                                                                 lab_country  \n",
       "0                                                                                                         Not applicable nan  \n",
       "1                                                                                                Not available Not available  \n",
       "2  International Atomic Energy Agency - Environment Laboratory _former Marine Environment Laboratory_ Principality of Monaco  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_lut=combine_lut_columns(lab_lut_path, ['lab','country'])\n",
    "df_lut.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913278b",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the ``LABORATORY`` column of the HELCOM dataset to the MARIS standard laboratory names using both `lab` and `country` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv'),\n",
    "                    maris_lut_fn= combine_lut_columns(lut_path=lab_lut_path, combine_cols=['lab','country']),\n",
    "                    maris_col_id='lab_id',\n",
    "                    maris_col_name='lab_country',\n",
    "                    provider_col_to_match='LABORATORY_NAME',\n",
    "                    provider_col_key='LABORATORY',\n",
    "                    fname_cache='lab_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1528926",
   "metadata": {},
   "source": [
    "Lets try to match ``LABORATORY`` names to MARIS standard laboratory names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [00:00<00:00, 52.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entries matched the criteria, while 20 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSSI</th>\n",
       "      <td>Central Mining Institute Poland</td>\n",
       "      <td>STATENS STRÅLSKYDDSINSTITUT, SWEDEN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRIL</th>\n",
       "      <td>Polytechnic Institute Romania</td>\n",
       "      <td>V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUK</th>\n",
       "      <td>Radiation and Nuclear Safety Authority Finland</td>\n",
       "      <td>SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAAS</th>\n",
       "      <td>National Board of Nuclear Safety and Radiation Protection Germany</td>\n",
       "      <td>NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISO</th>\n",
       "      <td>Risø National Laboratory - The Radiation Research Department Denmark</td>\n",
       "      <td>RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEPA</th>\n",
       "      <td>Environmental Protection Agency Ireland</td>\n",
       "      <td>ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCRS</th>\n",
       "      <td>The Swedish University of Agricultural Sciences Sweden</td>\n",
       "      <td>SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOR</th>\n",
       "      <td>Central Laboratory for Radiological Protection Poland</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSSM</th>\n",
       "      <td>SVERIGE S  STRÅL SÄKERHETS MYNDIGHETEN Sweden</td>\n",
       "      <td>SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTIG</th>\n",
       "      <td>JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany</td>\n",
       "      <td>JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBRS</th>\n",
       "      <td>Radiation Safety Department, Environmental Board Estonia</td>\n",
       "      <td>RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVEA</th>\n",
       "      <td>Latvian Environment Agency Latvia</td>\n",
       "      <td>LATVIAN ENVIRONMENT AGENCY, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFFG</th>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany</td>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVDC</th>\n",
       "      <td>Environmental Data Center of Latvia Latvia</td>\n",
       "      <td>ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JORC</th>\n",
       "      <td>Joint Research Center Lithuania</td>\n",
       "      <td>JOINT RESEARCH CENTER, LITHUANIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMGW</th>\n",
       "      <td>Institute of Meteorology and Water Management Poland</td>\n",
       "      <td>INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERPC</th>\n",
       "      <td>Estonian Radiation Protection Centre Estonia</td>\n",
       "      <td>ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMHI</th>\n",
       "      <td>Estonian Meteorological and Hydrological Institute Estonia</td>\n",
       "      <td>ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHIG</th>\n",
       "      <td>Federal Maritime and Hydrographic Agency Germany</td>\n",
       "      <td>FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LREB</th>\n",
       "      <td>Lielriga Regional Environmental Board Latvia</td>\n",
       "      <td>LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              matched_maris_name  \\\n",
       "source_key                                                                         \n",
       "SSSI                                             Central Mining Institute Poland   \n",
       "KRIL                                               Polytechnic Institute Romania   \n",
       "STUK                              Radiation and Nuclear Safety Authority Finland   \n",
       "SAAS           National Board of Nuclear Safety and Radiation Protection Germany   \n",
       "RISO        Risø National Laboratory - The Radiation Research Department Denmark   \n",
       "LEPA                                     Environmental Protection Agency Ireland   \n",
       "NCRS                      The Swedish University of Agricultural Sciences Sweden   \n",
       "CLOR                       Central Laboratory for Radiological Protection Poland   \n",
       "SSSM                               SVERIGE S  STRÅL SÄKERHETS MYNDIGHETEN Sweden   \n",
       "VTIG                                 JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany   \n",
       "EBRS                    Radiation Safety Department, Environmental Board Estonia   \n",
       "LVEA                                           Latvian Environment Agency Latvia   \n",
       "BFFG                                BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany   \n",
       "LVDC                                  Environmental Data Center of Latvia Latvia   \n",
       "JORC                                             Joint Research Center Lithuania   \n",
       "IMGW                        Institute of Meteorology and Water Management Poland   \n",
       "ERPC                                Estonian Radiation Protection Centre Estonia   \n",
       "EMHI                  Estonian Meteorological and Hydrological Institute Estonia   \n",
       "DHIG                            Federal Maritime and Hydrographic Agency Germany   \n",
       "LREB                                Lielriga Regional Environmental Board Latvia   \n",
       "\n",
       "                                                                    source_name  \\\n",
       "source_key                                                                        \n",
       "SSSI                                        STATENS STRÅLSKYDDSINSTITUT, SWEDEN   \n",
       "KRIL                                     V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA   \n",
       "STUK        SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND   \n",
       "SAAS         NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY   \n",
       "RISO           RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK   \n",
       "LEPA                                 ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA   \n",
       "NCRS                        SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN   \n",
       "CLOR                  CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "SSSM                              SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN   \n",
       "VTIG                              JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY   \n",
       "EBRS                   RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA   \n",
       "LVEA                                         LATVIAN ENVIRONMENT AGENCY, LATVIA   \n",
       "BFFG                              BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY   \n",
       "LVDC                                ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA   \n",
       "JORC                                           JOINT RESEARCH CENTER, LITHUANIA   \n",
       "IMGW                      INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND   \n",
       "ERPC                              ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA   \n",
       "EMHI                ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA   \n",
       "DHIG                          FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY   \n",
       "LREB                              LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "SSSI                 23  \n",
       "KRIL                 22  \n",
       "STUK                 21  \n",
       "SAAS                 10  \n",
       "RISO                  8  \n",
       "LEPA                  7  \n",
       "NCRS                  5  \n",
       "CLOR                  4  \n",
       "SSSM                  3  \n",
       "VTIG                  2  \n",
       "EBRS                  2  \n",
       "LVEA                  1  \n",
       "BFFG                  1  \n",
       "LVDC                  1  \n",
       "JORC                  1  \n",
       "IMGW                  1  \n",
       "ERPC                  1  \n",
       "EMHI                  1  \n",
       "DHIG                  1  \n",
       "LREB                  1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ba2b",
   "metadata": {},
   "source": [
    "Although the match score is 1 or greater for all entries, many are still matched appropriately. Let's manually correct any unmatched values. Here, we are manually aligning the data providers' laboratory names with those used by the MARIS LUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_lab_names = {\n",
    "    'STATENS STRÅLSKYDDSINSTITUT, SWEDEN': 'Swedish Radiation Safety Authority Sweden',\n",
    "    'V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA': 'V.G. Khlopin Radium Institute - Lab. of Environmental Radioactive Contamination Monitoring Russian Federation',\n",
    "    'ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA': 'Lithuanian Environmental Protection Agency Lithuania',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d8f3d",
   "metadata": {},
   "source": [
    "Now, lets apply the manual corrections, `fixes_lab_names` and try again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [00:00<00:00, 58.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 entries matched the criteria, while 17 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STUK</th>\n",
       "      <td>Radiation and Nuclear Safety Authority Finland</td>\n",
       "      <td>SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAAS</th>\n",
       "      <td>National Board of Nuclear Safety and Radiation Protection Germany</td>\n",
       "      <td>NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISO</th>\n",
       "      <td>Risø National Laboratory - The Radiation Research Department Denmark</td>\n",
       "      <td>RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCRS</th>\n",
       "      <td>The Swedish University of Agricultural Sciences Sweden</td>\n",
       "      <td>SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOR</th>\n",
       "      <td>Central Laboratory for Radiological Protection Poland</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              matched_maris_name  \\\n",
       "source_key                                                                         \n",
       "STUK                              Radiation and Nuclear Safety Authority Finland   \n",
       "SAAS           National Board of Nuclear Safety and Radiation Protection Germany   \n",
       "RISO        Risø National Laboratory - The Radiation Research Department Denmark   \n",
       "NCRS                      The Swedish University of Agricultural Sciences Sweden   \n",
       "CLOR                       Central Laboratory for Radiological Protection Poland   \n",
       "\n",
       "                                                                    source_name  \\\n",
       "source_key                                                                        \n",
       "STUK        SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND   \n",
       "SAAS         NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY   \n",
       "RISO           RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK   \n",
       "NCRS                        SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN   \n",
       "CLOR                  CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "STUK                 21  \n",
       "SAAS                 10  \n",
       "RISO                  8  \n",
       "NCRS                  5  \n",
       "CLOR                  4  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_lab_names)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b35a2",
   "metadata": {},
   "source": [
    "We have successfully matched the laboratory names to the MARIS standard laboratory names. We can now create a lookup table for the laboratory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for laboratory names\n",
    "lut_lab = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv'),\n",
    "                    maris_lut_fn= combine_lut_columns(lut_path=lab_lut_path, combine_cols=['lab','country']),\n",
    "                    maris_col_id='lab_id',\n",
    "                    maris_col_name='lab_country',\n",
    "                    provider_col_to_match='LABORATORY_NAME',\n",
    "                    provider_col_key='LABORATORY',\n",
    "                    fname_cache='lab_helcom.pkl').generate_lookup_table(fixes=fixes_lab_names,as_df=False, overwrite=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58648646",
   "metadata": {},
   "source": [
    "We now create the callback `RemapLabCB`, which will remap the nuclide names using the `lut_lab` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of unique laboratory names: \n",
      "       LABORATORY  LAB\n",
      "0           VTIG  342\n",
      "547         STUK  301\n",
      "2855        SSSM  340\n",
      "3095        SSSI  381\n",
      "3611        SAAS  118\n",
      "4249        RISO  329\n",
      "5109        NCRS  238\n",
      "5828        LVEA  325\n",
      "5850        LVDC  326\n",
      "5866        LREB  327\n",
      "5875        LEPA  324\n",
      "5916        JORC  323\n",
      "5940        ERPC  322\n",
      "5977        EBRS  350\n",
      "5999        CLOR  188\n",
      "8103        BFFG  341\n",
      "14055       IMGW  191\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER'])\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "unique_labs = tfm.dfs['BIOTA'][['LABORATORY', 'LAB']].drop_duplicates()\n",
    "print('Example of unique laboratory names: \\n', unique_labs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "## Add Sample ID (REVIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3625631",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Enhancing traceability of NetCDF entries to original samples in the datasource using a standardized `SMP_ID`.\n",
    "\n",
    "*Context*:\n",
    "\n",
    "Previously, the NetCDF output did not include a sample laboratory code (or `SMP_ID`), limiting our ability to trace data back to its source. \n",
    "\n",
    "*Issue Identified*:\n",
    "The `KEY` column in the HELCOM dataset, which combines a sample type, a laboratory code, and an integer sequence offers a way trace data back to the HELCOM source. The `KEY` is of type string which is not included in our NetCDF output. To include a way to trace data back to the HELCOM source, we propose to include a `SMP_ID` in the NetCDF output which is of type integer.\n",
    "\n",
    "*Proposed Solution*:\n",
    "For the HELCOM dataset, where the `KEY` column includes unique codes like `WDHIG1996246` (comprising sample type, lab code, and sequence), we propose encoding this into a structured `SMP_ID`. This `SMP_ID` will use standardized MARIS Lookup Tables (LUTs) to convert both the sample type and laboratory code into integers.\n",
    "\n",
    "*Implementation Details*:\n",
    "- The `SMP_ID` will be formatted such that:\n",
    "  - The first digit indicates the sample type (e.g., 1 for Seawater).\n",
    "  - The next three digits represent the laboratory code (e.g., 313 for DHIG as standardized in dbo_lab.xlsx).\n",
    "  - The remaining digits reflect the integer sequence from the HELCOM KEY.\n",
    "- Example: `WDHIG1996246` becomes `SMP_ID` `13131996246`.\n",
    "\n",
    "*Action Required*:\n",
    "To adopt this approach, a review and update of the laboratory codes in the LUT (dbo_lab.xlsx) are necessary to ensure consistency and accuracy. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af75adc",
   "metadata": {},
   "source": [
    "First we wil use ``check_unique_key_int`` to show the non unique integer part of the `KEY` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def check_unique_key_int(tfm):\n",
    "    \"\"\"\n",
    "    Extracts unique 'KEY' values from specified DataFrames, separates them into string and integer components,\n",
    "    and groups keys by their integer components.\n",
    "\n",
    "    Parameters:\n",
    "    tfm (Transformer): The transformer object containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with the unique keys, their string and integer components, and grouped keys by integer component.\n",
    "    \"\"\"\n",
    "    # Define the groups to extract keys from\n",
    "    groups = ['SEAWATER', 'BIOTA', 'SEDIMENT']\n",
    "    \n",
    "    # Initialize a set to store unique keys\n",
    "    unique_keys = set()\n",
    "    \n",
    "    # Collect unique keys from each DataFrame\n",
    "    for grp in groups:\n",
    "        unique_keys.update(tfm.dfs[grp]['KEY'].unique())\n",
    "    \n",
    "    # Initialize a dictionary to group keys by their integer components\n",
    "    int_key_map = {}\n",
    "    \n",
    "    for key in unique_keys:\n",
    "        # Assuming the integer part starts after the first 5 characters\n",
    "        int_part = int(key[5:]) if key[5:].isdigit() else None  # Remaining part as integer\n",
    "        \n",
    "        if int_part is not None:\n",
    "            if int_part not in int_key_map:\n",
    "                int_key_map[int_part] = []  # Initialize list for this integer part\n",
    "            int_key_map[int_part].append(key)  # Append the complete key to the list\n",
    "    \n",
    "    return {\n",
    "        'int_key_map': int_key_map  # Return the mapping of integer parts to complete keys\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64748dbf",
   "metadata": {},
   "source": [
    "Below, we will generate a DataFrame where the index (labeled 'INT COMPONENT OF `KEY`') represents the integer portion extracted from the Helcom `KEY`. The 'KEYS' column lists all the `KEY` values that include this integer component. Originally, the plan was to use the integer part of the `KEY` column to create the `SMP_ID`. However, as demonstrated below, the integer part is not unique, which complicates this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEYS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT COMPONENT OF `KEY`</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013090</th>\n",
       "      <td>[SDHIG2013090, SSTUK2013090]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005031</th>\n",
       "      <td>[WKRIL2005031, SSSSI2005031, WRISO2005031, SLVEA2005031, SCLOR2005031, WIMGW2005031, SKRIL2005031, SSTUK2005031]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016022</th>\n",
       "      <td>[WRISO2016022, WIMGW2016022, SSTUK2016022, SCLOR2016022, SSSSM2016022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009184</th>\n",
       "      <td>[SDHIG2009184]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005169</th>\n",
       "      <td>[WDHIG2005169]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    KEYS\n",
       "INT COMPONENT OF `KEY`                                                                                                                  \n",
       "2013090                                                                                                     [SDHIG2013090, SSTUK2013090]\n",
       "2005031                 [WKRIL2005031, SSSSI2005031, WRISO2005031, SLVEA2005031, SCLOR2005031, WIMGW2005031, SKRIL2005031, SSTUK2005031]\n",
       "2016022                                                           [WRISO2016022, WIMGW2016022, SSTUK2016022, SCLOR2016022, SSSSM2016022]\n",
       "2009184                                                                                                                   [SDHIG2009184]\n",
       "2005169                                                                                                                   [WDHIG2005169]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Create DataFrame from dictionary and set index name and column name\n",
    "unique_key_df = pd.DataFrame.from_dict(check_unique_key_int(tfm)).rename_axis('INT COMPONENT OF `KEY`')\n",
    "unique_key_df=unique_key_df.rename(columns={unique_key_df.columns[0]: 'KEYS'})\n",
    "unique_key_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc7e07",
   "metadata": {},
   "source": [
    "Below we will create a callback `AddSampleIDCB` to remap the `KEY` column to the `SMP_ID` column in each DataFrame.\n",
    "\n",
    "Remeber that in HELCOM, the `KEY` column is encoded to include the sample type (S=Sediment, W=Seawater, B=Biota), the laboratory code (e.g., DHIG), followed by an integer sequence. \n",
    "\n",
    "If we update the MARIS LUT (dbo_lab.xlsx), to include laboratory codes (i.e. update the ``lab_abb`` column), then the remapping of the  `LAB` and the `AddSampleIDCB` can be much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "smp_type_lut = {\n",
    "    'SEAWATER': 1,\n",
    "    'BIOTA': 2,\n",
    "    'SEDIMENT': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class AddSampleIDCB(Callback):\n",
    "    \"Remap `KEY` column to `SMP_ID` in each DataFrame.\"\n",
    "    def __init__(self, lut_type: Dict[str, int]):\n",
    "        self.lut_type = lut_type\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp], grp)\n",
    "    \n",
    "    def _remap_sample_id(self, df: pd.DataFrame, grp: str):\n",
    "        \"\"\"\n",
    "        Remaps the 'KEY' column to 'SMP_ID' using the provided lookup table.\n",
    "        Sets 'SMP_ID' to -1 if 'LAB' or 'SEQUENCE' is NaN.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "            grp (str): The group key from the DataFrame dictionary, used to access specific LUT values.\n",
    "        \"\"\"\n",
    "        # Check for NaNs in 'LAB' or 'SEQUENCE' and compute 'SMP_ID' conditionally\n",
    "        df['SMP_ID'] = np.where(\n",
    "            df['LAB'].isna() | df['SEQUENCE'].isna(),\n",
    "            -1,\n",
    "            str(self.lut_type[grp]) + df['LAB'].astype(str).str.zfill(3) + df['SEQUENCE'].astype(str).str.zfill(7)\n",
    "        )\n",
    "\n",
    "        # Convert 'SMP_ID' to integer, handling floating point representations\n",
    "        df['SMP_ID'] = df['SMP_ID'].apply(lambda x: int(float(x)) if isinstance(x, str) and '.' in x else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12112012003 12112012004 12112012005 ... 13400201806 13400201807\n",
      " 13400201808]\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                        RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                        AddSampleIDCB(lut_type=smp_type_lut),\n",
    "                        CompareDfsAndTfmCB(dfs)\n",
    "                        ])\n",
    "\n",
    "print(tfm()['SEAWATER']['SMP_ID'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac551",
   "metadata": {},
   "source": [
    "## Add depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7940b",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a column for the sampling depth (`SDEPTH`) for the `SEAWATER` and `BIOTA` datasets. Additionally, it contains a column for the total depth (`TDEPTH`) applicable to both the `SEDIMENT` and `SEAWATER` datasets. In this section, we will create a callback to incorporate both the sampling depth (`smp_depth`) and total depth (`tot_depth`) into the MARIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f14b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddDepthCB(Callback):\n",
    "    \"Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'SDEPTH' in df.columns:\n",
    "                df['SMP_DEPTH'] = df['SDEPTH'].astype(float)\n",
    "            if 'TDEPTH' in df.columns:\n",
    "                df['TOT_DEPTH'] = df['TDEPTH'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96264ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA:        SMP_DEPTH\n",
      "0            NaN\n",
      "78         22.00\n",
      "88         39.00\n",
      "96         40.00\n",
      "183        65.00\n",
      "...          ...\n",
      "14198      17.65\n",
      "14206      14.65\n",
      "14400      91.00\n",
      "14636      35.40\n",
      "14644      17.10\n",
      "\n",
      "[279 rows x 1 columns]\n",
      "SEAWATER:        SMP_DEPTH  TOT_DEPTH\n",
      "0            0.0        NaN\n",
      "1           29.0        NaN\n",
      "4           39.0        NaN\n",
      "6           62.0        NaN\n",
      "10          71.0        NaN\n",
      "...          ...        ...\n",
      "20081        9.5       11.5\n",
      "20090       40.0       86.0\n",
      "20091       60.0       86.0\n",
      "20093       84.0       86.0\n",
      "20096       91.0       93.0\n",
      "\n",
      "[1664 rows x 2 columns]\n",
      "SEDIMENT:        TOT_DEPTH\n",
      "0           71.0\n",
      "2           23.0\n",
      "15          12.0\n",
      "17          56.0\n",
      "30          40.0\n",
      "...          ...\n",
      "35844        3.9\n",
      "36048      103.0\n",
      "36406      108.9\n",
      "36455        4.5\n",
      "36899      125.0\n",
      "\n",
      "[195 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddDepthCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'SMP_DEPTH' in tfm.dfs[grp].columns and 'TOT_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SMP_DEPTH','TOT_DEPTH']].drop_duplicates())\n",
    "    elif 'SMP_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SMP_DEPTH']].drop_duplicates())\n",
    "    elif 'TOT_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['TOT_DEPTH']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e169c8",
   "metadata": {},
   "source": [
    "## Add Sailinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e599987",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**\n",
    "\n",
    "The HELCOM dataset includes a column for the salinity of the water (`SALIN`). According to the HELCOM documentation, the `SALIN` column represents:\n",
    "> 'Salinity of water in PSU units'\n",
    "\n",
    "In the SEAWATER dataset, three entries have salinity values greater than 50 PSU. While salinity values greater than 50 PSU are possible, these entries may require further verification. Notably, these three entries have a salinity value of 99.99 PSU, which suggests potential data entry errors.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e7a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12288</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>CS137</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>CS134</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12290</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>SR90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "12288  WDHIG1998072   CS137      3           NaN         40.1        1.6   \n",
       "12289  WDHIG1998072   CS134      3           NaN          1.1       23.6   \n",
       "12290  WDHIG1998072    SR90      2           NaN          8.5        1.9   \n",
       "\n",
       "      DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... TDEPTH  SDEPTH  \\\n",
       "12288             NaN        6       DHIG   1998072  ...   25.0     0.0   \n",
       "12289             NaN        6       DHIG   1998072  ...   25.0     0.0   \n",
       "12290             NaN        6       DHIG   1998072  ...   25.0     0.0   \n",
       "\n",
       "       SALIN  TTEMP FILT  MORS_SUBBASIN  HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \\\n",
       "12288  99.99    5.0    F              5               15              NaN   \n",
       "12289  99.99    5.0    F              5               15              NaN   \n",
       "12290  99.99    5.0    F              5               15              NaN   \n",
       "\n",
       "       SMP_DEPTH  TOT_DEPTH  \n",
       "12288        0.0       25.0  \n",
       "12289        0.0       25.0  \n",
       "12290        0.0       25.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "tfm.dfs['SEAWATER'][tfm.dfs['SEAWATER']['SALIN'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fd696",
   "metadata": {},
   "source": [
    "Lets add the salinity values to the SEAWATER DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddSalinityCB(Callback):\n",
    "    def __init__(self, salinity_col: str = 'SALIN'):\n",
    "        self.salinity_col = salinity_col\n",
    "    \"Add salinity to the SEAWATER DataFrame.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if self.salinity_col in df.columns:\n",
    "                df['SALINITY'] = df[self.salinity_col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER:        SALINITY\n",
      "0           NaN\n",
      "97       7.5700\n",
      "98       7.2100\n",
      "101      7.2800\n",
      "104      7.4700\n",
      "...         ...\n",
      "19859    6.5718\n",
      "19863    2.8932\n",
      "19867    3.0216\n",
      "19871    4.9392\n",
      "19874    6.3919\n",
      "\n",
      "[2590 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddSalinityCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'SALINITY' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SALINITY']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31cc1d5",
   "metadata": {},
   "source": [
    "## Add Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6b981",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**\n",
    "\n",
    "The HELCOM dataset includes a column for the temperature of the water (`TTEMP`). According to the HELCOM documentation, the `TTEMP` column represents:\n",
    "> 'Water temperature in Celsius (ºC) degrees of sampled water'\n",
    "\n",
    "In the SEAWATER dataset, several entries have temperature values greater than 50ºC. These entries may require further verification. Notably, these entries have a temperature value of 99.99ºC, which suggests potential data entry errors, see below.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e1b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with temperature greater than 50ºC:  92\n",
      "               KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "5954  WDHIG1995559   CS134      4           NaN          1.7       15.0   \n",
      "5955  WDHIG1995559   CS137      4           NaN         58.7        2.0   \n",
      "5960  WDHIG1995569   CS134      4           NaN          1.4       12.0   \n",
      "5961  WDHIG1995569   CS137      4           NaN         62.8        1.0   \n",
      "5964  WDHIG1995571   CS134      4           NaN          1.5       17.0   \n",
      "\n",
      "     DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (dddddd)  \\\n",
      "5954             NaN        6       DHIG   1995559  ...            10.2033   \n",
      "5955             NaN        6       DHIG   1995559  ...            10.2033   \n",
      "5960             NaN        6       DHIG   1995569  ...            10.2777   \n",
      "5961             NaN        6       DHIG   1995569  ...            10.2777   \n",
      "5964             NaN        6       DHIG   1995571  ...            10.2000   \n",
      "\n",
      "      TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
      "5954    13.0    11.0  14.81  99.9     N              5               15   \n",
      "5955    13.0    11.0  14.81  99.9     N              5               15   \n",
      "5960    14.0    12.0  14.80  99.9     N              5               15   \n",
      "5961    14.0    12.0  14.80  99.9     N              5               15   \n",
      "5964    19.0    17.0  14.59  99.9     N              5               15   \n",
      "\n",
      "      DATE_OF_ENTRY_y  SALINITY  \n",
      "5954              NaN     14.81  \n",
      "5955              NaN     14.81  \n",
      "5960              NaN     14.80  \n",
      "5961              NaN     14.80  \n",
      "5964              NaN     14.59  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "t_df= tfm.dfs['SEAWATER'][tfm.dfs['SEAWATER']['TTEMP'] > 50]\n",
    "print('Number of entries with temperature greater than 50ºC: ', t_df.shape[0])\n",
    "print(t_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd942d",
   "metadata": {},
   "source": [
    "Lets add the temperature values to the SEAWATER DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047afa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddTemperatureCB(Callback):\n",
    "    def __init__(self, temperature_col: str = 'TTEMP'):\n",
    "        self.temperature_col = temperature_col\n",
    "    \"Add temperature to the SEAWATER DataFrame.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if self.temperature_col in df.columns:\n",
    "                df['TEMPERATURE'] = df[self.temperature_col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER:        TEMPERATURE\n",
      "0              NaN\n",
      "987         7.8000\n",
      "990         6.5000\n",
      "993         4.1000\n",
      "996         4.8000\n",
      "...            ...\n",
      "19859       2.8613\n",
      "19863       2.2059\n",
      "19867       1.7740\n",
      "19871       7.0978\n",
      "19874       4.2820\n",
      "\n",
      "[881 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddTemperatureCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'TEMPERATURE' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['TEMPERATURE']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05383c",
   "metadata": {},
   "source": [
    "## Add Methods (FOR NEXT VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307c018",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a look-up table `ANALYSIS_METHOD.csv` which captures the methods used by HELCOM in a description field (free text). Lets review the ANALYSIS METHOD descriptions of HELCOM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG01</td>\n",
       "      <td>6</td>\n",
       "      <td>Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFFG02</td>\n",
       "      <td>6</td>\n",
       "      <td>Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLOR02</td>\n",
       "      <td>67</td>\n",
       "      <td>Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   METHOD  COUNTRY  \\\n",
       "0  BFFG01        6   \n",
       "1  BFFG02        6   \n",
       "2  CLOR02       67   \n",
       "\n",
       "                                                                                                                                                                                                                                               DESCRIPTION  \n",
       "0                                                            Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)  \n",
       "1                                                    Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)  \n",
       "2  Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "analsis_method_df=pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv')\n",
    "analsis_method_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39ead8",
   "metadata": {},
   "source": [
    "Number of unique ANALYSIS_METHOD DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28536ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "len(analsis_method_df['DESCRIPTION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9976e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_method = lambda: pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a7232",
   "metadata": {},
   "source": [
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['UPPSLI']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef89d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "prepmet_lut = pd.read_excel(prepmet_lut_path())\n",
    "sampmet_lut = pd.read_excel(sampmet_lut_path())\n",
    "counmet_lut = pd.read_excel(counmet_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d625717",
   "metadata": {},
   "source": [
    "**DISCUSS** repition of counting method in `counmet_lut`. When should we use each of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counmet_id</th>\n",
       "      <th>counmet</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Atomic absorption</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>ALP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Alpha ionization chamber spectrometry</td>\n",
       "      <td>ALPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Alpha liquid scintillation spectrometry</td>\n",
       "      <td>ALPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Alpha semiconductor spectrometry</td>\n",
       "      <td>ALPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Alpha total</td>\n",
       "      <td>ALPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Accelerator mass spectrometry</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>Beta</td>\n",
       "      <td>BET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counmet_id                                  counmet  code\n",
       "0          -1                           Not applicable   NaN\n",
       "1           0                            Not available     0\n",
       "2           1                        Atomic absorption    AA\n",
       "3           2                                    Alpha   ALP\n",
       "4           3    Alpha ionization chamber spectrometry  ALPI\n",
       "5           4  Alpha liquid scintillation spectrometry  ALPL\n",
       "6           5         Alpha semiconductor spectrometry  ALPS\n",
       "7           6                              Alpha total  ALPT\n",
       "8           7            Accelerator mass spectrometry   AMS\n",
       "9           8                                     Beta   BET"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "counmet_lut.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "## Add slice position (TOP and BOTTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['UPPSLI']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOP  BOTTOM\n",
      "0  15.0    20.0\n",
      "1  20.0    27.0\n",
      "2   0.0     2.0\n",
      "3   2.0     4.0\n",
      "4   4.0     6.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedSliceTopBottomCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEDIMENT'][['TOP','BOTTOM']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "## Add dry weight, wet weight and percentage weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d2796",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Entries for the ``BASIS`` value of the ``BIOTA`` dataset report a value of `F` which is not consistent with the HELCOM description provided in the metadata. The `GUIDELINES FOR MONITORING OF RADIOACTIVE SUBSTANCES` was obtained from [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2b08",
   "metadata": {},
   "source": [
    "Lets take a look at the BIOTA BASIS values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcfc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafeff5",
   "metadata": {},
   "source": [
    "Number of entries for each ``BASIS`` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d37b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASIS\n",
       "W    11167\n",
       "D     3634\n",
       "F       25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc763755",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some entries for ``DW%`` (Dry weight as percentage (%) of fresh weight) are much higher than 100%. Additionally, ``DW%`` is repoted as 0% in some cases.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f3249",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc7826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b30b6b",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f386973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b1201",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f48f6",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44234014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00833c1f",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Several SEDIMENT entries have `DW%` (Dry weight as percentage of fresh weight) values less than 1%. While technically possible, this would indicate samples contained more than 99% water content.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fb178",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` less than 1% but greater than 0.001%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c78c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "percent=1\n",
    "dfs['SEDIMENT']['DW%'][(dfs['SEDIMENT']['DW%'] < percent) & (dfs['SEDIMENT']['DW%'] > 0.001)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c2a",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS description of the `percentwt`, `drywt` and `wetwt` variables:\n",
    "\n",
    "- `percentwt`: Dry weight as ratio of fresh weight, expressed as a decimal .\n",
    "- `drywt`: Dry weight in grams.\n",
    "- `wetwt`: Fresh weight in grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92f75f",
   "metadata": {},
   "source": [
    "Lets take a look at the HELCOM dataset, the weight of the sample is not reported for ``SEDIMENT``. However, the percentage dry weight is reported as `DW%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92c9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1037bff",
   "metadata": {},
   "source": [
    "The BIOTA dataset reports the weight of the sample as `WEIGHT` and the percentage dry weight as `DW%`. The `BASIS` column describes the basis the value reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
       "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
       "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
       "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
       "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
       "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
       "       'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA'].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetPercentWeightCB(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "            if 'WEIGHT' in tfm.dfs[grp].columns and 'BASIS' in tfm.dfs[grp].columns:\n",
    "                self._correct_basis(tfm.dfs[grp])\n",
    "                self._apply_weight(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['PERCENTWT'] = df['DW%'] / 100  # Convert percentage to fraction\n",
    "        df.loc[df['PERCENTWT'] == 0, 'PERCENTWT'] = np.NaN  # Convert 0% to NaN\n",
    "\n",
    "    def _correct_basis(self, df: pd.DataFrame) -> None:\n",
    "        \"Correct BASIS values. Assuming F = Fresh weight, so F = W\"\n",
    "        df.loc[df['BASIS'] == 'F', 'BASIS'] = 'W'\n",
    "\n",
    "    def _apply_weight(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply weight conversion and formatting to the given DataFrame.\"\n",
    "        dry_condition = df['BASIS'] == 'D'\n",
    "        wet_condition = df['BASIS'] == 'W'\n",
    "        \n",
    "        df.loc[dry_condition, 'DRYWT'] = df['WEIGHT']\n",
    "        df.loc[dry_condition & df['PERCENTWT'].notna(), 'WETWT'] = df['WEIGHT'] / df['PERCENTWT']\n",
    "        \n",
    "        df.loc[wet_condition, 'WETWT'] = df['WEIGHT']\n",
    "        df.loc[wet_condition & df['PERCENTWT'].notna(), 'DRYWT'] = df['WEIGHT'] * df['PERCENTWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "BIOTA:    PERCENTWT      DRYWT  WETWT\n",
      "0    0.18453  174.93444  948.0\n",
      "1    0.18453  174.93444  948.0\n",
      "2    0.18453  174.93444  948.0\n",
      "3    0.18453  174.93444  948.0\n",
      "4    0.18458  177.93512  964.0\n",
      "SEDIMENT: 0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: PERCENTWT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('BIOTA:', tfm.dfs['BIOTA'][['PERCENTWT','DRYWT','WETWT']].head())\n",
    "print('SEDIMENT:', tfm.dfs['SEDIMENT']['PERCENTWT'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68925d7c",
   "metadata": {},
   "source": [
    "Note that the dry weight is greater than the wet weight for some entries in the BIOTA dataset due to the DW% being greater than 100%, see above. Lets take a look at the number of entries where this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRYWT    20\n",
       "WETWT    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['BIOTA'][['DRYWT','WETWT']][tfm.dfs['BIOTA']['DRYWT'] > tfm.dfs['BIOTA']['WETWT']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203cb3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Column names for geographical coordinates are inconsistent across sample types (biota, sediment, seawater). Sometimes using parentheses, sometimes not.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c04fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: ['LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
      "SEAWATER: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
      "SEDIMENT: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for grp in dfs.keys():\n",
    "    print(f'{grp}: {[col for col in dfs[grp].columns if \"LON\" in col or \"LAT\" in col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83c2e1",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: HELCOM SEAWATER datase includes values of 0 for both latitude and longitude. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "19238  WSTUK2015001      H3  STUK04             <        920.0        0.0   \n",
      "19239  WSTUK2015002      H3  STUK04             <        920.0        0.0   \n",
      "19240  WSTUK2015003      H3  STUK04             <        920.0        0.0   \n",
      "19241  WSTUK2015004      H3  STUK04             <        920.0        0.0   \n",
      "19242  WSTUK2015005      H3  STUK04             <        920.0        0.0   \n",
      "\n",
      "         DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ...  \\\n",
      "19238  12/07/16 00:00:00       34       STUK   2015001  ...   \n",
      "19239  12/07/16 00:00:00       34       STUK   2015002  ...   \n",
      "19240  12/07/16 00:00:00       34       STUK   2015003  ...   \n",
      "19241  12/07/16 00:00:00       34       STUK   2015004  ...   \n",
      "19242  12/07/16 00:00:00       34       STUK   2015005  ...   \n",
      "\n",
      "      LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
      "19238            23.3761                 0.0    81.0     1.0   NaN    NaN   \n",
      "19239            23.3761                 0.0    81.0    80.0   NaN    NaN   \n",
      "19240            26.2080                 0.0    69.0     1.0   NaN    NaN   \n",
      "19241            26.2080                 0.0    69.0    68.0   NaN    NaN   \n",
      "19242            21.0477                 0.0   173.0     1.0   NaN    NaN   \n",
      "\n",
      "       FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
      "19238     N             11               11  12/07/16 00:00:00  \n",
      "19239     N             11               11  12/07/16 00:00:00  \n",
      "19240     N             11               11  12/07/16 00:00:00  \n",
      "19241     N             11               11  12/07/16 00:00:00  \n",
      "19242     N              3                3  12/07/16 00:00:00  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (ddmmmm)_LONGITUDE (ddmmmm):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "def get_invalid_coordinate_df(df, lat_cols, lon_cols):\n",
    "    invalid_dfs = {}\n",
    "    \n",
    "    for lat_col, lon_col in zip(lat_cols, lon_cols):\n",
    "        # Filter rows where latitude or longitude is NaN or zero\n",
    "        invalid_df = df[(df[lat_col].isna() | df[lon_col].isna()) | \n",
    "                        (df[lat_col] == 0) | (df[lon_col] == 0)]\n",
    "        \n",
    "        # Store the invalid DataFrame in the dictionary\n",
    "        if not invalid_df.empty:\n",
    "            invalid_dfs[f'{lat_col}_{lon_col}'] = invalid_df\n",
    "\n",
    "    return invalid_dfs\n",
    "\n",
    "def print_invalid_coordinates(invalid_dfs, dataset_name):\n",
    "    for key, invalid_df in invalid_dfs.items():\n",
    "        print(f'{dataset_name} invalid coordinates for {key}:')\n",
    "        print(invalid_df.head())\n",
    "\n",
    "# Define the columns for each dataset\n",
    "biota_lat_cols = ['LATITUDE ddmmmm', 'LATITUDE dddddd']\n",
    "biota_lon_cols = ['LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
    "\n",
    "seawater_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "seawater_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "sediment_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "sediment_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "# Get invalid coordinate DataFrames for each dataset\n",
    "biota_invalid_dfs = get_invalid_coordinate_df(dfs['BIOTA'], biota_lat_cols, biota_lon_cols)\n",
    "seawater_invalid_dfs = get_invalid_coordinate_df(dfs['SEAWATER'], seawater_lat_cols, seawater_lon_cols)\n",
    "sediment_invalid_dfs = get_invalid_coordinate_df(dfs['SEDIMENT'], sediment_lat_cols, sediment_lon_cols)\n",
    "\n",
    "# Print only non-empty invalid DataFrames\n",
    "print_invalid_coordinates(biota_invalid_dfs, 'BIOTA')\n",
    "print_invalid_coordinates(seawater_invalid_dfs, 'SEAWATER')\n",
    "print_invalid_coordinates(sediment_invalid_dfs, 'SEDIMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseCoordinates(Callback):\n",
    "    \"Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_cor: Callable # Function that converts coordinates from degree-minute to decimal degree format\n",
    "                 ):\n",
    "        self.fn_convert_cor = fn_convert_cor\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._format_coordinates(df)\n",
    "\n",
    "    def _format_coordinates(self, df:pd.DataFrame) -> None:\n",
    "        coord_cols = self._get_coord_columns(df.columns)\n",
    "        \n",
    "        for coord in ['lat', 'lon']:\n",
    "            decimal_col, minute_col = coord_cols[f'{coord}_d'], coord_cols[f'{coord}_m']\n",
    "            \n",
    "            condition = df[decimal_col].isna() | (df[decimal_col] == 0)\n",
    "            df[coord.upper()] = np.where(condition,\n",
    "                                 df[minute_col].apply(self._safe_convert),\n",
    "                                 df[decimal_col])\n",
    "        \n",
    "        df.dropna(subset=['LAT', 'LON'], inplace=True)\n",
    "\n",
    "    def _get_coord_columns(self, columns) -> dict:\n",
    "        return {\n",
    "            'lon_d': self._find_coord_column(columns, 'LON', 'dddddd'),\n",
    "            'lat_d': self._find_coord_column(columns, 'LAT', 'dddddd'),\n",
    "            'lon_m': self._find_coord_column(columns, 'LON', 'ddmmmm'),\n",
    "            'lat_m': self._find_coord_column(columns, 'LAT', 'ddmmmm')\n",
    "        }\n",
    "\n",
    "    def _find_coord_column(self, columns, coord_type, coord_format) -> str:\n",
    "        pattern = re.compile(f'{coord_type}.*{coord_format}', re.IGNORECASE)\n",
    "        matching_columns = [col for col in columns if pattern.search(col)]\n",
    "        return matching_columns[0] if matching_columns else None\n",
    "\n",
    "    def _safe_convert(self, value) -> str:\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RemapNuclideNameCB.__init__() missing 1 required positional argument: 'col_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| eval: false\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dfs \u001b[38;5;241m=\u001b[39m load_data(fname_in)\n\u001b[1;32m      3\u001b[0m tfm \u001b[38;5;241m=\u001b[39m Transformer(dfs, cbs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m                             LowerStripNameCB(col_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUCLIDE\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m----> 5\u001b[0m                             \u001b[43mRemapNuclideNameCB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlut_nuclides\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m                             ParseTimeCB(),\n\u001b[1;32m      7\u001b[0m                             EncodeTimeCB(),\n\u001b[1;32m      8\u001b[0m                             SplitSedimentValuesCB(coi_sediment),\n\u001b[1;32m      9\u001b[0m                             SanitizeValueCB(coi_val),       \n\u001b[1;32m     10\u001b[0m                             NormalizeUncCB(),\n\u001b[1;32m     11\u001b[0m                             RemapUnitCB(),\n\u001b[1;32m     12\u001b[0m                             RemapDetectionLimitCB(coi_dl, lut_dl),                           \n\u001b[1;32m     13\u001b[0m                             RemapCB(fn_lut\u001b[38;5;241m=\u001b[39mlut_biota, col_remap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPECIES\u001b[39m\u001b[38;5;124m'\u001b[39m, col_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRUBIN\u001b[39m\u001b[38;5;124m'\u001b[39m, dest_grps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBIOTA\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     14\u001b[0m                             RemapCB(fn_lut\u001b[38;5;241m=\u001b[39mlut_tissues, col_remap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBODY_PART\u001b[39m\u001b[38;5;124m'\u001b[39m, col_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTISSUE\u001b[39m\u001b[38;5;124m'\u001b[39m, dest_grps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBIOTA\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     15\u001b[0m                             RemapCB(fn_lut\u001b[38;5;241m=\u001b[39mlut_biogroup_from_biota, col_remap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBIO_GROUP\u001b[39m\u001b[38;5;124m'\u001b[39m, col_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPECIES\u001b[39m\u001b[38;5;124m'\u001b[39m, dest_grps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBIOTA\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     16\u001b[0m                             RemapSedimentCB(fn_lut\u001b[38;5;241m=\u001b[39mlut_sediments, replace_lut\u001b[38;5;241m=\u001b[39msed_replace_lut),\n\u001b[1;32m     17\u001b[0m                             RemapFiltCB(lut_filtered),\n\u001b[1;32m     18\u001b[0m                             RemapCB(fn_lut\u001b[38;5;241m=\u001b[39mlut_lab, col_remap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAB\u001b[39m\u001b[38;5;124m'\u001b[39m, col_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABORATORY\u001b[39m\u001b[38;5;124m'\u001b[39m, dest_grps\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBIOTA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEDIMENT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEAWATER\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     19\u001b[0m                             AddSampleIDCB(lut_type\u001b[38;5;241m=\u001b[39msmp_type_lut),\n\u001b[1;32m     20\u001b[0m                             AddDepthCB(),\n\u001b[1;32m     21\u001b[0m                             AddSalinityCB(),\n\u001b[1;32m     22\u001b[0m                             AddTemperatureCB(),\n\u001b[1;32m     23\u001b[0m                             RemapSedSliceTopBottomCB(),\n\u001b[1;32m     24\u001b[0m                             LookupDryWetPercentWeightCB(),\n\u001b[1;32m     25\u001b[0m                             ParseCoordinates(ddmm_to_dd),\n\u001b[1;32m     26\u001b[0m                             SanitizeLonLatCB(),\n\u001b[1;32m     27\u001b[0m                             CompareDfsAndTfmCB(dfs)\n\u001b[1;32m     28\u001b[0m                             ])\n\u001b[1;32m     30\u001b[0m tfm()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(tfm\u001b[38;5;241m.\u001b[39mcompare_stats) , \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: RemapNuclideNameCB.__init__() missing 1 required positional argument: 'col_name'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                            AddSampleIDCB(lut_type=smp_type_lut),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA columns:\n",
      "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y', 'TIME', 'VALUE', 'UNCERTAINTY', 'UNIT', 'DL',\n",
      "       'SPECIES', 'BODY_PART', 'BIO_GROUP', 'LAB', 'SMP_ID', 'SMP_DEPTH',\n",
      "       'PERCENTWT', 'DRYWT', 'WETWT', 'LAT', 'LON'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "grp = 'BIOTA'\n",
    "print(f'{grp} columns:')\n",
    "print(tfm.dfs[grp].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c7a2",
   "metadata": {},
   "source": [
    "For instance, lets inspect dropped rows for SEDIMENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ad4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER, no of dropped rows: 76\n",
      "Viewing 5 dropped rows for SEAWATER:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>WRISO2001025</td>\n",
       "      <td>CS137</td>\n",
       "      <td>RISO02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>RISO</td>\n",
       "      <td>2001025</td>\n",
       "      <td>...</td>\n",
       "      <td>10.500</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>WLEPA2002001</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002001</td>\n",
       "      <td>...</td>\n",
       "      <td>21.030</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>14.40</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>WLEPA2002002</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002004</td>\n",
       "      <td>...</td>\n",
       "      <td>20.574</td>\n",
       "      <td>20.956667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.57</td>\n",
       "      <td>11.95</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>WLEPA2002003</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002007</td>\n",
       "      <td>...</td>\n",
       "      <td>19.236</td>\n",
       "      <td>19.393333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>WLEPA2002004</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002010</td>\n",
       "      <td>...</td>\n",
       "      <td>20.205</td>\n",
       "      <td>20.341700</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.06</td>\n",
       "      <td>8.65</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "13439  WRISO2001025   CS137  RISO02           NaN          NaN       10.0   \n",
       "14017  WLEPA2002001   CS134  LEPA02             <          NaN        NaN   \n",
       "14020  WLEPA2002002   CS134  LEPA02             <          NaN        NaN   \n",
       "14023  WLEPA2002003   CS134  LEPA02             <          NaN        NaN   \n",
       "14026  WLEPA2002004   CS134  LEPA02             <          NaN        NaN   \n",
       "\n",
       "      DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "13439             NaN       26       RISO   2001025  ...             10.500   \n",
       "14017             NaN       93       LEPA   2002001  ...             21.030   \n",
       "14020             NaN       93       LEPA   2002004  ...             20.574   \n",
       "14023             NaN       93       LEPA   2002007  ...             19.236   \n",
       "14026             NaN       93       LEPA   2002010  ...             20.205   \n",
       "\n",
       "       LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "13439           10.833333    22.0    20.0  0.00    NaN     N              5   \n",
       "14017           21.050000    16.0     0.0  3.77  14.40     N              4   \n",
       "14020           20.956667    14.0     0.0  6.57  11.95     N              4   \n",
       "14023           19.393333    73.0     0.0  7.00   9.19     N              4   \n",
       "14026           20.341700    47.0     0.0  7.06   8.65     N              4   \n",
       "\n",
       "       HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \n",
       "13439                5              NaN  \n",
       "14017                9              NaN  \n",
       "14020                9              NaN  \n",
       "14023                9              NaN  \n",
       "14026                9              NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='SEAWATER' # 'SEAWATER', 'BIOTA' or 'SEDIMENT'\n",
    "print(f'{grp}, no of dropped rows: {tfm.dfs_dropped[grp].shape[0]}')\n",
    "view_number=5\n",
    "print(f'Viewing {view_number} dropped rows for {grp}:')\n",
    "tfm.dfs_dropped[grp].head(view_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column.\",\n",
       " 'Remap data provider nuclide names to standardized MARIS nuclide names.',\n",
       " 'Standardize time format across all dataframes.',\n",
       " 'Encode time as seconds since epoch.',\n",
       " 'Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements.',\n",
       " 'Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column.',\n",
       " 'Convert from relative error ( % ) to standard uncertainty.',\n",
       " 'Set the `unit` id column in the DataFrames based on a lookup table.',\n",
       " 'Remap value type to MARIS format.',\n",
       " \"Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA.\",\n",
       " \"Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA.\",\n",
       " \"Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA.\",\n",
       " 'Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).',\n",
       " 'Lookup FILT value in dataframe using the lookup table.',\n",
       " \"Remap values from 'LABORATORY' to 'LAB' for groups: BIOTA, SEDIMENT and SEAWATER.\",\n",
       " 'Remap `KEY` column to `SMP_ID` in each DataFrame.',\n",
       " \"Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns.\",\n",
       " 'Remap Sediment slice top and bottom to MARIS format.',\n",
       " 'Lookup dry-wet ratio and format for MARIS.',\n",
       " 'Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.',\n",
       " 'Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                            AddSampleIDCB(lut_type=smp_type_lut),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB()\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109b5b1",
   "metadata": {},
   "source": [
    "## Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c293bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(\n",
    "    tfm: Transformer, # Transformer object\n",
    "    zotero_key: str, # Zotero dataset record key\n",
    "    kw: list = kw # List of keywords\n",
    "    ) -> dict: # Global attributes\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'geospatial_vertical_max': '437.0',\n",
       " 'geospatial_vertical_min': '0.0',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2018-12-14T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error ( % ) to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA., Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Lookup FILT value in dataframe using the lookup table., Remap values from 'LABORATORY' to 'LAB' for groups: BIOTA, SEDIMENT and SEAWATER., Remap `KEY` column to `SMP_ID` in each DataFrame., Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### <a name=\"encoding-netcdf\"></a>Encoding NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(\n",
    "    fname_in: str, # Input file name\n",
    "    fname_out_nc: str, # Output file name\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Encode data to NetCDF.\"\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            #RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                            #AddSampleIDCB(lut_type=smp_type_lut),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB()\n",
    "                            ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec225f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n",
      "--------------------------------------------------------------------------------\n",
      "Creating enums for the following columns:\n",
      "['UNIT', 'DL', 'AREA', 'SED_TYPE', 'SPECIES', 'BIO_GROUP', 'BODY_PART', 'NUCLIDE', 'FILT']\n",
      "Creating enum for unit_t with values {'Not applicable': -1, 'NOT AVAILABLE': 0, 'Bq per m3': 1, 'Bq per m2': 2, 'Bq per kg': 3, 'Bq per kgd': 4, 'Bq per kgw': 5, 'kg per kg': 6, 'TU': 7, 'DELTA per mill': 8, 'atom per kg': 9, 'atom per kgd': 10, 'atom per kgw': 11, 'atom per l': 12, 'Bq per kgC': 13}.\n",
      "Creating enum for dl_t with values {'Not applicable': -1, 'Not available': 0, 'Detected value': 1, 'Detection limit': 2, 'Not detected': 3, 'Derived': 4}.\n",
      "Creating enum for area_t with values {'Not applicable': -1, 'Not available': 0, 'North Atlantic Ocean': 1912, 'Baltic Sea': 2, 'Mediterranean Region': 3, 'South Atlantic Ocean': 1914, 'Indian Ocean': 1904, 'South China & Eastern Archipelagic Seas': 6, 'North Pacific Ocean': 1908, 'South Pacific Ocean': 1910, 'Arctic Ocean': 1906, 'Southern Ocean': 1907, 'Arctic Sea': 18, 'Atlantic, Northwest': 21, 'Atlantic, Northeast': 27, 'Atlantic, Western Central': 31, 'Atlantic, Eastern Central': 34, 'Mediterranean and Black Sea': 37, 'Atlantic, Southwest': 41, 'Atlantic, Southeast': 47, 'Atlantic, Antarctic': 48, 'Indian Ocean, Western': 51, 'Indian Ocean, Eastern': 57, 'Indian Ocean, Antarctic': 58, 'Pacific, Northwest': 61, 'Pacific, Northeast': 67, 'Pacific, Western Central': 71, 'Pacific, Eastern Central': 77, 'Pacific, Southwest': 81, 'Pacific, Southeast': 87, 'Pacific, Antarctic': 88, 'North Sea': 2350, 'Celtic Sea': 2351, 'Norwegian Sea': 2353, 'Greenland Sea': 2356, 'Irish Sea': 2357, 'Bay of Biscay': 2359, 'Kattegat': 2374, 'Skagerrak': 2379, 'English Channel': 2389, 'Central Baltic Sea': 2401, 'Gulf of Bothnia': 2402, 'Gulf of Finland': 2407, 'Gulf of Riga': 2409, 'Bristol Channel': 3141, 'Adriatic Sea': 3314, 'Aegean Sea': 3315, 'Black Sea': 3319, 'Sea of Azov': 3320, 'Balearic Sea': 3322, 'Alboran Sea': 3324, 'Strait of Gibraltar': 3346, 'Ionian Sea': 3351, 'Ligurian Sea': 3363, 'Sea of Marmara': 3369, 'Tyrrhenian Sea': 3386, 'East Siberian Sea': 4244, 'Laptev Sea': 4245, 'Kara Sea': 4246, 'Barentsz Sea': 4247, 'White Sea': 4248, 'Davis Strait': 4250, 'Hudson Strait': 4251, 'Hudson Bay': 4252, 'Baffin Bay': 4253, 'Lincoln Sea': 4254, 'Beaufort Sea': 4256, 'Chukchi Sea': 4257, 'Mozambique Channel': 4261, 'Gulf of Suez': 4262, 'Gulf of Aqaba': 4263, 'Red Sea': 4264, 'Gulf of Aden': 4265, 'Persian Gulf': 4266, 'Gulf of Oman': 4267, 'Arabian Sea': 4268, 'Laccadive Sea': 4269, 'Bay of Bengal': 4273, 'Andaman Sea': 4274, 'Malacca Strait': 4275, 'Great Australian Bight': 4276, 'Mediterranean Sea   Western Basin_x000D_': 4279, 'Mediterranean Sea   Eastern Basin': 4280, 'Inner Seas off the West Coast of Scotland': 4283, 'Gulf of Guinea': 4286, 'Caribbean Sea': 4287, 'Gulf of Mexico': 4288, 'Bay of Fundy': 4289, 'Gulf of St Lawrence': 4290, 'Labrador Sea': 4291, 'Philippine Sea': 4300, 'East China Sea': 4302, 'Yellow Sea': 4303, 'Seto Naikai': 4306, 'Japan Sea': 4307, 'Sea of Okhotsk': 4309, 'Bering Sea': 4310, 'Gulf of Alaska': 4312, 'Coastal Waters of Southeast Alaska and British Columbia': 4313, 'Gulf of California': 4314, 'Rio de La Plata': 4325, 'South China Sea': 4332, 'Gulf of Thailand': 4334, 'Singapore Strait': 4336, 'Jawa Sea': 4338, 'Selat Makasar': 4339, 'Bali Sea': 4340, 'Flores Sea': 4341, 'Sawu Sea': 4343, 'Timor Sea': 4344, 'Arafura Sea': 4347, 'Banda Sea': 4349, 'Teluk Bone': 4350, 'Ceram Sea': 4351, 'Halmahera Sea': 4353, 'Molucca Sea': 4354, 'Teluk Tomini': 4355, 'Sulu Sea': 4358, 'Celebes Sea': 4359, 'Bismarck Sea': 4360, 'Solomon Sea': 4361, 'Coral Sea': 4364, 'Tasman Sea': 4365, 'Bass Strait': 4366, 'Northwestern Passages': 5698, 'Unassigned': 9999}.\n",
      "Creating enum for sed_type_t with values {'Not applicable': -1, 'Not available': 0, 'Clay': 1, 'Gravel': 2, 'Marsh': 3, 'Mud': 4, 'Muddy sand': 5, 'Sand': 6, 'Fine sand': 7, 'Sandy mud': 8, 'Pebby sand': 9, 'Silt and clay': 10, 'Silt and gravel': 11, 'Silt': 12, 'Silty sand': 13, 'Sludge': 14, 'Turf': 15, 'Very coarse sand': 16, 'Coarse sand': 17, 'Medium sand': 18, 'Very fine sand': 19, 'Coarse silt': 20, 'Medium silt': 21, 'Fine silt': 22, 'Very fine silt': 23, 'Calcareous': 24, 'Glacial': 25, 'Soft': 26, 'Sulphidic': 27, 'Fe Mg concretions': 28, 'Sand and gravel': 29, 'Pure sand': 30, 'Sand and fine sand': 31, 'Sand and clay': 32, 'Sand and mud': 33, 'Fine sand and gravel': 34, 'Fine sand and sand': 35, 'Pure fine sand': 36, 'Fine sand and silt': 37, 'Fine sand and clay': 38, 'Fine sand and mud': 39, 'Silt and sand': 40, 'Silt and fine sand': 41, 'Pure silt': 42, 'Silt and mud': 43, 'Clay and gravel': 44, 'Clay and sand': 45, 'Clay and fine sand': 46, 'Pure clay': 47, 'Clay and silt': 48, 'Clay and mud': 49, 'Glacial clay': 50, 'Soft clay': 51, 'Sulphidic clay': 52, 'Clay and Fe Mg concretions': 53, 'Mud and gravel': 54, 'Mud and sand': 55, 'Mud and fine sand': 56, 'Mud and clay': 57, 'Pure mud': 58, 'Soft mud': 59, 'Sulphidic mud': 60, 'Mud and Fe Mg concretions': 61, 'Sand and silt': 62}.\n",
      "Creating enum for species_t with values {'NOT AVAILABLE': 0, 'Aristeus antennatus': 1, 'Apostichopus': 2, 'Saccharina japonica var religiosa': 3, 'Siganus fuscescens': 4, 'Alpheus dentipes': 5, 'Hexagrammos agrammus': 6, 'Ditrema temminckii': 7, 'Parapristipoma trilineatum': 8, 'Scombrops boops': 9, 'Pseudopleuronectes schrenki': 10, 'Desmarestia ligulata': 11, 'Saccharina japonica': 12, 'Neodilsea yendoana': 13, 'Costaria costata': 14, 'Sargassum yezoense': 15, 'Acanthephyra pelagica': 16, 'Sargassum ringgoldianum': 17, 'Acanthephyra quadrispinosa': 18, 'Sargassum thunbergii': 19, 'Sargassum patens': 20, 'Asterias rubens': 21, 'Sargassum miyabei': 22, 'Homarus gammarus': 23, 'Acanthephyra stylorostratis': 24, 'Acanthocybium solandri': 25, 'Acanthopagrus bifasciatus': 26, 'Acanthophora muscoides': 27, 'Acanthophora spicifera': 28, 'Acanthurus triostegus': 29, 'Actinopterygii': 30, 'Adamussium colbecki': 31, 'Ahnfeltiopsis densa': 32, 'Alepes melanoptera': 33, 'Ampharetidae': 34, 'Anchoviella lepidentostole': 35, 'Anguillidae': 36, 'Aphroditidae': 37, 'Arnoglossus': 38, 'Aurigequula fasciata': 39, 'Balaenoptera musculus': 40, 'Balaenoptera physalus': 41, 'Balistes': 42, 'Beryciformes': 43, 'Bryopsis maxima': 44, 'Callinectes sp': 45, 'Callorhinus ursinus': 46, 'Carassius auratus auratus': 47, 'Carcharhinus sorrah': 48, 'Caridae': 49, 'Clupea harengus': 50, 'Cathorops spixii': 51, 'Caulerpa racemosa': 52, 'Caulerpa scalpelliformis': 53, 'Caulerpa sertularioides': 54, 'Cellana radiata': 55, 'Coscinasterias tenuispina': 56, 'Centroceras clavulatum': 57, 'Centropomus parallelus': 58, 'Crangon crangon': 59, 'Ceramium diaphanum': 60, 'Ceramium rubrum': 61, 'Chaenocephalus aceratus': 62, 'Chaetodipterus faber': 63, 'Chaetomorpha antennina': 64, 'Chaetomorpha linoides': 65, 'Chelidonichthys kumu': 66, 'Chelon ramada': 67, 'Chiloscyllium': 68, 'Chionodraco hamatus': 69, 'Chlamys islandica': 70, 'Chlorophyta': 71, 'Chondrichthyes': 72, 'Chrysaora': 73, 'Cladophora nitellopsis': 74, 'Cladophora vagabunda': 75, 'Cladophoropsis membranacea': 76, 'Clupea': 77, 'Coccotylus truncatus': 78, 'Codium fragile': 79, 'Crassostrea': 80, 'Cynoscion acoupa': 81, 'Cynoscion jamaicensis': 82, 'Cynoscion leiarchus': 83, 'Engraulis encrasicolus': 84, 'Cypselurus agoo agoo': 85, 'Cystophora cristata': 86, 'Cystoseira barbata': 87, 'Cystoseira crinita': 88, 'Decapodiformes': 89, 'Decapterus russelli': 90, 'Decapterus scombrinus': 91, 'Delphinapterus leucas': 92, 'Delphinus capensis': 93, 'Diapterus rhombeus': 94, 'Dicentrarchus punctatus': 95, 'Fucus vesiculosus': 96, 'Funchalia woodwardi': 97, 'Ecklonia bicyclis': 98, 'Gadus morhua': 99, 'Ecklonia kurome': 100, 'Gennadas elegans': 101, 'Eisenia arborea': 102, 'Encrasicholina devisi': 103, 'Enteromorpha': 104, 'Enteromorpha flexuosa': 105, 'Enteromorpha intestinalis': 106, 'Epinephelinae': 107, 'Epinephelus diacanthus': 108, 'Exocoetidae': 109, 'Saccharina latissima': 110, 'Gracilaria corticata': 111, 'Ligur ensiferus': 112, 'Gracilaria debilis': 113, 'Gracilaria edulis': 114, 'Gracilariales': 115, 'Grateloupia elliptica': 116, 'Grateloupia filicina': 117, 'Lysmata seticaudata': 118, 'Gymnogongrus griffithsiae': 119, 'Mya arenaria': 120, 'Halichoerus grypus': 121, 'Macoma balthica': 122, 'Marthasterias glacialis': 123, 'Halimeda macroloba': 124, 'Harengula clupeola': 125, 'Harpagifer antarcticus': 126, 'Hemifusus ternatanus': 127, 'Hemiramphus brasiliensis': 128, 'Mytilus edulis': 129, 'Metapenaeus affinis': 130, 'Heteroscleromorpha': 131, 'Heterosigma akashiwo': 132, 'Hilsa ilisha': 133, 'Metapenaeus monoceros': 134, 'Metapenaeus stebbingi': 135, 'Holothuria': 136, 'Hoplobrotula armata': 137, 'Hypnea musciformis': 138, 'Merlangius merlangus': 139, 'Iridaea cordata': 140, 'Jania rubens': 141, 'Meganyctiphanes norvegica': 142, 'Johnius glaucus': 143, 'Kappaphycus': 144, 'Kappaphycus alvarezii': 145, 'Laevistrombus canarium': 146, 'Lagenodelphis hosei': 147, 'Lambia': 148, 'Laminaria japonica': 149, 'Laminaria longissima': 150, 'Larimus breviceps': 151, 'Laurencia papillosa': 152, 'Leiognathidae': 153, 'Leiognathus dussumieri': 154, 'Lepidochelys olivacea': 155, 'Leptonychotes weddellii': 156, 'Limanda yokohamae': 157, 'Nephrops norvegicus': 158, 'Neuston': 159, 'Littoraria undulata': 160, 'Loligo vulgaris': 161, 'Lumbrineridae': 162, 'Lutjanus fulviflamma': 163, 'Marginisporum aberrans': 164, 'Megalaspis cordyla': 165, 'Octopus vulgaris': 166, 'Menticirrhus americanus': 167, 'Mesoplodon densirostris': 168, 'Palaemon longirostris': 169, 'Metapenaeus brevicornis': 170, 'Pasiphaea multidentata': 171, 'Pasiphaea sivado': 172, 'Parapenaeopsis stylifera': 173, 'Miichthys miiuy': 174, 'Mirounga leonina': 175, 'Brachidontes striatulus': 176, 'Monodon monoceros': 177, 'Mugil platanus': 178, 'Penaeus semisulcatus': 179, 'Mullus barbatus': 180, 'Mycteroperca rubra': 181, 'Philocheras echinulatus': 182, 'Myelophycus simplex': 183, 'Mytilus coruscus': 184, 'Penaeus indicus': 185, 'Natator depressus': 186, 'Pandalus jordani': 187, 'Melicertus kerathurus': 188, 'Parapenaeus longirostris': 189, 'Plesionika': 190, 'Platichthys flesus': 191, 'Pleuronectes platessa': 192, 'Nematopalaemon tenuipes': 193, 'Nematoscelis difficilis': 194, 'Nemipterus': 195, 'Aegaeon lacazei': 196, 'Nephtyidae': 197, 'Nereididae': 198, 'Netuma bilineata': 199, 'Nibea maculata': 200, 'Oceana serrulata': 201, 'Palaemon serratus': 202, 'Ocypode': 203, 'Odobenus rosmarus': 204, 'Ogcocephalus vespertilio': 205, 'Oligoplites saurus': 206, 'Onuphidae': 207, 'Opheliidae': 208, 'Opisthonema oglinum': 209, 'Opisthopterus tardoore': 210, 'Orientomysis mitsukurii': 211, 'Otolithes cuvieri': 212, 'Padina pavonica': 213, 'Padina tetrastromatica': 214, 'Padina vickersiae': 215, 'Pagellus affinis': 216, 'Pagophilus groenlandicus': 217, 'Paguroidea': 218, 'Pagurus': 219, 'Systellaspis debilis': 220, 'Sergestes': 221, 'Sergestes arcticus': 222, 'Pampus argenteus': 223, 'Sergestes arachnipodus': 224, 'Sergestes henseni': 225, 'Sergestes prehensilis': 226, 'Sergestes robustus': 227, 'Pangasius pangasius': 228, 'Panulirus homarus': 229, 'Paracentrotus lividus': 230, 'Pasiphaea sp': 231, 'Pectinariidae': 232, 'Penaeus': 233, 'Phoca vitulina': 234, 'Photopectoralis bindus': 235, 'Phyllospadix iwatensis': 236, 'Plectorhinchus mediterraneus': 237, 'Pleuronectes mochigarei': 238, 'Pleuronectes obscurus': 239, 'Plocamium brasiliense': 240, 'Polynemus paradiseus': 241, 'Polysiphonia': 242, 'Sprattus sprattus': 243, 'Scomber scombrus': 244, 'Polysiphonia fucoides': 245, 'Gonostomatidae': 246, 'Perca fluviatilis': 247, 'Pomadasys crocro': 248, 'Porphyra tenera': 249, 'Potamogeton pectinatus': 250, 'Priacanthus hamrur': 251, 'Pseudorhombus malayanus': 252, 'Pterocladiella capillacea': 253, 'Pusa caspica': 254, 'Pusa sibirica': 255, 'Pylaiella littoralis': 256, 'Sabellidae': 257, 'Salangichthys ishikawae': 258, 'Sarconema filiforme': 259, 'Sardinella albella': 260, 'Sardinella brasiliensis': 261, 'Sardinops melanostictus': 262, 'Sargassum cymosum': 263, 'Sargassum linearifolium': 264, 'Sargassum micracanthum': 265, 'Xiphias gladius': 266, 'Sargassum novae hollandiae': 267, 'Sargassum oligocystum': 268, 'Esox lucius': 269, 'Limanda limanda': 270, 'Abramis brama': 271, 'Anguilla anguilla': 272, 'Arctica islandica': 273, 'Cerastoderma edule': 274, 'Cyprinus carpio': 275, 'Echinodermata': 276, 'Fish larvae': 277, 'Myoxocephalus scorpius': 278, 'Osmerus eperlanus': 279, 'Plankton': 280, 'Scophthalmus maximus': 281, 'Rhodophyta': 282, 'Rutilus rutilus': 283, 'Saduria entomon': 284, 'Sander lucioperca': 285, 'Gasterosteus aculeatus': 286, 'Zoarces viviparus': 287, 'Gymnocephalus cernua': 288, 'Furcellaria lumbricalis': 289, 'Cladophora glomerata': 290, 'Lateolabrax japonicus': 291, 'Okamejei kenojei': 292, 'Sebastes pachycephalus': 293, 'Squalus acanthias': 294, 'Gadus macrocephalus': 295, 'Paralichthys olivaceus': 296, 'Ovalipes punctatus': 297, 'Pseudopleuronectes yokohamae': 298, 'Hemitripterus villosus': 299, 'Clidoderma asperrimum': 300, 'Microstomus achne': 301, 'Lepidotrigla microptera': 302, 'Hexagrammos otakii': 303, 'Kareius bicoloratus': 304, 'Pleuronichthys cornutus': 305, 'Enteroctopus dofleini': 306, 'Ammodytes personatus': 307, 'Lophius litulon': 308, 'Eopsetta grigorjewi': 309, 'Takifugu porphyreus': 310, 'Loliolus japonica': 311, 'Sepia andreana': 312, 'Sebastes cheni': 313, 'Portunus trituberculatus': 314, 'Sebastes schlegelii': 315, 'Pennahia argentata': 316, 'Platichthys stellatus': 317, 'Gadus chalcogrammus': 318, 'Chelidonichthys spinosus': 319, 'Conger myriaster': 320, 'Heterololigo bleekeri': 321, 'Stichaeus grigorjewi': 322, 'Pseudopleuronectes herzensteini': 323, 'Octopus conispadiceus': 324, 'Hippoglossoides dubius': 325, 'Cleisthenes pinetorum': 326, 'Glyptocephalus stelleri': 327, 'Tanakius kitaharae': 328, 'Nibea mitsukurii': 329, 'Dasyatis matsubarai': 330, 'Verasper moseri': 331, 'Hemitrygon akajei': 332, 'Triakis scyllium': 333, 'Trachurus japonicus': 334, 'Zeus faber': 335, 'Pagrus major': 336, 'Acanthopagrus schlegelii': 337, 'Dentex tumifrons': 338, 'Mustelus manazo': 339, 'Seriola quinqueradiata': 340, 'Hyperoglyphe japonica': 341, 'Carcharhinus': 342, 'Platycephalus': 343, 'Scomber japonicus': 344, 'Squatina japonica': 345, 'Alopias pelagicus': 346, 'Zenopsis nebulosa': 347, 'Cynoglossus joyneri': 348, 'Verasper variegatus': 349, 'Oncorhynchus keta': 350, 'Physiculus japonicus': 351, 'Oplegnathus punctatus': 352, 'Arothron hispidus': 353, 'Stereolepis doederleini': 354, 'Takifugu snyderi': 355, 'Scomber australasicus': 356, 'Liparis tanakae': 357, 'Thamnaconus modestus': 358, 'Gnathophis nystromi': 359, 'Sebastes oblongus': 360, 'Sebastiscus marmoratus': 361, 'Takifugu pardalis': 362, 'Mugil cephalus': 363, 'Ditrema temminckii temminckii': 364, 'Konosirus punctatus': 365, 'Tribolodon brandtii': 366, 'Oncorhynchus masou': 367, 'Aluterus monoceros': 368, 'Todarodes pacificus': 369, 'Myoxocephalus stelleri': 370, 'Myliobatis tobijei': 371, 'Scyliorhinus torazame': 372, 'Lophiomus setigerus': 373, 'Heterodontus japonicus': 374, 'Sebastes vulpes': 375, 'Paraplagusia japonica': 376, 'Ostrea edulis': 377, 'Melanogrammus aeglefinus': 378, 'Pollachius virens': 379, 'Pollachius pollachius': 380, 'Sebastes marinus': 381, 'Anarhichas minor': 382, 'Anarhichas denticulatus': 383, 'Reinhardtius hippoglossoides': 384, 'Trisopterus esmarkii': 385, 'Micromesistius poutassou': 386, 'Coryphaenoides rupestris': 387, 'Argentina silus': 388, 'Salmo salar': 389, 'Sebastes viviparus': 390, 'Buccinum undatum': 391, 'Fucus serratus': 392, 'Merluccius merluccius': 393, 'Littorina littorea': 394, 'Fucus': 395, 'Rhodymenia': 396, 'Solea solea': 397, 'Trachurus trachurus': 398, 'Eutrigla gurnardus': 399, 'Pelvetia canaliculata': 400, 'Ascophyllum nodosum': 401, 'Mallotus villosus': 402, 'Pecten maximus': 403, 'Hippoglossoides platessoides': 404, 'Sebastes mentella': 405, 'Modiolus modiolus': 406, 'Boreogadus saida': 407, 'Sepia': 408, 'Gadus': 409, 'Sardina pilchardus': 410, 'Pleuronectiformes': 411, 'Molva molva': 412, 'Patella': 413, 'Crassostrea gigas': 414, 'Dasyatis pastinaca': 415, 'Lophius piscatorius': 416, 'Porphyra umbilicalis': 417, 'Patella vulgata': 418, 'Brosme brosme': 419, 'Glyptocephalus cynoglossus': 420, 'Galeus melastomus': 421, 'Chimaera monstrosa': 422, 'Etmopterus spinax': 423, 'Dicentrarchus labrax': 424, 'Osilinus lineatus': 425, 'Hippoglossus hippoglossus': 426, 'Cyclopterus lumpus': 427, 'Molva dypterygia': 428, 'Microstomus kitt': 429, 'Fucus distichus': 430, 'Tapes': 431, 'Sebastes norvegicus': 432, 'Phycis blennoides': 433, 'Fucus spiralis': 434, 'Laminaria digitata': 435, 'Dipturus batis': 436, 'Anarhichas lupus': 437, 'Lumpenus lampretaeformis': 438, 'Lycodes vahlii': 439, 'Argentina sphyraena': 440, 'Trisopterus minutus': 441, 'Thunnus': 442, 'Hyperoplus lanceolatus': 443, 'Gaidropsarus argentatus': 444, 'Engraulis japonicus': 445, 'Mytilus galloprovincialis': 446, 'Undaria pinnatifida': 447, 'Chlorophthalmus albatrossis': 448, 'Sargassum fusiforme': 449, 'Eisenia bicyclis': 450, 'Spisula sachalinensis': 451, 'Strongylocentrotus nudus': 452, 'Haliotis discus hannai': 453, 'Dexistes rikuzenius': 454, 'Ruditapes philippinarum': 455, 'Apostichopus japonicus': 456, 'Pterothrissus gissu': 457, 'Helicolenus hilgendorfii': 458, 'Buccinum isaotakii': 459, 'Neptunea intersculpta': 460, 'Apostichopus nigripunctatus': 461, 'Sebastes thompsoni': 462, 'Oratosquilla oratoria': 463, 'Oncorhynchus kisutch': 464, 'Erimacrus isenbeckii': 465, 'Sillago japonica': 466, 'Trachysalambria curvirostris': 467, 'Mytilus unguiculatus': 468, 'Crassostrea nippona': 469, 'Laminariales': 470, 'Uroteuthis edulis': 471, 'Takifugu poecilonotus': 472, 'Neptunea arthritica': 473, 'Katsuwonus pelamis': 474, 'Doederleinia berycoides': 475, 'Metapenaeopsis dalei': 476, 'Seriola dumerili': 477, 'Pseudorhombus pentophthalmus': 478, 'Stephanolepis cirrhifer': 479, 'Cookeolus japonicus': 480, 'Panulirus japonicus': 481, 'Thunnus orientalis': 482, 'Halocynthia roretzi': 483, 'Etrumeus sadina': 484, 'Cololabis saira': 485, 'Coryphaena hippurus': 486, 'Sarda orientalis': 487, 'Octopus ocellatus': 488, 'Sardinops sagax': 489, 'Sphyraena pinguis': 490, 'Sebastes ventricosus': 491, 'Occella iburia': 492, 'Glossanodon semifasciatus': 493, 'Mizuhopecten yessoensis': 494, 'Neosalangichthys ishikawae': 495, 'Bothrocara tanakae': 496, 'Malacocottus zonurus': 497, 'Coelorinchus macrochir': 498, 'Neptunea constricta': 499, 'Beringius polynematicus': 500, 'Sebastes nivosus': 501, 'Pandalus eous': 502, 'Synaphobranchus kaupii': 503, 'Sebastolobus macrochir': 504, 'Marsupenaeus japonicus': 505, 'Japelion hirasei': 506, 'Pleurogrammus azonus': 507, 'Monostroma nitidum': 508, 'Atheresthes evermanni': 509, 'Takifugu rubripes': 510, 'Chionoecetes opilio': 511, 'Pandalopsis coccinata': 512, 'Chionoecetes japonicus': 513, 'Sebastes matsubarae': 514, 'Scombrops gilberti': 515, 'Hyporhamphus sajori': 516, 'Trichiurus lepturus': 517, 'Alcichthys elongatus': 518, 'Volutharpa perryi': 519, 'Mercenaria stimpsoni': 520, 'Berryteuthis magister': 521, 'Aptocyclus ventricosus': 522, 'Euphausia pacifica': 523, 'Salangichthys microdon': 524, 'Telmessus acutidens': 525, 'Ceratophyllum demersum': 526, 'Pandalus nipponensis': 527, 'Sebastes owstoni': 528, 'Cociella crocodilus': 529, 'Conger japonicus': 530, 'Sardinella zunasi': 531, 'Cheilopogon pinnatibarbatus japonicus': 532, 'Oplegnathus fasciatus': 533, 'Macridiscus aequilatera': 534, 'Repomucenus ornatipinnis': 535, 'Clupea pallasii': 536, 'Scorpaena neglecta': 537, 'Scomberomorus niphonius': 538, 'Leucopsarion petersii': 539, 'Sebastes scythropus': 540, 'Strongylura anastomella': 541, 'Laemonema longipes': 542, 'Fusitriton oregonensis': 543, 'Japelion pericochlion': 544, 'Sebastes steindachneri': 545, 'Auxis rochei': 546, 'Lobotes surinamensis': 547, 'Auxis thazard': 548, 'Chlorophthalmus borealis': 549, 'Etelis coruscans': 550, 'Sebastes inermis': 551, 'Cynoglossus interruptus': 552, 'Erilepis zonifer': 553, 'Tridentiger obscurus': 554, 'Caranx sexfasciatus': 555, 'Thunnus thynnus': 556, 'Takifugu stictonotus': 557, 'Euthynnus affinis': 558, 'Synagrops japonicus': 559, 'Okamejei schmidti': 560, 'Suggrundus meerdervoortii': 561, 'Sebastes baramenuke': 562, 'Pleurogrammus monopterygius': 563, 'Decapterus maruadsi': 564, 'Girella punctata': 565, 'Sphyraena japonica': 566, 'Ommastrephes bartramii': 567, 'Sepiella japonica': 568, 'Sepioteuthis lessoniana': 569, 'Eucleoteuthis luminosa': 570, 'Gloiopeltis furcata': 571, 'Macrobrachium nipponense': 572, 'Sepia kobiensis': 573, 'Eriocheir japonica': 574, 'Magallana nippona': 575, 'Meretrix lusoria': 576, 'Chondrus ocellatus': 577, 'Chondrus elatus': 578, 'Gloiopeltis': 579, 'Holothuroidea': 580, 'Corbicula japonica': 581, 'Sunetta menstrualis': 582, 'Pseudorhombus cinnamoneus': 583, 'Takifugu niphobles': 584, 'Lagocephalus gloveri': 585, 'Beryx splendens': 586, 'Parastichopus nigripunctatus': 587, 'Venerupis philippinarum': 588, 'Haliotis': 589, 'Liparis agassizii': 590, 'Seriola lalandi': 591, 'Niphon spinosus': 592, 'Pleuronichthys japonicus': 593, 'Sergia lucens': 594, 'Sphoeroides pachygaster': 595, 'Coryphaenoides acrolepis': 596, 'Pseudopleuronectes obscurus': 597, 'Pyropia yezoensis': 598, 'Isurus oxyrinchus': 599, 'Sargassum fulvellum': 600, 'Prionace glauca': 601, 'Kajikia audax': 602, 'Thunnus albacares': 603, 'Thunnus alalunga': 604, 'Thunnus obesus': 605, 'Lamna ditropis': 606, 'Glyptocidaris crenularis': 607, 'Asterias amurensis': 608, 'Sepiida': 609, 'Congridae': 610, 'Takifugu': 611, 'Sargassum horneri': 612, 'Haliotis discus': 613, 'Pleuronectidae': 614, 'Acanthogobius flavimanus': 615, 'Acanthogobius lactipes': 616, 'Pholis nebulosa': 617, 'Hemigrapsus penicillatus': 618, 'Palaemon paucidens': 619, 'Mysidae': 620, 'Zostera marina': 621, 'Ulva pertusa': 622, 'Gobiidae': 623, 'Atherinidae': 624, 'Tribolodon': 625, 'Alpheus': 626, 'Polychaeta': 627, 'Sebastes': 628, 'Charybdis japonica': 629, 'Hemigrapsus': 630, 'Favonigobius gymnauchen': 631, 'Palaemon': 632, 'Planiliza haematocheila': 633, 'Palaemonidae': 634, 'Pholis crassispina': 635, 'Laminaria': 636, 'Distolasterias nipon': 637, 'Lophiiformes': 638, 'Alpheus brevicristatus': 639, 'Undaria undariodes': 640, 'Neomysis awatschensis': 641, 'Alpheidae': 642, 'Macrobrachium': 643, 'Hediste': 644, 'Gymnogobius breunigii': 645, 'Luidia quinaria': 646, 'Rhizoprionodon acutus': 647, 'Carangoides equula': 648, 'Carcinoplax longimana': 649, 'Anomura': 650, 'Spatangoida': 651, 'Plesiobatis daviesi': 652, 'Eusphyra blochii': 653, 'Ruditapes variegata': 654, 'Sinonovacula constricta': 655, 'Penaeus monodon': 656, 'Litopenaeus vannamei': 657, 'Solenocera crassicornis': 658, 'Stomatopoda': 659, 'Teuthida': 660, 'Octopus': 661, 'Larimichthys polyactis': 662, 'Scomberomorini': 663, 'Channa argus': 664, 'Ranina ranina': 665, 'Lates calcarifer': 666, 'Scomberomorus commerson': 667, 'Lutjanus malabaricus': 668, 'Thenus parindicus': 669, 'Amusium pleuronectes': 670, 'Loligo': 671, 'Plectropomus leopardus': 672, 'Sillago ciliata': 673, 'Scylla serrata': 674, 'Pinctada maxima': 675, 'Lutjanus argentimaculatus': 676, 'Protonibea diacanthus': 677, 'Polydactylus macrochir': 678, 'Rachycentron canadum': 679, 'Ibacus peronii': 680, 'Arripis trutta': 681, 'Sarda australis': 682, 'Seriola hippos': 683, 'Choerodon schoenleinii': 684, 'Panulirus ornatus': 685, 'Neotrygon kuhlii': 686, 'Lethrinus nebulosus': 687, 'Parupeneus multifasciatus': 688, 'Saccostrea cucullata': 689, 'Lutjanus sebae': 690, 'Thunnus maccoyii': 691, 'Acanthopagrus butcheri': 692, 'Lambis lambis': 693, 'Gerres subfasciatus': 694, 'Zooplankton': 695, 'Phytoplankton': 696, 'Rapana venosa': 697, 'Scapharca inaequivalvis': 698, 'Ulva intestinalis': 699, 'Ulva linza': 700, 'Ceramium virgatum': 701, 'Gayralia oxysperma': 702, 'Vertebrata fucoides': 703, 'Stuckenia pectinata': 704, 'Rochia nilotica': 705, 'Ctenochaetus striatus': 706, 'Serranidae': 707, 'Turbo setosus': 708, 'Pandalidae': 709, 'Gymnosarda unicolor': 710, 'Epinephelini': 711, 'Pisces': 712, 'Liza klunzingeri': 713, 'Acanthopagrus latus': 714, 'Liza subviridis': 715, 'Sparidentex hasta': 716, 'Otolithes ruber': 717, 'Crenidens crenidens': 718, 'Ensis': 719, 'Gastropoda': 720, 'Euheterodonta': 721, 'Scomber': 722, 'Theragra chalcogramma': 723, 'Engraulidae': 724, 'Ostreidae': 725, 'Phaeophyceae': 726, 'Porphyra': 727, 'Ulva reticulata': 728, 'Perna viridis': 729, 'Fenneropenaeus indicus': 730, 'Merluccius': 731, 'Soleidae': 732, 'Mugilidae': 733, 'Marine algae': 734, 'Scarus rivulatus': 735, 'Scarus coeruleus': 736, 'Sardinella fimbriata': 737, 'Dussumieria acuta': 738, 'Lutjanus kasmira': 739, 'Lutjanus rivulatus': 740, 'Lutjanus bohar': 741, 'Priacanthus blochii': 742, 'Pelates quadrilineatus': 743, 'Epinephelus fasciatus': 744, 'Upeneus vittatus': 745, 'Lethrinus laticaudis': 746, 'Lethrinus lentjan': 747, 'Lethrinus microdon': 748, 'Sphyraena barracuda': 749, 'Alectis indica': 750, 'Epinephelus latifasciatus': 751, 'Nemipterus japonicus': 752, 'Raconda russeliana': 753, 'Lactarius lactarius': 754, 'Aetomylaeus bovinus': 755, 'Pennahia anea': 756, 'Leiognathus fasciatus': 757, 'Sardinella longiceps': 758, 'Tenualosa ilisha': 759, 'Pellona ditchela': 760, 'Stolephorus indicus': 761, 'Setipinna breviceps': 762, 'Rastrelliger kanagurta': 763, 'Chanos chanos': 764, 'Lepturacanthus savala': 765, 'Epinephelus niveatus': 766, 'Lutjanus johnii': 767, 'Carangoides malabaricus': 768, 'Ablennes hians': 769, 'Chirocentrus dorab': 770, 'Scomberomorus cavalla': 771, 'Scomberomorus semifasciatus': 772, 'Scomberomorus guttatus': 773, 'Etrumeus teres': 774, 'Spondyliosoma cantharus': 775, 'Brama brama': 776, 'Dasyatis zugei': 777, 'Harpadon nehereus': 778, 'Carcharhinus melanopterus': 779, 'Penaeus plebejus': 780, 'Sepia officinalis': 781, 'Johnius dussumieri': 782, 'Lutjanus campechanus': 783, 'Ruditapes decussatus': 784, 'Carcinus aestuarii': 785, 'Squilla mantis': 786, 'Epinephelus polyphekadion': 787, 'Lutjanus gibbus': 788, 'Lethrinus mahsena': 789, 'Epinephelus chlorostigma': 790, 'Carangoides bajad': 791, 'Aethaloperca rogaa': 792, 'Atule mate': 793, 'Macolor niger': 794, 'Carangoides fulvoguttatus': 795, 'Plectropomus areolatus': 796, 'Cephalopholis argus': 797, 'Cephalopholis': 798, 'Scarus sordidus': 799, 'Scomberomorus tritor': 800, 'Triaenodon obesus': 801, 'Pomadasys commersonnii': 802, 'Monotaxis grandoculis': 803, 'Plectropomus maculatus': 804, 'Trachinotus blochii': 805, 'Pristipomoides filamentosus': 806, 'Acanthurus gahhm': 807, 'Acanthurus sohal': 808, 'Siganus argenteus': 809, 'Naso unicornis': 810, 'Chanos': 811, 'Oedalechilus labiosus': 812, 'Plectorhinchus gaterinus': 813, 'Mercenaria mercenaria': 814, 'Mytilus': 815, 'Turbo cornutus': 816, 'Decapoda': 817, 'Sphyraena': 818, 'Arius maculatus': 819, 'Penaeus merguiensis': 820, 'Tegillarca granosa': 821, 'Mullus barbatus barbatus': 822, 'Chamelea gallina': 823, 'Metanephrops thomsoni': 824, 'Magallana gigas': 825, 'Branchiostegus japonicus': 826, 'Cephalopoda': 827, 'Lutjanidae': 828, 'Lethrinidae': 829, 'Sphyraena argentea': 830, 'Chirocentrus nudus': 831, 'Trachinotus': 832, 'Mugil auratus': 833, 'Euthynnus alletteratus': 834, 'Sparus aurata': 835, 'Pagrus caeruleostictus': 836, 'Scorpaena scrofa': 837, 'Pagellus erythrinus': 838, 'Epinephelus aeneus': 839, 'Dentex maroccanus': 840, 'Caranx rhonchus': 841, 'Sardinella': 842, 'Siganus': 843, 'Solea': 844, 'Diplodus sargus': 845, 'Lithognathus mormyrus': 846, 'Oblada melanura': 847, 'Siganus rivulatus': 848, 'Chelon labrosus': 849, 'Cynoscion microlepidotus': 850, 'Genypterus brasiliensis': 851, 'Myoxocephalus polyacanthocephalus': 852, 'Hexagrammos lagocephalus': 853, 'Hexagrammos decagrammus': 854, 'Sebastes ciliatus': 855, 'Lepidopsetta polyxystra': 856, 'Clupeiformes': 857, 'Gadidae': 858, 'Brachyura': 859, 'Dasyatis': 860, 'Carcharias': 861, 'Saurida': 862, 'Upeneus': 863, 'Cynoglossus': 864, 'Scomberomorus': 865, 'Terapon': 866, 'Leiognathus': 867, 'Terapontidae': 868, 'Caranx': 869, 'Diplodus': 870, 'Plectorhinchus flavomaculatus': 871, 'Salmonidae': 872, 'Mollusca': 873, 'Boops boops': 874, 'Sarpa salpa': 875, 'Pagellus acarne': 876, 'Spicara smaris': 877, 'Diplodus vulgaris': 878, 'Chelidonichthys lucerna': 879, 'Sarda sarda': 880, 'Serranus cabrilla': 881, 'Diplodus annularis': 882, 'Pagrus pagrus': 883, 'Alosa fallax': 884, 'Belone belone': 885, 'Dentex dentex': 886, 'Sphyraena viridensis': 887, 'Trisopterus capelanus': 888, 'Arnoglossus laterna': 889, 'Procambarus clarkii': 890, 'Nemadactylus macropterus': 891, 'Pagrus auratus': 892, 'Jasus edwardsii': 893, 'Perna canaliculus': 894, 'Pseudophycis bachus': 895, 'Haliotis iris': 896, 'Hoplostethus atlanticus': 897, 'Rhombosolea leporina': 898, 'Zygochlamys delicatula': 899, 'Galeorhinus galeus': 900, 'Parapercis colias': 901, 'Tiostrea chilensis': 902, 'Genypterus blacodes': 903, 'Evechinus chloroticus': 904, 'Austrovenus stutchburyi': 905, 'Micromesistius australis': 906, 'Macruronus novaezelandiae': 907, 'Nototodarus': 908, 'Perna perna': 909, 'Sepia pharaonis': 910, 'Turbo bruneus': 911, 'Portunus sanguinolentus': 912, 'Charybdis natator': 913, 'Charybdis lucifera': 914, 'Panulirus argus': 915, 'Ethmalosa fimbriata': 916, 'Sardinella brachysoma': 917, 'Thryssa mystax': 918, 'Plicofollis dussumieri': 919, 'Nibea soldado': 920, 'Epinephelus melanostigma': 921, 'Megalops cyprinoides': 922, 'Decapterus macarellus': 923, 'Drepane punctata': 924, 'Sillago sihama': 925, 'Tylosurus crocodilus crocodilus': 926, 'Saurida tumbil': 927, 'Cynoglossus macrostomus': 928, 'Parupeneus indicus': 929, 'Synechogobius hasta': 930, 'Busycotypus canaliculatus': 931, 'Pampus cinereus': 932, 'Pomadasys kaakan': 933, 'Epinephelus coioides': 934, 'Sepiella inermis': 935, 'Uroteuthis duvauceli': 936, 'Stomatella auricula': 937, 'Cerithium scabridum': 938, 'Marcia recens': 939, 'Circe intermedia': 940, 'Marcia opima': 941, 'Fulvia fragile': 942, 'Charybdis feriatus': 943, 'Charybdis annulata': 944, 'Atergatis integerrimus': 945, 'Matuta lunaris': 946, 'Calappa lophos': 947, 'Uca annulipes': 948, 'Chlamys varia': 949, 'Cololabis adocetus': 950, 'Seriola lalandi dorsalis': 951, 'Brunneifusus ternatanus': 952, 'Metapenaeus joyneri': 953, 'Epinephelus tauvina': 954, 'Coilia dussumieri': 955, 'Carcharhinus dussumieri': 956, 'Upeneus tragula': 957, 'Sartoriana spinigera': 958, 'Lamellidens marginalis': 959, 'Polydactylus sextarius': 960, 'Johnius macrorhynus': 961, 'Hexanematichthys sagor': 962, 'Sargassum swartzii': 963, 'Argyrops spinifer': 964, 'Synodus intermedius': 965, 'Muraenesox cinereus': 966, 'Carangoides armatus': 967, 'Eleutheronema tetradactylum': 968, 'Mustelus mosis': 969, 'Nemipterus bipunctatus': 970, 'Lutjanus quinquelineatus': 971, 'Platycephalus indicus': 972, 'Rhabdosargus haffara': 973, 'Argyrops filamentosus': 974, 'Brachirus orientalis': 975, 'Mene maculata': 976, 'Hemiramphus marginatus': 977, 'Encrasicholina heteroloba': 978, 'Trachinotus africanus': 979, 'Bramidae': 980, 'Escualosa thoracata': 981, 'Sepia arabica': 982, 'Scatophagus argus': 983, 'Parastromateus niger': 984, 'Planiliza subviridis': 985, 'Labeo rohita': 986, 'Oreochromis niloticus': 987, 'Cardiidae': 988, 'Sargassum angustifolium': 989, 'Pomacea bridgesii': 990, 'Sebastes fasciatus': 991, 'Batoidea': 992, 'Urophycis chuss': 993, 'Dalatias licha': 994, 'Trisopterus luscus': 995, 'Scyliorhinus canicula': 996, 'Ruvettus pretiosus': 997, 'Aphanopus carbo': 998, 'Alepocephalus bairdii': 999, 'Centroscymnus coelolepis': 1000, 'Loligo forbesii': 1001, 'Lutjanus cyanopterus': 1002, 'Mugil liza': 1003, 'Micropogonias furnieri': 1004, 'Balistes capriscus': 1005, 'Haemulidae': 1006, 'Stenotomus caprinus': 1007, 'Hemanthias leptus': 1008, 'Micropogonias undulatus': 1009, 'Cynoscion nebulosus': 1010, 'Rhomboplites aurorubens': 1011, 'Bothidae': 1012, 'Pogonias cromis': 1013, 'Lutjanus synagris': 1014, 'Netuma thalassina': 1015, 'Sillaginopsis panijus': 1016, 'Leptomelanosoma indicum': 1017, 'Therapon': 1018, 'Pterotolithus maculatus': 1019, 'Ilisha filigera': 1020, 'Hilsa kelee': 1021, 'Pampus chinensis': 1022, 'Palaemon styliferus': 1023, 'Argyrosomus regius': 1024, 'Lutjanus': 1025, 'Sciades': 1026, 'Mullus': 1027, 'Albula vulpes': 1028, 'Selar crumenophthalmus': 1029, 'Centropomus': 1030, 'Sardinella aurita': 1031, 'Harengula humeralis': 1032, 'Diapterus auratus': 1033, 'Gerres cinereus': 1034, 'Haemulon parra': 1035, 'Ocyurus chrysurus': 1036, 'Sphyraena guachancho': 1037, 'Anoplopoma fimbria': 1038, 'Nerita versicolor': 1039, 'Bulla striata': 1040, 'Melongena melongena': 1041, 'Trachycardium muricatum': 1042, 'Isognomon alatus': 1043, 'Brachidontes exustus': 1044, 'Crassostrea virginica': 1045, 'Protothaca granulata': 1046, 'Cittarium pica': 1047, 'Penaeus schmitti': 1048, 'Penaeus notialis': 1049, 'Callinectes sapidus': 1050, 'Callinectes danae': 1051, 'Dasyatidae': 1052, 'Caridea': 1053, 'Nephropidae': 1054, 'Sparus': 1055, 'Sargassum boveanum': 1056, 'Haliotis tuberculata': 1057, 'Littorinidae': 1058, 'Seaweed': 1059, 'Echinoidea': 1060, 'Ostreida': 1061, 'Donax trunculus': 1062, 'Scrobicularia plana': 1063, 'Venus verrucosa': 1064, 'Solen marginatus': 1065, 'Testudines': 1066, 'Mullidae': 1067, 'Amphipoda': 1068, 'Cystosphaera jacquinotii': 1069, 'Daption capense': 1070, 'Desmarestia anceps': 1071, 'Himantothallus grandifolius': 1072, 'Mirounga': 1073, 'Nacella concinna': 1074, 'Notothenia coriiceps': 1075, 'Pygoscelis antarcticus': 1076, 'Pygoscelis papua': 1077, 'Oncorhynchus gorbuscha': 1078, 'Oncorhynchus mykiss': 1079, 'Oncorhynchus nerka': 1080, 'Oncorhynchus tshawytscha': 1081, 'Erignathus barbatus': 1082, 'Pusa hispida': 1083, 'Hippoglossus stenolepis': 1084, 'Squalus suckleyi': 1085, 'Sargassum': 1086, 'Codium': 1087, 'Membranoptera alata': 1088, 'Dictyota dichotoma': 1089, 'Plocamium cartilagineum': 1090, 'Galatea paradoxa': 1091, 'Crassostrea tulipa': 1092, 'Macrobrachium sp': 1093, 'Portunus': 1094, 'Tympanotonos fuscatus': 1095, 'Thais': 1096, 'Bivalvia': 1097, 'Cynoglossus senegalensis': 1098, 'Carlarius heudelotii': 1099, 'Fontitrygon margarita': 1100, 'Chrysichthys nigrodigitatus': 1101, 'Acanthephyra purpurea': 1102, 'Actinauge abyssorum': 1103, 'Alaria marginata': 1104, 'Anadara transversa': 1105, 'Anthomedusae': 1106, 'Archosargus probatocephalus': 1107, 'Argyropelecus aculeatus': 1108, 'Ariopsis felis': 1109, 'Astrometis sertulifera': 1110, 'Astropecten': 1111, 'Atherina breviceps': 1112, 'Atolla': 1113, 'Aulacomya atra': 1114, 'Auxis rochei rochei': 1115, 'Auxis thazard thazard': 1116, 'Avicennia marina': 1117, 'Balaena mysticetus': 1118, 'Balaenoptera acutorostrata': 1119, 'Balanus': 1120, 'Berardius bairdii': 1121, 'Beroe': 1122, 'Boopsoidea inornata': 1123, 'Calanoida': 1124, 'Calanus finmarchicus finmarchicus': 1125, 'Callorhinchus milii': 1126, 'Cepphus columba': 1127, 'Cladonia rangiferina': 1128, 'Clinus superciliosus': 1129, 'Codium tomentosum': 1130, 'Copepoda': 1131, 'Coregonus autumnalis': 1132, 'Coregonus nasus': 1133, 'Coregonus sardinella': 1134, 'Coryphaenoides armatus': 1135, 'Coryphoblennius galerita': 1136, 'Creseis sp': 1137, 'Crinoidea': 1138, 'Crossota': 1139, 'Cryptochiton stelleri': 1140, 'Delphinus delphis': 1141, 'Diacria': 1142, 'Dichistius capensis': 1143, 'Dosinia alta': 1144, 'Dugong dugon': 1145, 'Electrona risso': 1146, 'Engraulis capensis': 1147, 'Ensis siliqua': 1148, 'Eryonidae': 1149, 'Eualaria fistulosa': 1150, 'Eupasiphae gilesii': 1151, 'Euphausiacea': 1152, 'Euphausiidae': 1153, 'Eurypharynx pelecanoides': 1154, 'Eurythenes gryllus': 1155, 'Euthynnus lineatus': 1156, 'Fratercula cirrhata': 1157, 'Galeichthys feliceps': 1158, 'Gelidium corneum': 1159, 'Gibbula umbilicalis': 1160, 'Gnathophausia ingens': 1161, 'Gonatus fabricii': 1162, 'Haliaeetus leucocephalus': 1163, 'Haliclona': 1164, 'Halodule uninervis': 1165, 'Hemilepidotus': 1166, 'Hemilepidotus jordani': 1167, 'Heterocarpus ensifer': 1168, 'Heterodontus portusjacksoni': 1169, 'Hippasteria phrygiana': 1170, 'Homola barbata': 1171, 'Hyperoodon planifrons': 1172, 'Hypleurochilus geminatus': 1173, 'Invertebrata': 1174, 'Isognomon bicolor': 1175, 'Isopoda': 1176, 'Kogia breviceps': 1177, 'Labrus bergylta': 1178, 'Lagenorhynchus obliquidens': 1179, 'Lampris guttatus': 1180, 'Larus glaucescens': 1181, 'Leander serratus': 1182, 'Libinia emarginata': 1183, 'Lichia amia': 1184, 'Lipophrys pholis': 1185, 'Lipophrys trigloides': 1186, 'Lithognathus lithognathus': 1187, 'Lithophaga aristata': 1188, 'Lobianchia gemellarii': 1189, 'Loliginidae': 1190, 'Loligo reynaudii': 1191, 'Lophius budegassa': 1192, 'Magallana angulata': 1193, 'Majoidea': 1194, 'Megachasma pelagios': 1195, 'Megaptera novaeangliae': 1196, 'Menippe mercenaria': 1197, 'Mesoplodon carlhubbsi': 1198, 'Mesoplodon stejnegeri': 1199, 'Microstomus pacificus': 1200, 'Morone saxatilis': 1201, 'Mullus surmuletus': 1202, 'Mycteroperca xenarcha': 1203, 'Myliobatis australis': 1204, 'Mysida': 1205, 'Mytilus californianus': 1206, 'Mytilus trossulus': 1207, 'Nephasoma Nephasoma flagriferum': 1208, 'Nudibranchia': 1209, 'Odobenus rosmarus divergens': 1210, 'Ommastrephidae': 1211, 'Ophiomusa lymani': 1212, 'Ophiothrix lineata': 1213, 'Orcinus orca': 1214, 'Ostracoda': 1215, 'Pagellus bogaraveo': 1216, 'Pandalus borealis': 1217, 'Paphies subtriangulata': 1218, 'Parabrotula': 1219, 'Paracalanus': 1220, 'Patella aspera': 1221, 'Periphylla': 1222, 'Phocoena phocoena': 1223, 'Phocoenoides dalli': 1224, 'Phronima': 1225, 'Physeter macrocephalus': 1226, 'Pinctada radiata': 1227, 'Plesionika edwardsii': 1228, 'Pododesmus macrochisma': 1229, 'Pomatomus saltatrix': 1230, 'Portunus pelagicus': 1231, 'Praunus': 1232, 'Pyrosoma': 1233, 'Rangifer tarandus': 1234, 'Rhabdosargus globiceps': 1235, 'Saccorhiza polyschides': 1236, 'Sagitta': 1237, 'Salpa': 1238, 'Salvelinus alpinus': 1239, 'Salvelinus malma': 1240, 'Sarda chiliensis': 1241, 'Sargassum aquifolium': 1242, 'Scalibregmatidae': 1243, 'Sebastes alutus': 1244, 'Sebastes melanops': 1245, 'Seriola dorsalis': 1246, 'Serranus scriba': 1247, 'Sigmops bathyphilus': 1248, 'Silicula fragilis': 1249, 'Sipunculidae': 1250, 'Somateria mollissima': 1251, 'Somateria spectabilis': 1252, 'Sparodon durbanensis': 1253, 'Spicara maena': 1254, 'Squatina australis': 1255, 'Striostrea margaritacea': 1256, 'Stromateus fiatola': 1257, 'Strongylocentrotus polyacanthus': 1258, 'Taractichthys steindachneri': 1259, 'Tectura scutum': 1260, 'Tegula viridula': 1261, 'Thais haemastoma': 1262, 'Thegrefg': 1263, 'Themisto': 1264, 'Thunnus tonggol': 1265, 'Trachurus picturatus': 1266, 'Trachurus symmetricus': 1267, 'Trygonorrhina fasciata': 1268, 'Ulva lactuca': 1269, 'Ursus maritimus': 1270, 'Vampyroteuthis infernalis': 1271, 'Ziphius cavirostris': 1272, 'Alepes kleinii': 1273, 'Alepes vari': 1274, 'Decapterus macrosoma': 1275, 'Lutjanus madras': 1276, 'Lutjanus russellii': 1277, 'Rastrelliger brachysoma': 1278, 'Rastrelliger faughni': 1279, 'Selar boops': 1280, 'Selaroides leptolepis': 1281, 'Sphyraena obtusata': 1282, 'Geloina expansa': 1283, 'Caesio erythrogaster': 1284, 'Euristhmus microceps': 1285, 'Pomacanthus annularis': 1286, 'Scylla': 1287, 'Plotosus lineatus': 1288, 'Prionotus stephanophrys': 1289, 'Trachurus murphyi': 1290, 'Dosidicus gigas': 1291, 'Sarda chiliensis chiliensis': 1292, 'Cynoscion analis': 1293, 'Merluccius gayi peruanus': 1294, 'Brotula ordwayi': 1295, 'Loligo gahi': 1296, 'Merluccius gayi': 1297, 'Ophichthus remiger': 1298, 'Penaeus sp': 1299, 'Trachinotus paitensis': 1300, 'Cheilopogon heterurus': 1301, 'Engraulis ringens': 1302, 'Sciaena deliciosa': 1303, 'Isacia conceptionis': 1304, 'Odontesthes regia': 1305, 'Bodianus diplotaenia': 1306, 'Concholepas concholepas': 1307, 'Diplectrum conceptione': 1308, 'Genypterus maculatus': 1309, 'Labrisomus philippii': 1310, 'Paralabrax humeralis': 1311, 'Prionotus horrens': 1312, 'Dasyatis akajei': 1313, 'Arctoscopus japonicus': 1314, 'Sepia esculenta': 1315, 'Bothrocara hollandi': 1316, 'Cynoglossidae': 1317, 'Lepidotrigla': 1318, 'Lepidotrigla alata': 1319, 'Octopus sinensis': 1320, 'Rhabdosargus sarba': 1321, 'Lophiidae': 1322, 'Muraenesox': 1323, 'Physiculus maximowiczi': 1324, 'Pleuronectoidei': 1325, 'Sciaenidae': 1326, 'Triglidae': 1327, 'Atherina presbyter': 1328, 'Bentheogennema intermedia': 1329, 'Benthesicymidae': 1330, 'Benthesicymus': 1331, 'Buccinum striatissimum': 1332, 'Callinectes': 1333, 'Cancer pagurus': 1334, 'Chaetognatha': 1335, 'Chama macerophylla': 1336, 'Cirripedia': 1337, 'Cyclosalpa': 1338, 'Cymopolia barbata': 1339, 'Cynoscion': 1340, 'Cystoseira amentacea': 1341, 'Ectocarpus siliculosus': 1342, 'Ellisolandia elongata': 1343, 'Enteromorpha linza': 1344, 'Euphausia superba': 1345, 'Gaidropsarus mediterraneus': 1346, 'Gennadas valens': 1347, 'Globicephala': 1348, 'Haliptilon virgatum': 1349, 'Halocynthia aurantium': 1350, 'Heliocidaris crassispina': 1351, 'Hymenodora gracilis': 1352, 'Lagodon rhomboides': 1353, 'Lepas Anatifa anatifera': 1354, 'Lobophora variegata': 1355, 'Macrocystis pyrifera': 1356, 'Maculabatis gerrardi': 1357, 'Nemacystus decipiens': 1358, 'Neptunea polycostata': 1359, 'Padina pavonia': 1360, 'Penaeidae': 1361, 'Petricolinae': 1362, 'Polynemidae': 1363, 'Pristipomoides aquilonaris': 1364, 'Pyropia fallax': 1365, 'Radiolaria': 1366, 'Salpidae': 1367, 'Sardinops melanosticta': 1368, 'Sargassum vulgare': 1369, 'Sciaena umbra': 1370, 'Scorpaena porcus': 1371, 'Sergestidae': 1372, 'Sicyonia brevirostris': 1373, 'Sphaerococcus coronopifolius': 1374, 'Stenella coeruleoalba': 1375, 'Stichopus japonicus': 1376, 'Thalia democratica': 1377, 'Themisto gaudichaudii': 1378, 'Undaria': 1379, 'Analipus japonicus': 1380, 'Sargassum yamadae': 1381, 'Ahnfeltiopsis paradoxa': 1382, 'Scytosiphon lomentaria': 1383, 'Chondria crassicaulis': 1384, 'Grateloupia lanceolata': 1385, 'Colpomenia sinuosa': 1386, 'Chondrus giganteus': 1387, 'Sargassum muticum': 1388, 'Ulva prolifera': 1389, 'Petalonia fascia': 1390, 'Balanus roseus': 1391, 'Chaetomorpha moniligera': 1392, 'Lomentaria hakodatensis': 1393, 'Neodilsea longissima': 1394, 'Polyopes affinis': 1395, 'Schizymenia dubyi': 1396, 'Dictyopteris pacifica': 1397, 'Ahnfeltiopsis flabelliformis': 1398, 'Bangia fuscopurpurea': 1399, 'Calliarthron': 1400, 'Cladophora': 1401, 'Cladophora albida': 1402, 'Dasya sessilis': 1403, 'Delesseria serrulata': 1404, 'Ecklonia cava': 1405, 'Gelidium elegans': 1406, 'Grateloupia turuturu': 1407, 'Hypnea asiatica': 1408, 'Mazzaella japonica': 1409, 'Pachydictyon coriaceum': 1410, 'Padina arborescens': 1411, 'Pterosiphonia pinnulata': 1412, 'Alatocladia yessoensis': 1413, 'Bryopsis plumosa': 1414, 'Ceramium kondoi': 1415, 'Chondracanthus intermedius': 1416, 'Codium contractum': 1417, 'Codium lucasii': 1418, 'Corallina pilulifera': 1419, 'Dictyopteris undulata': 1420, 'Gastroclonium pacificum': 1421, 'Gelidium amansii': 1422, 'Grateloupia sparsa': 1423, 'Laurencia okamurae': 1424, 'Leathesia marina': 1425, 'Lomentaria catenata': 1426, 'Meristotheca papulosa': 1427, 'Sargassum confusum': 1428, 'Sargassum siliquastrum': 1429, 'Tinocladia crassa': 1430, 'Saccharina yendoana': 1431, 'Thalassiophyllum clathrus': 1432, 'Mytilida': 1433, 'Pteriomorphia': 1434, 'Conger': 1435, 'Scyliorhinidae': 1436, 'Labrus': 1437, 'Algae': 1438, 'Necora puber': 1439, 'Anguilla': 1440, 'Rajidae': 1441, 'Buccinidae': 1442, 'Crustacea': 1443, 'Green algae': 1444, 'Ammodytes japonicus': 1445, 'Evynnis tumifrons': 1446, 'Gnathophis nystromi nystromi': 1447, 'Loligo bleekeri': 1448, 'Platichthys bicoloratus': 1449, 'Limanda punctatissima': 1450, 'Loliolus Nipponololigo japonica': 1451, 'Acanthopagrus schlegelii schlegelii': 1452, 'Sepiolina': 1453, 'Gelidium': 1454, 'Atrina pectinata': 1455, 'Echinocardium cordatum': 1456, 'Lamnidae': 1457, 'Meretrix lamarckii': 1458, 'Noctiluca scintillans': 1459, 'Philine argentata': 1460, 'Sergestes lucens': 1461, 'Corbicula sandai': 1462, 'Ulva': 1463, 'Actiniaria': 1464, 'Ctenopharyngodon idella': 1465, 'Ophiuroidea': 1466, 'Scomberoides lysan': 1467, 'Scomberoides tol': 1468, 'Sebastolobus': 1469, 'Selachimorpha': 1470, 'Selene setapinnis': 1471, 'Selene vomer': 1472, 'Sepia elliptica': 1473, 'Sergestes sp': 1474, 'Setipinna taty': 1475, 'Siganus canaliculatus': 1476, 'Sigmops gracile': 1477, 'Solenocera sp': 1478, 'Sparidae': 1479, 'Spermatophytina': 1480, 'Sphoeroides testudineus': 1481, 'Sphyraena jello': 1482, 'Spyridia hypnoides': 1483, 'Squaliformes': 1484, 'Squillidae': 1485, 'Stegophiura sladeni': 1486, 'Stenella longirostris': 1487, 'Stenobrachius leucopsarus': 1488, 'Sternaspidae': 1489, 'Stoechospermum polypodioides': 1490, 'Stolephorus commersonnii': 1491, 'Stromateus cinereus': 1492, 'Stromateus niger': 1493, 'Stromateus sinensis': 1494, 'Synidotea': 1495, 'Takifugu vermicularis': 1496, 'Telatrygon zugei': 1497, 'Terapon jarbua': 1498, 'Terebellidae': 1499, 'Thryssa dussumieri': 1500, 'Thunnini': 1501, 'Tibia curta': 1502, 'Tonna dolium': 1503, 'Trachinus draco': 1504, 'Trematomus bernacchii': 1505, 'Tridacna': 1506, 'Trinectes paulistanus': 1507, 'Trochus radiatus': 1508, 'Turbinaria': 1509, 'Tursiops truncatus': 1510, 'Ucides': 1511, 'Ulva compressa': 1512, 'Ulva fasciata': 1513, 'Ulva flexuosa': 1514, 'Ulva rigida': 1515, 'Upeneus taeniopterus': 1516, 'Upogebiidae': 1517, 'Uroteuthis Photololigo edulis': 1518, 'Valoniopsis pachynema': 1519, 'Veneridae': 1520, 'Venus foveolata': 1521, 'Vertebrata': 1522, 'Volutharpa ampullacea perryi': 1523, 'Zannichellia palustris': 1524, 'Zeus japonicus': 1525, 'Favites': 1526, 'Gadiformes': 1527, 'Gafrarium dispar': 1528, 'Galaxaura frutescens': 1529, 'Gelidium crinale': 1530, 'Genidens genidens': 1531, 'Girella elevata': 1532, 'Girella tricuspidata': 1533, 'Dentex hypselosomus': 1534, 'Saurida elongata': 1535, 'Pseudolabrus eoethinus': 1536, 'Atrobucca nibe': 1537, 'Diagramma pictum': 1538, 'Sepia lycidas': 1539, 'Plectorhinchus cinctus': 1540, 'Metapenaeopsis acclivis': 1541, 'Metapenaeopsis barbata': 1542, 'Nibea albiflora': 1543, 'Girella leonina': 1544, 'Sphyraenidae': 1545, 'Parapercis pulchella': 1546, 'Parapercis sexfasciata': 1547, 'Thysanoteuthis rhombus': 1548, 'Lepidotrigla kishinouyi': 1549, 'Cystoseira': 1550, 'Padina': 1551, 'Halimeda': 1552, 'Pacifastacus leniusculus': 1553, 'Salmo trutta': 1554, 'Chondrus crispus': 1555, 'Ictalurus punctatus': 1556, 'Acanthurus': 1557, 'Scombridae': 1558, 'Leukoma staminea': 1559, 'Trochidae': 1560, 'Protonibea': 1562, 'Anchoa compressa': 1563, 'Ensis magnus': 1564, 'Bolinus brandaris': 1565, 'Lutjanus notatus': 1566, 'Lethrinus olivaceus': 1567, 'Carassius auratus': 1569, 'Mugil': 1570, 'Gobius': 1571, 'Lajonkairia lajonkairii': 1572, 'Chrysophrys auratus': 1573, 'Galeorhinus australis': 1574, 'Nototodarus sloanii gouldi': 1575, 'Tylosurus crocodilus': 1576, 'Acanthogobius hasta': 1577, 'Penaeus chinensis': 1578, 'Ruditapes variegatus': 1579, 'Marcia marmorata': 1580, 'Rachycentron': 1581, 'Scomber kanagurta': 1582, 'Arius': 1583, 'Panulirus versicolor': 1584, 'Tilapia zillii': 1585, 'Schizoporella errata': 1586, 'Phallusia nigra': 1587, 'Physeter catodon': 1588, 'Salmo trutta trutta': 1589, 'Tachysurus thalassinus': 1590, 'Sillago domina': 1591, 'Otolithus argenteus': 1592, 'Trichiurus haumela': 1593, 'Otolithes maculata': 1594, 'Hilsa kanagurta': 1595, 'Oreochromis mossambicus': 1596, 'Siluriformes': 1597, 'Theodoxus euxinus': 1598, 'Formio niger': 1599, 'Rastrelliger': 1600, 'Nephasoma flagriferum': 1601, 'Ophiomusium lymani': 1602, 'Nematonurus armatus': 1603, 'Thalamitoides spinigera': 1604, 'Capros aper': 1605, 'Gadiculus argenteus thori': 1606, 'Phorcus lineatus': 1607, 'Penaeus vannamei': 1608, 'Raja montagui': 1609, 'Scophthalmus rhombus': 1610, 'Crambe maritima': 1611, 'Fucus ceranoides': 1612, 'Maja squinado': 1613, 'Salicornia europaea': 1614, 'Aequipecten opercularis': 1615, 'Galathea squamifera': 1616, 'Cynoglossus semilaevis': 1617, 'Loliolus beka': 1619, 'Octopus variabilis': 1620, 'Abudefduf sexfasciatus': 1621, 'Acanthurus blochii': 1622, 'Achillea millefolium': 1623, 'Alaria crassifolia': 1624, 'Albulidae': 1625, 'Ammodytes': 1626, 'Anadara satowi': 1627, 'Argyrosomus japonicus': 1628, 'Ascidiacea': 1629, 'Aulopiformes': 1630, 'Babylonia japonica': 1631, 'Babylonia kirana': 1632, 'Bathylagidae': 1633, 'Beryx decadactylus': 1634, 'Branchiostegus': 1635, 'Buccinum': 1636, 'Caesio lunaris': 1637, 'Callionymus curvicornis': 1638, 'Campylaephora hypnaeoides': 1639, 'Cetoscarus ocellatus': 1640, 'Charonia tritonis': 1641, 'Chelon haematocheilus': 1642, 'Chlorurus sordidus': 1643, 'Choerodon azurio': 1644, 'Chromis notata': 1645, 'Cladosiphon okamuranus': 1646, 'Cociella punctata': 1647, 'Coryphaena': 1648, 'Cyclina sinensis': 1649, 'Cymbacephalus beauforti': 1650, 'Dendrobranchiata': 1651, 'Digenea simplex': 1652, 'Ditrema viride': 1653, 'Enteromorpha prolifera': 1654, 'Epinephelus': 1655, 'Epinephelus akaara': 1656, 'Epinephelus awoara': 1657, 'Etelis carbunculus': 1658, 'Fistularia commersonii': 1659, 'Fulvia mutica': 1660, 'Fusinus colus': 1661, 'Gafrarium tumidum': 1662, 'Gelidiaceae': 1663, 'Girella cyanea': 1664, 'Girella mezina': 1665, 'Goniistius zonatus': 1666, 'Gracilaria': 1667, 'Gymnocranius euanus': 1668, 'Heikeopsis japonica': 1669, 'Hemitrygon': 1670, 'Hippoglossoides pinetorum': 1671, 'Holothuria atra': 1672, 'Holothuria leucospilota': 1673, 'Idiosepiidae': 1674, 'Inegocia japonica': 1675, 'Inimicus didactylus': 1676, 'Ishige': 1677, 'Lagocephalus spadiceus': 1678, 'Lambis truncata': 1679, 'Leiognathus equula': 1680, 'Lethrinus xanthochilus': 1681, 'Lutjanus erythropterus': 1682, 'Lutjanus semicinctus': 1683, 'Monodonta labio': 1684, 'Monostroma kuroshiense': 1685, 'Mulloidichthys flavolineatus': 1686, 'Mulloidichthys vanicolensis': 1687, 'Muraenesocidae': 1688, 'Myagropsis myagroides': 1689, 'Mytilisepta virgata': 1690, 'Naso brevirostris': 1691, 'Nematalosa japonica': 1692, 'Nemipterus virgatus': 1693, 'Nipponacmea': 1694, 'Nuchequula nuchalis': 1695, 'Octopus cyanea': 1696, 'Panopea generosa': 1697, 'Paralichthys': 1698, 'Paralithodes camtschaticus': 1699, 'Parascolopsis inermis': 1700, 'Pectinidae': 1701, 'Pentapodus aureofasciatus': 1702, 'Pinctada fucata': 1703, 'Pitar citrinus': 1704, 'Platycephalidae': 1705, 'Plecoglossus altivelis': 1706, 'Pleuronectes herzensteini': 1707, 'Priacanthus macracanthus': 1708, 'Pristipomoides': 1709, 'Psenopsis anomala': 1710, 'Pseudobalistes fuscus': 1711, 'Pseudocaranx dentex': 1712, 'Pseudolabrus sieboldi': 1713, 'Pseudorhombus arsius': 1714, 'Pterocaesio chrysozona': 1715, 'Rhynchopelates oxyrhynchus': 1716, 'Ryukyupercis gushikeni': 1717, 'Saccostrea echinata': 1718, 'Sargassum hemiphyllum': 1719, 'Sargassum piluliferum': 1720, 'Saurida micropectoralis': 1721, 'Saurida undosquamis': 1722, 'Saurida wanieso': 1723, 'Scarus forsteni': 1724, 'Scarus ghobban': 1725, 'Scarus ovifrons': 1726, 'Scarus rubroviolaceus': 1727, 'Scyphozoa': 1728, 'Sebastes iracundus': 1729, 'Semicossyphus reticulatus': 1730, 'Sepia latimanus': 1731, 'Siganus guttatus': 1732, 'Siganus luridus': 1733, 'Sphaerotrichia divaricata': 1734, 'Sphyrnidae': 1735, 'Spondylus regius': 1736, 'Spratelloides gracilis': 1737, 'Sthenoteuthis oualaniensis': 1738, 'Tetraodontidae': 1739, 'Trichiurus lepturus japonicus': 1740, 'Tridacna crocea': 1741, 'Turbo argyrostomus': 1742, 'Tylosurus pacificus': 1743, 'Ulvophyceae': 1744, 'Upeneus japonicus': 1745, 'Upeneus moluccensis': 1746, 'Uranoscopus japonicus': 1747, 'Anguilliformes': 1748, 'Crithmum maritimum': 1749, 'Littorina': 1750, 'Nucella lapillus': 1752, 'Scyliorhinus stellaris': 1753, 'Annelida': 1754, 'Aphrodita aculeata': 1755, 'Callionymus lyra': 1756, 'Urticina felina': 1757, 'Gebiidea': 1758, 'Bonellia viridis': 1759, 'Alcyonium glomeratum': 1760}.\n",
      "Creating enum for bio_group_t with values {'Not applicable': -1, 'Not available': 0, 'Birds': 1, 'Crustaceans': 2, 'Echinoderms': 3, 'Fish': 4, 'Mammals': 5, 'Molluscs': 6, 'Others': 7, 'Plankton': 8, 'Polychaete worms': 9, 'Reptile': 10, 'Seaweeds and plants': 11, 'Cephalopods': 12, 'Gastropods': 13, 'Bivalves': 14}.\n",
      "Creating enum for body_part_t with values {'Not applicable': -1, 'Not available': 0, 'Whole animal': 1, 'Whole animal eviscerated': 2, 'Whole animal eviscerated without head': 3, 'Flesh with bones': 4, 'Blood': 5, 'Skeleton': 6, 'Bones': 7, 'Exoskeleton': 8, 'Endoskeleton': 9, 'Shells': 10, 'Molt': 11, 'Skin': 12, 'Head': 13, 'Tooth': 14, 'Otolith': 15, 'Fins': 16, 'Faecal pellet': 17, 'Byssus': 18, 'Soft parts': 19, 'Viscera': 20, 'Stomach': 21, 'Hepatopancreas': 22, 'Digestive gland': 23, 'Pyloric caeca': 24, 'Liver': 25, 'Intestine': 26, 'Kidney': 27, 'Spleen': 28, 'Brain': 29, 'Eye': 30, 'Fat': 31, 'Heart': 32, 'Branchial heart': 33, 'Muscle': 34, 'Mantle': 35, 'Gills': 36, 'Gonad': 37, 'Ovary': 38, 'Testes': 39, 'Whole plant': 40, 'Flower': 41, 'Leaf': 42, 'Old leaf': 43, 'Young leaf': 44, 'Leaf upper part': 45, 'Leaf lower part': 46, 'Scales': 47, 'Root rhizome': 48, 'Whole macro alga': 49, 'Phytoplankton': 50, 'Thallus': 51, 'Flesh without bones': 52, 'Stomach and intestine': 53, 'Whole haptophytic plants': 54, 'Loose drifting plants': 55, 'Growing tips': 56, 'Upper parts of plants': 57, 'Lower parts of plants': 58, 'Shells carapace': 59, 'Flesh with scales': 60}.\n",
      "Creating enum for nuclide_t with values {'NOT APPLICABLE': -1, 'NOT AVAILABLE': 0, 'h3': 1, 'be7': 2, 'c14': 3, 'k40': 4, 'cr51': 5, 'mn54': 6, 'co57': 7, 'co58': 8, 'co60': 9, 'zn65': 10, 'sr89': 11, 'sr90': 12, 'zr95': 13, 'nb95': 14, 'tc99': 15, 'ru103': 16, 'ru106': 17, 'rh106': 18, 'ag106m': 19, 'ag108': 20, 'ag108m': 21, 'ag110m': 22, 'sb124': 23, 'sb125': 24, 'te129m': 25, 'i129': 28, 'i131': 29, 'cs127': 30, 'cs134': 31, 'cs137': 33, 'ba140': 34, 'la140': 35, 'ce141': 36, 'ce144': 37, 'pm147': 38, 'eu154': 39, 'eu155': 40, 'pb210': 41, 'pb212': 42, 'pb214': 43, 'bi207': 44, 'bi211': 45, 'bi214': 46, 'po210': 47, 'rn220': 48, 'rn222': 49, 'ra223': 50, 'ra224': 51, 'ra225': 52, 'ra226': 53, 'ra228': 54, 'ac228': 55, 'th227': 56, 'th228': 57, 'th232': 59, 'th234': 60, 'pa234': 61, 'u234': 62, 'u235': 63, 'u238': 64, 'np237': 65, 'np239': 66, 'pu238': 67, 'pu239': 68, 'pu240': 69, 'pu241': 70, 'am240': 71, 'am241': 72, 'cm242': 73, 'cm243': 74, 'cm244': 75, 'cs134_137_tot': 76, 'pu239_240_tot': 77, 'pu239_240_iii_iv_tot': 78, 'pu239_240_v_vi_tot': 79, 'cm243_244_tot': 80, 'pu238_pu239_240_tot_ratio': 81, 'am241_pu239_240_tot_ratio': 82, 'cs137_134_ratio': 83, 'cd109': 84, 'eu152': 85, 'fe59': 86, 'gd153': 87, 'ir192': 88, 'pu238_240_tot': 89, 'rb86': 90, 'sc46': 91, 'sn113': 92, 'sn117m': 93, 'tl208': 94, 'mo99': 95, 'tc99m': 96, 'ru105': 97, 'te129': 98, 'te132': 99, 'i132': 100, 'i135': 101, 'cs136': 102, 'tbeta': 103, 'talpha': 104, 'i133': 105, 'th230': 106, 'pa231': 107, 'u236': 108, 'ag111': 109, 'in116m': 110, 'te123m': 111, 'sb127': 112, 'ba133': 113, 'ce139': 114, 'tl201': 116, 'hg203': 117, 'na22': 122, 'pa234m': 123, 'am243': 124, 'se75': 126, 'sr85': 127, 'y88': 128, 'ce140': 129, 'bi212': 130, 'u236_238_ratio': 131, 'i125': 132, 'ba137m': 133, 'u232': 134, 'pa233': 135, 'ru106_rh106_tot': 136, 'tu': 137, 'tbeta40k': 138, 'fe55': 139, 'ce144_pr144_tot': 140, 'pu240_pu239_ratio': 141, 'u233': 142, 'pu239_242_tot': 143, 'ac227': 144}.\n",
      "Creating enum for filt_t with values {'Not applicable': -1, 'Not available': 0, 'Yes': 1, 'No': 2}.\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: smp_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bio_group\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: species\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: body_part\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: drywt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: wetwt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: smp_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tot_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: filt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tot_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: area\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sed_type\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: top\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bottom\n"
     ]
    }
   ],
   "source": [
    "encode(fname_in, fname_out_nc, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7e258",
   "metadata": {},
   "source": [
    "## NetCDF QA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e5e7",
   "metadata": {},
   "source": [
    "First lets review the general properties of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 1096993\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: 0.0\n",
      "  geospatial_vertical_max: 437.0\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error ( % ) to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA., Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Lookup FILT value in dataframe using the lookup table., Remap values from 'LABORATORY' to 'LAB' for groups: BIOTA, SEDIMENT and SEAWATER., Remap `KEY` column to `SMP_ID` in each DataFrame., Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties=get_netcdf_properties(fname_out_nc)\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c821d",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Update TBD values. \n",
    "The ``publisher_postprocess_logs`` may include ',' in the string. Can we review how the ``publisher_postprocess_logs`` are encoded? Would a dictionary be better?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b8243",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Enums (LUTS) should be encoded in the NetCDF file. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cc5bc",
   "metadata": {},
   "source": [
    "Review the publisher_postprocess_logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert 'NUCLIDE' column values to lowercase, strip spaces, and store in 'None' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error ( % ) to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'RUBIN' to 'SPECIES' for groups: BIOTA., Remap values from 'TISSUE' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Lookup FILT value in dataframe using the lookup table., Remap values from 'LABORATORY' to 'LAB' for groups: BIOTA, SEDIMENT and SEAWATER., Remap `KEY` column to `SMP_ID` in each DataFrame., Ensure depth values are floats and add 'smp_depth' and 'tot_depth' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format  or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(properties['global_attributes']['publisher_postprocess_logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b00241",
   "metadata": {},
   "source": [
    "Now lets review the properties of the groups in the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'bio_group', 'species', 'body_part', 'drywt', 'wetwt']\n",
      "  dimensions: {'id': 14873}\n",
      "  attributes: {}\n",
      "seawater:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'filt']\n",
      "  dimensions: {'id': 20242}\n",
      "  attributes: {}\n",
      "sediment:\n",
      "  variables: ['lon', 'lat', 'time', 'area', 'nuclide', 'value', 'unit', 'dl', 'sed_type', 'top', 'bottom']\n",
      "  dimensions: {'id': 63868}\n",
      "  attributes: {}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties = get_netcdf_group_properties(fname_out_nc)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09981ba",
   "metadata": {},
   "source": [
    "Lets review all variable attributes for the groups of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff21c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>...</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>lon</td>\n",
       "      <td>lat</td>\n",
       "      <td>smp_depth</td>\n",
       "      <td>time</td>\n",
       "      <td>smp_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>lab</td>\n",
       "      <td>...</td>\n",
       "      <td>area</td>\n",
       "      <td>smp_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>lab</td>\n",
       "      <td>sed_type</td>\n",
       "      <td>top</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_id</th>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>...</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_size</th>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>...</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "      <td>(63868,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_long_name</th>\n",
       "      <td>Measurement longitude</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Sample depth below seal level</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Data provider sample ID</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>...</td>\n",
       "      <td>Marine area/region id</td>\n",
       "      <td>Data provider sample ID</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>Sediment type</td>\n",
       "      <td>Top depth of sediment layer</td>\n",
       "      <td>Bottom depth of sediment layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_standard_name</th>\n",
       "      <td>longitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>sample_depth_below_sea_floor</td>\n",
       "      <td>time</td>\n",
       "      <td>sample_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>...</td>\n",
       "      <td>area_id</td>\n",
       "      <td>sample_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>sediment_type_tbd</td>\n",
       "      <td>top_depth_of_sediment_layer_tbd</td>\n",
       "      <td>bottom_depth_of_sediment_layer_tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_units</th>\n",
       "      <td>degrees_east</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>m</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_origin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_abbreviation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_calendar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                     1   \\\n",
       "group                               biota                 biota   \n",
       "variable                              lon                   lat   \n",
       "dimensions_id                     ('id',)               ('id',)   \n",
       "dimensions_size                  (14873,)              (14873,)   \n",
       "data_type                             <f4                   <f4   \n",
       "attr_long_name      Measurement longitude  Measurement latitude   \n",
       "attr_standard_name              longitude              latitude   \n",
       "attr_units                   degrees_east         degrees_north   \n",
       "attr_axis                             NaN                   NaN   \n",
       "attr_time_origin                      NaN                   NaN   \n",
       "attr_time_zone                        NaN                   NaN   \n",
       "attr_abbreviation                     NaN                   NaN   \n",
       "attr_calendar                         NaN                   NaN   \n",
       "\n",
       "                                               2   \\\n",
       "group                                       biota   \n",
       "variable                                smp_depth   \n",
       "dimensions_id                             ('id',)   \n",
       "dimensions_size                          (14873,)   \n",
       "data_type                                     <f4   \n",
       "attr_long_name      Sample depth below seal level   \n",
       "attr_standard_name   sample_depth_below_sea_floor   \n",
       "attr_units                                      m   \n",
       "attr_axis                                       Z   \n",
       "attr_time_origin                              NaN   \n",
       "attr_time_zone                                NaN   \n",
       "attr_abbreviation                             NaN   \n",
       "attr_calendar                                 NaN   \n",
       "\n",
       "                                                     3   \\\n",
       "group                                             biota   \n",
       "variable                                           time   \n",
       "dimensions_id                                   ('id',)   \n",
       "dimensions_size                                (14873,)   \n",
       "data_type                                           <u8   \n",
       "attr_long_name                      Time of measurement   \n",
       "attr_standard_name                                 time   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0   \n",
       "attr_axis                                             T   \n",
       "attr_time_origin                    1970-01-01 00:00:00   \n",
       "attr_time_zone                                      UTC   \n",
       "attr_abbreviation                             Date/Time   \n",
       "attr_calendar                                 gregorian   \n",
       "\n",
       "                                         4         5         6         7   \\\n",
       "group                                 biota     biota     biota     biota   \n",
       "variable                             smp_id   nuclide     value      unit   \n",
       "dimensions_id                       ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                    (14873,)  (14873,)  (14873,)  (14873,)   \n",
       "data_type                               <u8       <i8       <f4       <i8   \n",
       "attr_long_name      Data provider sample ID   Nuclide  Activity      Unit   \n",
       "attr_standard_name                sample_id   nuclide  activity      unit   \n",
       "attr_units                              NaN       NaN       NaN       NaN   \n",
       "attr_axis                               NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                        NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                          NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                       NaN       NaN       NaN       NaN   \n",
       "attr_calendar                           NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 8           9   ...                     31  \\\n",
       "group                         biota       biota  ...               sediment   \n",
       "variable                         dl         lab  ...                   area   \n",
       "dimensions_id               ('id',)     ('id',)  ...                ('id',)   \n",
       "dimensions_size            (14873,)    (14873,)  ...               (63868,)   \n",
       "data_type                       <i8         <i8  ...                    <i8   \n",
       "attr_long_name      Detection limit  laboratory  ...  Marine area/region id   \n",
       "attr_standard_name  detection_limit  laboratory  ...                area_id   \n",
       "attr_units                      NaN         NaN  ...                    NaN   \n",
       "attr_axis                       NaN         NaN  ...                    NaN   \n",
       "attr_time_origin                NaN         NaN  ...                    NaN   \n",
       "attr_time_zone                  NaN         NaN  ...                    NaN   \n",
       "attr_abbreviation               NaN         NaN  ...                    NaN   \n",
       "attr_calendar                   NaN         NaN  ...                    NaN   \n",
       "\n",
       "                                         32        33        34        35  \\\n",
       "group                              sediment  sediment  sediment  sediment   \n",
       "variable                             smp_id   nuclide     value      unit   \n",
       "dimensions_id                       ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                    (63868,)  (63868,)  (63868,)  (63868,)   \n",
       "data_type                               <u8       <i8       <f4       <i8   \n",
       "attr_long_name      Data provider sample ID   Nuclide  Activity      Unit   \n",
       "attr_standard_name                sample_id   nuclide  activity      unit   \n",
       "attr_units                              NaN       NaN       NaN       NaN   \n",
       "attr_axis                               NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                        NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                          NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                       NaN       NaN       NaN       NaN   \n",
       "attr_calendar                           NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 36          37                 38  \\\n",
       "group                      sediment    sediment           sediment   \n",
       "variable                         dl         lab           sed_type   \n",
       "dimensions_id               ('id',)     ('id',)            ('id',)   \n",
       "dimensions_size            (63868,)    (63868,)           (63868,)   \n",
       "data_type                       <i8         <i8                <i8   \n",
       "attr_long_name      Detection limit  laboratory      Sediment type   \n",
       "attr_standard_name  detection_limit  laboratory  sediment_type_tbd   \n",
       "attr_units                      NaN         NaN                NaN   \n",
       "attr_axis                       NaN         NaN                NaN   \n",
       "attr_time_origin                NaN         NaN                NaN   \n",
       "attr_time_zone                  NaN         NaN                NaN   \n",
       "attr_abbreviation               NaN         NaN                NaN   \n",
       "attr_calendar                   NaN         NaN                NaN   \n",
       "\n",
       "                                                 39  \\\n",
       "group                                      sediment   \n",
       "variable                                        top   \n",
       "dimensions_id                               ('id',)   \n",
       "dimensions_size                            (63868,)   \n",
       "data_type                                       <f4   \n",
       "attr_long_name          Top depth of sediment layer   \n",
       "attr_standard_name  top_depth_of_sediment_layer_tbd   \n",
       "attr_units                                      NaN   \n",
       "attr_axis                                       NaN   \n",
       "attr_time_origin                                NaN   \n",
       "attr_time_zone                                  NaN   \n",
       "attr_abbreviation                               NaN   \n",
       "attr_calendar                                   NaN   \n",
       "\n",
       "                                                    40  \n",
       "group                                         sediment  \n",
       "variable                                        bottom  \n",
       "dimensions_id                                  ('id',)  \n",
       "dimensions_size                               (63868,)  \n",
       "data_type                                          <f4  \n",
       "attr_long_name          Bottom depth of sediment layer  \n",
       "attr_standard_name  bottom_depth_of_sediment_layer_tbd  \n",
       "attr_units                                         NaN  \n",
       "attr_axis                                          NaN  \n",
       "attr_time_origin                                   NaN  \n",
       "attr_time_zone                                     NaN  \n",
       "attr_abbreviation                                  NaN  \n",
       "attr_calendar                                      NaN  \n",
       "\n",
       "[13 rows x 41 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_var_prop=get_netcdf_variable_properties(fname_out_nc, as_df=True).T\n",
    "df_var_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c543039",
   "metadata": {},
   "source": [
    "Lets convert the NetCDF file to a dictionary of DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df252c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dfs=nc_to_dfs(fname_out_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750b936",
   "metadata": {},
   "source": [
    "Lets review the biota data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>bio_group</th>\n",
       "      <th>species</th>\n",
       "      <th>body_part</th>\n",
       "      <th>drywt</th>\n",
       "      <th>wetwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>4</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>33</td>\n",
       "      <td>4.338000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>177.935120</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>54.583302</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>53</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>3</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>4</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>33</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14871</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>53</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14872</th>\n",
       "      <td>19.433300</td>\n",
       "      <td>54.363899</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>33</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14873 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide       value  unit  dl  \\\n",
       "0      12.316667  54.283333 2012-09-23       31    0.010140     5   2   \n",
       "1      12.316667  54.283333 2012-09-23        4  135.300003     5   1   \n",
       "2      12.316667  54.283333 2012-09-23        9    0.013980     5   2   \n",
       "3      12.316667  54.283333 2012-09-23       33    4.338000     5   1   \n",
       "4      12.316667  54.283333 2012-09-23       31    0.009614     5   2   \n",
       "...          ...        ...        ...      ...         ...   ...  ..   \n",
       "14868  19.000000  54.583302 2018-02-26       53    0.043000     5   1   \n",
       "14869  15.500000  54.333302 2018-02-13        4   98.000000     5   1   \n",
       "14870  15.500000  54.333302 2018-02-13       33    3.690000     5   1   \n",
       "14871  15.500000  54.333302 2018-02-13       53    0.049000     5   1   \n",
       "14872  19.433300  54.363899 2018-10-03       33    0.830000     5   1   \n",
       "\n",
       "       bio_group  species  body_part       drywt  wetwt  \n",
       "0              4       99         52  174.934433  948.0  \n",
       "1              4       99         52  174.934433  948.0  \n",
       "2              4       99         52  174.934433  948.0  \n",
       "3              4       99         52  174.934433  948.0  \n",
       "4              4       99         52  177.935120  964.0  \n",
       "...          ...      ...        ...         ...    ...  \n",
       "14868          4      191          3  120.000000  500.0  \n",
       "14869          4      191         52  112.500000  500.0  \n",
       "14870          4      191         52  112.500000  500.0  \n",
       "14871          4      191         52  112.500000  500.0  \n",
       "14872          4      247         52         NaN  120.0  \n",
       "\n",
       "[14873 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_biota=dfs['BIOTA']\n",
    "nc_dfs_biota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef71cc",
   "metadata": {},
   "source": [
    "Lets review the sediment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e068f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>area</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>sed_type</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63863</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>8.916443</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63864</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.992929</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63865</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2164.945801</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63866</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2523.279053</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63867</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3929.780029</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63868 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lon        lat       time  area  nuclide        value  unit  dl  \\\n",
       "0      24.0000  59.666698 2012-06-17     0       53    35.000000     4   1   \n",
       "1      24.0000  59.666698 2012-06-17     0       53    36.000000     4   1   \n",
       "2      28.8433  59.860001 2012-08-10     0       53    38.000000     4   1   \n",
       "3      28.8433  59.860001 2012-08-10     0       53    36.000000     4   1   \n",
       "4      28.8433  59.860001 2012-08-10     0       53    30.000000     4   1   \n",
       "...        ...        ...        ...   ...      ...          ...   ...  ..   \n",
       "63863  21.0830  59.035999 2016-06-09     0       33     8.916443     4   1   \n",
       "63864  21.0830  59.035999 2016-06-09     0       33     5.992929     4   1   \n",
       "63865  19.7297  61.066700 2016-05-29     0       33  2164.945801     4   1   \n",
       "63866  19.7297  61.066700 2016-05-29     0       33  2523.279053     4   1   \n",
       "63867  19.7297  61.066700 2016-05-29     0       33  3929.780029     4   1   \n",
       "\n",
       "       sed_type   top  bottom  \n",
       "0             0  15.0    20.0  \n",
       "1             0  20.0    27.0  \n",
       "2             0   0.0     2.0  \n",
       "3             0   2.0     4.0  \n",
       "4             0   4.0     6.0  \n",
       "...         ...   ...     ...  \n",
       "63863        50  18.0    20.0  \n",
       "63864        50  20.0    22.0  \n",
       "63865        59   0.0     2.0  \n",
       "63866        51   2.0     4.0  \n",
       "63867        50   4.0     6.0  \n",
       "\n",
       "[63868 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_sediment=dfs['SEDIMENT']\n",
    "nc_dfs_sediment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d6fc",
   "metadata": {},
   "source": [
    "Lets review the seawater data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20237</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>54.006802</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>12</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20238</th>\n",
       "      <td>14.667200</td>\n",
       "      <td>54.499500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20239</th>\n",
       "      <td>14.334200</td>\n",
       "      <td>54.750500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20242 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide      value  unit  dl  filt\n",
       "0      29.333300  60.083302 2012-05-23       33   5.300000     1   1     0\n",
       "1      29.333300  60.083302 2012-05-23       33  19.900000     1   1     0\n",
       "2      23.150000  59.433300 2012-06-17       33  25.500000     1   1     0\n",
       "3      27.983299  60.250000 2012-05-24       33  17.000000     1   1     0\n",
       "4      27.983299  60.250000 2012-05-24       33  22.200001     1   1     0\n",
       "...          ...        ...        ...      ...        ...   ...  ..   ...\n",
       "20237  14.200000  54.006802 2015-06-22       12   6.600000     1   1     1\n",
       "20238  14.667200  54.499500 2015-06-23       12   6.900000     1   1     1\n",
       "20239  14.334200  54.750500 2015-06-23       12   6.800000     1   1     1\n",
       "20240  13.500200  54.916500 2015-06-24       12   7.300000     1   1     1\n",
       "20241  13.500200  54.916500 2015-06-24       12   5.500000     1   1     1\n",
       "\n",
       "[20242 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_seawater=dfs['SEAWATER']\n",
    "nc_dfs_seawater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05beed7f",
   "metadata": {},
   "source": [
    "## Open Refine Decoder (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d380cb",
   "metadata": {},
   "source": [
    "Currently, the processing of MARIS data to the master dataset is done in OpenRefine. A standardised CSV is processed in OpenRefine and exported to the MARIS database. \n",
    "\n",
    "A decoder is needed to convert the NetCDF file format to the standardised CSV format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2c6f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

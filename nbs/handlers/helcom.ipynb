{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709cfb6",
   "metadata": {},
   "source": [
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [HELCOM data](https://helcom.fi/about-us) into `NetCDF` format. The handler processes raw HELCOM data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw HELCOM data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring HELCOM data is properly integrated into the MARIS database.\n",
    "\n",
    "\n",
    "\n",
    "Note: *Additionally, an optional encoder (pipeline) is provided below to process data into a `.csv` format compatible with the MARIS master database. This feature is maintained for legacy purposes, as data ingestion was previously performed using OpenRefine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121843",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/helcom.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple\n",
    "from math import modf\n",
    "from collections import OrderedDict\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, Remapper, \n",
    "                           match_maris_lut, Match, get_unique_across_dfs)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, AddSampleTypeIdColumnCB,\n",
    "                               AddNuclideIdColumnCB, LowerStripNameCB, SanitizeLonLatCB, \n",
    "                               ReshapeLongToWide, CompareDfsAndTfmCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, \n",
    "                              TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (nuc_lut_path, nc_tpl_path, cfg, cache_path, \n",
    "                             cdl_cfg, Enums, lut_path, species_lut_path, \n",
    "                             sediments_lut_path, bodyparts_lut_path, \n",
    "                             detection_limit_lut_path, filtered_lut_path, \n",
    "                             area_lut_path, get_lut, unit_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder,  OpenRefineCsvEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration & file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **fname_in**: path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_csv**: path and filename for the Open Refine csv output.The path can be defined as a relative path.\n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "- **ref_id**: refers to the location in Archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "fname_out_csv = '../../_data/output/100-HELCOM-MORS-2024.csv'\n",
    "zotero_key ='26VMZZ2Q' # HELCOM MORS zotero key\n",
    "ref_id = 100 # HELCOM MORS reference id as defined by MARIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc83f",
   "metadata": {},
   "source": [
    "[Helcom MORS (Monitoring of Radioactive Substances in the Baltic Sea) data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "**Example steps**:\n",
    "\n",
    "\n",
    "1. [Download data](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24)\n",
    "\n",
    "2. Install mdbtools via VScode Terminal: \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ```\n",
    "\n",
    "3. Install unzip via VScode Terminal:\n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ```\n",
    "\n",
    "4. In `VS Code` terminal (for instance), navigate to the marisco data folder:\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip `MORS_ENVIRONMENT.zip`:\n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run `preprocess.sh` to generate the required data files:\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ```\n",
    "\n",
    "7. Content of `preprocess.sh` script:\n",
    "\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n",
    "\n",
    "    Once converted to `.csv` files, the data is ready to be loaded into a dictionary of dataframes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = [('SEA', 'seawater'), ('SED', 'sediment'), ('BIO', 'biota')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir:str|Path, # The directory where the source CSV files are located\n",
    "              smp_types:list=default_smp_types # A list of tuples, each containing the file prefix and the corresponding sample type name\n",
    "             ) -> Dict[str, pd.DataFrame]: # A dictionary with sample types as keys and their corresponding dataframes as values\n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df_meas = pd.read_csv(src_path / f'{file_prefix}02.csv')\n",
    "            df_smp = pd.read_csv(src_path / f'{file_prefix}01.csv')\n",
    "            return pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files for {file_prefix}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if files are not found\n",
    "    \n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys/sample types:  dict_keys(['seawater', 'sediment', 'biota'])\n",
      "seawater columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "sediment columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "biota columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('keys/sample types: ', dfs.keys())\n",
    "\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} columns: ', dfs[key].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687eade",
   "metadata": {},
   "source": [
    "## Add sample type column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984410e",
   "metadata": {},
   "source": [
    "The sample type (`seawater`, `biota`, `sediment`, ...) as defined in the `configs.ipynb` are encoded group names in netCDF produced. Addition of sample type ids into individual dataframes is done using the `AddSampleTypeIdColumnCB` callback for legacy purposes (i.e. Open Refine output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ba759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            KEY  samptype_id\n",
      "0  WKRIL2012003            1\n",
      "1  WKRIL2012004            1\n",
      "2  WKRIL2012005            1\n",
      "3  WKRIL2012006            1\n",
      "4  WKRIL2012007            1\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddSampleTypeIdColumnCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater'][['KEY', 'samptype_id']].head())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4ceb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d84ed7",
   "metadata": {},
   "source": [
    "This is demonstrated below for the `NUCLIDE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      value  n_chars  stripped_chars\n",
      "1       1   PU238           8               5\n",
      "15     15     SR90          6               4\n",
      "21     21  CS137            9               5\n",
      "42     42   SR90            8               4\n",
      "56     56   CO60            8               4\n",
      "57     57      SR90         5               4\n",
      "58     58   CS134           8               5\n",
      "60     60   CS137           8               5\n",
      "68     68   K40             8               3\n",
      "71     71     CS137         6               5\n",
      "73     73   AM241           8               5\n",
      "92     92    SR90           7               4\n",
      "93     93    TC99           7               4\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(fname_in), 'NUCLIDE', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s) and ensuring the number comes before letters (e.g. `137cs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "for key in tfm().keys():\n",
    "    print(f'{key} nuclides: ')\n",
    "    print(tfm()[key]['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58baf14",
   "metadata": {},
   "source": [
    "We below map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures into MARIS standards is one recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "As now on, we will use this pattern to remap the HELCOM data provider nomenclatures into MARIS standards and name it for the sake of brevity **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31bc",
   "metadata": {},
   "source": [
    "The unique values of the data provider nuclide names. The `get_unique_across_dfs` is a utility function allowing to retrieve unique values of a specific column across all dataframes (please remind that we have one dataframe per sample type - biota, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ee8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>th228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sc46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cs142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cs137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>zn65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  value\n",
       "0      0  th228\n",
       "1      1   sc46\n",
       "2      2  cs142\n",
       "3      3  cs137\n",
       "4      4   zn65"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "dfs_output = tfm()\n",
    "\n",
    "get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1bdf",
   "metadata": {},
   "source": [
    "Let's now create an instance of a fuzzy matching algorithm `Remapper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0ea0c",
   "metadata": {},
   "source": [
    "And try to match HELCOM to MARIS nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:01<00:00, 46.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cm243244</th>\n",
       "      <td>cm244</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs134137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs134137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu238240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu238240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu239240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu239240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs142</th>\n",
       "      <td>ce144</td>\n",
       "      <td>cs142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs143</th>\n",
       "      <td>cs127</td>\n",
       "      <td>cs143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs145</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs144</th>\n",
       "      <td>ce144</td>\n",
       "      <td>cs144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs146</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-40</th>\n",
       "      <td>k40</td>\n",
       "      <td>k-40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs141</th>\n",
       "      <td>ce141</td>\n",
       "      <td>cs141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs139</th>\n",
       "      <td>ce139</td>\n",
       "      <td>cs139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs138</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs140</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "cm243244                cm244    cm243244            3\n",
       "cs134137                cs137    cs134137            3\n",
       "pu238240                pu240    pu238240            3\n",
       "pu239240                pu240    pu239240            3\n",
       "cs142                   ce144       cs142            2\n",
       "cs143                   cs127       cs143            2\n",
       "cs145                   cs136       cs145            2\n",
       "cs144                   ce144       cs144            1\n",
       "cs146                   cs136       cs146            1\n",
       "k-40                      k40        k-40            1\n",
       "cs141                   ce141       cs141            1\n",
       "cs139                   ce139       cs139            1\n",
       "cs138                   cs137       cs138            1\n",
       "cs140                   ce140       cs140            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cb838",
   "metadata": {},
   "source": [
    "We then manually inspect the remaining unmatched names and create a fixes table to map them to the correct MARIS standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs143': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'k-40': 'k40',\n",
    "    'cs140': 'cs137',\n",
    "    'cs146': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs138': 'cs137'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575e7e",
   "metadata": {},
   "source": [
    "Let's try to match again but this time we use the `fixes_nuclide_names` to map the nuclide names to the MARIS standards:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:01<00:00, 51.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1276f",
   "metadata": {},
   "source": [
    "Test passes! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a189ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_helcom.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        \"Remap data provider nuclide names to MARIS nuclide names.\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name='NUCLIDE', as_df=True)\n",
    "        lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce649d7a",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `RemapRdnNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cs134', 'k40', 'co60', 'cs137', 'sr90', 'ag108m', 'mn54', 'co58',\n",
       "       'ag110m', 'zn65', 'sb125', 'pu239_240_tot', 'ru106', 'be7',\n",
       "       'ce144', 'pb210', 'po210', 'sb124', 'sr89', 'zr95', 'te129m',\n",
       "       'ru103', 'nb95', 'ce141', 'la140', 'i131', 'ba140', 'pu238',\n",
       "       'u235', 'bi214', 'pb214', 'pb212', 'tl208', 'ac228', 'ra223',\n",
       "       'eu155', 'ra226', 'gd153', 'sn113', 'fe59', 'tc99', 'co57',\n",
       "       'sn117m', 'eu152', 'sc46', 'rb86', 'ra224', 'th232',\n",
       "       'cs134_137_tot', 'am241', 'ra228', 'th228'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides)\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "dfs_out['biota'].NUCLIDE.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ba2d3",
   "metadata": {},
   "source": [
    "### Add Nuclide Id column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6c352",
   "metadata": {},
   "source": [
    "The `nuclide_id` column is added to the dataframe for legacy reasons (again Open Refine output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>nuclide_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs134</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>co60</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs137</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs134</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15822</th>\n",
       "      <td>k40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15823</th>\n",
       "      <td>cs137</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15824</th>\n",
       "      <td>be7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>k40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15826</th>\n",
       "      <td>cs137</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NUCLIDE  nuclide_id\n",
       "0       cs134          31\n",
       "1         k40           4\n",
       "2        co60           9\n",
       "3       cs137          33\n",
       "4       cs134          31\n",
       "...       ...         ...\n",
       "15822     k40           4\n",
       "15823   cs137          33\n",
       "15824     be7           2\n",
       "15825     k40           4\n",
       "15826   cs137          33\n",
       "\n",
       "[15827 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE')\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "dfs_out['biota'][['NUCLIDE', 'nuclide_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83309a2",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04817201-8c26-43d3-a769-9fd83d72751c",
   "metadata": {},
   "source": [
    "**Comment (FA)**: TO BE REFACTORED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Parse the time column in the dataframe.\"\n",
    "    def __init__(self): fc.store_attr()\n",
    "            \n",
    "    def __call__(self, \n",
    "                 tfm # The transformer object containing DataFrames\n",
    "                ):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            df = tfm.dfs[grp]\n",
    "            self._process_dates(df)\n",
    "            self._define_beg_period(df)\n",
    "\n",
    "    def _process_dates(self, \n",
    "                       df:pd.DataFrame # DataFrame containing the `DATE`, `YEAR`, `MONTH`, and `DAY` columns\n",
    "                      ):\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['time'] = pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S')\n",
    "        # if 'DATE' column is nan, get 'time' from 'YEAR','MONTH' and 'DAY' column. \n",
    "        # if 'DAY' or 'MONTH' is 0 then set it to 1. \n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        # if 'DAY' and 'MONTH' is nan but YEAR is not nan then set 'DAY' and 'MONTH' both to 1. \n",
    "        condition = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[condition, \"DAY\"] = 1\n",
    "        df.loc[condition, \"MONTH\"] = 1\n",
    "        \n",
    "        condition = df['DATE'].isna() # if 'DATE' is nan. \n",
    "        df['time']  = np.where(condition,\n",
    "                                            # 'coerce', then invalid parsing will be set as NaT. NaT will result if the number of days are not valid for the month.\n",
    "                                        pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']], format='%y%m%d', errors='coerce'),  \n",
    "                                        pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S'))\n",
    "        \n",
    "    def _define_beg_period(self, \n",
    "                           df: pd.DataFrame # DataFrame containing the `time` column\n",
    "                          ):\n",
    "        \"Create a standardized date representation for Open Refine.\"\n",
    "        df['begperiod'] = df['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the ``begperiod`` and `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "       begperiod       time\n",
      "0     2012-05-23 2012-05-23\n",
      "1     2012-05-23 2012-05-23\n",
      "2     2012-06-17 2012-06-17\n",
      "3     2012-05-24 2012-05-24\n",
      "4     2012-05-24 2012-05-24\n",
      "...          ...        ...\n",
      "21211 2021-10-15 2021-10-15\n",
      "21212 2021-11-04 2021-11-04\n",
      "21213 2021-10-15 2021-10-15\n",
      "21214 2021-05-17 2021-05-17\n",
      "21215 2021-05-13 2021-05-13\n",
      "\n",
      "[21216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['seawater'][['begperiod','time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "### Encode time\n",
    "\n",
    "Seconds since ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 of 21216 entries for `time` are invalid for seawater.\n",
      "1 of 39817 entries for `time` are invalid for sediment.\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg(), verbose=True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_val = {'seawater' : {'val': 'VALUE_Bq/m³'},\n",
    "           'biota':  {'val': 'VALUE_Bq/kg'},\n",
    "           'sediment': {'val': 'VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c59ae1-c523-4aa6-bc04-e824390bf06d",
   "metadata": {},
   "source": [
    "**Comment (FA)**: Those lines can be simplified I think:\n",
    "```\n",
    "value_col = self.coi.get(grp, {}).get('val')\n",
    "if value_col and value_col in df.columns:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981121ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class SanitizeValue(Callback):\n",
    "    \"Sanitize value by removing blank entries and ensuring the 'value' column is retained.\"\n",
    "    def __init__(self, \n",
    "                 coi:dict # Dictionary containing column names for values based on group\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, \n",
    "                 tfm # The transformer object containing DataFrames\n",
    "                ):\n",
    "        \"Sanitize the DataFrames in the transformer by removing rows with blank values in specified columns.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._sanitize_dataframe(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _sanitize_dataframe(self, \n",
    "                            df:pd.DataFrame, # DataFrame to sanitize\n",
    "                            grp:str # Group name to determine column names\n",
    "                           ):\n",
    "        \"Remove rows where specified value columns are blank and ensure the 'value' column is included.\"\n",
    "        value_col = self.coi.get(grp, {}).get('val')\n",
    "        if value_col and value_col in df.columns:\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            # Ensure 'value' column is retained\n",
    "            if 'value' not in df.columns:\n",
    "                df['value'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21122     39532  15798\n",
      "Number of dropped rows                                    94       285     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df:pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col:str, # Name of the column with measurement values\n",
    "    unc_col:str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the uncertainty is given as a relative uncertainty. The column names for both the value and the uncertainty vary by sample type. The coi_units_unc dictionary defines the column names for the Value and Uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the uncertainty by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"Convert from relative error % to uncertainty of activity unit.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc:Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi:List=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['uncertainty'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback NormalizeUncCB(). Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value  uncertainty\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        value  uncertainty\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   value  uncertainty\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val)])\n",
    "\n",
    "print(tfm()['seawater'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['biota'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['sediment'][['value', 'uncertainty']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd63300",
   "metadata": {},
   "source": [
    "We follow in the next following processing steps the same approach as for remapping of nuclide names above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7dbf2",
   "metadata": {},
   "source": [
    "Let's inspect the `RUBIN_NAME.csv` file provided by HELCOM describing the biota species nomenclature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb121e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2bd53",
   "metadata": {},
   "source": [
    "We try to remap the `SCIENTIFIC NAME` column to the `species` column of the MARIS nomenclature, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da393947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 46/46 [00:07<00:00,  5.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMI SAC</th>\n",
       "      <td>Laminaria japonica</td>\n",
       "      <td>LAMINARIA SACCHARINA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD EDU</th>\n",
       "      <td>Cardiidae</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSET MAX</th>\n",
       "      <td>Pinctada maxima</td>\n",
       "      <td>PSETTA MAXIMA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA           10\n",
       "LAMI SAC     Laminaria japonica     LAMINARIA SACCHARINA            7\n",
       "CARD EDU              Cardiidae            CARDIUM EDULE            6\n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "PSET MAX        Pinctada maxima            PSETTA MAXIMA            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='SCIENTIFIC NAME',\n",
    "                    provider_col_key='RUBIN',\n",
    "                    fname_cache='species_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592a7a9",
   "metadata": {},
   "source": [
    "We fix below some of the entries that are not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_species = {\n",
    "    'CARDIUM EDULE': 'Cerastoderma edule',\n",
    "    'LAMINARIA SACCHARINA': 'Saccharina latissima',\n",
    "    'PSETTA MAXIMA': 'Scophthalmus maximus',\n",
    "    'STIZOSTEDION LUCIOPERCA': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1d994",
   "metadata": {},
   "source": [
    "And give it an another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 46/46 [00:07<00:00,  6.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f49b32",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We now define a callback to apply the lookup table to the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2798566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapBiotaSpeciesCB(Callback):\n",
    "    \"Biota species standardized to MARIS format.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap biota species names in the DataFrame using the lookup table and print unmatched RUBIN values.\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: self._get_species(x, lut))\n",
    "\n",
    "    def _get_species(self, \n",
    "                     rubin_value:str, # The RUBIN value from the DataFrame\n",
    "                     lut:dict # The lookup table dictionary\n",
    "                    ):\n",
    "        \"Get the matched_id from the lookup table and print RUBIN if the matched_id is -1.\"\n",
    "        match = lut.get(rubin_value.strip(), Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self.print_unmatched_rubin(rubin_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_rubin(self, \n",
    "                              rubin_value: str # The RUBIN value from the DataFrame\n",
    "                             ):\n",
    "        \"Print the RUBIN value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched RUBIN: {rubin_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8c536",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `RemapBiotaSpeciesCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='SCIENTIFIC NAME',\n",
    "                             provider_col_key='RUBIN',\n",
    "                             fname_cache='species_helcom.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ffe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524  703\n",
      " 1611  621   60]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapBiotaSpeciesCB(lut_biota)])\n",
    "\n",
    "# For instance:\n",
    "print(tfm()['biota']['species'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "## Remap Biota tissues\n",
    "Let's inspect the `TISSUE.csv` file provided by HELCOM describing the tissue nomenclature. Biota tissue is known as `body part` in the maris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 123.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>SKIN/EPIDERMIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brain</td>\n",
       "      <td>ENTRAILS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                           source_name  \\\n",
       "source_key                                                                \n",
       "3             Flesh without bones  WHOLE FISH WITHOUT HEAD AND ENTRAILS   \n",
       "2             Flesh without bones           WHOLE FISH WITHOUT ENTRAILS   \n",
       "8                      Soft parts                        SKIN/EPIDERMIS   \n",
       "5             Flesh without bones          FLESH WITHOUT BONES (FILETS)   \n",
       "1                    Whole animal                            WHOLE FISH   \n",
       "12                          Brain                              ENTRAILS   \n",
       "15          Stomach and intestine                   STOMACH + INTESTINE   \n",
       "41                   Whole animal                         WHOLE ANIMALS   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "3                    20  \n",
       "2                    13  \n",
       "8                    10  \n",
       "5                     9  \n",
       "1                     5  \n",
       "12                    5  \n",
       "15                    3  \n",
       "41                    1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                    provider_col_key='TISSUE',\n",
    "                    fname_cache='tissues_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1bb9",
   "metadata": {},
   "source": [
    "We fix below some of the entries that are not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_tissues = {\n",
    "    'WHOLE FISH WITHOUT HEAD AND ENTRAILS': 'Whole animal eviscerated without head',\n",
    "    'ENTRAILS': 'Viscera',\n",
    "    'SKIN/EPIDERMIS': 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 123.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                   source_name  match_score\n",
       "source_key                                                                  \n",
       "2             Flesh without bones   WHOLE FISH WITHOUT ENTRAILS           13\n",
       "5             Flesh without bones  FLESH WITHOUT BONES (FILETS)            9\n",
       "1                    Whole animal                    WHOLE FISH            5\n",
       "15          Stomach and intestine           STOMACH + INTESTINE            3\n",
       "41                   Whole animal                 WHOLE ANIMALS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapBiotaBodyPartCB(Callback):\n",
    "    \"Update bodypart id based on MARIS body part LUT (dbo_bodypar.xlsx).\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap biota body parts in the DataFrame using the lookup table and print unmatched TISSUE values.\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: self._get_body_part(x, lut))\n",
    "\n",
    "    def _get_body_part(self, \n",
    "                       tissue_value:str, # The TISSUE value from the DataFrame\n",
    "                       lut:dict # The lookup table dictionary\n",
    "                      ):\n",
    "        \"Get the matched_id from the lookup table and print TISSUE if the matched_id is -1.\"\n",
    "        match = lut.get(tissue_value, Match(-1, None, None, None))\n",
    "        if match.matched_id == -1: \n",
    "            self.print_unmatched_tissue(tissue_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_tissue(self, \n",
    "                               tissue_value:str # The TISSUE value from the DataFrame\n",
    "                              ):\n",
    "        \"Print the TISSUE value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched TISSUE: {tissue_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                               provider_col_key='TISSUE',\n",
    "                               fname_cache='tissues_helcom.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a195f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  body_part\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapBiotaSpeciesCB(lut_biota),                \n",
    "                            RemapBiotaBodyPartCB(lut_tissues)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'][['TISSUE', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "## Remap biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biogroup = lambda: get_lut(species_lut_path().parent, species_lut_path().name, \n",
    "                               key='species_id', value='biogroup_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291637e",
   "metadata": {},
   "source": [
    "`RemapBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `lut_biogroup` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapBiogroupCB(Callback):\n",
    "    \"Update biogroup id based on MARIS species LUT (dbo_species.xlsx).\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        self.lut = {int(k):v for k,v in fn_lut().items()}\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(self._lookup_biogroup)\n",
    "\n",
    "    def _lookup_biogroup(self, species_id):\n",
    "        biogroup = self.lut.get(species_id, -1)\n",
    "        if biogroup == -1: print(f\"Warning: Species ID {species_id} not found in biogroup lookup table\")\n",
    "        return biogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapBiotaSpeciesCB(lut_biota),                \n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup)])\n",
    "\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea8647",
   "metadata": {},
   "source": [
    "## Remap Taxon Information\n",
    "These details (`Taxonname` , `TaxonRepName`, `Taxonrank`) are used for importing into the MARIS master database, but are not included in the `NetCDF` encoding.\n",
    "We need to get the taxon information from the `dbo_species.xlsx` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf19160",
   "metadata": {},
   "source": [
    "We need to get the taxon information from the `dbo_species.xlsx` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TODO: Include Commonname field after next MARIS data reconciling process.\n",
    "def get_taxon_info_lut(\n",
    "    maris_lut:str # Path to the MARIS lookup table (Excel file)\n",
    ") -> dict: # A dictionary mapping species_id to biogroup_id\n",
    "    \"Retrieve a lookup table for Taxonname from a MARIS lookup table.\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].set_index('species_id').to_dict()\n",
    "\n",
    "lut_taxon = lambda: get_taxon_info_lut(species_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapTaxonInformationCB(Callback):\n",
    "    \"Update taxon names based on MARIS species LUT `dbo_species.xlsx`.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable # Function that returns the lookup table dictionary\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Update taxon information columns in the DataFrame using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        df = tfm.dfs['biota']\n",
    "        \n",
    "        self._set_taxon_rep_name(df)\n",
    "        \n",
    "        taxon_columns = ['Taxonname', 'Taxonrank', 'TaxonDB', 'TaxonDBID', 'TaxonDBURL']\n",
    "        for col in taxon_columns:\n",
    "            df[col] = df['species'].apply(lambda x: self._get_name_by_species_id(x, lut[col]))\n",
    "\n",
    "    def _set_taxon_rep_name(self, df: pd.DataFrame):\n",
    "        \"Set the `TaxonRepName` column to the `RUBIN` column values if it exists.\"\n",
    "        if 'RUBIN' in df.columns:\n",
    "            df['TaxonRepName'] = df['RUBIN']\n",
    "        else:\n",
    "            print(\"Warning: 'RUBIN' column not found in DataFrame.\")\n",
    "\n",
    "    def _get_name_by_species_id(self, species_id: str, lut: dict) -> str:\n",
    "        \"Get the name from the lookup table, defaulting to 'Unknown' if not found.\"\n",
    "        name = lut.get(species_id, 'Unknown')\n",
    "        if name == 'Unknown':\n",
    "            print(f\"Unmatched species ID: {species_id}\")\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Taxonname Taxonrank   TaxonDB TaxonDBID  \\\n",
      "0           Gadus morhua   species  Wikidata   Q199788   \n",
      "40     Sprattus sprattus   species  Wikidata   Q506823   \n",
      "44       Clupea harengus   species  Wikidata  Q2396858   \n",
      "77  Merlangius merlangus   species  Wikidata   Q273083   \n",
      "78       Limanda limanda   species  Wikidata  Q1135526   \n",
      "\n",
      "                                TaxonDBURL  \n",
      "0    https://www.wikidata.org/wiki/Q199788  \n",
      "40   https://www.wikidata.org/wiki/Q506823  \n",
      "44  https://www.wikidata.org/wiki/Q2396858  \n",
      "77   https://www.wikidata.org/wiki/Q273083  \n",
      "78  https://www.wikidata.org/wiki/Q1135526  \n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ \n",
    "                            RemapBiotaSpeciesCB(lut_biota),                \n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon)\n",
    "                            ])\n",
    "tfm()\n",
    "print(tfm.dfs['biota'][['Taxonname', 'Taxonrank','TaxonDB','TaxonDBID','TaxonDBURL']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "## Remap Sediment types\n",
    "We use again the same **IMFA** (Inspect, Match, Fix, Apply) pattern to remap the HELCOM sediment types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938d40",
   "metadata": {},
   "source": [
    "Let's inspect the `SEDIMENT_TYPE.csv` file provided by HELCOM describing the sediment type nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>SILT</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99       NO DATA                    NaN\n",
       "1     0        GRAVEL                    YES\n",
       "2     1          SAND                    YES\n",
       "3     2     FINE SAND                     NO\n",
       "4     3          SILT                    YES"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05762600",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `SEDI` values `56` and `73` are not found in the `SEDIMENT_TYPE.csv` lookup table provided. Note also there are many `nan` values in the `SEDIMENT_TYPE.csv` file.\n",
    "\n",
    "We reassign them to `-99` for now but should be clarified/fixed. This is demonstrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SEDI values: {56.0, 73.0, nan}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_sed_lut = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "sediment_sedi = set(dfs['sediment'].SEDI.unique())\n",
    "lookup_sedi = set(df_sed_lut['SEDI'])\n",
    "missing = sediment_sedi - lookup_sedi\n",
    "print(f\"Missing SEDI values: {missing if missing else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f305d9",
   "metadata": {},
   "source": [
    "Let's try to match as many as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac413a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 137.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>Soft</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99                      Soft         NO DATA            5\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in)/'SEDIMENT_TYPE.csv'),\n",
    "                    maris_lut_fn=sediments_lut_path,\n",
    "                    maris_col_id='sedtype_id',\n",
    "                    maris_col_name='sedtype',\n",
    "                    provider_col_to_match='SEDIMENT TYPE',\n",
    "                    provider_col_key='SEDI',\n",
    "                    fname_cache='sediments_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_sediments = {\n",
    "    'NO DATA': '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 83.93it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "50             Mud and gravel  MUD AND GARVEL            2\n",
       "46               Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_sediments)\n",
    "remapper.select_match(match_score_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad7ec2-97fd-43a8-83cb-c965ae89efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedimentCB(Callback):\n",
    "    \"Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:Callable, # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def _fix_inconsistent_sedi(self, df:pd.DataFrame):\n",
    "        \"Temporary fix for inconsistent SEDI values. Data provider to confirm and clarify.\"\n",
    "        df['SEDI'] = df['SEDI'].replace({56: -99, 73: -99, np.nan: -99})\n",
    "        return df\n",
    "    \n",
    "    def __call__(self, tfm):\n",
    "        \"Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Set SedRepName (TBC: what's used for?)\n",
    "        tfm.dfs['sediment']['SedRepName']  = tfm.dfs['sediment']['SEDI'] \n",
    "        \n",
    "        tfm.dfs['sediment'] = self._fix_inconsistent_sedi(tfm.dfs['sediment'])\n",
    "        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: self._get_sediment_type(x, lut))\n",
    "\n",
    "    def _get_sediment_type(self, \n",
    "                           sedi_value:int, # The `SEDI` value from the DataFrame\n",
    "                           lut:dict # The lookup table dictionary\n",
    "                          ): \n",
    "        \"Get the matched_id from the lookup table and print SEDI if the matched_id is -1.\"\n",
    "        match = lut.get(sedi_value, Match(-1, None, None, None))\n",
    "        \n",
    "        if match.matched_id == -1:\n",
    "            self._print_unmatched_sedi(sedi_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def _print_unmatched_sedi(self, \n",
    "                              sedi_value:int # The `SEDI` value from the DataFram\n",
    "                             ):\n",
    "        \"Print the SEDI value if the matched_id is -1.\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_sediments = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv'),\n",
    "                                 maris_lut_fn=sediments_lut_path,\n",
    "                                 maris_col_id='sedtype_id',\n",
    "                                 maris_col_name='sedtype',\n",
    "                                 provider_col_to_match='SEDIMENT TYPE',\n",
    "                                 provider_col_key='SEDI',\n",
    "                                 fname_cache='sediments_helcom.pkl'\n",
    "                                 ).generate_lookup_table(fixes=fixes_sediments, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131e929",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `RemapSedimentCB(get_maris_sediments)`. Then, print the `SEDI` and `sed_type` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d42cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 58, 30, 59, 55, 56, 36, 29, 47,  4, 54, 33,  6, 44, 42, 48,\n",
       "       61, 57, 28, 49, 32, 45, 39, 46, 38, 31, 60, 62, 26, 53, 52,  1, 51,\n",
       "       37, 34, 50,  7, 10, 41, 43, 35])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedimentCB(lut_sediments)])\n",
    "\n",
    "tfm()['sediment']['sed_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4064ed",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The handling of unit types varies between `biota` and `sediment` sample types. For consistency and ease of use, it would be beneficial to have dedicated unit columns for all sample types.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a682ac",
   "metadata": {},
   "source": [
    "For `seawater` and `sediment` sample types, the HELCOM dataset refers to units direcly in the name of certain columns, such as `VALUE_Bq/m³` or `VALUE_Bq/kg`. As for `biota`, the units are included in the `BASIS` column. This is shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab93970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "sediment: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "seawater: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for grp in ['biota', 'sediment', 'seawater']:\n",
    "    print(f\"{grp}: {dfs[grp].columns}\")\n",
    "    \n",
    "dfs['biota']['BASIS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "Given the inconsistent handling of units across sample types, we need to define custom mapping rules for standardizing the units. Below the MARIS unit types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a86baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized\n",
       "0        -1  Not applicable  Not applicable\n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE\n",
       "2         1           Bq/m3       Bq per m3\n",
       "3         2           Bq/m2       Bq per m2\n",
       "4         3           Bq/kg       Bq per kg\n",
       "5         4          Bq/kgd      Bq per kgd\n",
       "6         5          Bq/kgw      Bq per kgw\n",
       "7         6           kg/kg       kg per kg\n",
       "8         7              TU              TU\n",
       "9         8      DELTA/mill  DELTA per mill\n",
       "10        9         atom/kg     atom per kg\n",
       "11       10        atom/kgd    atom per kgd\n",
       "12       11        atom/kgw    atom per kgw\n",
       "13       12          atom/l      atom per l\n",
       "14       13          Bq/kgC      Bq per kgC"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())[['unit_id', 'unit', 'unit_sanitized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec28334",
   "metadata": {},
   "source": [
    "We define unit names renaming rules from HELCOM in an **ad hoc** way for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_units = {\n",
    "    'seawater': 1,  # 'Bq/m3'\n",
    "    'sediment': 4,  # 'Bq/kgd' for sediment\n",
    "    'biota': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemapUnitCB(Callback):\n",
    "    \"Set the `unit` id column in the DataFrames based on a lookup table.\"\n",
    "    def __init__(self, \n",
    "                 lut_units:dict=lut_units # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp in ['seawater', 'sediment']:\n",
    "                tfm.dfs[grp]['unit'] = self.lut_units[grp]\n",
    "            else:\n",
    "                tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut_units[grp].get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `RemapUnitCB()`. Then, print the unique `unit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota: [5 0 4]\n",
      "sediment: [4]\n",
      "seawater: [1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapUnitCB()])\n",
    "\n",
    "for grp in ['biota', 'sediment', 'seawater']:\n",
    "    print(f\"{grp}: {tfm()[grp]['unit'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "## Remap detection limit\n",
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b07268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7083b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023ddb4",
   "metadata": {},
   "source": [
    "Based on columns of interest for each sample type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc43c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'seawater' : {'val' : 'VALUE_Bq/m³',\n",
    "                       'unc' : 'ERROR%_m³',\n",
    "                       'dl' : '< VALUE_Bq/m³'},\n",
    "          'biota':  {'val' : 'VALUE_Bq/kg',\n",
    "                     'unc' : 'ERROR%',\n",
    "                     'dl' : '< VALUE_Bq/kg'},\n",
    "          'sediment': {\n",
    "              'val' : 'VALUE_Bq/kg',\n",
    "              'unc' : 'ERROR%_kg',\n",
    "              'dl' : '< VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ac6a6",
   "metadata": {},
   "source": [
    "We follow the following business logic to encode the detection limit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`RemapDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or detection limit) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "# TO BE REFACTORED\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    def __init__(self, \n",
    "                 coi:dict, # Configuration options for column names\n",
    "                 fn_lut:callable # Function that returns a lookup table\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "    \n",
    "    def _update_detection_limit(self, \n",
    "                                df:pd.DataFrame, # The DataFrame to modify\n",
    "                                grp:str, # The group name to get the column configuration\n",
    "                                lut:dict # The lookup table dictionary\n",
    "                               ):\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        detection_col = self.coi[grp]['dl']\n",
    "        value_col = self.coi[grp]['val']\n",
    "        uncertainty_col = self.coi[grp]['unc']\n",
    "        \n",
    "        # Copy detection limit column\n",
    "        df['detection_limit'] = df[detection_col]\n",
    "        \n",
    "        # Fill values with '=' or 'Not Available'\n",
    "        condition = ((df[value_col].notna()) & (df[uncertainty_col].notna()) &\n",
    "                     (~df['detection_limit'].isin(lut.keys())))\n",
    "        df.loc[condition, 'detection_limit'] = '='\n",
    "        df.loc[~df['detection_limit'].isin(lut.keys()), 'detection_limit'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup\n",
    "        df['detection_limit'] = df['detection_limit'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota: [2 1 0]\n",
      "sediment: [1 2 0]\n",
      "seawater: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            NormalizeUncCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl)])\n",
    "\n",
    "\n",
    "for grp in ['biota', 'sediment', 'seawater']:\n",
    "    print(f\"{grp}: {tfm()[grp]['detection_limit'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "## Remap filtering status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea63f3",
   "metadata": {},
   "source": [
    "HELCOM filtered status is encoded as follows in the `FILT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index value\n",
       "0      0   NaN\n",
       "1      1     N\n",
       "2      2     F\n",
       "3      3     n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "get_unique_across_dfs(dfs, col_name='FILT', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee067",
   "metadata": {},
   "source": [
    "While MARIS uses a different encoding for filtered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(filtered_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf457",
   "metadata": {},
   "source": [
    "For only four categories to remap, the `Remapper` is an overkill. We can use a simple dictionary to map the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_filtered = {\n",
    "    'N': 2,\n",
    "    'n': 2,\n",
    "    'F': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`RemapFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapFiltCB(Callback):\n",
    "    \"Lookup FILT value in dataframe using the lookup table.\"\n",
    "    def __init__(self,\n",
    "                 lut_filtered:dict=lut_filtered, # Dictionary mapping FILT codes to their corresponding names\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'FILT' in df.columns:\n",
    "                df['FILT'] = df['FILT'].map(lambda x: self.lut_filtered.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719feb2c",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapFiltCB(lut_filtered)])\n",
    "\n",
    "print(tfm()['seawater']['FILT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "## Add Sample Laboratory code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a02de8",
   "metadata": {},
   "source": [
    "Sample Laboratory code is currently stored in MARIS master DB but not encoded as NetCDF variable. Decision to include it in the NetCDF output is TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class AddSampleLabCodeCB(Callback):\n",
    "    \"Remap `KEY` column to `samplabcode` in each DataFrame.\"\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp])\n",
    "    \n",
    "    def _remap_sample_id(self, df:pd.DataFrame):\n",
    "        df['samplabcode'] = df['KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WKRIL2012003' 'WKRIL2012004' 'WKRIL2012005' ... 'WSSSM2021006'\n",
      " 'WSSSM2021007' 'WSSSM2021008']\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['samplabcode'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0fb210",
   "metadata": {},
   "source": [
    "## Add masurement note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05383c",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a look-up table `ANALYSIS_METHOD.csv` capturing the measurement method used as described by HELCOM. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG01</td>\n",
       "      <td>Gammaspectrometric analysis with Germanium det...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFFG02</td>\n",
       "      <td>Sr-90, a) Y-90 extraction method dried ash and...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFFG03</td>\n",
       "      <td>Pu238, Pu239241; Ashing and and drying the tra...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFFG04</td>\n",
       "      <td>Am-241 (not to in use any more)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLOR01</td>\n",
       "      <td>137Cs and 40K activity concentrations are dete...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   METHOD                                        DESCRIPTION  COUNTRY\n",
       "0  BFFG01  Gammaspectrometric analysis with Germanium det...        6\n",
       "1  BFFG02  Sr-90, a) Y-90 extraction method dried ash and...        6\n",
       "2  BFFG03  Pu238, Pu239241; Ashing and and drying the tra...        6\n",
       "3  BFFG04                    Am-241 (not to in use any more)        6\n",
       "4  CLOR01  137Cs and 40K activity concentrations are dete...       67"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9976e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_method = lambda: pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddMeasurementNoteCB(Callback):\n",
    "    \"Record measurement notes by adding a 'measurenote' column to DataFrames.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut:callable # Function that returns the lookup dictionary with `METHOD` as key and `DESCRIPTION` as value\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'METHOD' in df.columns:\n",
    "                df['measurementnote'] = df['METHOD'].map(lambda x: lut.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0\n",
      " 'Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.'\n",
      " 'Radiochem. meth of Sr90. Precipation with oxalate and separation of calcium, barium, radium and ytrium couting with low background anticoincidence beta counter. 1982-1994'\n",
      " 'For tritium liquid scintialtion counting, combined with electrolytic enrichment of analysed water samples, double distilled, before and after electrolysis in cells. Liquid Scintillation spectrometer LKB Wallac model 1410'\n",
      " 'Pretreatment drying (sediment, biota samples) and ashing (biota samples)or vaporization to 1000 ml (sea water samples), measured by gamma-spectrometry using HPGe detectors sediment, biota, sea water /Cs-137, Cs-134, K-40']\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddMeasurementNoteCB(lut_method),\n",
    "                            CompareDfsAndTfmCB(dfs)])\n",
    "\n",
    "tfm()\n",
    "print(tfm.dfs['seawater']['measurementnote'].unique()[:5])\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa59a",
   "metadata": {},
   "source": [
    "## Add station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa0216",
   "metadata": {},
   "source": [
    "*Not included in the NetCDF output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapStationIdCB(Callback):\n",
    "    \"Remap Station ID to MARIS format.\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap `STATION` to `station_id`.\"\n",
    "        for grp in tfm.dfs.keys(): \n",
    "            tfm.dfs[grp]['station'] = tfm.dfs[grp]['STATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb2604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            RemapStationIdCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "## Add slice position (top and bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615911d",
   "metadata": {},
   "source": [
    "*Not included in the NetCDF output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['sediment']['top'] = tfm.dfs['sediment']['UPPSLI']\n",
    "        tfm.dfs['sediment']['bottom'] = tfm.dfs['sediment']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    top  bottom\n",
      "0  15.0    20.0\n",
      "1  20.0    27.0\n",
      "2   0.0     2.0\n",
      "3   2.0     4.0\n",
      "4   4.0     6.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedSliceTopBottomCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['sediment'][['top','bottom']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "## Add dry to wet ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb091cc0",
   "metadata": {},
   "source": [
    "*`DW%` is not included in the NetCDF output currently.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735dd22",
   "metadata": {},
   "source": [
    "HELCOM Description:\n",
    "\n",
    "**Sediment:**\n",
    "1. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "2. VALUE_Bq/kg: Measured radioactivity concentration in Bq/kg dry wt. in scientific format(e.g. 123 = 1.23E+02, 0.076 = 7.6E-02)\n",
    "\n",
    "**Biota:**\n",
    "1. WEIGHT: Average weight (in g) of specimen in the sample\n",
    "2. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetRatio(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame):\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['dry_wet_ratio'] = df['DW%']\n",
    "        # Convert 'DW%' = 0% to NaN.\n",
    "        df.loc[df['dry_wet_ratio'] == 0, 'dry_wet_ratio'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21216     39817  15827\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "0    18.453\n",
      "1    18.453\n",
      "2    18.453\n",
      "3    18.453\n",
      "4    18.458\n",
      "Name: dry_wet_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetRatio(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota']['dry_wet_ratio'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b9aa0",
   "metadata": {},
   "source": [
    "## Standardize Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3541d",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd85aa4",
   "metadata": {},
   "source": [
    "Use decimal degree coordinates if available; otherwise, convert from degree-minute format to decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00410917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_coordinates = {\n",
    "    'seawater': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    },\n",
    "    'biota': {\n",
    "        'lon_d': 'LONGITUDE dddddd',\n",
    "        'lat_d': 'LATITUDE dddddd',\n",
    "        'lon_m': 'LONGITUDE ddmmmm',\n",
    "        'lat_m': 'LATITUDE ddmmmm'\n",
    "    },\n",
    "    'sediment': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def ddmmmm2dddddd(\n",
    "    ddmmmm:float # Coordinates in `ddmmmm` format where `dd` are degrees and `mmmm`` are minutes\n",
    "    ) -> float: # Coordinates in `dddddd`` format\n",
    "    # Split into degrees and minutes\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    # Convert minutes to decimal\n",
    "    mins = mins * 100\n",
    "    # Convert to 'dddddd' format\n",
    "    return round(int(degs) + (mins / 60), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class FormatCoordinates(Callback):\n",
    "    \"Format coordinates for MARIS. Converts coordinates from 'ddmmmm' to 'dddddd' format if needed.\"\n",
    "    def __init__(self, \n",
    "                 coi:dict, # Column names mapping for coordinates\n",
    "                 fn_convert_cor:Callable # Function to convert coordinates\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Apply formatting to coordinates in the DataFrame.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._format_coordinates(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _format_coordinates(self, \n",
    "                            df:pd.DataFrame, # DataFrame to modify\n",
    "                            grp: str # Group name to determine column names\n",
    "                            ):\n",
    "        \"Format coordinates in the DataFrame for a specific group.\"\n",
    "        lon_col_d = self.coi[grp]['lon_d']\n",
    "        lat_col_d = self.coi[grp]['lat_d']\n",
    "        lon_col_m = self.coi[grp]['lon_m']\n",
    "        lat_col_m = self.coi[grp]['lat_m']\n",
    "        \n",
    "        # Define condition where 'dddddd' format is not available or is zero\n",
    "        condition = (\n",
    "            (df[lon_col_d].isna() | (df[lon_col_d] == 0)) |\n",
    "            (df[lat_col_d].isna() | (df[lat_col_d] == 0))\n",
    "        )\n",
    "        \n",
    "        # Apply conversion function only to non-null and non-zero values\n",
    "        df['lon'] = np.where(\n",
    "            condition,\n",
    "            df[lon_col_m].apply(lambda x: self._safe_convert(x)),\n",
    "            df[lon_col_d]\n",
    "        )\n",
    "        \n",
    "        df['lat'] = np.where(\n",
    "            condition,\n",
    "            df[lat_col_m].apply(lambda x: self._safe_convert(x)),\n",
    "            df[lat_col_d]\n",
    "        )\n",
    "        \n",
    "        # Drop rows where coordinate columns contain NaN values\n",
    "        df.dropna(subset=['lat', 'lon'], inplace=True)\n",
    "\n",
    "    def _safe_convert(self, \n",
    "                      value:float # Coordinate value to convert\n",
    "                      ):\n",
    "        \"Convert coordinate value safely, handling NaN values.\"\n",
    "        if pd.isna(value):\n",
    "            return value  # Return NaN if value is NaN\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value  # Return original value if an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "15822  60.373333  18.395667\n",
      "15823  60.373333  18.395667\n",
      "15824  60.503333  18.366667\n",
      "15825  60.503333  18.366667\n",
      "15826  60.503333  18.366667\n",
      "\n",
      "[15827 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754289f1",
   "metadata": {},
   "source": [
    "### Sanitizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21208     39816  15827\n",
      "Number of dropped rows                                     8         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "15822  60.373333  18.395667\n",
      "15823  60.373333  18.395667\n",
      "15824  60.503333  18.366667\n",
      "15825  60.503333  18.366667\n",
      "15826  60.503333  18.366667\n",
      "\n",
      "[15827 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21114     39531  15798\n",
      "Number of dropped rows                                   102       286     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapBiotaSpeciesCB(lut_biota),\n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon),\n",
    "                            RemapSedimentCB(lut_sediments),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            AddMeasurementNoteCB(lut_method),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c7a2",
   "metadata": {},
   "source": [
    "For instance, to inspect dropped rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29baf65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>WRISO2001025</td>\n",
       "      <td>CS137</td>\n",
       "      <td>RISO02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>RISO</td>\n",
       "      <td>2001025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.500</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>WLEPA2002001</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.030</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>14.40</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>WLEPA2002002</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.574</td>\n",
       "      <td>20.956667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.57</td>\n",
       "      <td>11.95</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>WLEPA2002003</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.236</td>\n",
       "      <td>19.393333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>WLEPA2002004</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.205</td>\n",
       "      <td>20.341700</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.06</td>\n",
       "      <td>8.65</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "13439  WRISO2001025   CS137  RISO02           NaN          NaN       10.0   \n",
       "14017  WLEPA2002001   CS134  LEPA02             <          NaN        NaN   \n",
       "14020  WLEPA2002002   CS134  LEPA02             <          NaN        NaN   \n",
       "14023  WLEPA2002003   CS134  LEPA02             <          NaN        NaN   \n",
       "14026  WLEPA2002004   CS134  LEPA02             <          NaN        NaN   \n",
       "\n",
       "      DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "13439             NaN     26.0       RISO  2001025.0  ...             10.500   \n",
       "14017             NaN     93.0       LEPA  2002001.0  ...             21.030   \n",
       "14020             NaN     93.0       LEPA  2002004.0  ...             20.574   \n",
       "14023             NaN     93.0       LEPA  2002007.0  ...             19.236   \n",
       "14026             NaN     93.0       LEPA  2002010.0  ...             20.205   \n",
       "\n",
       "       LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "13439           10.833333    22.0    20.0  0.00    NaN     N            5.0   \n",
       "14017           21.050000    16.0     0.0  3.77  14.40     N            4.0   \n",
       "14020           20.956667    14.0     0.0  6.57  11.95     N            4.0   \n",
       "14023           19.393333    73.0     0.0  7.00   9.19     N            4.0   \n",
       "14026           20.341700    47.0     0.0  7.06   8.65     N            4.0   \n",
       "\n",
       "       HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \n",
       "13439              5.0              NaN  \n",
       "14017              9.0              NaN  \n",
       "14020              9.0              NaN  \n",
       "14023              9.0              NaN  \n",
       "14026              9.0              NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs_dropped['seawater'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f6685",
   "metadata": {},
   "source": [
    "## Rename columns of interest for NetCDF or Open Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af441203",
   "metadata": {},
   "source": [
    "> Column names are standardized to MARIS NetCDF format (i.e. PEP8 ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23653799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# TO BE REFACTORED\n",
    "def get_renaming_rules(encoding_type='netcdf'):\n",
    "    \"Define columns of interest (keys) and renaming rules (values).\"\n",
    "    vars = cdl_cfg()['vars']\n",
    "    if encoding_type == 'netcdf':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'lat': vars['defaults']['lat']['name'],\n",
    "                'lon': vars['defaults']['lon']['name'],\n",
    "                'time': vars['defaults']['time']['name'],\n",
    "                'NUCLIDE': 'nuclide',\n",
    "                'detection_limit': vars['suffixes']['detection_limit']['name'],\n",
    "                'unit': vars['suffixes']['unit']['name'],\n",
    "                'value': 'value',\n",
    "                'uncertainty': vars['suffixes']['uncertainty']['name'],\n",
    "                'counting_method': vars['suffixes']['counting_method']['name'],\n",
    "                'sampling_method': vars['suffixes']['sampling_method']['name'],\n",
    "                'preparation_method': vars['suffixes']['preparation_method']['name']\n",
    "            },\n",
    "            ('seawater',): {\n",
    "                # SEAWATER\n",
    "                'SALIN': vars['suffixes']['salinity']['name'],\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                #'FILT': vars['suffixes']['filtered']['name'], Need to fix\n",
    "                'TTEMP': vars['suffixes']['temperature']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "\n",
    "            },\n",
    "            ('biota',): {\n",
    "                # BIOTA\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                'species': vars['bio']['species']['name'],\n",
    "                'body_part': vars['bio']['body_part']['name'],\n",
    "                'bio_group': vars['bio']['bio_group']['name']\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sed_type': vars['sed']['sed_type']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif encoding_type == 'openrefine':\n",
    "        return OrderedDict({\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'samptype_id': 'samptype_id',\n",
    "                'lat': 'latitude',\n",
    "                'lon': 'longitude',\n",
    "                'station': 'station',\n",
    "                'begperiod': 'begperiod',\n",
    "                'samplabcode': 'samplabcode',\n",
    "                #'endperiod': 'endperiod',\n",
    "                'nuclide_id': 'nuclide_id',\n",
    "                'detection_limit': 'detection',\n",
    "                'unit': 'unit_id',\n",
    "                'value': 'activity',\n",
    "                'uncertainty': 'uncertaint',\n",
    "                #'vartype': 'vartype',\n",
    "                #'rangelow': 'rangelow',\n",
    "                #'rangeupp': 'rangeupp',\n",
    "                #'rl_detection': 'rl_detection',\n",
    "                #'ru_detection': 'ru_detection',\n",
    "                #'freq': 'freq',\n",
    "                'SDEPTH': 'sampdepth',\n",
    "                #'samparea': 'samparea',\n",
    "                'SALIN': 'salinity',\n",
    "                'TTEMP': 'temperatur',\n",
    "                'FILT': 'filtered',\n",
    "                #'oxygen': 'oxygen',\n",
    "                #'sampquality': 'sampquality',\n",
    "                #'station': 'station',\n",
    "                #'samplabcode': 'samplabcode',\n",
    "                #'profile': 'profile',\n",
    "                #'transect': 'transect',\n",
    "                #'IODE_QualityFlag': 'IODE_QualityFlag',\n",
    "                'TDEPTH': 'totdepth',\n",
    "                #'counmet_id': 'counting_method',\n",
    "                #'sampmet_id': 'sampling_method',\n",
    "                #'prepmet_id': 'preparation_method',\n",
    "                'sampnote': 'sampnote',\n",
    "                'measurenote': 'measurenote'\n",
    "            },\n",
    "            ('seawater',) : {\n",
    "                # SEAWATER\n",
    "                #'volume': 'volume',\n",
    "                #'filtpore': 'filtpore',\n",
    "                #'acid': 'acid'\n",
    "            },\n",
    "            ('biota',) : {\n",
    "                # BIOTA\n",
    "                'species': 'species_id',\n",
    "                'Taxonname': 'Taxonname',\n",
    "                'TaxonRepName': 'TaxonRepName',\n",
    "                #'Commonname': 'Commonname',\n",
    "                'Taxonrank': 'Taxonrank',\n",
    "                'TaxonDB': 'TaxonDB',\n",
    "                'TaxonDBID': 'TaxonDBID',\n",
    "                'TaxonDBURL': 'TaxonDBURL',\n",
    "                'body_part': 'bodypar_id',\n",
    "                #'drywt': 'drywt',\n",
    "                #'wetwt': 'wetwt',\n",
    "                'dry_wet_ratio': 'percentwt',\n",
    "                #'drymet_id': 'drymet_id'\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sed_type': 'sedtype_id',\n",
    "                #'sedtrap': 'sedtrap',\n",
    "                'top': 'sliceup',\n",
    "                'bottom': 'slicedown',\n",
    "                'SedRepName': 'SedRepName',\n",
    "                #'drywt': 'drywt',\n",
    "                #'wetwt': 'wetwt',\n",
    "                'dry_wet_ratio': 'percentwt',\n",
    "                #'drymet_id': 'drymet_id'\n",
    "                \n",
    "            }\n",
    "        })\n",
    "    else:\n",
    "        print(\"Invalid encoding_type provided. Please use 'netcdf' or 'openrefine'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SelectAndRenameColumnCB(Callback):\n",
    "    \"Select and rename columns in a DataFrame based on renaming rules for a specified encoding type.\"\n",
    "    def __init__(self, \n",
    "                 fn_renaming_rules:Callable, # A function that returns an OrderedDict of renaming rules \n",
    "                 encoding_type:str='netcdf', # The encoding type (`netcdf` or `openrefine`) to determine which renaming rules to use\n",
    "                 verbose:bool=False # Whether to print out renaming rules that were not applied\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        \"Apply column selection and renaming to DataFrames in the transformer, and identify unused rules.\"\n",
    "        try:\n",
    "            renaming_rules = self.fn_renaming_rules(self.encoding_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fetching renaming rules: {e}\")\n",
    "            return\n",
    "\n",
    "        for group in tfm.dfs.keys():\n",
    "            # Get relevant renaming rules for the current group\n",
    "            group_rules = self._get_group_rules(renaming_rules, group)\n",
    "\n",
    "            if not group_rules:\n",
    "                continue\n",
    "\n",
    "            # Apply renaming rules and track keys not found in the DataFrame\n",
    "            df = tfm.dfs[group]\n",
    "            df, not_found_keys = self._apply_renaming(df, group_rules)\n",
    "            tfm.dfs[group] = df\n",
    "            \n",
    "            # Print any renaming rules that were not used\n",
    "            if not_found_keys and self.verbose:\n",
    "                print(f\"\\nGroup '{group}' has the following renaming rules not applied:\")\n",
    "                for old_col in not_found_keys:\n",
    "                    print(f\"Key '{old_col}' from renaming rules was not found in the DataFrame.\")\n",
    "\n",
    "    def _get_group_rules(self, \n",
    "                         renaming_rules:OrderedDict, # Renaming rules\n",
    "                         group:str # Group name to filter rules\n",
    "                         ) -> OrderedDict: # Renaming rules applicable to the specified group\n",
    "        \"Retrieve and merge renaming rules for the specified group based on the encoding type.\"\n",
    "        relevant_rules = [rules for key, rules in renaming_rules.items() if group in key]\n",
    "        merged_rules = OrderedDict()\n",
    "        for rules in relevant_rules:\n",
    "            merged_rules.update(rules)\n",
    "        return merged_rules\n",
    "\n",
    "    def _apply_renaming(self, \n",
    "                        df:pd.DataFrame, # DataFrame to modify\n",
    "                        rename_rules:OrderedDict # Renaming rules\n",
    "                        ) -> tuple: # (Renamed and filtered df, Column names from renaming rules that were not found in the DataFrame)\n",
    "        \"\"\"\n",
    "        Select columns based on renaming rules and apply renaming, only for existing columns\n",
    "        while maintaining the order of the dictionary columns.\"\"\"\n",
    "        existing_columns = set(df.columns)\n",
    "        valid_rules = OrderedDict((old_col, new_col) for old_col, new_col in rename_rules.items() if old_col in existing_columns)\n",
    "\n",
    "        # Create a list to maintain the order of columns\n",
    "        columns_to_keep = [col for col in rename_rules.keys() if col in existing_columns]\n",
    "        columns_to_keep += [new_col for old_col, new_col in valid_rules.items() if new_col in df.columns]\n",
    "\n",
    "        df = df[list(OrderedDict.fromkeys(columns_to_keep))]\n",
    "\n",
    "        # Apply renaming\n",
    "        df.rename(columns=valid_rules, inplace=True)\n",
    "\n",
    "        # Determine which keys were not found\n",
    "        not_found_keys = set(rename_rules.keys()) - existing_columns\n",
    "        return df, not_found_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a8682-672f-4188-9091-821b727b4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater columns:\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       '_sal', 'smp_depth', '_temp', 'tot_depth'],\n",
      "      dtype='object')\n",
      "sediment columns:\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       'sed_type', 'tot_depth'],\n",
      "      dtype='object')\n",
      "biota columns:\n",
      "Index(['lat', 'lon', 'time', 'nuclide', '_dl', '_unit', 'value', '_unc',\n",
      "       'smp_depth', 'species', 'body_part', 'bio_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapBiotaSpeciesCB(lut_biota),\n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon),\n",
    "                            RemapSedimentCB(lut_sediments),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            AddMeasurementNoteCB(lut_method),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():\n",
    "    print(f'{grp} columns:')\n",
    "    print(tfm.dfs[grp].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7efe2d",
   "metadata": {},
   "source": [
    "## Reshape: long to wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59b263",
   "metadata": {},
   "source": [
    "Convert data from long to wide and rename columns to comply with NetCDF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater columns:\n",
      "Index(['lon', 'lat', 'tot_depth', 'time', 'smp_depth', 'ag110m_dl', 'am241_dl',\n",
      "       'ba140_dl', 'ce144_dl', 'cm242_dl',\n",
      "       ...\n",
      "       'pu240', 'ru103', 'ru106', 'sb125', 'sr89', 'sr90', 'tc99', 'u234',\n",
      "       'u238', 'zr95'],\n",
      "      dtype='object', length=175)\n",
      "sediment columns:\n",
      "Index(['sed_type', 'lon', 'lat', 'tot_depth', 'time', 'ac228_dl', 'ag110m_dl',\n",
      "       'am241_dl', 'ba140_dl', 'be7_dl',\n",
      "       ...\n",
      "       'sb124', 'sb125', 'sr90', 'th228', 'th232', 'th234', 'tl208', 'u235',\n",
      "       'zn65', 'zr95'],\n",
      "      dtype='object', length=177)\n",
      "biota columns:\n",
      "Index(['body_part', 'lon', 'bio_group', 'lat', 'species', 'time', 'smp_depth',\n",
      "       'ac228_dl', 'ag108m_dl', 'ag110m_dl',\n",
      "       ...\n",
      "       'sr89', 'sr90', 'tc99', 'te129m', 'th228', 'th232', 'tl208', 'u235',\n",
      "       'zn65', 'zr95'],\n",
      "      dtype='object', length=211)\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapBiotaSpeciesCB(lut_biota),\n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon),\n",
    "                            RemapSedimentCB(lut_sediments),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            AddMeasurementNoteCB(lut_method),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide()\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():\n",
    "    print(f'{grp} columns:')\n",
    "    print(tfm.dfs[grp].columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'.\",\n",
       " 'Encode time as `int` representing seconds since xxx',\n",
       " 'Remap `KEY` column to `samplabcode` in each DataFrame.',\n",
       " 'Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "tfm = Transformer(dfs, cbs=[AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapBiotaSpeciesCB(lut_biota),\n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon),\n",
    "                            RemapSedimentCB(lut_sediments),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            AddMeasurementNoteCB(lut_method),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide()\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2021-12-15T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Encode time as `int` representing seconds since xxx, Remap `KEY` column to `samplabcode` in each DataFrame., Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ebcce-b8c8-4963-8c1c-f32e820f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as `species_t` for instance.\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### <a name=\"encoding-netcdf\"></a>Encoding NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            AddNuclideIdColumnCB(col_value='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            SanitizeValue(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapBiotaSpeciesCB(lut_biota),\n",
    "                            RemapBiotaBodyPartCB(lut_tissues),\n",
    "                            RemapBiogroupCB(lut_biogroup),\n",
    "                            RemapTaxonInformationCB(lut_taxon),\n",
    "                            RemapSedimentCB(lut_sediments),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleLabCodeCB(),\n",
    "                            AddMeasurementNoteCB(lut_method),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide()\n",
    "                            ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "encode(fname_in, fname_out_nc, nc_tpl_path(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05beed7f",
   "metadata": {},
   "source": [
    "## Open Refine Pipeline (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f45970",
   "metadata": {},
   "source": [
    "### Rename columns for Open Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 'seawater' has the following renaming rules not applied:\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'sediment' has the following renaming rules not applied:\n",
      "Key 'FILT' from renaming rules was not found in the DataFrame.\n",
      "Key 'TTEMP' from renaming rules was not found in the DataFrame.\n",
      "Key 'SDEPTH' from renaming rules was not found in the DataFrame.\n",
      "Key 'SALIN' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'biota' has the following renaming rules not applied:\n",
      "Key 'TDEPTH' from renaming rules was not found in the DataFrame.\n",
      "Key 'FILT' from renaming rules was not found in the DataFrame.\n",
      "Key 'TTEMP' from renaming rules was not found in the DataFrame.\n",
      "Key 'SALIN' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampnote' from renaming rules was not found in the DataFrame.\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  21216     39817  15827\n",
      "Number of rows in tfm.dfs                              21114     39531  15798\n",
      "Number of dropped rows                                   102       286     29\n",
      "Number of rows in tfm.dfs + Number of dropped rows     21216     39817  15827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            AddSampleTypeIdColumnCB(),\n",
    "                            LowerStripRdnNameCB(col_src='NUCLIDE'),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),        \n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            NormalizeUncCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                            LookupFiltCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine', verbose=True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e68ad8",
   "metadata": {},
   "source": [
    "**Example of data included in dfs_dropped.**\n",
    "\n",
    "Main reasons for data to be dropped from dfs:\n",
    "- No activity value reported (e.g. VALUE_Bq/kg)\n",
    "- No time value reported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>SLREB1998021</td>\n",
       "      <td>SR90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11824</th>\n",
       "      <td>SLVDC1997023</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>SLVDC1997031</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>SLVDC1997040</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>SLVDC1998011</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>CO60</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39774</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>RA226</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39775</th>\n",
       "      <td>SSSSM2021030</td>\n",
       "      <td>RA223</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39777</th>\n",
       "      <td>SSSSM2021031</td>\n",
       "      <td>CS137</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.993243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39779</th>\n",
       "      <td>SSSSM2021031</td>\n",
       "      <td>CO60</td>\n",
       "      <td>SSSM43</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.993243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/06/22 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "11784  SLREB1998021    SR90       2           NaN          NaN        NaN   \n",
       "11824  SLVDC1997023   CS137       1           NaN          NaN        NaN   \n",
       "11832  SLVDC1997031   CS137       1           NaN          NaN        NaN   \n",
       "11841  SLVDC1997040   CS137       1           NaN          NaN        NaN   \n",
       "11849  SLVDC1998011   CS137       1           NaN          NaN        NaN   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "39769  SSSSM2021030    CO60  SSSM43             <          NaN        NaN   \n",
       "39774  SSSSM2021030   RA226  SSSM43             <          NaN        NaN   \n",
       "39775  SSSSM2021030   RA223  SSSM43             <          NaN        NaN   \n",
       "39777  SSSSM2021031   CS137  SSSM43             <          NaN        NaN   \n",
       "39779  SSSSM2021031    CO60  SSSM43             <          NaN        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "11784           NaN          NaN        NaN                NaN  ...    12.0   \n",
       "11824           NaN          NaN        NaN                NaN  ...    14.0   \n",
       "11832           NaN          NaN        NaN                NaN  ...    14.0   \n",
       "11841           NaN          NaN        NaN                NaN  ...    16.0   \n",
       "11849           NaN          NaN        NaN                NaN  ...    16.0   \n",
       "...             ...          ...        ...                ...  ...     ...   \n",
       "39769             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39774             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39775             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39777             <          0.0        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "39779             <          NaN        NaN  09/06/22 00:00:00  ...     2.0   \n",
       "\n",
       "          AREA  SEDI OXIC        DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  \\\n",
       "11784  0.02100  55.0    O        NaN   NaN           14.0            14.0   \n",
       "11824  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11832  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11841  0.02100  55.0    O        NaN   NaN            9.0             9.0   \n",
       "11849  0.02100  55.0    O        NaN   NaN           14.0            14.0   \n",
       "...        ...   ...  ...        ...   ...            ...             ...   \n",
       "39769  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39774  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39775  0.01608   NaN  NaN  28.200000  15.0           12.0            12.0   \n",
       "39777  0.01608   NaN  NaN  31.993243   NaN           13.0            13.0   \n",
       "39779  0.01608   NaN  NaN  31.993243   NaN           13.0            13.0   \n",
       "\n",
       "       SUM_LINK    DATE_OF_ENTRY_y  \n",
       "11784         a                NaN  \n",
       "11824         a                NaN  \n",
       "11832         a                NaN  \n",
       "11841         a                NaN  \n",
       "11849         a                NaN  \n",
       "...         ...                ...  \n",
       "39769       NaN  09/06/22 00:00:00  \n",
       "39774       NaN  09/06/22 00:00:00  \n",
       "39775       NaN  09/06/22 00:00:00  \n",
       "39777       NaN  09/06/22 00:00:00  \n",
       "39779       NaN  09/06/22 00:00:00  \n",
       "\n",
       "[286 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='sediment'\n",
    "#grp='seawater'\n",
    "#grp='biota'\n",
    "\n",
    "tfm.dfs_dropped[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6241c",
   "metadata": {},
   "source": [
    "## Open Refine encoder (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd81eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def encode_or(fname_in, fname_out_csv, ref_id, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                                AddSampleTypeIdColumnCB(),\n",
    "                                LowerStripRdnNameCB(col_src='NUCLIDE'),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),        \n",
    "                                SanitizeValue(coi_val),                       \n",
    "                                NormalizeUncCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupTaxonInformationCB(partial(get_taxon_info_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),    \n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RecordMeasurementNoteCB(get_helcom_method_desc),\n",
    "                                LookupFiltCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='openrefine'),\n",
    "                                CompareDfsAndTfmCB(dfs)\n",
    "                                ])\n",
    "    tfm()\n",
    "\n",
    "    encoder = OpenRefineCsvEncoder(tfm.dfs, \n",
    "                                    dest_fname=fname_out_csv, \n",
    "                                    ref_id = ref_id,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "encode_or(fname_in, fname_out_csv, ref_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc9e8",
   "metadata": {},
   "source": [
    "###  Open Refine Variables not included in Helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca95cc",
   "metadata": {},
   "source": [
    "| Field name      | Full name                | HELCOM     |\n",
    "|-----------------|--------------------------|------------|\n",
    "| sampquality     | Sample quality           | N          |\n",
    "| lab_id          | Laboratory ID            | N          |\n",
    "| profile_id      | Profile ID               | N          |\n",
    "| transect_id     | Transect ID              | N          |\n",
    "| endperiod       | End period               | N          |\n",
    "| vartype         | Variable type            | N          |\n",
    "| freq            | Frequency                | N          |\n",
    "| rl_detection    | Range low detection      | N          |\n",
    "| rangelow        | Range low                | N          |\n",
    "| rangeupp        | Range upper              | N          |\n",
    "| Commonname      | Common name              | N          |\n",
    "| volume          | Volume                   | N          |\n",
    "| filtpore        | Filter pore              | N          |\n",
    "| acid            | Acidified                | N          |\n",
    "| oxygen          | Oxygen                   | N          |\n",
    "| samparea        | Sample area              | N          |\n",
    "| drywt           | Dry weight               | N          |\n",
    "| wetwt           | Wet weight               | N          |\n",
    "| sampmet_id      | Sampling method ID       | N          |\n",
    "| drymet_id       | Drying method ID         | N          |\n",
    "| prepmet_id      | Preparation method ID    | N          |\n",
    "| counmet_id      | Counting method ID       | N          |\n",
    "| refnote         | Reference note           | N          |\n",
    "| sampnote        | Sample note              | N          |\n",
    "| gfe             | Good for export          | ?          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d9df4",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "\n",
    "- Should we use a single encoder for both NetCDF and OpenRefine? If so, should we have a single encode function that accepts a variable 'encoding_type'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a206afa",
   "metadata": {},
   "source": [
    "TODO: Include FILT for NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44bf97",
   "metadata": {},
   "source": [
    "TODO: Check sediment 'DW%' data that is less than 1%. Is this realistic? Check the 'DW%' data that is 0%. Run below before SelectAndRenameColumnCB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002712da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seawater':                 KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       " 0      WKRIL2012003   cs137    NaN           NaN          5.3  32.000000   \n",
       " 1      WKRIL2012004   cs137    NaN           NaN         19.9  20.000000   \n",
       " 2      WKRIL2012005   cs137    NaN           NaN         25.5  20.000000   \n",
       " 3      WKRIL2012006   cs137    NaN           NaN         17.0  29.000000   \n",
       " 4      WKRIL2012007   cs137    NaN           NaN         22.2  18.000000   \n",
       " ...             ...     ...    ...           ...          ...        ...   \n",
       " 21211  WSSSM2021005      h3  SSM45           NaN       1030.0  93.203883   \n",
       " 21212  WSSSM2021006      h3  SSM45           NaN       2240.0  43.303571   \n",
       " 21213  WSSSM2021007      h3  SSM45           NaN       2060.0  47.087379   \n",
       " 21214  WSSSM2021008      h3  SSM45           NaN       2300.0  43.478261   \n",
       " 21215  WSSSM2021004      h3  SSM45             <          NaN        NaN   \n",
       " \n",
       "          DATE_OF_ENTRY_x  COUNTRY LABORATORY   SEQUENCE  ...  \\\n",
       " 0      08/20/14 00:00:00     90.0       KRIL  2012003.0  ...   \n",
       " 1      08/20/14 00:00:00     90.0       KRIL  2012004.0  ...   \n",
       " 2      08/20/14 00:00:00     90.0       KRIL  2012005.0  ...   \n",
       " 3      08/20/14 00:00:00     90.0       KRIL  2012006.0  ...   \n",
       " 4      08/20/14 00:00:00     90.0       KRIL  2012007.0  ...   \n",
       " ...                  ...      ...        ...        ...  ...   \n",
       " 21211  09/06/22 00:00:00     77.0       SSSM   202105.0  ...   \n",
       " 21212  09/06/22 00:00:00     77.0       SSSM   202106.0  ...   \n",
       " 21213  09/06/22 00:00:00     77.0       SSSM   202107.0  ...   \n",
       " 21214  09/06/22 00:00:00     77.0       SSSM   202108.0  ...   \n",
       " 21215  09/06/22 00:00:00     77.0       SSSM   202104.0  ...   \n",
       " \n",
       "       LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
       " 0                29.2000             29.3333     NaN     0.0   NaN    NaN   \n",
       " 1                29.2000             29.3333     NaN    29.0   NaN    NaN   \n",
       " 2                23.0900             23.1500     NaN     0.0   NaN    NaN   \n",
       " 3                27.5900             27.9833     NaN     0.0   NaN    NaN   \n",
       " 4                27.5900             27.9833     NaN    39.0   NaN    NaN   \n",
       " ...                  ...                 ...     ...     ...   ...    ...   \n",
       " 21211            18.2143             18.3572     NaN     1.0   NaN    NaN   \n",
       " 21212            17.0000             17.0000     NaN     1.0   NaN    NaN   \n",
       " 21213            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       " 21214            11.5671             11.9452     NaN     1.0   NaN    NaN   \n",
       " 21215            11.1470             11.2450     NaN     1.0   NaN    NaN   \n",
       " \n",
       "        FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       " 0       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 1       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 2       NaN           11.0              3.0  08/20/14 00:00:00  \n",
       " 3       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " 4       NaN           11.0             11.0  08/20/14 00:00:00  \n",
       " ...     ...            ...              ...                ...  \n",
       " 21211     N            1.0              8.0  09/06/22 00:00:00  \n",
       " 21212     N           10.0             10.0  09/06/22 00:00:00  \n",
       " 21213     N           12.0             12.0  09/06/22 00:00:00  \n",
       " 21214     N           12.0             12.0  09/06/22 00:00:00  \n",
       " 21215     N           15.0             18.0  09/06/22 00:00:00  \n",
       " \n",
       " [21216 rows x 27 columns],\n",
       " 'sediment':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       " 0      SKRIL2012048   ra226     NaN           NaN         35.0      26.00   \n",
       " 1      SKRIL2012049   ra226     NaN           NaN         36.0      22.00   \n",
       " 2      SKRIL2012050   ra226     NaN           NaN         38.0      24.00   \n",
       " 3      SKRIL2012051   ra226     NaN           NaN         36.0      25.00   \n",
       " 4      SKRIL2012052   ra226     NaN           NaN         30.0      23.00   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 39812  SSSSM2020029   ac228  SSSM43           NaN         37.5       5.00   \n",
       " 39813  SSSSM2020030     k40  SSSM43           NaN        526.0       1.72   \n",
       " 39814  SSSSM2020030   cs137  SSSM43           NaN         17.2       2.21   \n",
       " 39815  SSSSM2020031     k40  SSSM43           NaN       1000.0       1.80   \n",
       " 39816  SSSSM2020031   cs137  SSSM43           NaN         64.0       1.20   \n",
       " \n",
       "       < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       " 0               NaN          NaN        NaN  08/20/14 00:00:00  ...    20.0   \n",
       " 1               NaN          NaN        NaN  08/20/14 00:00:00  ...    27.0   \n",
       " 2               NaN          NaN        NaN  08/20/14 00:00:00  ...     2.0   \n",
       " 3               NaN          NaN        NaN  08/20/14 00:00:00  ...     4.0   \n",
       " 4               NaN          NaN        NaN  08/20/14 00:00:00  ...     6.0   \n",
       " ...             ...          ...        ...                ...  ...     ...   \n",
       " 39812           NaN        255.0       28.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39813           NaN       5690.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39814           NaN        186.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39815           NaN      16000.0        2.0  04/22/22 00:00:00  ...     2.0   \n",
       " 39816           NaN       1020.0        1.0  04/22/22 00:00:00  ...     2.0   \n",
       " \n",
       "         AREA  SEDI OXIC    DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       " 0      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 1      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 2      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 3      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " 4      0.006   NaN  NaN    NaN   NaN           11.0            11.0       NaN   \n",
       " ...      ...   ...  ...    ...   ...            ...             ...       ...   \n",
       " 39812  0.019   0.0    O  28.73  14.0           13.0            13.0       NaN   \n",
       " 39813  0.019   0.0    O  32.03   NaN           12.0            12.0       NaN   \n",
       " 39814  0.019   0.0    O  32.03   NaN           12.0            12.0       NaN   \n",
       " 39815  0.017   0.0    O  48.77   NaN            1.0             8.0       NaN   \n",
       " 39816  0.017   0.0    O  48.77   NaN            1.0             8.0       NaN   \n",
       " \n",
       "          DATE_OF_ENTRY_y  \n",
       " 0      08/20/14 00:00:00  \n",
       " 1      08/20/14 00:00:00  \n",
       " 2      08/20/14 00:00:00  \n",
       " 3      08/20/14 00:00:00  \n",
       " 4      08/20/14 00:00:00  \n",
       " ...                  ...  \n",
       " 39812  04/22/22 00:00:00  \n",
       " 39813  04/22/22 00:00:00  \n",
       " 39814  04/22/22 00:00:00  \n",
       " 39815  04/22/22 00:00:00  \n",
       " 39816  04/22/22 00:00:00  \n",
       " \n",
       " [39817 rows x 35 columns],\n",
       " 'biota':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       " 0      BVTIG2012041   cs134  VTIG01             <     0.010140     W     NaN   \n",
       " 1      BVTIG2012041     k40  VTIG01                 135.300000     W    3.57   \n",
       " 2      BVTIG2012041    co60  VTIG01             <     0.013980     W     NaN   \n",
       " 3      BVTIG2012041   cs137  VTIG01                   4.338000     W    3.48   \n",
       " 4      BVTIG2012040   cs134  VTIG01             <     0.009614     W     NaN   \n",
       " ...             ...     ...     ...           ...          ...   ...     ...   \n",
       " 15822  BSSSM2020016     k40  SSSM42           NaN    65.000000     D   10.20   \n",
       " 15823  BSSSM2020016   cs137  SSSM42           NaN     4.500000     D    6.20   \n",
       " 15824  BSSSM2020017     be7  SSSM42           NaN    94.000000     D    3.40   \n",
       " 15825  BSSSM2020017     k40  SSSM42           NaN  1100.000000     D    1.60   \n",
       " 15826  BSSSM2020017   cs137  SSSM42           NaN    13.000000     D    2.50   \n",
       " \n",
       "        NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE     NO  \\\n",
       " 0         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 1         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 2         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 3         NaN  02/27/14 00:00:00      6.0  ...         F       5   16.0   \n",
       " 4         NaN  02/27/14 00:00:00      6.0  ...         F       5   17.0   \n",
       " ...       ...                ...      ...  ...       ...     ...    ...   \n",
       " 15822     NaN  04/22/22 00:00:00     77.0  ...         B      41  319.0   \n",
       " 15823     NaN  04/22/22 00:00:00     77.0  ...         B      41  319.0   \n",
       " 15824     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " 15825     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " 15826     NaN  04/22/22 00:00:00     77.0  ...         P      51    NaN   \n",
       " \n",
       "        LENGTH  WEIGHT     DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
       " 0        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 1        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 2        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 3        45.7   948.0  18.453  92.9            2.0               16   \n",
       " 4        45.9   964.0  18.458  92.9            2.0               16   \n",
       " ...       ...     ...     ...   ...            ...              ...   \n",
       " 15822     NaN     NaN  41.000   0.0            1.0                8   \n",
       " 15823     NaN     NaN  41.000   0.0            1.0                8   \n",
       " 15824     NaN     NaN  21.000   0.0            1.0                8   \n",
       " 15825     NaN     NaN  21.000   0.0            1.0                8   \n",
       " 15826     NaN     NaN  21.000   0.0            1.0                8   \n",
       " \n",
       "          DATE_OF_ENTRY_y  \n",
       " 0      02/27/14 00:00:00  \n",
       " 1      02/27/14 00:00:00  \n",
       " 2      02/27/14 00:00:00  \n",
       " 3      02/27/14 00:00:00  \n",
       " 4      02/27/14 00:00:00  \n",
       " ...                  ...  \n",
       " 15822  04/22/22 00:00:00  \n",
       " 15823  04/22/22 00:00:00  \n",
       " 15824  04/22/22 00:00:00  \n",
       " 15825  04/22/22 00:00:00  \n",
       " 15826  04/22/22 00:00:00  \n",
       " \n",
       " [15827 rows x 33 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(col_src='NUCLIDE'),\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de551778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30938</th>\n",
       "      <td>SLVEA2010001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.886</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30939</th>\n",
       "      <td>SLVEA2010002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.58</td>\n",
       "      <td>1.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.092</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30940</th>\n",
       "      <td>SLVEA2010003</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.69</td>\n",
       "      <td>1.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.390</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30941</th>\n",
       "      <td>SLVEA2010004</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.699</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30942</th>\n",
       "      <td>SLVEA2010005</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.894</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30943</th>\n",
       "      <td>SLVEA2010006</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.02</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.523</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30944</th>\n",
       "      <td>SLVEA2010007</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.946</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30945</th>\n",
       "      <td>SLVEA2010008</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.07</td>\n",
       "      <td>2.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.162</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30946</th>\n",
       "      <td>SLVEA2010009</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.70</td>\n",
       "      <td>3.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.444</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30947</th>\n",
       "      <td>SLVEA2010010</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.63</td>\n",
       "      <td>3.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.220</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30948</th>\n",
       "      <td>SLVEA2010011</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>12.24</td>\n",
       "      <td>3.88</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>5.035</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30949</th>\n",
       "      <td>SLVEA2010012</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.330</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30950</th>\n",
       "      <td>SLVEA2010013</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331.61</td>\n",
       "      <td>1.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.566</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30951</th>\n",
       "      <td>SLVEA2010014</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.06</td>\n",
       "      <td>1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.516</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30952</th>\n",
       "      <td>SLVEA2010015</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367.11</td>\n",
       "      <td>1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.434</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30953</th>\n",
       "      <td>SLVEA2010016</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.97</td>\n",
       "      <td>1.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.348</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30954</th>\n",
       "      <td>SLVEA2010017</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356.30</td>\n",
       "      <td>1.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.447</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30955</th>\n",
       "      <td>SLVEA2010018</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.75</td>\n",
       "      <td>1.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.765</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30956</th>\n",
       "      <td>SLVEA2010019</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.64</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.580</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30957</th>\n",
       "      <td>SLVEA2010020</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.058</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30958</th>\n",
       "      <td>SLVEA2010021</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.65</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.680</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30959</th>\n",
       "      <td>SLVEA2010022</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.36</td>\n",
       "      <td>2.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.153</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30960</th>\n",
       "      <td>SLVEA2010023</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.12</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.873</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30961</th>\n",
       "      <td>SLVEA2010024</td>\n",
       "      <td>cs137</td>\n",
       "      <td>LVEA01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.864</td>\n",
       "      <td>41179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/11 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "30938  SLVEA2010001   cs137  LVEA01           NaN       334.25       1.57   \n",
       "30939  SLVEA2010002   cs137  LVEA01           NaN       343.58       1.49   \n",
       "30940  SLVEA2010003   cs137  LVEA01           NaN       334.69       1.56   \n",
       "30941  SLVEA2010004   cs137  LVEA01           NaN       348.50       1.56   \n",
       "30942  SLVEA2010005   cs137  LVEA01           NaN       258.67       1.73   \n",
       "30943  SLVEA2010006   cs137  LVEA01           NaN       182.02       2.05   \n",
       "30944  SLVEA2010007   cs137  LVEA01           NaN       116.34       2.79   \n",
       "30945  SLVEA2010008   cs137  LVEA01           NaN        94.07       2.61   \n",
       "30946  SLVEA2010009   cs137  LVEA01           NaN        69.70       3.12   \n",
       "30947  SLVEA2010010   cs137  LVEA01           NaN        59.63       3.40   \n",
       "30948  SLVEA2010011   cs137  LVEA01             <        12.24       3.88   \n",
       "30949  SLVEA2010012   cs137  LVEA01             <         0.83        NaN   \n",
       "30950  SLVEA2010013   cs137  LVEA01           NaN       331.61       1.40   \n",
       "30951  SLVEA2010014   cs137  LVEA01           NaN       352.06       1.33   \n",
       "30952  SLVEA2010015   cs137  LVEA01           NaN       367.11       1.36   \n",
       "30953  SLVEA2010016   cs137  LVEA01           NaN       328.97       1.42   \n",
       "30954  SLVEA2010017   cs137  LVEA01           NaN       356.30       1.37   \n",
       "30955  SLVEA2010018   cs137  LVEA01           NaN       314.75       1.42   \n",
       "30956  SLVEA2010019   cs137  LVEA01           NaN       261.64       1.52   \n",
       "30957  SLVEA2010020   cs137  LVEA01           NaN       181.00       1.76   \n",
       "30958  SLVEA2010021   cs137  LVEA01           NaN       143.65       2.02   \n",
       "30959  SLVEA2010022   cs137  LVEA01           NaN       109.36       2.15   \n",
       "30960  SLVEA2010023   cs137  LVEA01           NaN        94.12       1.39   \n",
       "30961  SLVEA2010024   cs137  LVEA01           NaN        96.63       1.35   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "30938           NaN      131.886    41179.0             NaN  ...     2.0   \n",
       "30939           NaN      132.092    41179.0             NaN  ...     4.0   \n",
       "30940           NaN      134.390    41179.0             NaN  ...     6.0   \n",
       "30941           NaN      136.699    41179.0             NaN  ...     8.0   \n",
       "30942           NaN      104.894    41179.0             NaN  ...    10.0   \n",
       "30943           NaN       77.523    41179.0             NaN  ...    12.0   \n",
       "30944           NaN       46.946    41179.0             NaN  ...    14.0   \n",
       "30945           NaN       38.162    41179.0             NaN  ...    16.0   \n",
       "30946           NaN       27.444    41179.0             NaN  ...    18.0   \n",
       "30947           NaN       24.220    41179.0             NaN  ...    20.0   \n",
       "30948             <        5.035    41179.0             NaN  ...    22.0   \n",
       "30949             <        0.330    41179.0             NaN  ...    24.0   \n",
       "30950           NaN      125.566    41179.0             NaN  ...     2.0   \n",
       "30951           NaN      144.516    41179.0             NaN  ...     4.0   \n",
       "30952           NaN      139.434    41179.0             NaN  ...     6.0   \n",
       "30953           NaN      124.348    41179.0             NaN  ...     8.0   \n",
       "30954           NaN      135.447    41179.0             NaN  ...    10.0   \n",
       "30955           NaN      118.765    41179.0             NaN  ...    12.0   \n",
       "30956           NaN      104.580    41179.0             NaN  ...    14.0   \n",
       "30957           NaN       74.058    41179.0             NaN  ...    16.0   \n",
       "30958           NaN       57.680    41179.0             NaN  ...    18.0   \n",
       "30959           NaN       42.153    41179.0             NaN  ...    20.0   \n",
       "30960           NaN       35.873    41179.0             NaN  ...    22.0   \n",
       "30961           NaN       38.864    41179.0             NaN  ...    24.0   \n",
       "\n",
       "         AREA  SEDI OXIC    DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  \\\n",
       "30938  0.0151   5.0    O  0.115   0.9           14.0            14.0   \n",
       "30939  0.0151   5.0    A  0.159   0.8           14.0            14.0   \n",
       "30940  0.0151   5.0    A  0.189   0.8           14.0            14.0   \n",
       "30941  0.0151   5.0    A  0.194   0.8           14.0            14.0   \n",
       "30942  0.0151   5.0    A  0.195   0.8           14.0            14.0   \n",
       "30943  0.0151   5.0    A  0.221   0.8           14.0            14.0   \n",
       "30944  0.0151   5.0    A  0.238   0.8           14.0            14.0   \n",
       "30945  0.0151   5.0    A  0.234   0.8           14.0            14.0   \n",
       "30946  0.0151   5.0    A  0.242   0.8           14.0            14.0   \n",
       "30947  0.0151   5.0    A  0.257   0.7           14.0            14.0   \n",
       "30948  0.0151   5.0    A  0.264   0.7           14.0            14.0   \n",
       "30949  0.0151   5.0    A  0.244   0.8           14.0            14.0   \n",
       "30950  0.0151   5.0    O  0.115   0.9           14.0            14.0   \n",
       "30951  0.0151   5.0    A  0.164   0.8           14.0            14.0   \n",
       "30952  0.0151   5.0    A  0.191   0.8           14.0            14.0   \n",
       "30953  0.0151   5.0    A  0.188   0.8           14.0            14.0   \n",
       "30954  0.0151   5.0    A  0.179   0.8           14.0            14.0   \n",
       "30955  0.0151   5.0    A  0.186   0.8           14.0            14.0   \n",
       "30956  0.0151   5.0    A  0.194   0.8           14.0            14.0   \n",
       "30957  0.0151   5.0    A  0.209   0.8           14.0            14.0   \n",
       "30958  0.0151   5.0    A  0.214   0.8           14.0            14.0   \n",
       "30959  0.0151   5.0    A  0.218   0.8           14.0            14.0   \n",
       "30960  0.0151   5.0    A  0.212   0.8           14.0            14.0   \n",
       "30961  0.0151   5.0    A  0.217   0.8           14.0            14.0   \n",
       "\n",
       "       SUM_LINK    DATE_OF_ENTRY_y  \n",
       "30938       NaN  11/11/11 00:00:00  \n",
       "30939       NaN  11/11/11 00:00:00  \n",
       "30940       NaN  11/11/11 00:00:00  \n",
       "30941       NaN  11/11/11 00:00:00  \n",
       "30942       NaN  11/11/11 00:00:00  \n",
       "30943       NaN  11/11/11 00:00:00  \n",
       "30944       NaN  11/11/11 00:00:00  \n",
       "30945       NaN  11/11/11 00:00:00  \n",
       "30946       NaN  11/11/11 00:00:00  \n",
       "30947       NaN  11/11/11 00:00:00  \n",
       "30948       NaN  11/11/11 00:00:00  \n",
       "30949       NaN  11/11/11 00:00:00  \n",
       "30950       NaN  11/11/11 00:00:00  \n",
       "30951       NaN  11/11/11 00:00:00  \n",
       "30952       NaN  11/11/11 00:00:00  \n",
       "30953       NaN  11/11/11 00:00:00  \n",
       "30954       NaN  11/11/11 00:00:00  \n",
       "30955       NaN  11/11/11 00:00:00  \n",
       "30956       NaN  11/11/11 00:00:00  \n",
       "30957       NaN  11/11/11 00:00:00  \n",
       "30958       NaN  11/11/11 00:00:00  \n",
       "30959       NaN  11/11/11 00:00:00  \n",
       "30960       NaN  11/11/11 00:00:00  \n",
       "30961       NaN  11/11/11 00:00:00  \n",
       "\n",
       "[24 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] < 1) & (tfm.dfs[grp]['DW%'] > 0.001) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe533d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9824</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9825</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.78</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9828</th>\n",
       "      <td>SERPC1997003</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15257</th>\n",
       "      <td>SKRIL1999062</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15258</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>k40</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra226</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra228</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "9824   SERPC1997001   cs134     NaN           NaN         3.80       20.0   \n",
       "9825   SERPC1997001   cs137     NaN           NaN       389.00        4.0   \n",
       "9826   SERPC1997002   cs134     NaN           NaN         4.78       13.0   \n",
       "9827   SERPC1997002   cs137     NaN           NaN       420.00        4.0   \n",
       "9828   SERPC1997003   cs134     NaN           NaN         3.12       17.0   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "15257  SKRIL1999062   th228       1           NaN        68.00        NaN   \n",
       "15258  SKRIL1999063     k40       1           NaN      1210.00        NaN   \n",
       "15259  SKRIL1999063   ra226  KRIL01           NaN        56.50        NaN   \n",
       "15260  SKRIL1999063   ra228  KRIL01           NaN        72.20        NaN   \n",
       "15261  SKRIL1999063   th228       1           NaN        74.20        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "9824            NaN         5.75        NaN             NaN  ...     2.0   \n",
       "9825            NaN       589.00        NaN             NaN  ...     2.0   \n",
       "9826            NaN        12.00        NaN             NaN  ...     4.0   \n",
       "9827            NaN      1060.00        NaN             NaN  ...     4.0   \n",
       "9828            NaN        12.00        NaN             NaN  ...     6.0   \n",
       "...             ...          ...        ...             ...  ...     ...   \n",
       "15257           NaN          NaN        NaN             NaN  ...    15.0   \n",
       "15258           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15259           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15260           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "15261           NaN          NaN        NaN             NaN  ...    21.5   \n",
       "\n",
       "        AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "9824   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9825   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9826   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9827   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "9828   0.008   5.0    A  0.0   0.0           11.0            11.0         a   \n",
       "...      ...   ...  ...  ...   ...            ...             ...       ...   \n",
       "15257  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15258  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15259  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15260  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "15261  0.006   0.0    O  0.0   0.0           11.0            11.0         a   \n",
       "\n",
       "      DATE_OF_ENTRY_y  \n",
       "9824              NaN  \n",
       "9825              NaN  \n",
       "9826              NaN  \n",
       "9827              NaN  \n",
       "9828              NaN  \n",
       "...               ...  \n",
       "15257             NaN  \n",
       "15258             NaN  \n",
       "15259             NaN  \n",
       "15260             NaN  \n",
       "15261             NaN  \n",
       "\n",
       "[302 rows x 35 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357222d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>BIOTATYPE</th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>NO</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.60</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>W</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>W</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "5971  BERPC1997002     k40    NaN           NaN       116.00     W     3.0   \n",
       "5972  BERPC1997002   cs137    NaN           NaN        12.60     W     4.0   \n",
       "5973  BERPC1997002   cs134    NaN           NaN         0.14     W    18.0   \n",
       "5974  BERPC1997001     k40    NaN           NaN       116.00     W     4.0   \n",
       "5975  BERPC1997001   cs137    NaN           NaN        12.00     W     4.0   \n",
       "5976  BERPC1997001   cs134    NaN           NaN         0.21     W    24.0   \n",
       "\n",
       "      NUMBER DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE   NO  LENGTH  \\\n",
       "5971     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5972     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5973     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5974     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5975     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "5976     NaN             NaN     91.0  ...         F       5  0.0     0.0   \n",
       "\n",
       "      WEIGHT  DW% LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN  DATE_OF_ENTRY_y  \n",
       "5971     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5972     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5973     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5974     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5975     0.0  0.0  0.0           11.0               11              NaN  \n",
       "5976     0.0  0.0  0.0           11.0               11              NaN  \n",
       "\n",
       "[6 rows x 33 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='biota'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

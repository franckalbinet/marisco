{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "> Data pipeline (handler) to convert HELCOM data ([source](https://helcom.fi/about-us)) to `NetCDF` format or `Open Refine` format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5eece",
   "metadata": {},
   "source": [
    "<!-- ## HELCOM MORS Environment database -->\n",
    "\n",
    "[Helcom MORS data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "Example steps:\n",
    "1. Download data (e.g. https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24). \n",
    "2. Install mdbtools via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In VS code terminal, navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip MORS_ENVIRONMENT.zip \n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run preprocess.sh to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ````\n",
    "7. Conetens of 'preprocess.sh' script.\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c4c6b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd # Python package that provides fast, flexible, and expressive data structures.\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Python Progress Bar Library\n",
    "from functools import partial # Function which Return a new partial object which when called will behave like func called with the positional arguments args and keyword arguments keywords\n",
    "import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.\n",
    "from pathlib import Path # This module offers classes representing filesystem paths\n",
    "from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Optional, Tuple\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, match_maris_lut, Match)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, SanitizeLonLatCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (base_path, nc_tpl_path, cfg, cache_path, cdl_cfg, Enums, lut_path,\n",
    "                             species_lut_path, sediments_lut_path, bodyparts_lut_path, \n",
    "                             detection_limit_lut_path, filtered_lut_path, area_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder\n",
    "from collections.abc import Callable\n",
    "from math import modf\n",
    "import warnings\n",
    "from marisco.netcdf_to_csv import (LookupTimeFromEncodedTime, GetSampleTypeCB,\n",
    "                                   LookupNuclideByIdCB, ConvertLonLatCB, LookupUnitByIdCB,\n",
    "                                   LookupValueTypeByIdCB, LookupSpeciesByIdCB, \n",
    "                                   LookupBodypartByIdCB, LookupSedimentTypeByIdCB)                                  \n",
    "from marisco.serializers import OpenRefineCsvEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "cc705a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed39cdd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a65e9b",
   "metadata": {},
   "source": [
    "##  MARIS NetCDF \n",
    "When MARISCO is installed, it uses `cdl.toml` to create the `maris-template.nc`, which acts as a standardized template for MARIS NetCDF files. The `cdl.toml` is a configuration file listing all the variables allowed in the NetCDF4 files. The contents of the cdl.toml can be retrieved with the function `cdl_cfg()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907924b",
   "metadata": {},
   "source": [
    "Retrieving the keys of the `cdl_cfg()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "50406959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['defaults', 'bio', 'sed', 'suffixes'])\n"
     ]
    }
   ],
   "source": [
    "print (cdl_cfg()['vars'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32b0fd",
   "metadata": {},
   "source": [
    "Printing the contents of all keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "535b6a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lon', 'lat', 'smp_depth', 'tot_depth', 'time', 'area'])\n",
      "dict_keys(['bio_group', 'species', 'body_part'])\n",
      "dict_keys(['sed_type'])\n",
      "dict_keys(['uncertainty', 'detection_limit', 'volume', 'salinity', 'temperature', 'filtered', 'counting_method', 'sampling_method', 'preparation_method', 'unit'])\n"
     ]
    }
   ],
   "source": [
    "print (cdl_cfg()['vars']['defaults'].keys())\n",
    "print (cdl_cfg()['vars']['bio'].keys())\n",
    "print (cdl_cfg()['vars']['sed'].keys())\n",
    "print (cdl_cfg()['vars']['suffixes'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5519f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78f26f",
   "metadata": {},
   "source": [
    "## MARIS Open Refine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c37687",
   "metadata": {},
   "source": [
    "Currently, updates to the MARIS database are facilitated through a standardized CSV file using Open Refine. Description of the variables included in this CSV file are provided at [Maris](https://maris.iaea.org/help/1132).\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe953fc7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f31d33",
   "metadata": {},
   "source": [
    "## MARIS Open Refine CSV & MARIS NetCDF variable relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fc4c6",
   "metadata": {},
   "source": [
    "The table below lists the MARIS variables in both MARIS Open Refine and MARIS NetCDF formats. Each variable's presence in both formats for the seawater (``sea``), biota (``bio``), and sediment (``sed``) groups is indicated with a checkmark (``✓``)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65a7c1",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "  table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse\n",
    "  }\n",
    "\n",
    "  td,\n",
    "  th {\n",
    "    border: 1px solid #000;\n",
    "    padding: 5px;\n",
    "    text-align: center\n",
    "  }\n",
    "\n",
    "  th {\n",
    "    background-color: #f2f2f2\n",
    "  }\n",
    "\n",
    "  .open-refine {\n",
    "    background-color: #fff;\n",
    "    color: black;\n",
    "    text-align: center\n",
    "\n",
    "  }\n",
    "\n",
    "  .netcdf {\n",
    "    background-color: #e6e6e6;\n",
    "    color: black;\n",
    "    text-align: center\n",
    "  }\n",
    "</style>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"open-refine\">Open Refine Variables</th>\n",
    "      <th class=\"open-refine\">sea</th>\n",
    "      <th class=\"open-refine\">bio</th>\n",
    "      <th class=\"open-refine\">sed</th>\n",
    "      <th class=\"netcdf\">sea</th>\n",
    "      <th class=\"netcdf\">bio</th>\n",
    "      <th class=\"netcdf\">sed</th>\n",
    "      <th class=\"netcdf\">NetCDF Variables</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample type</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">*Included as netcdf.group*</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Latitude decimal</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">lat</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Longitude decimal</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">lon</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling start date</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">time</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling start time</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">time</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling end date</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling end time</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Nuclide</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">nuclide</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Value type</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">detection_limit</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Unit</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">unit</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Activity or MDA</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">value</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Uncertainty</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">uncertainty</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling depth</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">smp_depth</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Top</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Bottom</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Species</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">species</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Body part</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">body_part</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">bio_group</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Salinity</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">salinity</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Temperature</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">temperature</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Filtered</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">filtered</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Mesh size</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Quality flag</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sediment type</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sed_type</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Dry weight</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Wet weight</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Dry/wet ratio</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Station ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">data_provider_sample_id</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Total depth</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">tot_depth</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Profile or transect ID</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sampling method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sampling_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Preparation method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">preparation_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Drying method</td>\n",
    "      <td class=\"open-refine\"></td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "      <td class=\"netcdf\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Counting method</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">counting_method</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Sample notes</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">sample_notes<sup>*1</sup></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td class=\"open-refine\">Measurement notes</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"open-refine\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">✓</td>\n",
    "      <td class=\"netcdf\">measurement_notes<sup>*1</sup></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcd47a",
   "metadata": {},
   "source": [
    "<sup>*1</sup> The MARIS NetCDF does not currently support strings of variable length (i.e. vlen string data type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc6103",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "1. **fname_in** - is the path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "2. **fname_out_nc** - is the path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "3. **Zotero key** - is used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "fname_out_csv = '../../_data/output/100-HELCOM-MORS-2024.csv'\n",
    "zotero_key ='26VMZZ2Q'\n",
    "ref_id = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf9628",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd04abcd",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "7f9f0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_data(src_dir: str, smp_types: List[str] = ['SEA', 'SED', 'BIO']) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\n",
    "    \n",
    "    Args:\n",
    "    src_dir (str): The directory where the source CSV files are located.\n",
    "    smp_types (List[str]): A list of sample types to load. Defaults to ['SEA', 'SED', 'BIO'].\n",
    "    \n",
    "    Returns:\n",
    "    Dict[str, pd.DataFrame]: A dictionary with sample types as keys and their corresponding dataframes as values.\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    lut_smp_type = {'SEA': 'seawater', 'SED': 'sediment', 'BIO': 'biota'}\n",
    "    \n",
    "    for smp_type in smp_types:\n",
    "        fname_meas = smp_type + '02.csv'  # Measurement (i.e., radioactivity) information\n",
    "        fname_smp = smp_type + '01.csv'  # Sample information\n",
    "        \n",
    "        df_meas = pd.read_csv(Path(src_dir) / fname_meas)\n",
    "        df_smp = pd.read_csv(Path(src_dir) / fname_smp)\n",
    "        \n",
    "        df = pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        dfs[lut_smp_type[smp_type]] = df\n",
    "    \n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bb0fd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e534545",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['seawater', 'sediment', 'biota'])\n",
      "Seawater cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Sediment cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "Biota cols: Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print(dfs.keys())\n",
    "print(f\"Seawater cols: {dfs['seawater'].columns}\")\n",
    "print(f\"Sediment cols: {dfs['sediment'].columns}\")\n",
    "print(f\"Biota cols: {dfs['biota'].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785805a",
   "metadata": {},
   "source": [
    "Show the structure of the `seawater` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "7f9aeb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (ddmmmm)</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004</td>\n",
       "      <td>...</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005</td>\n",
       "      <td>...</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007</td>\n",
       "      <td>...</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (ddmmmm)  \\\n",
       "0  08/20/14 00:00:00       90       KRIL   2012003  ...              29.20   \n",
       "1  08/20/14 00:00:00       90       KRIL   2012004  ...              29.20   \n",
       "2  08/20/14 00:00:00       90       KRIL   2012005  ...              23.09   \n",
       "3  08/20/14 00:00:00       90       KRIL   2012006  ...              27.59   \n",
       "4  08/20/14 00:00:00       90       KRIL   2012007  ...              27.59   \n",
       "\n",
       "   LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  FILT  MORS_SUBBASIN  \\\n",
       "0             29.3333     NaN     0.0   NaN    NaN   NaN             11   \n",
       "1             29.3333     NaN    29.0   NaN    NaN   NaN             11   \n",
       "2             23.1500     NaN     0.0   NaN    NaN   NaN             11   \n",
       "3             27.9833     NaN     0.0   NaN    NaN   NaN             11   \n",
       "4             27.9833     NaN    39.0   NaN    NaN   NaN             11   \n",
       "\n",
       "   HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0               11  08/20/14 00:00:00  \n",
       "1               11  08/20/14 00:00:00  \n",
       "2                3  08/20/14 00:00:00  \n",
       "3               11  08/20/14 00:00:00  \n",
       "4               11  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423d697",
   "metadata": {},
   "source": [
    "Show the structure of the `biota` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "1ac781a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>BIOTATYPE</th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>NO</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>135.300000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CO60</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS137</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>4.338000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BVTIG2012040</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.9</td>\n",
       "      <td>964.0</td>\n",
       "      <td>18.458</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY   NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "0  BVTIG2012041  CS134     VTIG01             <     0.010140     W     NaN   \n",
       "1  BVTIG2012041  K40       VTIG01                 135.300000     W    3.57   \n",
       "2  BVTIG2012041  CO60      VTIG01             <     0.013980     W     NaN   \n",
       "3  BVTIG2012041  CS137     VTIG01                   4.338000     W    3.48   \n",
       "4  BVTIG2012040  CS134     VTIG01             <     0.009614     W     NaN   \n",
       "\n",
       "   NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... BIOTATYPE  TISSUE    NO  LENGTH  \\\n",
       "0     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "1     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "2     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "3     NaN  02/27/14 00:00:00      6.0  ...         F       5  16.0    45.7   \n",
       "4     NaN  02/27/14 00:00:00      6.0  ...         F       5  17.0    45.9   \n",
       "\n",
       "   WEIGHT     DW%  LOI%  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
       "0   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "1   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "2   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "3   948.0  18.453  92.9              2               16  02/27/14 00:00:00  \n",
       "4   964.0  18.458  92.9              2               16  02/27/14 00:00:00  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['biota'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840141d5",
   "metadata": {},
   "source": [
    "Show the structure of the `sediment` dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "b6013611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0  SKRIL2012048   RA226    NaN           NaN         35.0       26.0   \n",
       "1  SKRIL2012049   RA226    NaN           NaN         36.0       22.0   \n",
       "2  SKRIL2012050   RA226    NaN           NaN         38.0       24.0   \n",
       "3  SKRIL2012051   RA226    NaN           NaN         36.0       25.0   \n",
       "4  SKRIL2012052   RA226    NaN           NaN         30.0       23.0   \n",
       "\n",
       "  < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00  ...    20.0   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00  ...    27.0   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00  ...     2.0   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00  ...     4.0   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00  ...     6.0   \n",
       "\n",
       "    AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "0  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "1  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "2  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "3  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "4  0.006   NaN  NaN  NaN   NaN           11.0            11.0       NaN   \n",
       "\n",
       "     DATE_OF_ENTRY_y  \n",
       "0  08/20/14 00:00:00  \n",
       "1  08/20/14 00:00:00  \n",
       "2  08/20/14 00:00:00  \n",
       "3  08/20/14 00:00:00  \n",
       "4  08/20/14 00:00:00  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs['sediment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f3eef",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d68abc3",
   "metadata": {},
   "source": [
    "## Data transformation pipeline for NetCDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd7de4",
   "metadata": {},
   "source": [
    "### Data transformation pipeline utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ceb64d",
   "metadata": {},
   "source": [
    "``CompareDfsAndTfm`` compares the original dataframes to the transformed dataframe. A dictionary of dataframes, ``tfm.dfs_dropped``, is created to include the data present in the original dataset but absent from the transformed data. ``tfm.compare_stats`` provides a quick overview of the number of rows in both the original dataframes and the transformed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "4ae81009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from marisco.callbacks import Callback, Transformer\n",
    "\n",
    "class CompareDfsAndTfm(Callback):\n",
    "    \"Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.\"\n",
    "    \n",
    "    def __init__(self, dfs: Dict[str, pd.DataFrame]):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: Transformer) -> None:\n",
    "        self._initialize_tfm_attributes(tfm)\n",
    "        for grp in tfm.dfs.keys():\n",
    "            dropped_df = self._get_dropped_data(grp, tfm)\n",
    "            tfm.dfs_dropped[grp] = dropped_df\n",
    "            tfm.compare_stats[grp] = self._compute_stats(grp, tfm)\n",
    "\n",
    "    def _initialize_tfm_attributes(self, tfm: Transformer) -> None:\n",
    "        \"\"\"Initialize attributes in `tfm`.\"\"\"\n",
    "        tfm.dfs_dropped = {}\n",
    "        tfm.compare_stats = {}\n",
    "\n",
    "    def _get_dropped_data(self, grp: str, tfm: Transformer) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get the data that is present in `dfs` but not in `tfm.dfs`.\n",
    "        \n",
    "        Args:\n",
    "        grp (str): The group key.\n",
    "        tfm (Transformer): The transformation object containing `dfs`.\n",
    "        \n",
    "        Returns:\n",
    "        pd.DataFrame: Dataframe with dropped rows.\n",
    "        \"\"\"\n",
    "        index_diff = self.dfs[grp].index.difference(tfm.dfs[grp].index)\n",
    "        return self.dfs[grp].loc[index_diff]\n",
    "    \n",
    "    def _compute_stats(self, grp: str, tfm: Transformer) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Compute comparison statistics between `dfs` and `tfm.dfs`.\n",
    "        \n",
    "        Args:\n",
    "        grp (str): The group key.\n",
    "        tfm (Transformer): The transformation object containing `dfs`.\n",
    "        \n",
    "        Returns:\n",
    "        Dict[str, int]: Dictionary with comparison statistics.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Number of rows in dfs': len(self.dfs[grp].index),\n",
    "            'Number of rows in tfm.dfs': len(tfm.dfs[grp].index),\n",
    "            'Number of dropped rows': len(tfm.dfs_dropped[grp].index),\n",
    "            'Number of rows in tfm.dfs + Number of dropped rows': len(tfm.dfs[grp].index) + len(tfm.dfs_dropped[grp].index)\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b690d9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``nuclide``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992b23c",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Nuclide``.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "#### Lower & strip nuclide names\n",
    "\n",
    "Create a callback function, `LowerStripRdnNameCB`, that receives a dictionary of dataframes. For each dataframe in the dictionary, it converts the contents of the `Nuclides` column to lowercase and removes any leading or trailing whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5b10f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LowerStripRdnNameCB(Callback):\n",
    "    \"\"\"Convert nuclide names to lowercase and strip any trailing spaces.\"\"\"\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for key in tfm.dfs.keys():\n",
    "            self._process_nuclide_column(tfm.dfs[key])\n",
    "\n",
    "    def _process_nuclide_column(self, df):\n",
    "        \"\"\"Apply transformation to the 'NUCLIDE' column of the given DataFrame.\"\"\"\n",
    "        df['NUCLIDE'] = df['NUCLIDE'].apply(self._transform_nuclide)\n",
    "\n",
    "    def _transform_nuclide(self, nuclide):\n",
    "        \"\"\"Convert nuclide name to lowercase and strip trailing spaces.\"\"\"\n",
    "        return nuclide.lower().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb73d9",
   "metadata": {},
   "source": [
    "Here we call a transformer, which applies the callback (e.g. `LowerStripRdnNameCB`) to the dictionary of dataframes, `dfs`. We then print the unique entries of the transformed `NUCLIDE` column for each dataframe included in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB()])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm()['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "#### Remap HELCOM nuclide names to MARIS nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9905c7",
   "metadata": {},
   "source": [
    "The `maris-template.nc` file, which  is created from the `cdl.toml` on installation of the Marisco package, provides details of the nuclides permitted in the  MARIS NetCDF file. Here we define a function  `get_unique_nuclides()` which creates a list of the unique nuclides from each dataframe in the dictionary of dataframes `dfs`. The function `has_valid_varname` checks that each nuclide in this list is included in the `maris-template.nc` (i.e. the `cdl.toml`). `has_valid_varname` returns all variables in the list that are not in the `maris-template.nc` or returns `True`. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "bbf213bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unique_nuclides(dfs: Dict[str, pd.DataFrame]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of unique radionuclide types measured across samples.\n",
    "\n",
    "    Args:\n",
    "        dfs (Dict[str, pd.DataFrame]): A dictionary where keys are sample names and values are DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of unique radionuclide types.\n",
    "    \"\"\"\n",
    "    # Collect unique nuclide names from all DataFrames\n",
    "    nuclides = set()\n",
    "    for df in dfs.values():\n",
    "        nuclides.update(df['NUCLIDE'].unique())\n",
    "\n",
    "    return list(nuclides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "a68dacd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cs143\" variable name not found in MARIS CDL\n",
      "\"cs139\" variable name not found in MARIS CDL\n",
      "\"cs144\" variable name not found in MARIS CDL\n",
      "\"cs142\" variable name not found in MARIS CDL\n",
      "\"k-40\" variable name not found in MARIS CDL\n",
      "\"cs146\" variable name not found in MARIS CDL\n",
      "\"cs145\" variable name not found in MARIS CDL\n",
      "\"cs134137\" variable name not found in MARIS CDL\n",
      "\"pu239240\" variable name not found in MARIS CDL\n",
      "\"cs141\" variable name not found in MARIS CDL\n",
      "\"cm243244\" variable name not found in MARIS CDL\n",
      "\"cs138\" variable name not found in MARIS CDL\n",
      "\"pu238240\" variable name not found in MARIS CDL\n",
      "\"cs140\" variable name not found in MARIS CDL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Check if these variable names are consistent with MARIS CDL\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501bd59",
   "metadata": {},
   "source": [
    "Many nuclide names are not listed in the `maris-template.nc`. Here we create a look up table, `varnames_lut_updates`, which will be used to correct the nuclide names in the dictionary of dataframes (i.e. dfs) that are not compatible with the `maris-template.nc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "b4abac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "varnames_lut_updates = {\n",
    "    'k-40': 'k40',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs138': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs140': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs143': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs146': 'cs137'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b877d3d",
   "metadata": {},
   "source": [
    "Function `get_varnames_lut` returns a dictionary of nuclide names. This dictionary includes the `NUCLIDE` names from the dataframes in dfs, along with corrections specified in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "35f89931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_varnames_lut(\n",
    "    dfs: Dict[str, pd.DataFrame], \n",
    "    lut: Dict[str, str] = varnames_lut_updates\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generate a lookup table for radionuclide names, updating with provided mappings.\n",
    "\n",
    "    Args:\n",
    "        dfs (Dict[str, pd.DataFrame]): A dictionary where keys are sample names and values are DataFrames.\n",
    "        lut (Dict[str, str], optional): A dictionary with additional mappings to update the lookup table.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary mapping radionuclide names to their corresponding names.\n",
    "    \"\"\"\n",
    "    # Generate a base lookup table from unique nuclide names\n",
    "    unique_nuclides = get_unique_nuclides(dfs)\n",
    "    base_lut = {name: name for name in unique_nuclides}\n",
    "\n",
    "    # Update the base lookup table with additional mappings\n",
    "    base_lut.update(lut)\n",
    "    \n",
    "    return base_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d2ea0",
   "metadata": {},
   "source": [
    "Create a callback that remaps the nuclide names in the dataframes within dfs to the updated names in `varnames_lut_updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "6f6b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapRdnNameCB(Callback):\n",
    "    \"\"\"Remap radionuclide names to MARIS radionuclide names.\"\"\"\n",
    "\n",
    "    def __init__(self, fn_lut: Callable[[Dict[str, pd.DataFrame]], Dict[str, str]] =  partial(get_varnames_lut, lut=varnames_lut_updates)):\n",
    "        \"\"\"\n",
    "        Initialize the RemapRdnNameCB with a function to generate the lookup table.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable, optional): A function that takes a dictionary of DataFrames and returns a lookup table.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the lookup table to remap radionuclide names in DataFrames.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut(tfm.dfs)\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_nuclide_names(tfm.dfs[grp], lut)\n",
    "    \n",
    "    def _remap_nuclide_names(self, df: pd.DataFrame, lut: Dict[str, str]):\n",
    "        \"\"\"\n",
    "        Remap radionuclide names in the 'NUCLIDE' column of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the 'NUCLIDE' column.\n",
    "            lut (Dict[str, str]): Lookup table for remapping radionuclide names.\n",
    "        \"\"\"\n",
    "        if 'NUCLIDE' in df.columns:\n",
    "            df['NUCLIDE'].replace(lut, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must contain a 'NUCLIDE' column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa0d93",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB` and `RemapRdnNameCB`. Then, print the unique nuclides for each dataframe in the dictionary dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "1c075d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seawater nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239_240_tot' 'am241' 'cm242'\n",
      " 'cm244' 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95'\n",
      " 'ag110m' 'cm243_244_tot' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239'\n",
      " 'pb210' 'po210' 'np237' 'pu240' 'mn54']\n",
      "biota nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239_240_tot' 'ru106' 'be7' 'ce144' 'pb210' 'po210'\n",
      " 'sb124' 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131'\n",
      " 'ba140' 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223'\n",
      " 'eu155' 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152'\n",
      " 'sc46' 'rb86' 'ra224' 'th232' 'cs134_137_tot' 'am241' 'ra228' 'th228']\n",
      "sediment nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134_137_tot' 'cs134'\n",
      " 'pu239_240_tot' 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144'\n",
      " 'am241' 'be7' 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210'\n",
      " 'ra224' 'nb95' 'pu238_240_tot' 'pu241' 'pu239' 'eu155' 'ir192' 'th232'\n",
      " 'cd109' 'sb124' 'zn65' 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228'\n",
      " 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            #CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "\n",
    "#print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('seawater nuclides: ')\n",
    "print(tfm.dfs['seawater']['NUCLIDE'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm.dfs['biota']['NUCLIDE'].unique())\n",
    "print('sediment nuclides: ')\n",
    "print(tfm.dfs['sediment']['NUCLIDE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de9359a",
   "metadata": {},
   "source": [
    "After apply correction to the nuclide names check that all nuclide in the dictionary of dataframees are valid. Returns `True` if all are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "3c644322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca601fc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23281e3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: `time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691210e1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83309a2",
   "metadata": {},
   "source": [
    "Create a callback that remaps the time format in the dictionary of dataframes (i.e. `%m/%d/%y %H:%M:%S`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParseTimeCB(Callback):\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "            \n",
    "        \n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            df = tfm.dfs[grp]\n",
    "            self._process_dates(df)\n",
    "\n",
    "    def _process_dates(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Process and correct date and time information in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the 'DATE', 'YEAR', 'MONTH', and 'DAY' columns.\n",
    "        \"\"\"\n",
    "        # get 'time' from 'DATE' column\n",
    "        df['time'] = pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S')\n",
    "        # if 'DATE' column is nan, get 'time' from 'YEAR','MONTH' and 'DAY' column. \n",
    "        # if 'DAY' or 'MONTH' is 0 then set it to 1. \n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        # if 'DAY' and 'MONTH' is nan but YEAR is not nan then set 'DAY' and 'MONTH' both to 1. \n",
    "        condition = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[condition, \"DAY\"] = 1\n",
    "        df.loc[condition, \"MONTH\"] = 1\n",
    "        \n",
    "        condition = df['DATE'].isna() # if 'DATE' is nan. \n",
    "        df['time']  = np.where(condition,\n",
    "                                            # 'coerce', then invalid parsing will be set as NaT. NaT will result if the number of days are not valid for the month.\n",
    "                                        pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']], format='%y%m%d', errors='coerce'),  \n",
    "                                        pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB` and `ParseTimeCB`. Then, print the `time` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20318     37347  14893\n",
      "Number of dropped rows                                     0         0      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "#print(tfm.dfs['seawater']['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e52eb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2c925",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``time``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e7277",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: `Sampling start date` and `Sampling start time`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 37347 entries for `time` are invalid for sediment.\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20318     37346  14893\n",
      "Number of dropped rows                                     0         1      0\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg(), verbose = True),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "f7099e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MONTH  DAY DATE\n",
       "35783   NaN    NaN  NaN  NaN"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs_dropped['sediment'][['YEAR', 'MONTH', 'DAY', 'DATE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14328eb9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "### Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42f151",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``value``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e99464",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Activity or MDA``.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_val = {'seawater' : { 'val' : 'VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "981121ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SanitizeValue(Callback):\n",
    "    \"Sanitize value by removing blank entries and ensuring the 'value' column is retained.\"\n",
    "\n",
    "    def __init__(self, coi: dict):\n",
    "        \"\"\"\n",
    "        Initialize the SanitizeValue callback.\n",
    "\n",
    "        Args:\n",
    "            coi (dict): Dictionary containing column names for values based on group.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"\n",
    "        Sanitize the DataFrames in the transformer by removing rows with blank values in specified columns.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._sanitize_dataframe(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _sanitize_dataframe(self, df: pd.DataFrame, grp: str):\n",
    "        \"\"\"\n",
    "        Remove rows where specified value columns are blank and ensure the 'value' column is included.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to sanitize.\n",
    "            grp (str): Group name to determine column names.\n",
    "        \"\"\"\n",
    "        value_col = self.coi.get(grp, {}).get('val')\n",
    "        if value_col and value_col in df.columns:\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            # Ensure 'value' column is retained\n",
    "            if 'value' not in df.columns:\n",
    "                df['value'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba93b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "### Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12185ee",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``uncertainty``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b02a81",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Uncertainty`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` coverts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Make measurement and uncertainty units consistent\n",
    "def unc_rel2stan(df: pd.DataFrame, meas_col: str, unc_col: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert relative uncertainty to absolute uncertainty.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing measurement and uncertainty columns.\n",
    "        meas_col (str): Name of the column with measurement values.\n",
    "        unc_col (str): Name of the column with relative uncertainty values (percentages).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series with calculated absolute uncertainties.\n",
    "    \"\"\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the uncertainty is given as a relative uncertainty to the value (i.e., activity). The column names for both the value and the uncertainty vary by sample type. The coi_units_unc dictionary defines the column names for the Value and Uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_units_unc = [('seawater', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('biota', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('sediment', 'VALUE_Bq/kg', 'ERROR%_kg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncUnitCB callback normalizes the uncertainty by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeUncUnitCB(Callback):\n",
    "    \"\"\"Convert from relative error % to uncertainty of activity unit.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fn_convert_unc: Callable[[pd.DataFrame, str, str], pd.Series] = unc_rel2stan,\n",
    "                 coi: List[Tuple[str, str, str]] = coi_units_unc):\n",
    "        \"\"\"\n",
    "        Initialize the NormalizeUncUnitCB with a function to convert uncertainties and units.\n",
    "\n",
    "        Args:\n",
    "            fn_convert_unc (Callable[[pd.DataFrame, str, str], pd.Series], optional): \n",
    "                Function to convert relative uncertainty to absolute uncertainty. \n",
    "                Defaults to `unc_rel2stan`.\n",
    "            coi (List[Tuple[str, str, str]], optional): List of tuples with group name, \n",
    "                measurement column, and uncertainty column. Defaults to `coi_units_unc`.\n",
    "        \"\"\"\n",
    "        # Automatically initialize attributes using fc.store_attr()\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply the conversion function to each DataFrame in the transformer.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['uncertainty'] = self.fn_convert_unc(df, val, unc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB` and `NormalizeUncUnitCB()`. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   value  uncertainty\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        value  uncertainty\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   value  uncertainty\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val)])\n",
    "\n",
    "print(tfm()['seawater'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['biota'][['value', 'uncertainty']][:5])\n",
    "print(tfm()['sediment'][['value', 'uncertainty']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8540",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "### Lookup transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f44637",
   "metadata": {},
   "source": [
    "#### Lookup MARIS function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6e294",
   "metadata": {},
   "source": [
    "`get_maris_lut` performs a lookup of data provided in `data_provider_lut` against the MARIS lookup (`maris_lut`) using a fuzzy matching algorithm based on Levenshtein distance. The `get_maris_lut` is used to correct the HELCOM data to a standard format for MARIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "2f6f0c03-7666-461d-a5ce-d0021bc9e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maris_lut(fname_in, \n",
    "                  fname_cache, # For instance 'species_helcom.pkl'\n",
    "                  data_provider_lut: str, # Data provider lookup table name\n",
    "                  data_provider_id_col: str, # Data provider lookup column id of interest\n",
    "                  data_provider_name_col: str, # Data provider lookup column name of interest\n",
    "                  maris_lut: Callable, # Function retrieving MARIS source lookup table\n",
    "                  maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "                  maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "                  unmatched_fixes: dict = {},\n",
    "                  as_dataframe: bool = False,\n",
    "                  overwrite: bool = False\n",
    "                 ):\n",
    "    # Use fname_cache directly for the file path\n",
    "    cache_file = cache_path() / fname_cache\n",
    "    lut = {}\n",
    "    maris_lut = maris_lut()\n",
    "    df = pd.read_csv(Path(fname_in) / data_provider_lut)\n",
    "    \n",
    "    if overwrite or (not cache_file.exists()):\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
    "            # Fix if unmatched\n",
    "            has_to_be_fixed = row[data_provider_id_col] in unmatched_fixes            \n",
    "            name_to_match = unmatched_fixes[row[data_provider_id_col]] if has_to_be_fixed else row[data_provider_name_col]\n",
    "\n",
    "            # Match\n",
    "            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)\n",
    "            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], \n",
    "                          row[data_provider_name_col], result.iloc[0]['score'])\n",
    "            \n",
    "            lut[row[data_provider_id_col]] = match\n",
    "        \n",
    "        fc.save_pickle(cache_file, lut)\n",
    "    else:\n",
    "        lut = fc.load_pickle(cache_file)\n",
    "\n",
    "    if as_dataframe:\n",
    "        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()\n",
    "        df_lut.index.name = 'source_id'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)\n",
    "    else:\n",
    "        return lut\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5868c16b",
   "metadata": {},
   "source": [
    "#### Lookup : Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2bbb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``species``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19098ae",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Species`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40671f8f",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `RUBIN_NAME.csv` file for biota species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "bdd0d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "df_rubin = pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')\n",
    "df_rubin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa8871",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_species` to correct the spelling of names that are unmatched in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "15acca89-169a-45eb-98fe-cf7c7b2ee0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_species = {\n",
    "    'CARD EDU': 'Cerastoderma edule',\n",
    "    'LAMI SAC': 'Saccharina latissima',\n",
    "    'PSET MAX': 'Scophthalmus maximus',\n",
    "    'STIZ LUC': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2adaa417-6b01-45d8-80d7-2e3d97cb0f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:07<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "species_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='species_helcom.pkl', \n",
    "                               data_provider_lut='RUBIN_NAME.csv',\n",
    "                               data_provider_id_col='RUBIN',\n",
    "                               data_provider_name_col='SCIENTIFIC NAME',\n",
    "                               maris_lut=species_lut_path,\n",
    "                               maris_id='species_id',\n",
    "                               maris_name='species',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915a7fc",
   "metadata": {},
   "source": [
    "Display `species_lut_df`. The `match_score` represents the number insertions, deletions, or substitutions needed to transform from the HECOM source name (`source_name`) to the maris name, (`matched_maris_name`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "c341f814-3343-47b7-958c-5df7d34a683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLY FUC</th>\n",
       "      <td>245</td>\n",
       "      <td>Polysiphonia fucoides</td>\n",
       "      <td>POLYSIPHONIA FUCOIDES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id     matched_maris_name              source_name  \\\n",
       "source_id                                                              \n",
       "ENCH CIM         276          Echinodermata       ENCHINODERMATA CIM   \n",
       "MACO BAL         122        Macoma balthica           MACOMA BALTICA   \n",
       "STUC PEC         704    Stuckenia pectinata      STUCKENIA PECTINATE   \n",
       "STIZ LUC         285      Sander lucioperca  STIZOSTEDION LUCIOPERCA   \n",
       "POLY FUC         245  Polysiphonia fucoides    POLYSIPHONIA FUCOIDES   \n",
       "\n",
       "          match_score  \n",
       "source_id              \n",
       "ENCH CIM            5  \n",
       "MACO BAL            1  \n",
       "STUC PEC            1  \n",
       "STIZ LUC            1  \n",
       "POLY FUC            0  "
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "species_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557931bd",
   "metadata": {},
   "source": [
    "Show `species_lut_df` where `match_type` is not a perfect match ( i.e. not equal 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "657f297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>276</td>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>122</td>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>704</td>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>285</td>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id   matched_maris_name              source_name match_score\n",
       "source_id                                                                     \n",
       "ENCH CIM         276        Echinodermata       ENCHINODERMATA CIM           5\n",
       "MACO BAL         122      Macoma balthica           MACOMA BALTICA           1\n",
       "STUC PEC         704  Stuckenia pectinata      STUCKENIA PECTINATE           1\n",
       "STIZ LUC         285    Sander lucioperca  STIZOSTEDION LUCIOPERCA           1"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_lut_df[species_lut_df['match_score'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d900eb6",
   "metadata": {},
   "source": [
    "`LookupBiotaSpeciesCB` applies the corrected `biota` `species` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "c2798566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookupBiotaSpeciesCB(Callback):\n",
    "    \"\"\"\n",
    "    Biota species remapped to MARIS db:\n",
    "        CARD EDU: Cerastoderma edule\n",
    "        LAMI SAC: Saccharina latissima\n",
    "        PSET MAX: Scophthalmus maximus\n",
    "        STIZ LUC: Sander luciopercas\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut: Callable[[], dict]):\n",
    "        \"\"\"\n",
    "        Initialize the LookupBiotaSpeciesCB with a function to generate the lookup table.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap biota species names in the DataFrame using the lookup table and print unmatched RUBIN values.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Apply the function to the 'RUBIN' column\n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['RUBIN'].apply(lambda x: self._get_species(x, lut))\n",
    "\n",
    "    def _get_species(self, rubin_value: str, lut: dict):\n",
    "        \"\"\"\n",
    "        Get the matched_id from the lookup table and print RUBIN if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            rubin_value (str): The RUBIN value from the DataFrame.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "\n",
    "        Returns:\n",
    "            The matched_id from the lookup table.\n",
    "        \"\"\"\n",
    "        match = lut.get(rubin_value.strip(), Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self.print_unmatched_rubin(rubin_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_rubin(self, rubin_value: str):\n",
    "        \"\"\"\n",
    "        Print the RUBIN value if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            rubin_value (str): The RUBIN value from the DataFrame.\n",
    "        \"\"\"\n",
    "        print(f\"Unmatched RUBIN: {rubin_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b98d51",
   "metadata": {},
   "source": [
    "`get_maris_species` defines a partial function of `get_maris_lut`, with predefined arguments  for species lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "33ddf185-8ee8-4cb0-abd6-427fe4e52c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_species = partial(get_maris_lut,\n",
    "                            fname_in, fname_cache='species_helcom.pkl', \n",
    "                            data_provider_lut='RUBIN_NAME.csv',\n",
    "                            data_provider_id_col='RUBIN',\n",
    "                            data_provider_name_col='SCIENTIFIC NAME',\n",
    "                            maris_lut=species_lut_path,\n",
    "                            maris_id='species_id',\n",
    "                            maris_name='species',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18132f3",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()` and `LookupBiotaSpeciesCB(get_maris_species)`. Then, print the unique `species` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b83ffe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species)\n",
    "                            ])\n",
    "\n",
    "#print(tfm()['biota'][['RUBIN', 'species']][:10])\n",
    "print(tfm()['biota']['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0faa085",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "#### Lookup : Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92384b",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``body_part``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7388fd",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Body part`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31449525",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `TISSUE.csv` file for biota tissues. Biota tissue is known as `body part` in the maris data set.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6a4e9",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_biota_tissues` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {\n",
    "    3: 'Whole animal eviscerated without head',\n",
    "    12: 'Viscera',\n",
    "    8: 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "2d2a502e-3826-404c-84e1-0d60b4be0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 93.70it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df = get_maris_lut(fname_in, \n",
    "                               fname_cache='tissues_helcom.pkl', \n",
    "                               data_provider_lut='TISSUE.csv',\n",
    "                               data_provider_id_col='TISSUE',\n",
    "                               data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                               maris_lut=bodyparts_lut_path,\n",
    "                               maris_id='bodypar_id',\n",
    "                               maris_name='bodypar',\n",
    "                               unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                               as_dataframe=True,\n",
    "                               overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "967c1a7d-ba91-4400-ba0a-bad180eee1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_id</th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matched_id     matched_maris_name                   source_name  \\\n",
       "source_id                                                                   \n",
       "2                 52    Flesh without bones   WHOLE FISH WITHOUT ENTRAILS   \n",
       "5                 52    Flesh without bones  FLESH WITHOUT BONES (FILETS)   \n",
       "1                  1           Whole animal                    WHOLE FISH   \n",
       "15                53  Stomach and intestine           STOMACH + INTESTINE   \n",
       "41                 1           Whole animal                 WHOLE ANIMALS   \n",
       "\n",
       "          match_score  \n",
       "source_id              \n",
       "2                  13  \n",
       "5                   9  \n",
       "1                   5  \n",
       "15                  3  \n",
       "41                  1  "
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissues_lut_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811aa06",
   "metadata": {},
   "source": [
    "`LookupBiotaBodyPartCB` applies the corrected `biota` `TISSUE` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "bbe9a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    \"\"\"\n",
    "    Update bodypart id based on MARIS dbo_bodypar.xlsx:\n",
    "        - 3: 'Whole animal eviscerated without head',\n",
    "        - 12: 'Viscera',\n",
    "        - 8: 'Skin'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut: Callable[[], dict]):\n",
    "        \"\"\"\n",
    "        Initialize the LookupBiotaBodyPartCB with a function to generate the lookup table.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap biota body parts in the DataFrame using the lookup table and print unmatched TISSUE values.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['TISSUE'].apply(lambda x: self._get_body_part(x, lut))\n",
    "\n",
    "    def _get_body_part(self, tissue_value: str, lut: dict):\n",
    "        \"\"\"\n",
    "        Get the matched_id from the lookup table and print TISSUE if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            tissue_value (str): The TISSUE value from the DataFrame.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "\n",
    "        Returns:\n",
    "            The matched_id from the lookup table.\n",
    "        \"\"\"\n",
    "        match = lut.get(tissue_value, Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self.print_unmatched_tissue(tissue_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def print_unmatched_tissue(self, tissue_value: str):\n",
    "        \"\"\"\n",
    "        Print the TISSUE value if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            tissue_value (str): The TISSUE value from the DataFrame.\n",
    "        \"\"\"\n",
    "        print(f\"Unmatched TISSUE: {tissue_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a3904",
   "metadata": {},
   "source": [
    "`get_maris_bodypart` defines a partial function of `get_maris_lut`, with predefined arguments  for  `TISSUE` (or `bodypar`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "5460dc4c-6927-460f-924f-322606ad903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_bodypart = partial(get_maris_lut,\n",
    "                             fname_in,\n",
    "                             fname_cache='tissues_helcom.pkl', \n",
    "                             data_provider_lut='TISSUE.csv',\n",
    "                             data_provider_id_col='TISSUE',\n",
    "                             data_provider_name_col='TISSUE_DESCRIPTION',\n",
    "                             maris_lut=bodyparts_lut_path,\n",
    "                             maris_id='bodypar_id',\n",
    "                             maris_name='bodypar',\n",
    "                             unmatched_fixes=unmatched_fixes_biota_tissues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877064bf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)` and `LookupbioooooooootaBodyPartCB(get_maris_bodypart)`. Then, print the `TISSUE` and `body_part` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "53a195f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  body_part\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota'][['TISSUE', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718285f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "#### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513576a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``bio_group``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96421826",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Biogroup is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`get_biogroup_lut` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "d933de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_biogroup_lut(maris_lut: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve a lookup table for biogroup ids from a MARIS lookup table.\n",
    "\n",
    "    Args:\n",
    "        maris_lut (str): Path to the MARIS lookup table (Excel file).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping species_id to biogroup_id.\n",
    "    \"\"\"\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291637e",
   "metadata": {},
   "source": [
    "`LookupBiogroupCB` applies the corrected `biota` `bio group` data obtained from the `get_maris_lut` function to the `biota` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "41c8ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiogroupCB(Callback):\n",
    "    \"\"\"\n",
    "    Update biogroup id based on MARIS dbo_species.xlsx\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut: Callable[[], dict]):\n",
    "        \"\"\"\n",
    "        Initialize the LookupBiogroupCB with a function to generate the lookup table.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Update the 'bio_group' column in the DataFrame using the lookup table and print unmatched species values.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: self._get_biogroup(x, lut))\n",
    "\n",
    "    def _get_biogroup(self, species_value: str, lut: dict) -> int:\n",
    "        \"\"\"\n",
    "        Get the biogroup id from the lookup table and print species if the biogroup id is not found.\n",
    "\n",
    "        Args:\n",
    "            species_value (str): The species value from the DataFrame.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "\n",
    "        Returns:\n",
    "            int: The biogroup id from the lookup table.\n",
    "        \"\"\"\n",
    "        biogroup_id = lut.get(species_value, -1)\n",
    "        if biogroup_id == -1:\n",
    "            self.print_unmatched_species(species_value)\n",
    "        return biogroup_id\n",
    "\n",
    "    def print_unmatched_species(self, species_value: str):\n",
    "        \"\"\"\n",
    "        Print the species value if the biogroup id is not found.\n",
    "\n",
    "        Args:\n",
    "            species_value (str): The species value from the DataFrame.\n",
    "        \"\"\"\n",
    "        print(f\"Unmatched species: {species_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f2d40",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)` and `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` . Then, print the `bio_group` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3e74513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))\n",
    "                            ])\n",
    "\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158b423",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "#### Lookup : Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1fe91",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes look-up in the `SEDIMENT_TYPE.csv` file for Sediment types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169727",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sed_type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be172080",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: `Sediment type`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "bf7665a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI    SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99          NO DATA                    NaN\n",
       "1    30  SILT AND GRAVEL                    YES\n",
       "2     0           GRAVEL                    YES\n",
       "3     1             SAND                    YES\n",
       "4     2        FINE SAND                     NO"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "df_sediment = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "df_sediment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dba05",
   "metadata": {},
   "source": [
    "Create `unmatched_fixes_sediments` to correct entries in the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "d553b9bf-d305-456f-9bf1-620f2804637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_sediments = {\n",
    "    #np.nan: 'Not applicable',\n",
    "    -99: '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "480c716f-d2de-455f-b58f-22af28ca01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 100.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "sediments_lut_df = get_maris_lut(\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments,\n",
    "    as_dataframe=True,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17cfe1",
   "metadata": {},
   "source": [
    "`get_maris_sediments` defines a partial function of `get_maris_lut`, with predefined arguments  for  `SEDI` (or `sedtype`) lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "4053bfbb-8f04-434c-a8a1-35b4d58dd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_sediments = partial(\n",
    "    get_maris_lut,\n",
    "    fname_in, \n",
    "    fname_cache='sediments_helcom.pkl', \n",
    "    data_provider_lut='SEDIMENT_TYPE.csv',\n",
    "    data_provider_id_col='SEDI',\n",
    "    data_provider_name_col='SEDIMENT TYPE',\n",
    "    maris_lut=sediments_lut_path,\n",
    "    maris_id='sedtype_id',\n",
    "    maris_name='sedtype',\n",
    "    unmatched_fixes=unmatched_fixes_sediments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528f164",
   "metadata": {},
   "source": [
    "`LookupSedimentCB` applies the corrected `sediment` `SEDI` data obtained from the `get_maris_lut` function to the `sediment` dataframe in the dictionary of dataframes, `dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "e790bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_sedi(df, column_name='SEDI'):\n",
    "    \"\"\"\n",
    "    Preprocess the 'SEDI' column in the DataFrame by handling missing values and specific replacements.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the 'SEDI' column.\n",
    "        column_name (str): The name of the column to preprocess. Default is 'SEDI'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with preprocessed 'SEDI' column.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].fillna(-99).astype('int')\n",
    "        df[column_name].replace([56, 73], -99, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "6a9fb63d-2459-4497-9086-bb98ccd524e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupSedimentCB(Callback):\n",
    "    \"\"\"\n",
    "    Update sediment id based on MARIS dbo_sedtype.xlsx.\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut: Callable[[], dict], preprocess_fn: Callable[[pd.DataFrame, str], pd.DataFrame] = preprocess_sedi):\n",
    "        \"\"\"\n",
    "        Initialize the LookupSedimentCB with a function to generate the lookup table and a preprocessing function.\n",
    "\n",
    "        Args:\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "            preprocess_fn (Callable[[pd.DataFrame, str], pd.DataFrame]): Function to preprocess the sediment DataFrame. Default is preprocess_sedi.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "\n",
    "        # Apply preprocessing to the 'SEDI' column\n",
    "        tfm.dfs['sediment'] = self.preprocess_fn(tfm.dfs['sediment'])\n",
    "        \n",
    "        # Apply the lookup function\n",
    "        tfm.dfs['sediment']['sed_type'] = tfm.dfs['sediment']['SEDI'].apply(lambda x: self._get_sediment_type(x, lut))\n",
    "\n",
    "    def _get_sediment_type(self, sedi_value: int, lut: dict):\n",
    "        \"\"\"\n",
    "        Get the matched_id from the lookup table and print SEDI if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            sedi_value (int): The SEDI value from the DataFrame.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "\n",
    "        Returns:\n",
    "            The matched_id from the lookup table.\n",
    "        \"\"\"\n",
    "        match = lut.get(sedi_value, Match(-1, None, None, None))\n",
    "        if match.matched_id == -1:\n",
    "            self._print_unmatched_sedi(sedi_value)\n",
    "        return match.matched_id\n",
    "\n",
    "    def _print_unmatched_sedi(self, sedi_value: int):\n",
    "        \"\"\"\n",
    "        Print the SEDI value if the matched_id is -1.\n",
    "\n",
    "        Args:\n",
    "            sedi_value (int): The SEDI value from the DataFrame.\n",
    "        \"\"\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131e929",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)` and `LookupSedimentCB(get_maris_sediments)`. Then, print the `SEDI` and `sed_type` for the `biota` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "16d42cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEDI  sed_type\n",
      "0   -99         0\n",
      "1   -99         0\n",
      "2   -99         0\n",
      "3   -99         0\n",
      "4   -99         0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(tfm.dfs['sediment'][['SEDI', 'sed_type']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d5871",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "#### Lookup : Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a777c3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebee28",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Unit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "Create `renaming_unit_rules` to rename the units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "ea7fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {\n",
    "    'seawater': 1,  # 'Bq/m3'\n",
    "    'sediment': 4,  # 'Bq/kgd' for sediment\n",
    "    'biota': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12793b79",
   "metadata": {},
   "source": [
    "`LookupUnitCB` defines a `unit` column each dataframe based on the units provided in the value (`VALUE_Bq/m³` or `VALUE_Bq/kg`) column of the HELCOM dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    def __init__(self, renaming_unit_rules=renaming_unit_rules):\n",
    "        \"\"\"\n",
    "        Initialize the LookupUnitCB with unit renaming rules.\n",
    "\n",
    "        Args:\n",
    "            renaming_unit_rules (dict): Dictionary containing renaming rules for different unit categories.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Apply unit renaming rules to DataFrames within the transformer.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs:\n",
    "            rules = renaming_unit_rules.get(grp)\n",
    "            if rules is not None:\n",
    "                # if group tules include a dictionary, apply the dictionay. \n",
    "                if isinstance(rules, dict):\n",
    "                    # Apply rules based on the 'BASIS' column\n",
    "                    tfm.dfs[grp]['unit'] = tfm.dfs[grp]['BASIS'].apply(lambda x: rules.get(x, 0))\n",
    "                else:\n",
    "                    # Apply a single rule to the entire DataFrame\n",
    "                    tfm.dfs[grp]['unit'] = rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())` and `LookupUnitCB()`. Then, print the unique `unit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB()])\n",
    "\n",
    "print(tfm()['biota']['unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422eeb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "#### Lookup : Detection limit or Value type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c95ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``detection_limit``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fd987",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine foramt variable: ``Value type``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3a699",
   "metadata": {},
   "source": [
    "Create `coi_dl` to define the column names related to Value type for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "9c6e542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest\n",
    "coi_dl = {'seawater' : { 'val' : 'VALUE_Bq/m³',\n",
    "                        'unc' : 'ERROR%_m³',\n",
    "                        'dl' : '< VALUE_Bq/m³'},\n",
    "                 'biota':  {'val' : 'VALUE_Bq/kg',\n",
    "                            'unc' : 'ERROR%',\n",
    "                            'dl' : '< VALUE_Bq/kg'},\n",
    "                 'sediment': { 'val' : 'VALUE_Bq/kg',\n",
    "                              'unc' : 'ERROR%_kg',\n",
    "                              'dl' : '< VALUE_Bq/kg'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290b3fa",
   "metadata": {},
   "source": [
    "`get_detectionlimit_lut` reads the file at `detection_limit_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`.\n",
    "| id | name | name_sanitized |\n",
    "| :-: | :-: | :-: |\n",
    "|-1|Not applicable|Not applicable|\n",
    "|0|Not Available|Not available|\n",
    "|1|=|Detected value|\n",
    "|2|<|Detection limit|\n",
    "|3|ND|Not detected|\n",
    "|4|DE|Derived|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "3dfce2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_detectionlimit_lut():\n",
    "    df = pd.read_excel(detection_limit_lut_path(), usecols=['name','id'])\n",
    "    return df.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`LookupDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or detection limit) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg>` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 coi=coi_dl,\n",
    "                 fn_lut=get_detectionlimit_lut):\n",
    "        \"\"\"\n",
    "        Initialize the LookupDetectionLimitCB with configuration options and lookup function.\n",
    "\n",
    "        Args:\n",
    "            coi (dict): Configuration options for column names.\n",
    "            fn_lut (Callable): Function that returns a lookup table.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap detection limits in the DataFrames using the lookup table.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "    \n",
    "    def _update_detection_limit(self, df: pd.DataFrame, grp: str, lut: dict):\n",
    "        \"\"\"\n",
    "        Update detection limit column in the DataFrame based on lookup table and rules.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "            grp (str): The group name to get the column configuration.\n",
    "            lut (dict): The lookup table dictionary.\n",
    "        \"\"\"\n",
    "        detection_col = self.coi[grp]['dl']\n",
    "        value_col = self.coi[grp]['val']\n",
    "        uncertainty_col = self.coi[grp]['unc']\n",
    "        \n",
    "        # Copy detection limit column\n",
    "        df['detection_limit'] = df[detection_col]\n",
    "        \n",
    "        # Fill values with '=' or 'Not Available'\n",
    "        condition = ((df[value_col].notna()) & (df[uncertainty_col].notna()) &\n",
    "                     (~df['detection_limit'].isin(lut.keys())))\n",
    "        df.loc[condition, 'detection_limit'] = '='\n",
    "        df.loc[~df['detection_limit'].isin(lut.keys()), 'detection_limit'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup\n",
    "        df['detection_limit'] = df['detection_limit'].map(lut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66db5cf",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()` and `LookupDetectionLimitCB`. Then, print the unique `detection_limit` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB()])\n",
    "\n",
    "print(tfm()['seawater']['detection_limit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb3b44",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9114d",
   "metadata": {},
   "source": [
    "#### Lookup : Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef2b9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *NetCDF4 format variables: ``counting_method``, ``sampling_method`` and ``preparation_method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200156a7",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sampling method``,\t``Preparation method`` and ``Counting method``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4052e59",
   "metadata": {},
   "source": [
    "> 'Method' is provided in the HELCOM data but some work is required to link it to MARIS 'counting_method', 'sampling_method' and 'preparation_method'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084de15c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "### Data provider sample id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7b8a4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``data_provider_sample_id``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018492bf",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3238f",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format for variable type ``data_provider_sample_id`` does not support vlen strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapDataProviderSampleIdCB(Callback):\n",
    "    \"\"\"\n",
    "    Remap 'KEY' column to 'data_provider_sample_id' in each DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapDataProviderSampleIdCB.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Remap 'KEY' column to 'data_provider_sample_id' in the DataFrames.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp])\n",
    "    \n",
    "    def _remap_sample_id(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap the 'KEY' column to 'data_provider_sample_id' in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['data_provider_sample_id'] = df['KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WKRIL2012003' 'WKRIL2012004' 'WKRIL2012005' ... 'WSSSM2018006'\n",
      " 'WSSSM2018007' 'WSSSM2018008']\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['data_provider_sample_id'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf5780",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "### Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c3ba",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13e4ad",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Filtered``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84079a35",
   "metadata": {},
   "source": [
    "`get_filtered_lut` reads the file at `filtered_lut_path()` and from the contents of this file creates a dictionary linking `name` to `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "ceab5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_filtered_lut() -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve a filtered lookup table from an Excel file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping names to IDs.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(filtered_lut_path(), usecols=['name', 'id'])\n",
    "    return df.set_index('name').to_dict()['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "a9746673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Not applicable': -1, 'Not available': 0, 'Yes': 1, 'No': 2}"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filtered_lut()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70453b9",
   "metadata": {},
   "source": [
    "Create  `renaming_rules` to rename the HELCOM data to the MARIS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "2d1c17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_rules = {'N': 'No',\n",
    "                  'n': 'No',\n",
    "                  'F': 'Yes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`LookupFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupFiltCB(Callback):\n",
    "    \"Lookup FILT value.\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 rules=renaming_rules,\n",
    "                 fn_lut=get_filtered_lut):\n",
    "        \"\"\"\n",
    "        Initialize the LookupFiltCB with renaming rules and a function for generating the lookup table.\n",
    "\n",
    "        Args:\n",
    "            rules (dict): Dictionary mapping FILT codes to their corresponding names.\n",
    "            fn_lut (Callable[[], dict]): Function that returns the lookup table dictionary.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Update the FILT column in the DataFrames using the renaming rules and lookup table.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        lut = self.fn_lut()\n",
    "        rules = self.rules\n",
    "        \n",
    "        for grp in tfm.dfs.keys():\n",
    "            if \"FILT\" in tfm.dfs[grp].columns:\n",
    "                self._update_filt_column(tfm.dfs[grp], rules, lut)\n",
    "\n",
    "    def _update_filt_column(self, df: pd.DataFrame, rules: dict, lut: dict):\n",
    "        \"\"\"\n",
    "        Update the FILT column based on renaming rules and lookup table.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "            rules (dict): Dictionary mapping FILT codes to their corresponding names.\n",
    "            lut (dict): Dictionary for lookup values.\n",
    "        \"\"\"\n",
    "        # Fill values that are not in the renaming rules with 'Not available'.\n",
    "        df['FILT'] = df['FILT'].apply(lambda x: rules.get(x, 'Not available'))\n",
    "        \n",
    "        # Perform lookup\n",
    "        df['FILT'] = df['FILT'].map(lambda x: lut.get(x, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625063c",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `LowerStripRdnNameCB`, `RemapRdnNameCB`, `ParseTimeCB`,  `NormalizeUncUnitCB()`, `LookupBiotaSpeciesCB(get_maris_species)`, `LookupBiotaBodyPartCB(get_maris_bodypart)`, `LookupSedimentCB(get_maris_sediments)`, `LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())`, `LookupUnitCB()`,  `LookupDetectionLimitCB` and `LookupFiltCB()`. Then, print the unique `FILT` for the `seawater` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            LookupFiltCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['FILT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0502e9d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfe106",
   "metadata": {},
   "source": [
    "#### ~~Lookup : Area~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b0d3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``area``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e60cf4",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: Area is not included*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59862b",
   "metadata": {},
   "source": [
    "TODO : Write callback for area. Will I use the marineregions.org API to complete lookup? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "5cfac24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#| export \\ndef get_area_lut():\\n    df = pd.read_excel(area_lut_path(), usecols=['displayName','areaId'])\\n    return df.set_index('displayName').to_dict()['areaId']\\n\""
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#| export \n",
    "def get_area_lut():\n",
    "    df = pd.read_excel(area_lut_path(), usecols=['displayName','areaId'])\n",
    "    return df.set_index('displayName').to_dict()['areaId']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81152cc4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85a9ac",
   "metadata": {},
   "source": [
    "### ~~Sample Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a021f2a",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``sample_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba363cb2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Sample notes\n",
    "``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a3e6",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``sample_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64d446",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247b50a",
   "metadata": {},
   "source": [
    "### ~~Measurement Notes~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93974d7e",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: ``measurement_notes``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819c1f2",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Measurement notes``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d993a77",
   "metadata": {},
   "source": [
    ">  HELCOM data does not include ``measurement_notes``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d452362",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa59a",
   "metadata": {},
   "source": [
    "### Station ID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e08cc9",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Station ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296ba42",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Station ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c799173",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Station ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "768db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapStationIdCB(Callback):\n",
    "    \"Remap Station ID to MARIS format.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapStationIdCB with no specific parameters.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Iterate through all DataFrames in the transformer object and remap 'STATION' to 'station_id'.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._remap_station_id(tfm.dfs[grp])\n",
    "\n",
    "    def _remap_station_id(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap 'STATION' column to 'station_id' in the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['station_id'] = df['STATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "0ccb2604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RU10' 'RU11' 'RU19' 'RU20' 'RU23' 'RU25' 'RU32' 'RU52' 'RU89' 'RU94*'\n",
      " 'RU99' 'RU141' 'RU156' 'B6' 'B50' 'BY15' 'BY28' 'L6' 'L7' 'L8' 'LА-11'\n",
      " 'L13' 'Т1' 'RU5' 'B46' 'P16' 'Z1' 'SM1' 'SM2' 'SM5' 'P116' 'K11' 'P110'\n",
      " '2N2' 'ZN2' 'P14' 'P63' 'P140' 'P2' 'P3' 'P5' 'P39' 'B12' 'B13' 'B15'\n",
      " 'K3' 'M3' 'R4' 'P1' 'P40' 'A' 'GDR250' 'Z' 'K6' 'P127' 'P104' 'NP' '4P7'\n",
      " 'MW4' 'ZN4' 'EDC19' 'STOLGR' 'SCHLEI' 'KALKGR' 'KLBELT' 'KN' 'EDC20'\n",
      " 'GBELT2' 'EDC38' 'EDC42' 'EDC32' 'EDC46' 'EDC47' 'KATT1' 'EDC55' 'SOUNDA'\n",
      " 'SUND2' 'EDC58' 'ARKO1' 'BY2' 'EDC65' 'EDC68' 'GDR213' 'EDC80' 'EDC101'\n",
      " 'EDC88' '2' 'EDC73' 'BHOLM3' 'EDC63' '18' 'DARSS' 'KOTN11' 'KFOTN6'\n",
      " 'EDC35' 'EDC16' 'EDC7' 'EDC148' 'FBELT1' 'EDC92' '87/21' 'EDC70' 'EDC66'\n",
      " 'GDR109' 'GDR069' 'EDC18' 'EDC17' 'EDC39' 'ZZZ' 'EDC93' 'EDC81' 'GBELT1'\n",
      " 'EDC40' '8' 'EDC145' 'EDC36' '11' 'EDC54' 'EDC53' 'SUND4' 'SUND3' 'SUND1'\n",
      " 'BHOLM2' 'EDC75' '22' '29' 'EDC821' 'EDC82' 'EDC89' 'EDC98' 'EDC119'\n",
      " 'EDC114' '33' 'EDC96' 'EDC118' 'EDC109' '37' 'EDC100' '39' 'EDC84'\n",
      " 'EDC85' '42' 'EDC90' '45' 'EDC107' 'EDC120' '46' 'EDC134' '50' 'EDC136'\n",
      " '52' 'GA51' '54' 'EDC138' 'EDC140' '57' 'GA56' 'EDC124' 'EDC150' 'EDC149'\n",
      " 'EDC130' 'EDC126' 'EDC110' 'GA63' 'EDC122' 'EDC113' '68' 'TEILI1'\n",
      " 'EDC139' 'GA73' '74' 'EDC135' 'EDC125' 'EDC83' 'EDC23' '88' 'EDC78'\n",
      " 'EDC27' '91' 'EDC69' '93' 'BHOLM5' '95' 'ARKO2' 'EDC59' 'NEUBU' 'EDC15'\n",
      " 'ECKFBU' 'EDC24' 'KIBU1' 'KIBU2' 'FBELT2' 'EDC10' 'MEBU2' 'EDC11'\n",
      " 'HOWABU' 'EDC14' 'EDC146' 'EDC51' 'EDC74' 'EDC91' 'EDC94' 'EDC99' '63'\n",
      " 'EDC129' '48' '76' 'EDC142' '73' 'EDC137' 'EDC133' 'EDC131' '79' 'EDC29'\n",
      " '82' 'EDC28' 'EDC116' 'EDC121' '86' 'EDC106' 'EDC147' '102' 'L.MDGR'\n",
      " 'EDC52' 'EDC64' 'EDC48' 'EDC103' 'GDR245' 'EDC104' 'SR5' 'EDC115' 'BO3'\n",
      " 'LL7' 'EDC105' 'EDC45' 'EDC33' 'EDC34' 'EDC49' 'EDC57' 'EDC86' 'GDR284'\n",
      " 'EDC112' 'EDC117' 'EDC102' 'USSR50' 'GDR113' 'WGER031' 'EDC8' 'WGER030'\n",
      " 'EDC5' 'GDR160' 'EDC44' 'EDC43' 'EDC21' 'GDR023' 'ARKO3' 'EDC56' 'TROLGR'\n",
      " 'GBELT3' 'EDC41' 'EDC13' 'EDC37' 'EDC50' 'EDC3' 'EDC6' 'EDC22' 'WARNEM'\n",
      " 'MEBU1' 'ARKO4' 'USEDOM' 'EDC123' 'EDC127' 'EDC128' 'XV1' 'LL3A' 'EDC141'\n",
      " 'EDC30' 'EB1' 'LTKIEL' 'GTBEL3' 'BHOLM1' 'BHOLM4' 'EDC87' 'EDC97'\n",
      " 'EDC108' 'F81' 'EDC111' 'EDC95' 'EDC31' 'EDC79' 'EDC76' 'EDC77' 'EDC67'\n",
      " 'EDC62' 'LUEBU' 'WGER004' 'WGER047' 'WGER007' 'WGER059' 'BY31' 'WGER066'\n",
      " 'WGER068' 'WGER072' 'WGER077' 'WGER079' 'WGER081' 'WGER083' 'WGER089'\n",
      " 'WGER091' 'WGER086' 'WGER085' 'WGER078' 'WGER069' 'WGER065' 'WGER061'\n",
      " 'WGER058' 'WGER045' 'WGER041' 'WGER044' 'WGER039' 'WGER033' 'WGER032'\n",
      " 'WGER053' 'WGER075' 'WGER090' 'WGER095' 'WGER097' 'WGER099' 'WGER100'\n",
      " 'WGER098' 'WGER096' 'WGER092' 'WGER087' 'WGER084' 'WGER082' 'WGER080'\n",
      " 'WGER067' 'WGER070' 'WGER074' 'WGER071' 'WGER064' 'WGER038' 'WGER034'\n",
      " 'WGER036' 'WGER055' 'WGER054' 'WGER049' 'WGER048' 'WGER043' 'WGER037'\n",
      " 'PE' 'PW' 'EE22' 'N8' 'EE17' 'B18R' 'B12R' 'K' 'M' 'SW3' '46a' '65' 'LT4'\n",
      " 'LT7' '46A' 'LT10' 'LT12A' 'EDC132' 'USSR06' 'BY15B' 'USSR46' 'USSR03'\n",
      " 'USSR12' 'USSR13' 'USSR14' 'USSR15' 'USSR18' 'USSR19' 'EDC143' 'USSR05'\n",
      " 'USSR08' 'USSR24' 'EDC144' 'USSR10' 'USSR11' 'USSR27' 'USSR28' 'USSR32'\n",
      " 'USSRK1' 'USSRR1' 'USSRR6' 'USSR45' 'USSR25' 'USSR16' 'USSR22' 'USSR23'\n",
      " 'USSR31' 'USSR33' 'USSR34' 'USSR35' 'RU06' 'RU46' 'RU50' 'RU27' 'RU28'\n",
      " 'RU31' 'RU33' 'RU34' 'RU35' 'RU3' 'RU12' 'RU13' 'LV119' 'BMP61' '40A'\n",
      " '45A' '23' '24' 'Kullen' 'Hesselö' 'Kattegat SW' 'Asnaes rev'\n",
      " 'Halskov rev' 'Langeland belt' 'Femern belt' 'GEDSER ODDE' 'Möen'\n",
      " 'SOUND-S' 'SOUNDB' 'BORNHOLM' 'KLINT' 'Kattegat-413' 'GDR012' 'GDR030'\n",
      " 'GDR152' 'GDR162' 'GDR-OB' 'F64' 'US5B' 'BS' 'F2' 'LL11' 'GDR271'\n",
      " 'BCS315' 'GDR010' 'GNIBEN' 'S.MDGR' 'FLADEN' 'GF6' 'GDR046' 'GDR140'\n",
      " 'GDR355' 'GDR357' 'GDR350' 'GDR033' 'GDR041' 'GDR121' 'GDR200' 'GDR202'\n",
      " 'GDR220' 'GDR233' 'GDR260' 'GDR282' 'GDR285' '3' '25' '71' '00076A'\n",
      " 'GDR001' 'GDR034' 'GDR242' 'GDR253' 'GDR280' 'GDR302' 'KB' 'OLK2' 'LOV3'\n",
      " 'LOVR1' 'F75' 'CVI' 'W19A' 'LAV4' 'F16' 'LOV2' 'F45A' 'F45B' 'F44' 'F41'\n",
      " 'F40' 'LEDAM1' 'LL17' 'WGER040' 'WGER042' 'WGER003' 'WGER046' 'WGER062'\n",
      " 'WGER063' 'WGER057' 'OKG34' 'WGER035' 'WGER006' 'WGER056' 'WGER050'\n",
      " 'BODDEN' 'WGER001' 'WGER002' 'RUDEN' 'WGER052' 'WGER005' 'WGER051'\n",
      " 'WGER060' 'WGER073' 'WGER076' 'WGER094' 'WGER093' 'WGER088' 'KATT4' nan\n",
      " 'BHOLM1/B' 'KATT6' 'KATT5' 'LT46A' 'LT65' 'LK7' 'BY9' 'LV120'\n",
      " 'THE SOUND-S' 'The Sound-N A' '?7' 'KOTN12' 'DARSS2' 'N5' 'JML' 'LT7R'\n",
      " 'RU16' '45-A' 'RU102' 'RU150' 'RU307' 'RU310' 'RU311' 'Ru313' 'RU210'\n",
      " 'RU211' 'RU201' 'RU205' 'RU207' 'RU208' 'RU209' 'LT6' 'MYREFJ' 'SWR36'\n",
      " 'SWR35' 'SWF135' 'C14' 'A5' '23b' 'LOV02' 'ODER' 'EE38' 'EE23' 'LT 65'\n",
      " 'SWS36' 'SWF101' 'SWR3' 'SWS2' 'SWB2' 'OBANK' 'ADLERG' 'K4' 'BSH4A'\n",
      " 'LT6B' 'RU152' 'RU155' 'RU95' 'RU96' 'RU129' 'LA3' 'LA7' 'LA8' 'LA13'\n",
      " 'LA2' 'RU' 'The Sound-S' 'LT20' 'LT64A1' 'Asnæs Rev' 'Femern bælt '\n",
      " 'Gedser odde' 'Hesselø' 'Kattegat SW ' 'CV1' 'Langeland bælt' 'Møen'\n",
      " 'P140 ' 'P5 ' 'P39 ' 'B15 ' 'K6 ' 'M3 ' 'P16 ' 'Ł7 ' 'P116 ' 'ZN2 '\n",
      " 'P110 ' 'ZN4 ' 'SW7' 'TROLGR16' 'P2 ' 'P3 ' 'SW3 ' 'B13 ' 'P1 ' 'P14 '\n",
      " 'KO ' 'WITTOW' 'LTKIEL2' 'LT64A2' 'BMPK4']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['station_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548633f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eae7e5",
   "metadata": {},
   "source": [
    "#TODO : Helcom SEQUENCE is 'SEQUENCE: SEQUENCE NUMBER CONSISTS OF YEAR AND SEQUENTAL SAMPLING NUMBER WHICH IS THE SAME AS IN THE KEY (7 LAST CHARACTERS OF THE KEY)   ' which is different to Profile ID or Transect ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb378b1",
   "metadata": {},
   "source": [
    "### Profile ID, Transect ID or Sequence ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23069215",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Profile ID, Transect ID or Sequence ID is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abe1c5",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variable: ``Profile or transect ID``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a497c",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include Profile ID, Transect ID or Sequence ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "d20c5dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2012041\n",
       "1        2012041\n",
       "2        2012041\n",
       "3        2012041\n",
       "4        2012040\n",
       "          ...   \n",
       "14888    2018021\n",
       "14889    2018022\n",
       "14890    2018022\n",
       "14891    2018022\n",
       "14892    2018001\n",
       "Name: SEQUENCE, Length: 14873, dtype: int64"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['biota']['SEQUENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "433cdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapProfileIdCB(Callback):\n",
    "    \"Remap Profile ID to MARIS format.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapProfileIdCB with no specific parameters.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Iterate through all DataFrames in the transformer object and remap 'SEQUENCE' to 'profile_or_transect_id'.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._remap_profile_id(tfm.dfs[grp])\n",
    "\n",
    "    def _remap_profile_id(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap 'SEQUENCE' column to 'profile_or_transect_id' in the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['profile_or_transect_id'] = df['SEQUENCE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "95f09821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2012003 2012004 2012005 ...  201806  201807  201808]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                         \n",
    "                            LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),                           \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['seawater']['profile_or_transect_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb97f00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "### Sediment slice position (top and bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb47624",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: Top and Bottom is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533568d8",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Top`` and ``Bottom``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3358f02",
   "metadata": {},
   "source": [
    ">  MARIS NetCDF4 format does not include sediment slice top and bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the RemapSedSliceTopBottomCB with no specific parameters.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        if 'sediment' in tfm.dfs:\n",
    "            self._remap_sediment_slice(tfm.dfs['sediment'])\n",
    "\n",
    "    def _remap_sediment_slice(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Remap 'LOWSLI' column to 'bottom' and 'UPPSLI' column to 'top' in the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['bottom'] = df['LOWSLI']\n",
    "        df['top'] = df['UPPSLI']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15.0\n",
      "1    20.0\n",
      "2     0.0\n",
      "3     2.0\n",
      "4     4.0\n",
      "Name: top, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB()\n",
    "                            ])\n",
    "\n",
    "print(tfm()['sediment']['top'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96b18f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "### Dry to wet ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64f432",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variable: DW% is not included.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0fd19",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Dry/wet ratio``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735dd22",
   "metadata": {},
   "source": [
    "HELCOM Description:\n",
    "\n",
    "**Sediment:**\n",
    "1. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT.\n",
    "2. VALUE_Bq/kg: Measured radioactivity concentration in Bq/kg dry wt. in scientific format(e.g. 123 = 1.23E+02, 0.076 = 7.6E-02)\n",
    "\n",
    "**Biota:**\n",
    "1. WEIGHT: Average weight (in g) of specimen in the sample\n",
    "2. DW%: DRY WEIGHT AS PERCENTAGE (%) OF FRESH WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDryWetRatio(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the LookupDryWetRatio callback with no specific parameters.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: 'Transformer'):\n",
    "        \"\"\"\n",
    "        Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Apply dry-wet ratio conversion and formatting to the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to modify.\n",
    "        \"\"\"\n",
    "        df['dry_wet_ratio'] = df['DW%']\n",
    "        # Convert 'DW%' = 0% to NaN.\n",
    "        df.loc[df['dry_wet_ratio'] == 0, 'dry_wet_ratio'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n",
      "0    18.453\n",
      "1    18.453\n",
      "2    18.453\n",
      "3    18.453\n",
      "4    18.458\n",
      "Name: dry_wet_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                    \n",
    "\n",
    "print(tfm.dfs['biota']['dry_wet_ratio'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02488c00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3541d",
   "metadata": {},
   "source": [
    "### Capture Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c1fb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a07ea",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd85aa4",
   "metadata": {},
   "source": [
    "Use decimal degree coordinates if available; otherwise, convert from degree-minute format to decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "00410917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Columns of interest coordinates\n",
    "coi_coordinates = {\n",
    "    'seawater': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    },\n",
    "    'biota': {\n",
    "        'lon_d': 'LONGITUDE dddddd',\n",
    "        'lat_d': 'LATITUDE dddddd',\n",
    "        'lon_m': 'LONGITUDE ddmmmm',\n",
    "        'lat_m': 'LATITUDE ddmmmm'\n",
    "    },\n",
    "    'sediment': {\n",
    "        'lon_d': 'LONGITUDE (dddddd)',\n",
    "        'lat_d': 'LATITUDE (dddddd)',\n",
    "        'lon_m': 'LONGITUDE (ddmmmm)',\n",
    "        'lat_m': 'LATITUDE (ddmmmm)'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ce34364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def ddmmmm2dddddd(ddmmmm):\n",
    "    \"\"\"\n",
    "    Convert coordinates from 'ddmmmm' format to 'dddddd' format.\n",
    "    \n",
    "    Args:\n",
    "        ddmmmm (float): Coordinates in 'ddmmmm' format where 'dd' are degrees and 'mmmm' are minutes.\n",
    "    \n",
    "    Returns:\n",
    "        float: Coordinates in 'dddddd' format.\n",
    "    \"\"\"\n",
    "    # Split into degrees and minutes\n",
    "    mins, degs = modf(ddmmmm)\n",
    "    # Convert minutes to decimal\n",
    "    mins = mins * 100\n",
    "    # Convert to 'dddddd' format\n",
    "    return round(int(degs) + (mins / 60), 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "bbabbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class FormatCoordinates(Callback):\n",
    "    \"\"\"\n",
    "    Format coordinates for MARIS. Converts coordinates from 'ddmmmm' to 'dddddd' format if needed.\n",
    "\n",
    "    Args:\n",
    "        coi (dict): Dictionary containing column names for longitude and latitude in various formats.\n",
    "        fn_convert_cor (Callable): Function to convert coordinates from 'ddmmmm' to 'dddddd' format.\n",
    "    \"\"\"\n",
    "    def __init__(self, coi: dict, fn_convert_cor: Callable[[float], float]):\n",
    "        \"\"\"\n",
    "        Initialize the FormatCoordinates callback.\n",
    "\n",
    "        Args:\n",
    "            coi (dict): Column names mapping for coordinates.\n",
    "            fn_convert_cor (Callable): Function to convert coordinates.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"\n",
    "        Apply formatting to coordinates in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            self._format_coordinates(tfm.dfs[grp], grp)\n",
    "\n",
    "    def _format_coordinates(self, df: pd.DataFrame, grp: str):\n",
    "        \"\"\"\n",
    "        Format coordinates in the DataFrame for a specific group.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to modify.\n",
    "            grp (str): Group name to determine column names.\n",
    "        \"\"\"\n",
    "        lon_col_d = self.coi[grp]['lon_d']\n",
    "        lat_col_d = self.coi[grp]['lat_d']\n",
    "        lon_col_m = self.coi[grp]['lon_m']\n",
    "        lat_col_m = self.coi[grp]['lat_m']\n",
    "        \n",
    "        # Define condition where 'dddddd' format is not available or is zero\n",
    "        condition = (\n",
    "            (df[lon_col_d].isna() | (df[lon_col_d] == 0)) |\n",
    "            (df[lat_col_d].isna() | (df[lat_col_d] == 0))\n",
    "        )\n",
    "        \n",
    "        # Convert coordinates using the provided conversion function where needed\n",
    "        df['lon'] = np.where(\n",
    "            condition,\n",
    "            df[lon_col_m].apply(self.fn_convert_cor),\n",
    "            df[lon_col_d]\n",
    "        )\n",
    "        \n",
    "        df['lat'] = np.where(\n",
    "            condition,\n",
    "            df[lat_col_m].apply(self.fn_convert_cor),\n",
    "            df[lat_col_d]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14873 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7fc59",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754289f1",
   "metadata": {},
   "source": [
    "### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e413",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*NetCDF4 format variables: ``lon``  and ``lat``*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f808d23",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Open Refine format variables: ``Longitude decimal`` and ``Latitude decimal``.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n",
      "             lat        lon\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14873 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),    \n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['biota'][['lat','lon']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf2efc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "### Review DFS and TFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "d36a0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_review=tfm.dfs_dropped['seawater']\n",
    "biota_review=tfm.dfs_dropped['biota']\n",
    "sediment_review=tfm.dfs_dropped['sediment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f71af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "14c77306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
       "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
       "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
       "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y',\n",
       "       'time', 'uncertainty', 'value', 'unit', 'detection_limit',\n",
       "       'data_provider_sample_id', 'station_id', 'profile_or_transect_id',\n",
       "       'lon', 'lat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['seawater'].columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17f6685",
   "metadata": {},
   "source": [
    "### Rename columns of interest for NetCDF or Open Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af441203",
   "metadata": {},
   "source": [
    "> Column names are standardized to MARIS NetCDF format (i.e. PEP8 ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "23653799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).\n",
    "def get_renaming_rules(encoding_type='netcdf'):\n",
    "    vars = cdl_cfg()['vars']\n",
    "    \n",
    "    if encoding_type == 'netcdf':\n",
    "        return {\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'lat': vars['defaults']['lat']['name'],\n",
    "                'lon': vars['defaults']['lon']['name'],\n",
    "                'time': vars['defaults']['time']['name'],\n",
    "                'NUCLIDE': 'nuclide',\n",
    "                'detection_limit': vars['suffixes']['detection_limit']['name'],\n",
    "                'unit': vars['suffixes']['unit']['name'],\n",
    "                'value': 'value',\n",
    "                'uncertainty': vars['suffixes']['uncertainty']['name'],\n",
    "                'counting_method': vars['suffixes']['counting_method']['name'],\n",
    "                'sampling_method': vars['suffixes']['sampling_method']['name'],\n",
    "                'preparation_method': vars['suffixes']['preparation_method']['name']\n",
    "            },\n",
    "            ('seawater',): {\n",
    "                # SEAWATER\n",
    "                'SALIN': vars['suffixes']['salinity']['name'],\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                #'FILT': vars['suffixes']['filtered']['name'], Need to fix\n",
    "                'TTEMP': vars['suffixes']['temperature']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "\n",
    "            },\n",
    "            ('biota',): {\n",
    "                # BIOTA\n",
    "                'SDEPTH': vars['defaults']['smp_depth']['name'],\n",
    "                'species': vars['bio']['species']['name'],\n",
    "                'body_part': vars['bio']['body_part']['name'],\n",
    "                'bio_group': vars['bio']['bio_group']['name']\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sed_type': vars['sed']['sed_type']['name'],\n",
    "                'TDEPTH': vars['defaults']['tot_depth']['name'],\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    elif encoding_type == 'openrefine':\n",
    "        return {\n",
    "            ('seawater', 'biota', 'sediment'): {\n",
    "                # DEFAULT\n",
    "                'latitude': 'lat',\n",
    "                'longitude': 'lon',\n",
    "                'begperiod': 'time',\n",
    "                'endperiod': 'endperiod',\n",
    "                'nuclide_id': 'NUCLIDE',\n",
    "                'detection': 'detection_limit',\n",
    "                'unit_id': 'unit',\n",
    "                'activity': 'value',\n",
    "                'uncertaint': 'uncertainty',\n",
    "                'vartype': 'vartype',\n",
    "                'rangelow': 'rangelow',\n",
    "                'rangeupp': 'rangeupp',\n",
    "                'rl_detection': 'rl_detection',\n",
    "                'ru_detection': 'ru_detection',\n",
    "                'freq': 'freq',\n",
    "                'sampdepth': 'SDEPTH',\n",
    "                'samparea': 'samparea',\n",
    "                'salinity': 'SALIN',\n",
    "                'temperatur': 'TTEMP',\n",
    "                'filtered': 'FILT',\n",
    "                'oxygen': 'oxygen',\n",
    "                'sampquality': 'sampquality',\n",
    "                'station': 'station',\n",
    "                'samplabcode': 'samplabcode',\n",
    "                'profile': 'profile',\n",
    "                'transect': 'transect',\n",
    "                'IODE_QualityFlag': 'IODE_QualityFlag',\n",
    "                'totdepth': 'TDEPTH',\n",
    "                'counting_method': 'counmet_id',\n",
    "                'sampling_method': 'sampmet_id',\n",
    "                'preparation_method': 'prepmet_id',\n",
    "                'sampnote': 'sampnote',\n",
    "                'measurenote': 'measurenote'\n",
    "            },\n",
    "            ('seawater',): {\n",
    "                # SEAWATER\n",
    "                'volume': 'volume',\n",
    "                'filtpore': 'filtpore',\n",
    "                'acid': 'acid'\n",
    "            },\n",
    "            ('biota',): {\n",
    "                # BIOTA\n",
    "                'TaxonRepName': 'TaxonRepName',\n",
    "                'species_id': 'species',\n",
    "                'bodypar_id': 'body_part',\n",
    "                'drywt': 'drywt',\n",
    "                'wetwt': 'wetwt',\n",
    "                'percentwt': 'percentwt',\n",
    "                'drymet_id': 'drymet_id'\n",
    "            },\n",
    "            ('sediment',): {\n",
    "                # SEDIMENT\n",
    "                'sedtype_id': 'sed_type',\n",
    "                'sedtrap': 'sedtrap',\n",
    "                'sliceup': 'sliceup',\n",
    "                'slicedown': 'slicedown',\n",
    "                'SedRepName': 'SedRepName',\n",
    "                'drywt': 'drywt',\n",
    "                'wetwt': 'wetwt',\n",
    "                'percentwt': 'percentwt',\n",
    "                'drymet_id': 'drymet_id'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid encoding_type provided. Please use 'netcdf' or 'openrefine'.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "ec18f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'lon', 'tot_depth', 'lat', 'sed_type', 'ac228_dl', 'ag110m_dl',\n",
       "       'am241_dl', 'ba140_dl', 'be7_dl',\n",
       "       ...\n",
       "       'sb124', 'sb125', 'sr90', 'th228', 'th232', 'th234', 'tl208', 'u235',\n",
       "       'zn65', 'zr95'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['sediment'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "ec96d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SelectAndRenameColumnCB(Callback):\n",
    "    \"\"\"\n",
    "    A callback to select and rename columns in a DataFrame based on provided renaming rules\n",
    "    for a specified encoding type. It also prints renaming rules that were not applied\n",
    "    because their keys were not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn_renaming_rules, encoding_type='netcdf', verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize the SelectAndRenameColumnCB callback.\n",
    "\n",
    "        Args:\n",
    "            fn_renaming_rules (function): A function that returns a dictionary of renaming rules.\n",
    "            encoding_type (str): The encoding type ('netcdf' or 'openrefine') to determine which renaming rules to use.\n",
    "            verbose (bool): Whether to print out renaming rules that were not applied.\n",
    "        \"\"\"\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        \"\"\"\n",
    "        Apply column selection and renaming to DataFrames in the transformer, and identify unused rules.\n",
    "\n",
    "        Args:\n",
    "            tfm (Transformer): The transformer object containing DataFrames.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            renaming_rules = self.fn_renaming_rules(self.encoding_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error fetching renaming rules: {e}\")\n",
    "            return\n",
    "\n",
    "        for group in tfm.dfs.keys():\n",
    "            # Get relevant renaming rules for the current group\n",
    "            group_rules = self._get_group_rules(renaming_rules, group)\n",
    "\n",
    "            if not group_rules:\n",
    "                continue\n",
    "\n",
    "            # Apply renaming rules and track keys not found in the DataFrame\n",
    "            df = tfm.dfs[group]\n",
    "            df, not_found_keys = self._apply_renaming(df, group_rules)\n",
    "            tfm.dfs[group] = df\n",
    "            \n",
    "            # Print any renaming rules that were not used\n",
    "            if not_found_keys and self.verbose:\n",
    "                print(f\"\\nGroup '{group}' has the following renaming rules not applied:\")\n",
    "                for old_col in not_found_keys:\n",
    "                    print(f\"Key '{old_col}' from renaming rules was not found in the DataFrame.\")\n",
    "\n",
    "    def _get_group_rules(self, renaming_rules, group):\n",
    "        \"\"\"\n",
    "        Retrieve and merge renaming rules for the specified group based on the encoding type.\n",
    "\n",
    "        Args:\n",
    "            renaming_rules (dict): Dictionary of all renaming rules.\n",
    "            group (str): Group name to filter rules.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of renaming rules applicable to the specified group.\n",
    "        \"\"\"\n",
    "        relevant_rules = [rules for key, rules in renaming_rules.items() if group in key]\n",
    "        merged_rules = {}\n",
    "        for rules in relevant_rules:\n",
    "            merged_rules.update(rules)\n",
    "        return merged_rules\n",
    "\n",
    "    def _apply_renaming(self, df, rename_rules):\n",
    "        \"\"\"\n",
    "        Select columns based on renaming rules and apply renaming, only for existing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame to modify.\n",
    "            rename_rules (dict): Dictionary of column renaming rules.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - The DataFrame with columns renamed and filtered.\n",
    "                - A set of column names from renaming rules that were not found in the DataFrame.\n",
    "        \"\"\"\n",
    "        existing_columns = set(df.columns)\n",
    "        valid_rules = {old_col: new_col for old_col, new_col in rename_rules.items() if old_col in existing_columns}\n",
    "\n",
    "        # Ensure that columns to keep includes both existing and valid new columns\n",
    "        columns_to_keep = set(valid_rules.keys()).union(valid_rules.values())\n",
    "        columns_to_keep = columns_to_keep.intersection(existing_columns)\n",
    "        df = df[list(columns_to_keep)]\n",
    "        \n",
    "        # Apply renaming\n",
    "        df.rename(columns=valid_rules, inplace=True)\n",
    "\n",
    "        # Determine which keys were not found\n",
    "        not_found_keys = set(rename_rules.keys()) - existing_columns\n",
    "        return df, not_found_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "9a4a8682-672f-4188-9091-821b727b4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 'seawater' has the following renaming rules not applied:\n",
      "Key 'preparation_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampling_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'counting_method' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'sediment' has the following renaming rules not applied:\n",
      "Key 'preparation_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampling_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'counting_method' from renaming rules was not found in the DataFrame.\n",
      "\n",
      "Group 'biota' has the following renaming rules not applied:\n",
      "Key 'preparation_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'sampling_method' from renaming rules was not found in the DataFrame.\n",
      "Key 'counting_method' from renaming rules was not found in the DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seawater':        smp_depth  _sal        time nuclide  tot_depth  _temp      lon  value  \\\n",
       " 0            0.0   NaN  1337731200   cs137        NaN    NaN  29.3333    5.3   \n",
       " 1           29.0   NaN  1337731200   cs137        NaN    NaN  29.3333   19.9   \n",
       " 2            0.0   NaN  1339891200   cs137        NaN    NaN  23.1500   25.5   \n",
       " 3            0.0   NaN  1337817600   cs137        NaN    NaN  27.9833   17.0   \n",
       " 4           39.0   NaN  1337817600   cs137        NaN    NaN  27.9833   22.2   \n",
       " ...          ...   ...         ...     ...        ...    ...      ...    ...   \n",
       " 20313        4.0   7.5  1434931200    sr90       12.0    NaN  14.2000    6.6   \n",
       " 20314        4.0   7.7  1435017600    sr90       20.0    NaN  14.6672    6.9   \n",
       " 20315        4.0   7.8  1435017600    sr90       17.0    NaN  14.3342    6.8   \n",
       " 20316        4.0   8.4  1435104000    sr90       47.0    NaN  13.5002    7.3   \n",
       " 20317       45.0  15.9  1435104000    sr90       47.0    NaN  13.5002    5.5   \n",
       " \n",
       "            lat    _unc  _unit  _dl  \n",
       " 0      60.0833  1.6960      1    1  \n",
       " 1      60.0833  3.9800      1    1  \n",
       " 2      59.4333  5.1000      1    1  \n",
       " 3      60.2500  4.9300      1    1  \n",
       " 4      60.2500  3.9960      1    1  \n",
       " ...        ...     ...    ...  ...  \n",
       " 20313  54.0068  0.4950      1    1  \n",
       " 20314  54.4995  0.5175      1    1  \n",
       " 20315  54.7505  0.5100      1    1  \n",
       " 20316  54.9165  0.5475      1    1  \n",
       " 20317  54.9165  0.4180      1    1  \n",
       " \n",
       " [20242 rows x 12 columns],\n",
       " 'sediment':              time nuclide  tot_depth      lon   value      lat    _unc  \\\n",
       " 0      1339891200   ra226       71.0  24.0000   35.00  59.6667   9.100   \n",
       " 1      1339891200   ra226       71.0  24.0000   36.00  59.6667   7.920   \n",
       " 2      1344556800   ra226       23.0  28.8433   38.00  59.8600   9.120   \n",
       " 3      1344556800   ra226       23.0  28.8433   36.00  59.8600   9.000   \n",
       " 4      1344556800   ra226       23.0  28.8433   30.00  59.8600   6.900   \n",
       " ...           ...     ...        ...      ...     ...      ...     ...   \n",
       " 37342  1465430400   cs137      171.0  21.0830    1.20  59.0360   0.144   \n",
       " 37343  1465430400   cs137      171.0  21.0830    0.79  59.0360   0.158   \n",
       " 37344  1464480000   cs137      131.0  19.7297  512.00  61.0667  56.320   \n",
       " 37345  1464480000   cs137      131.0  19.7297  527.00  61.0667  33.201   \n",
       " 37346  1464480000   cs137      131.0  19.7297  684.00  61.0667  34.200   \n",
       " \n",
       "        sed_type  _unit  _dl  \n",
       " 0             0      4    1  \n",
       " 1             0      4    1  \n",
       " 2             0      4    1  \n",
       " 3             0      4    1  \n",
       " 4             0      4    1  \n",
       " ...         ...    ...  ...  \n",
       " 37342        50      4    1  \n",
       " 37343        50      4    1  \n",
       " 37344        59      4    1  \n",
       " 37345        51      4    1  \n",
       " 37346        50      4    1  \n",
       " \n",
       " [37089 rows x 10 columns],\n",
       " 'biota':        smp_depth        time nuclide        lon  body_part       value  \\\n",
       " 0            NaN  1348358400   cs134  12.316667         52    0.010140   \n",
       " 1            NaN  1348358400     k40  12.316667         52  135.300000   \n",
       " 2            NaN  1348358400    co60  12.316667         52    0.013980   \n",
       " 3            NaN  1348358400   cs137  12.316667         52    4.338000   \n",
       " 4            NaN  1348358400   cs134  12.316667         52    0.009614   \n",
       " ...          ...         ...     ...        ...        ...         ...   \n",
       " 14888       61.0  1519603200   ra226  19.000000          3    0.043000   \n",
       " 14889       65.0  1518480000     k40  15.500000         52   98.000000   \n",
       " 14890       65.0  1518480000   cs137  15.500000         52    3.690000   \n",
       " 14891       65.0  1518480000   ra226  15.500000         52    0.049000   \n",
       " 14892        NaN  1538524800   cs137  19.433300         52    0.830000   \n",
       " \n",
       "              lat      _unc  species  _unit  _dl  bio_group  \n",
       " 0      54.283333       NaN       99      5    2          4  \n",
       " 1      54.283333  4.830210       99      5    1          4  \n",
       " 2      54.283333       NaN       99      5    2          4  \n",
       " 3      54.283333  0.150962       99      5    1          4  \n",
       " 4      54.283333       NaN       99      5    2          4  \n",
       " ...          ...       ...      ...    ...  ...        ...  \n",
       " 14888  54.583300  0.011008      191      5    1          4  \n",
       " 14889  54.333300  1.097600      191      5    1          4  \n",
       " 14890  54.333300  0.078597      191      5    1          4  \n",
       " 14891  54.333300  0.007007      191      5    1          4  \n",
       " 14892  54.363900  0.229993      247      5    1          4  \n",
       " \n",
       " [14873 rows x 12 columns]}"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf', verbose = True),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "\n",
    "#print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f7682",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7efe2d",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59b263",
   "metadata": {},
   "source": [
    "Convert data from long to wide and rename columns to comply with NetCDF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "918ee54c-19aa-4f21-b2a7-8f3f182f3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns=['nuclide'], values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        df.index.name = 'org_index'\n",
    "        df=df.reset_index()\n",
    "        idx = list(set(df.columns) - set(self.columns + derived_coi + self.values))\n",
    "        \n",
    "        # Create a fill_value to replace NaN values in the columns used as the index in the pivot table.\n",
    "        # Check if num_fill_value is already in the dataframe index values. If num_fill_value already exists\n",
    "        # then increase num_fill_value by 1 until a value is found for num_fill_value that is not in the dataframe. \n",
    "        num_fill_value = -999\n",
    "        while (df[idx] == num_fill_value).any().any():\n",
    "            num_fill_value += 1\n",
    "        # Fill in nan values for each col found in idx. \n",
    "        for col in idx:   \n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                fill_value = num_fill_value\n",
    "            if pd.api.types.is_string_dtype(df[col]):\n",
    "                fill_value = 'NOT AVAILABLE'\n",
    "                \n",
    "            df[col]=df[col].fillna(fill_value)\n",
    "\n",
    "        pivot_df=df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "        \n",
    "\n",
    "        # Replace fill_value  with  np.nan\n",
    "        pivot_df[idx]=pivot_df[idx].replace({'NOT AVAILABLE': np.nan,\n",
    "                                             num_fill_value : np.nan})\n",
    "        # Set the index to be the org_index\n",
    "        pivot_df = pivot_df.set_index('org_index')\n",
    "                \n",
    "        return (pivot_df)\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp] = self.pivot(tfm.dfs[grp])\n",
    "            tfm.dfs[grp].columns = self.renamed_cols(tfm.dfs[grp].columns)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "0a330905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                time  smp_depth      lon  body_part  species      lat  \\\n",
      "org_index                                                               \n",
      "7824       442540800        0.0  20.0000          7       50  56.0000   \n",
      "7826       442540800        0.0  20.0000          7       99  56.0000   \n",
      "7825       442540800        0.0  20.0000         52       50  56.0000   \n",
      "7827       442540800        0.0  20.0000         52       99  56.0000   \n",
      "5103       448070400        0.0  12.9083         54       96  55.7633   \n",
      "\n",
      "           bio_group  ac228_dl  ag108m_dl  ag110m_dl  ...  sr89  sr90  tc99  \\\n",
      "org_index                                             ...                     \n",
      "7824               4       NaN        NaN        NaN  ...   NaN   2.0   NaN   \n",
      "7826               4       NaN        NaN        NaN  ...   NaN   3.4   NaN   \n",
      "7825               4       NaN        NaN        NaN  ...   NaN   NaN   NaN   \n",
      "7827               4       NaN        NaN        NaN  ...   NaN   NaN   NaN   \n",
      "5103              11       NaN        NaN        NaN  ...   NaN   NaN   NaN   \n",
      "\n",
      "           te129m  th228  th232  tl208  u235  zn65  zr95  \n",
      "org_index                                                 \n",
      "7824          NaN    NaN    NaN    NaN   NaN   NaN   NaN  \n",
      "7826          NaN    NaN    NaN    NaN   NaN   NaN   NaN  \n",
      "7825          NaN    NaN    NaN    NaN   NaN   NaN   NaN  \n",
      "7827          NaN    NaN    NaN    NaN   NaN   NaN   NaN  \n",
      "5103          NaN    NaN    NaN    NaN   NaN  35.0   NaN  \n",
      "\n",
      "[5 rows x 211 columns]\n",
      "                                                    seawater  sediment  biota\n",
      "Number of rows in dfs                                  20318     37347  14893\n",
      "Number of rows in tfm.dfs                              20242     37089  14873\n",
      "Number of dropped rows                                    76       258     20\n",
      "Number of rows in tfm.dfs + Number of dropped rows     20318     37347  14893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            CompareDfsAndTfm(dfs)\n",
    "\n",
    "                            ])\n",
    "tfm()\n",
    "print(tfm.dfs['biota'].head())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "3ab81ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater_dfs_review=tfm.dfs['seawater']\n",
    "biota_dfs_review=tfm.dfs['biota']\n",
    "sediment_dfs_review=tfm.dfs['sediment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c700a05",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba0e40a",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Convert nuclide names to lowercase and strip any trailing spaces.',\n",
       " 'Remap radionuclide names to MARIS radionuclide names.',\n",
       " 'Encode time as `int` representing seconds since xxx',\n",
       " 'Convert from relative error % to uncertainty of activity unit.',\n",
       " \"Sanitize value by removing blank entries and ensuring the 'value' column is retained.\",\n",
       " '\\n    Biota species remapped to MARIS db:\\n        CARD EDU: Cerastoderma edule\\n        LAMI SAC: Saccharina latissima\\n        PSET MAX: Scophthalmus maximus\\n        STIZ LUC: Sander luciopercas\\n    ',\n",
       " \"\\n    Update bodypart id based on MARIS dbo_bodypar.xlsx:\\n        - 3: 'Whole animal eviscerated without head',\\n        - 12: 'Viscera',\\n        - 8: 'Skin'\\n    \",\n",
       " '\\n    Update biogroup id based on MARIS dbo_species.xlsx\\n    ',\n",
       " '\\n    Update sediment id based on MARIS dbo_sedtype.xlsx.\\n    ',\n",
       " 'Remap value type to MARIS format.',\n",
       " \"\\n    Remap 'KEY' column to 'data_provider_sample_id' in each DataFrame.\\n    \",\n",
       " 'Remap Station ID to MARIS format.',\n",
       " 'Remap Profile ID to MARIS format.',\n",
       " 'Remap Sediment slice top and bottom to MARIS format.',\n",
       " 'Lookup dry-wet ratio and format for MARIS.',\n",
       " \"\\n    Format coordinates for MARIS. Converts coordinates from 'ddmmmm' to 'dddddd' format if needed.\\n\\n    Args:\\n        coi (dict): Dictionary containing column names for longitude and latitude in various formats.\\n        fn_convert_cor (Callable): Function to convert coordinates from 'ddmmmm' to 'dddddd' format.\\n    \",\n",
       " 'Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator.',\n",
       " '\\n    A callback to select and rename columns in a DataFrame based on provided renaming rules\\n    for a specified encoding type. It also prints renaming rules that were not applied\\n    because their keys were not found in the DataFrame.\\n    ',\n",
       " 'Convert data from long to wide with renamed columns.']"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            SanitizeValue(coi_val),                       \n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                            ReshapeLongToWide(), \n",
    "                            #CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "\n",
    "# Transform\n",
    "tfm()\n",
    "# Check transformation logs\n",
    "tfm.logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82526cc",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "ac6ba4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2018-12-14T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert nuclide names to lowercase and strip any trailing spaces., Remap radionuclide names to MARIS radionuclide names., Encode time as `int` representing seconds since xxx, Convert from relative error % to uncertainty of activity unit., Sanitize value by removing blank entries and ensuring the 'value' column is retained., \\n    Biota species remapped to MARIS db:\\n        CARD EDU: Cerastoderma edule\\n        LAMI SAC: Saccharina latissima\\n        PSET MAX: Scophthalmus maximus\\n        STIZ LUC: Sander luciopercas\\n    , \\n    Update bodypart id based on MARIS dbo_bodypar.xlsx:\\n        - 3: 'Whole animal eviscerated without head',\\n        - 12: 'Viscera',\\n        - 8: 'Skin'\\n    , \\n    Update biogroup id based on MARIS dbo_species.xlsx\\n    , \\n    Update sediment id based on MARIS dbo_sedtype.xlsx.\\n    , Remap value type to MARIS format., \\n    Remap 'KEY' column to 'data_provider_sample_id' in each DataFrame.\\n    , Remap Station ID to MARIS format., Remap Profile ID to MARIS format., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \\n    Format coordinates for MARIS. Converts coordinates from 'ddmmmm' to 'dddddd' format if needed.\\n\\n    Args:\\n        coi (dict): Dictionary containing column names for longitude and latitude in various formats.\\n        fn_convert_cor (Callable): Function to convert coordinates from 'ddmmmm' to 'dddddd' format.\\n    , Drop row when both longitude & latitude equal 0. Drop unrealistic longitude & latitude values. Convert longitude & latitude `,` separator to `.` separator., \\n    A callback to select and rename columns in a DataFrame based on provided renaming rules\\n    for a specified encoding type. It also prints renaming rules that were not applied\\n    because their keys were not found in the DataFrame.\\n    , Convert data from long to wide with renamed columns.\"}"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "471ebcce-b8c8-4963-8c1c-f32e820f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### Encoding NETCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out_nc, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                EncodeTimeCB(cfg()),                             \n",
    "                                NormalizeUncUnitCB(),\n",
    "                                SanitizeValue(coi_val),                       \n",
    "                                LookupBiotaSpeciesCB(get_maris_species),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart),                          \n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupSedimentCB(get_maris_sediments),\n",
    "                                LookupUnitCB(),\n",
    "                                LookupDetectionLimitCB(),\n",
    "                                RemapDataProviderSampleIdCB(),\n",
    "                                RemapStationIdCB(),\n",
    "                                RemapProfileIdCB(), \n",
    "                                RemapSedSliceTopBottomCB(),\n",
    "                                LookupDryWetRatio(),\n",
    "                                FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                                SanitizeLonLatCB(),\n",
    "                                SelectAndRenameColumnCB(get_renaming_rules, encoding_type='netcdf'),\n",
    "                                ReshapeLongToWide()\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: smp_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tot_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: h3_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: k40_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: mn54\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: mn54_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: mn54_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: mn54_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: mn54_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: co60_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr89\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr89_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr89_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr89_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr89_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sr90_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: zr95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: zr95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: zr95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: zr95_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: zr95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nb95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: tc99_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru103_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ru106_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ag110m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ag110m_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ag110m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ag110m_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ag110m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: sb125_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs134_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cs137_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ba140\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ba140_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ba140_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ba140_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ba140_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ce144\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ce144_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ce144_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ce144_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: ce144_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pb210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: po210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u234\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u234_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u234_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u234_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u234_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u238\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u238_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u238_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u238_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: u238_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: np237\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: np237_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: np237_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: np237_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: np237_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu238_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu240\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu240_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu240_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu240_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu240_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: am241_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm242_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm244_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: pu239_240_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot_sal\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot_temp\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: cm243_244_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tot_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sed_type\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: be7\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: be7_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: be7_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: be7_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: k40\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: k40_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: k40_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: k40_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: mn54\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: mn54_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: mn54_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: mn54_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co58\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co58_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co58_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co58_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co60\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co60_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co60_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: co60_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zn65\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zn65_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zn65_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zn65_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sr90\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sr90_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sr90_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sr90_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zr95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zr95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zr95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: zr95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nb95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nb95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nb95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nb95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru103\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru103_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru103_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru103_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru106\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru106_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru106_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ru106_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ag110m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ag110m_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ag110m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ag110m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb124\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb124_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb124_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb124_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb125\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb125_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb125_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sb125_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs137\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs137_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs137_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs137_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ba140\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ba140_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ba140_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ba140_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ce144\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ce144_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ce144_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ce144_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: eu155\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: eu155_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: eu155_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: eu155_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb212\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb212_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb212_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb212_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb214\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb214_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb214_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pb214_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi214\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi214_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi214_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi214_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: po210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: po210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: po210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: po210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra223\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra223_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra223_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra223_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra224\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra224_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra224_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra224_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra226\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra226_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra226_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra226_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ra228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ac228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ac228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ac228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ac228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th232\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th232_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th232_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th232_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th234\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th234_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th234_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: th234_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: u235\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: u235_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: u235_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: u235_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu238\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu238_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu238_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu238_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu241\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu241_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu241_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu241_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: am241\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: am241_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: am241_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: am241_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_137_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_137_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_137_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cs134_137_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_240_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_240_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_240_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: pu239_240_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cd109\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cd109_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cd109_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: cd109_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ir192\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ir192_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ir192_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: ir192_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tl208\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tl208_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tl208_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: tl208_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi212\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi212_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi212_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bi212_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: smp_depth\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bio_group\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: species\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: body_part\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: be7\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: be7_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: be7_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: be7_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: k40\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: k40_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: k40_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: k40_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: mn54\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: mn54_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: mn54_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: mn54_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co57\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co57_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co57_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co57_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co58\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co58_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co58_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co58_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co60\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co60_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co60_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: co60_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zn65\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zn65_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zn65_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zn65_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr89\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr89_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr89_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr89_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr90\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr90_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr90_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sr90_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zr95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zr95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zr95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: zr95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nb95\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nb95_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nb95_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nb95_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tc99_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru103\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru103_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru103_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru103_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru106\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru106_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru106_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ru106_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag108m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag108m_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag108m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag108m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag110m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag110m_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag110m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ag110m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb124\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb124_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb124_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb124_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb125\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb125_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb125_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sb125_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: te129m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: te129m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: te129m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: i131\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: i131_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: i131_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs137_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ba140\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ba140_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ba140_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: la140\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: la140_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: la140_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce141\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce141_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce141_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce141_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce144\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce144_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce144_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ce144_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu155\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu155_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu155_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu155_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb212\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb212_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb212_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb212_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb214\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb214_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb214_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pb214_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bi214\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bi214_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bi214_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bi214_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: po210_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra223\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra223_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra223_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra223_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra224\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra224_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra224_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra224_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra226_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ra228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ac228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ac228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ac228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: ac228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th228\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th228_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th228_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th228_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th232\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th232_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th232_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: th232_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: u235\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: u235_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: u235_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: u235_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu238_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: am241_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_137_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_137_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_137_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: cs134_137_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: pu239_240_tot_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu152\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu152_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu152_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: eu152_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: fe59\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: fe59_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: fe59_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: fe59_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: gd153\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: gd153_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: gd153_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: gd153_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: rb86\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: rb86_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: rb86_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: rb86_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sc46\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sc46_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sc46_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sc46_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn113\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn113_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn113_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn113_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn117m\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn117m_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn117m_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: sn117m_unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tl208\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tl208_unc\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tl208_dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: tl208_unit\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, fname_out_nc, nc_tpl_path(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59162832",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33549327",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a206afa",
   "metadata": {},
   "source": [
    "TODO: Include FILT for NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0be1f5",
   "metadata": {},
   "source": [
    "TODO : Do we want to include laboratory code in NetCDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44bf97",
   "metadata": {},
   "source": [
    "TODO: Check sediment 'DW%' data that is less than 1%. Is this realistic? Check the 'DW%' data that is 0%. Run below before SelectAndRenameColumnCB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002712da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seawater':                 KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       " 0      WKRIL2012003   cs137     NaN           NaN          5.3     1.6960   \n",
       " 1      WKRIL2012004   cs137     NaN           NaN         19.9     3.9800   \n",
       " 2      WKRIL2012005   cs137     NaN           NaN         25.5     5.1000   \n",
       " 3      WKRIL2012006   cs137     NaN           NaN         17.0     4.9300   \n",
       " 4      WKRIL2012007   cs137     NaN           NaN         22.2     3.9960   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 20313  WDHIG2015227    sr90  DHIG02           NaN          6.6     0.4950   \n",
       " 20314  WDHIG2015237    sr90  DHIG02           NaN          6.9     0.5175   \n",
       " 20315  WDHIG2015239    sr90  DHIG02           NaN          6.8     0.5100   \n",
       " 20316  WDHIG2015255    sr90  DHIG02           NaN          7.3     0.5475   \n",
       " 20317  WDHIG2015256    sr90  DHIG02           NaN          5.5     0.4180   \n",
       " \n",
       "          DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... HELCOM_SUBBASIN  \\\n",
       " 0      08/20/14 00:00:00       90       KRIL   2012003  ...              11   \n",
       " 1      08/20/14 00:00:00       90       KRIL   2012004  ...              11   \n",
       " 2      08/20/14 00:00:00       90       KRIL   2012005  ...               3   \n",
       " 3      08/20/14 00:00:00       90       KRIL   2012006  ...              11   \n",
       " 4      08/20/14 00:00:00       90       KRIL   2012007  ...              11   \n",
       " ...                  ...      ...        ...       ...  ...             ...   \n",
       " 20313  11/22/16 00:00:00        6       DHIG   2015227  ...               6   \n",
       " 20314  11/22/16 00:00:00        6       DHIG   2015237  ...               6   \n",
       " 20315  11/22/16 00:00:00        6       DHIG   2015239  ...               2   \n",
       " 20316  11/22/16 00:00:00        6       DHIG   2015255  ...               2   \n",
       " 20317  11/22/16 00:00:00        6       DHIG   2015256  ...               2   \n",
       " \n",
       "          DATE_OF_ENTRY_y        time  unit detection_limit  \\\n",
       " 0      08/20/14 00:00:00  1337731200     1               1   \n",
       " 1      08/20/14 00:00:00  1337731200     1               1   \n",
       " 2      08/20/14 00:00:00  1339891200     1               1   \n",
       " 3      08/20/14 00:00:00  1337817600     1               1   \n",
       " 4      08/20/14 00:00:00  1337817600     1               1   \n",
       " ...                  ...         ...   ...             ...   \n",
       " 20313  11/22/16 00:00:00  1434931200     1               1   \n",
       " 20314  11/22/16 00:00:00  1435017600     1               1   \n",
       " 20315  11/22/16 00:00:00  1435017600     1               1   \n",
       " 20316  11/22/16 00:00:00  1435104000     1               1   \n",
       " 20317  11/22/16 00:00:00  1435104000     1               1   \n",
       " \n",
       "        data_provider_sample_id  station_id  profile_or_transect_id      lon  \\\n",
       " 0                 WKRIL2012003        RU10                 2012003  29.3333   \n",
       " 1                 WKRIL2012004        RU10                 2012004  29.3333   \n",
       " 2                 WKRIL2012005        RU11                 2012005  23.1500   \n",
       " 3                 WKRIL2012006        RU19                 2012006  27.9833   \n",
       " 4                 WKRIL2012007        RU19                 2012007  27.9833   \n",
       " ...                        ...         ...                     ...      ...   \n",
       " 20313             WDHIG2015227        ODER                 2015227  14.2000   \n",
       " 20314             WDHIG2015237       OBANK                 2015237  14.6672   \n",
       " 20315             WDHIG2015239      ADLERG                 2015239  14.3342   \n",
       " 20316             WDHIG2015255       ARKO2                 2015255  13.5002   \n",
       " 20317             WDHIG2015256       ARKO2                 2015256  13.5002   \n",
       " \n",
       "            lat  \n",
       " 0      60.0833  \n",
       " 1      60.0833  \n",
       " 2      59.4333  \n",
       " 3      60.2500  \n",
       " 4      60.2500  \n",
       " ...        ...  \n",
       " 20313  54.0068  \n",
       " 20314  54.4995  \n",
       " 20315  54.7505  \n",
       " 20316  54.9165  \n",
       " 20317  54.9165  \n",
       " \n",
       " [20242 rows x 35 columns],\n",
       " 'sediment':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       " 0      SKRIL2012048   ra226     NaN           NaN        35.00      9.100   \n",
       " 1      SKRIL2012049   ra226     NaN           NaN        36.00      7.920   \n",
       " 2      SKRIL2012050   ra226     NaN           NaN        38.00      9.120   \n",
       " 3      SKRIL2012051   ra226     NaN           NaN        36.00      9.000   \n",
       " 4      SKRIL2012052   ra226     NaN           NaN        30.00      6.900   \n",
       " ...             ...     ...     ...           ...          ...        ...   \n",
       " 37342  SSTUK2016044   cs137  STUK01           NaN         1.20      0.144   \n",
       " 37343  SSTUK2016045   cs137  STUK01           NaN         0.79      0.158   \n",
       " 37344  SSTUK2016050   cs137  STUK01           NaN       512.00     56.320   \n",
       " 37345  SSTUK2016051   cs137  STUK01           NaN       527.00     33.201   \n",
       " 37346  SSTUK2016052   cs137  STUK01           NaN       684.00     34.200   \n",
       " \n",
       "       < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  unit  \\\n",
       " 0               NaN          NaN        NaN  08/20/14 00:00:00  ...     4   \n",
       " 1               NaN          NaN        NaN  08/20/14 00:00:00  ...     4   \n",
       " 2               NaN          NaN        NaN  08/20/14 00:00:00  ...     4   \n",
       " 3               NaN          NaN        NaN  08/20/14 00:00:00  ...     4   \n",
       " 4               NaN          NaN        NaN  08/20/14 00:00:00  ...     4   \n",
       " ...             ...          ...        ...                ...  ...   ...   \n",
       " 37342           NaN     8.916443       15.0                NaN  ...     4   \n",
       " 37343           NaN     5.992930       23.0                NaN  ...     4   \n",
       " 37344           NaN  2164.945699       14.0                NaN  ...     4   \n",
       " 37345           NaN  2523.279045        9.3                NaN  ...     4   \n",
       " 37346           NaN  3929.780107        8.0                NaN  ...     4   \n",
       " \n",
       "       detection_limit  data_provider_sample_id station_id  \\\n",
       " 0                   1             SKRIL2012048       RU25   \n",
       " 1                   1             SKRIL2012049       RU25   \n",
       " 2                   1             SKRIL2012050       RU28   \n",
       " 3                   1             SKRIL2012051       RU28   \n",
       " 4                   1             SKRIL2012052       RU28   \n",
       " ...               ...                      ...        ...   \n",
       " 37342               1             SSTUK2016044       LL17   \n",
       " 37343               1             SSTUK2016045       LL17   \n",
       " 37344               1             SSTUK2016050        EB1   \n",
       " 37345               1             SSTUK2016051        EB1   \n",
       " 37346               1             SSTUK2016052        EB1   \n",
       " \n",
       "        profile_or_transect_id  bottom   top dry_wet_ratio      lon      lat  \n",
       " 0                   2012048.0    20.0  15.0           NaN  24.0000  59.6667  \n",
       " 1                   2012049.0    27.0  20.0           NaN  24.0000  59.6667  \n",
       " 2                   2012050.0     2.0   0.0           NaN  28.8433  59.8600  \n",
       " 3                   2012051.0     4.0   2.0           NaN  28.8433  59.8600  \n",
       " 4                   2012052.0     6.0   4.0           NaN  28.8433  59.8600  \n",
       " ...                       ...     ...   ...           ...      ...      ...  \n",
       " 37342               2016044.0    20.0  18.0           NaN  21.0830  59.0360  \n",
       " 37343               2016045.0    22.0  20.0           NaN  21.0830  59.0360  \n",
       " 37344               2016050.0     2.0   0.0           NaN  19.7297  61.0667  \n",
       " 37345               2016051.0     4.0   2.0           NaN  19.7297  61.0667  \n",
       " 37346               2016052.0     6.0   4.0           NaN  19.7297  61.0667  \n",
       " \n",
       " [37089 rows x 47 columns],\n",
       " 'biota':                 KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  \\\n",
       " 0      BVTIG2012041   cs134  VTIG01             <     0.010140     W   \n",
       " 1      BVTIG2012041     k40  VTIG01                 135.300000     W   \n",
       " 2      BVTIG2012041    co60  VTIG01             <     0.013980     W   \n",
       " 3      BVTIG2012041   cs137  VTIG01                   4.338000     W   \n",
       " 4      BVTIG2012040   cs134  VTIG01             <     0.009614     W   \n",
       " ...             ...     ...     ...           ...          ...   ...   \n",
       " 14888  BCLOR2018021   ra226  CLOR06           NaN     0.043000     W   \n",
       " 14889  BCLOR2018022     k40  CLOR01           NaN    98.000000     W   \n",
       " 14890  BCLOR2018022   cs137  CLOR01           NaN     3.690000     W   \n",
       " 14891  BCLOR2018022   ra226  CLOR06           NaN     0.049000     W   \n",
       " 14892  BIMGW2018011   cs137  IMGW03           NaN     0.830000     W   \n",
       " \n",
       "          ERROR%  NUMBER    DATE_OF_ENTRY_x  COUNTRY  ... body_part  bio_group  \\\n",
       " 0           NaN     NaN  02/27/14 00:00:00      6.0  ...        52          4   \n",
       " 1      4.830210     NaN  02/27/14 00:00:00      6.0  ...        52          4   \n",
       " 2           NaN     NaN  02/27/14 00:00:00      6.0  ...        52          4   \n",
       " 3      0.150962     NaN  02/27/14 00:00:00      6.0  ...        52          4   \n",
       " 4           NaN     NaN  02/27/14 00:00:00      6.0  ...        52          4   \n",
       " ...         ...     ...                ...      ...  ...       ...        ...   \n",
       " 14888  0.011008     NaN  03/30/20 00:00:00     67.0  ...         3          4   \n",
       " 14889  1.097600     NaN  03/30/20 00:00:00     67.0  ...        52          4   \n",
       " 14890  0.078597     NaN  03/30/20 00:00:00     67.0  ...        52          4   \n",
       " 14891  0.007007     NaN  03/30/20 00:00:00     67.0  ...        52          4   \n",
       " 14892  0.229993     NaN  04/30/20 00:00:00     67.0  ...        52          4   \n",
       " \n",
       "       unit  detection_limit  data_provider_sample_id  station_id  \\\n",
       " 0        5                2             BVTIG2012041        SD24   \n",
       " 1        5                1             BVTIG2012041        SD24   \n",
       " 2        5                2             BVTIG2012041        SD24   \n",
       " 3        5                1             BVTIG2012041        SD24   \n",
       " 4        5                2             BVTIG2012040        SD24   \n",
       " ...    ...              ...                      ...         ...   \n",
       " 14888    5                1             BCLOR2018021         PL1   \n",
       " 14889    5                1             BCLOR2018022         PL4   \n",
       " 14890    5                1             BCLOR2018022         PL4   \n",
       " 14891    5                1             BCLOR2018022         PL4   \n",
       " 14892    5                1             BIMGW2018011        LZWI   \n",
       " \n",
       "       profile_or_transect_id  dry_wet_ratio        lon        lat  \n",
       " 0                    2012041         18.453  12.316667  54.283333  \n",
       " 1                    2012041         18.453  12.316667  54.283333  \n",
       " 2                    2012041         18.453  12.316667  54.283333  \n",
       " 3                    2012041         18.453  12.316667  54.283333  \n",
       " 4                    2012040         18.458  12.316667  54.283333  \n",
       " ...                      ...            ...        ...        ...  \n",
       " 14888                2018021         24.000  19.000000  54.583300  \n",
       " 14889                2018022         22.500  15.500000  54.333300  \n",
       " 14890                2018022         22.500  15.500000  54.333300  \n",
       " 14891                2018022         22.500  15.500000  54.333300  \n",
       " 14892                2018001            NaN  19.433300  54.363900  \n",
       " \n",
       " [14873 rows x 45 columns]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(cfg()),                             \n",
    "                            NormalizeUncUnitCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart), \n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupSedimentCB(get_maris_sediments),\n",
    "                            LookupUnitCB(),\n",
    "                            LookupDetectionLimitCB(),\n",
    "                            RemapDataProviderSampleIdCB(),\n",
    "                            RemapStationIdCB(),\n",
    "                            RemapProfileIdCB(), \n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetRatio(),\n",
    "                            FormatCoordinates(coi_coordinates, ddmmmm2dddddd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            SanitizeValue(coi_val)\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de551778",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] < 1) & (tfm.dfs[grp]['DW%'] > 0.001) ]\n",
    "#check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe533d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>unit</th>\n",
       "      <th>detection_limit</th>\n",
       "      <th>data_provider_sample_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>profile_or_transect_id</th>\n",
       "      <th>bottom</th>\n",
       "      <th>top</th>\n",
       "      <th>dry_wet_ratio</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9824</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>EE17</td>\n",
       "      <td>1997001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0167</td>\n",
       "      <td>59.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9825</th>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.00</td>\n",
       "      <td>15.5600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>589.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>SERPC1997001</td>\n",
       "      <td>EE17</td>\n",
       "      <td>1997001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0167</td>\n",
       "      <td>59.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>EE17</td>\n",
       "      <td>1997002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0167</td>\n",
       "      <td>59.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.00</td>\n",
       "      <td>16.8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>SERPC1997002</td>\n",
       "      <td>EE17</td>\n",
       "      <td>1997002.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0167</td>\n",
       "      <td>59.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9828</th>\n",
       "      <td>SERPC1997003</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.5304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>SERPC1997003</td>\n",
       "      <td>EE17</td>\n",
       "      <td>1997003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0167</td>\n",
       "      <td>59.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15257</th>\n",
       "      <td>SKRIL1999062</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>SKRIL1999062</td>\n",
       "      <td>RU23</td>\n",
       "      <td>1999062.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>59.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15258</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>k40</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>RU23</td>\n",
       "      <td>1999063.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>59.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra226</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>RU23</td>\n",
       "      <td>1999063.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>59.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>ra228</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>RU23</td>\n",
       "      <td>1999063.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>59.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>th228</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>SKRIL1999063</td>\n",
       "      <td>RU23</td>\n",
       "      <td>1999063.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>59.8167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "9824   SERPC1997001   cs134     NaN           NaN         3.80     0.7600   \n",
       "9825   SERPC1997001   cs137     NaN           NaN       389.00    15.5600   \n",
       "9826   SERPC1997002   cs134     NaN           NaN         4.78     0.6214   \n",
       "9827   SERPC1997002   cs137     NaN           NaN       420.00    16.8000   \n",
       "9828   SERPC1997003   cs134     NaN           NaN         3.12     0.5304   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "15257  SKRIL1999062   th228       1           NaN        68.00        NaN   \n",
       "15258  SKRIL1999063     k40       1           NaN      1210.00        NaN   \n",
       "15259  SKRIL1999063   ra226  KRIL01           NaN        56.50        NaN   \n",
       "15260  SKRIL1999063   ra228  KRIL01           NaN        72.20        NaN   \n",
       "15261  SKRIL1999063   th228       1           NaN        74.20        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  unit  \\\n",
       "9824            NaN         5.75        NaN             NaN  ...     4   \n",
       "9825            NaN       589.00        NaN             NaN  ...     4   \n",
       "9826            NaN        12.00        NaN             NaN  ...     4   \n",
       "9827            NaN      1060.00        NaN             NaN  ...     4   \n",
       "9828            NaN        12.00        NaN             NaN  ...     4   \n",
       "...             ...          ...        ...             ...  ...   ...   \n",
       "15257           NaN          NaN        NaN             NaN  ...     4   \n",
       "15258           NaN          NaN        NaN             NaN  ...     4   \n",
       "15259           NaN          NaN        NaN             NaN  ...     4   \n",
       "15260           NaN          NaN        NaN             NaN  ...     4   \n",
       "15261           NaN          NaN        NaN             NaN  ...     4   \n",
       "\n",
       "      detection_limit  data_provider_sample_id station_id  \\\n",
       "9824                1             SERPC1997001       EE17   \n",
       "9825                1             SERPC1997001       EE17   \n",
       "9826                1             SERPC1997002       EE17   \n",
       "9827                1             SERPC1997002       EE17   \n",
       "9828                1             SERPC1997003       EE17   \n",
       "...               ...                      ...        ...   \n",
       "15257               0             SKRIL1999062       RU23   \n",
       "15258               0             SKRIL1999063       RU23   \n",
       "15259               0             SKRIL1999063       RU23   \n",
       "15260               0             SKRIL1999063       RU23   \n",
       "15261               0             SKRIL1999063       RU23   \n",
       "\n",
       "       profile_or_transect_id  bottom   top dry_wet_ratio      lon      lat  \n",
       "9824                1997001.0     2.0   0.0           NaN  25.0167  59.7167  \n",
       "9825                1997001.0     2.0   0.0           NaN  25.0167  59.7167  \n",
       "9826                1997002.0     4.0   2.0           NaN  25.0167  59.7167  \n",
       "9827                1997002.0     4.0   2.0           NaN  25.0167  59.7167  \n",
       "9828                1997003.0     6.0   4.0           NaN  25.0167  59.7167  \n",
       "...                       ...     ...   ...           ...      ...      ...  \n",
       "15257               1999062.0    15.0  10.0           NaN  25.5000  59.8167  \n",
       "15258               1999063.0    21.5  15.0           NaN  25.5000  59.8167  \n",
       "15259               1999063.0    21.5  15.0           NaN  25.5000  59.8167  \n",
       "15260               1999063.0    21.5  15.0           NaN  25.5000  59.8167  \n",
       "15261               1999063.0    21.5  15.0           NaN  25.5000  59.8167  \n",
       "\n",
       "[302 rows x 47 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='sediment'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357222d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>BASIS</th>\n",
       "      <th>ERROR%</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>...</th>\n",
       "      <th>body_part</th>\n",
       "      <th>bio_group</th>\n",
       "      <th>unit</th>\n",
       "      <th>detection_limit</th>\n",
       "      <th>data_provider_sample_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>profile_or_transect_id</th>\n",
       "      <th>dry_wet_ratio</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>3.4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.60</td>\n",
       "      <td>W</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>W</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997002</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>k40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4.6400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>W</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>cs134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>W</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>BERPC1997001</td>\n",
       "      <td>Paldiski</td>\n",
       "      <td>1997001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1667</td>\n",
       "      <td>59.3667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg BASIS  ERROR%  \\\n",
       "5971  BERPC1997002     k40    NaN           NaN       116.00     W  3.4800   \n",
       "5972  BERPC1997002   cs137    NaN           NaN        12.60     W  0.5040   \n",
       "5973  BERPC1997002   cs134    NaN           NaN         0.14     W  0.0252   \n",
       "5974  BERPC1997001     k40    NaN           NaN       116.00     W  4.6400   \n",
       "5975  BERPC1997001   cs137    NaN           NaN        12.00     W  0.4800   \n",
       "5976  BERPC1997001   cs134    NaN           NaN         0.21     W  0.0504   \n",
       "\n",
       "      NUMBER DATE_OF_ENTRY_x  COUNTRY  ... body_part  bio_group unit  \\\n",
       "5971     NaN             NaN     91.0  ...        52          4    5   \n",
       "5972     NaN             NaN     91.0  ...        52          4    5   \n",
       "5973     NaN             NaN     91.0  ...        52          4    5   \n",
       "5974     NaN             NaN     91.0  ...        52          4    5   \n",
       "5975     NaN             NaN     91.0  ...        52          4    5   \n",
       "5976     NaN             NaN     91.0  ...        52          4    5   \n",
       "\n",
       "      detection_limit  data_provider_sample_id  station_id  \\\n",
       "5971                1             BERPC1997002    Paldiski   \n",
       "5972                1             BERPC1997002    Paldiski   \n",
       "5973                1             BERPC1997002    Paldiski   \n",
       "5974                1             BERPC1997001    Paldiski   \n",
       "5975                1             BERPC1997001    Paldiski   \n",
       "5976                1             BERPC1997001    Paldiski   \n",
       "\n",
       "     profile_or_transect_id  dry_wet_ratio      lon      lat  \n",
       "5971                1997002            NaN  24.1667  59.3667  \n",
       "5972                1997002            NaN  24.1667  59.3667  \n",
       "5973                1997002            NaN  24.1667  59.3667  \n",
       "5974                1997001            NaN  24.1667  59.3667  \n",
       "5975                1997001            NaN  24.1667  59.3667  \n",
       "5976                1997001            NaN  24.1667  59.3667  \n",
       "\n",
       "[6 rows x 45 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp='biota'\n",
    "check_data_sediment=tfm.dfs[grp][(tfm.dfs[grp]['DW%'] == 0) ]\n",
    "check_data_sediment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eefdfcc",
   "metadata": {},
   "source": [
    "TODO: Note weight definition in HELCOM is different than in MARIS.  HELCOM definition is 'Average weight (in g) of specimen in the sample. MARIS definition is 'dry weight of biota sample in grammes (g).' or 'wet weight of biota sample in grammes (g).'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208aa11",
   "metadata": {},
   "source": [
    "TODO :  For biota we have some entries that include a YEAR but no month and day (see tfm.dfs_dropped['biota'][['YEAR', 'MONTH', 'DAY', 'DATE']]). For these entries I have included a day and month as 1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7560d",
   "metadata": {},
   "source": [
    "TODO: Review the format of 'ddmmmm'.. Example of data '29.2000'. Assuming that this is 29 degrees. Then 20 minutes with a remainder of .00 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa5e77",
   "metadata": {},
   "source": [
    "TODO: Follow up with HELCOM on entries where the value is nan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b010f",
   "metadata": {},
   "source": [
    "TODO: Review Maris Open Refine date format. The description format is 'DD-MMM-YYYY'. The example format is '29/Sep/2008'.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

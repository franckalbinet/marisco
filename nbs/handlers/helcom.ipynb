{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709cfb6",
   "metadata": {},
   "source": [
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [HELCOM data](https://helcom.fi/about-us) into `NetCDF` format. The handler processes raw HELCOM data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw HELCOM data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring HELCOM data is properly integrated into the MARIS database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/blob/main/nbs/metadata/field-definition.ipynb) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3f7e3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new HELCOM users, please refer to the [HELCOM Metadata Portal](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24) for detailed information regarding the `GUIDELINES FOR MONITORING OF RADIOACTIVE SUBSTANCES`.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121843",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/helcom.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "from typing import List, Dict, Callable, Tuple, Any \n",
    "import re\n",
    "import time\n",
    "\n",
    "from marisco.utils import (\n",
    "    Remapper, \n",
    "    ddmm_to_dd,\n",
    "    Match, \n",
    "    get_unique_across_dfs,\n",
    "    ExtractNetcdfContents,\n",
    "    NA\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback, \n",
    "    Transformer, \n",
    "    EncodeTimeCB, \n",
    "    LowerStripNameCB, \n",
    "    SanitizeLonLatCB, \n",
    "    CompareDfsAndTfmCB, \n",
    "    RemapCB\n",
    ")\n",
    "\n",
    "from marisco.metadata import (\n",
    "    GlobAttrsFeeder, \n",
    "    BboxCB, \n",
    "    DepthRangeCB, \n",
    "    TimeRangeCB, \n",
    "    ZoteroCB, \n",
    "    KeyValuePairCB\n",
    ")\n",
    "\n",
    "from marisco.configs import (\n",
    "    nuc_lut_path, \n",
    "    cfg, \n",
    "    species_lut_path, \n",
    "    sediments_lut_path, \n",
    "    bodyparts_lut_path, \n",
    "    detection_limit_lut_path, \n",
    "    filtered_lut_path, \n",
    "    get_lut, \n",
    "    unit_lut_path,\n",
    "    prepmet_lut_path,\n",
    "    sampmet_lut_path,\n",
    "    counmet_lut_path, \n",
    "    lab_lut_path,\n",
    "    SMP_TYPE_LUT,\n",
    "    cache_path\n",
    ")\n",
    "\n",
    "from marisco.encoders import (\n",
    "    NetCDFEncoder, \n",
    ")\n",
    "\n",
    "from marisco.handlers.data_format_transformation import (\n",
    "    decode, \n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration & file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **src_dir**: path to the [maris-crawlers](https://github.com/franckalbinet/maris-crawlers) folder containing the HELCOM data in CSV format.\n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034b0a9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: Review the NetCDF file naming convention as discussed [here](https://trello.com/c/RlB7mM8N#comment-6747489a3ef094e3520a4272). I think we should include 'MARISCO' in the filename and attributes to acknowledge the contributions and branding of the project.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "src_dir = 'https://raw.githubusercontent.com/franckalbinet/maris-crawlers/refs/heads/main/data/processed/HELCOM%20MORS'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "zotero_key ='26VMZZ2Q' # HELCOM MORS zotero key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc83f",
   "metadata": {},
   "source": [
    "[Helcom MORS (Monitoring of Radioactive Substances in the Baltic Sea) data](https://helcom.fi/about-us) is provided as a zipped Microsoft Access database. We automatically fetch and convert this dataset with database tables exported as `.csv` files using a Github action here: [maris-crawlers](https://github.com/franckalbinet/maris-crawlers/blob/main/.github/workflows/fetch-data-sources.yml). \n",
    "\n",
    "The dataset is then accessible in an amenable format for the `marisco` data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = {  \n",
    "    'BIO': 'BIOTA', \n",
    "    'SEA': 'SEAWATER', \n",
    "    'SED': 'SEDIMENT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def read_csv(file_name, dir=src_dir):\n",
    "    file_path = f'{dir}/{file_name}'\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_url: str, \n",
    "              smp_types: dict = default_smp_types, \n",
    "              use_cache: bool = False,\n",
    "              save_to_cache: bool = False,\n",
    "              verbose: bool = False) -> Dict[str, pd.DataFrame]:\n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        \n",
    "        if use_cache:\n",
    "            dir=cache_path()\n",
    "        else:\n",
    "            dir = src_url\n",
    "            \n",
    "        file_smp_path = f'{dir}/{file_prefix}01.csv'\n",
    "        file_meas_path = f'{dir}/{file_prefix}02.csv'\n",
    "\n",
    "        if use_cache:\n",
    "            if not Path(file_smp_path).exists():\n",
    "                print(f'{file_smp_path} not found.')            \n",
    "            if not Path(file_meas_path).exists():\n",
    "                print(f'{file_meas_path} not found.')\n",
    "        \n",
    "        if verbose:\n",
    "            start_time = time.time()\n",
    "        df_meas = read_csv(f'{file_prefix}02.csv', dir)\n",
    "        df_smp = read_csv(f'{file_prefix}01.csv', dir)\n",
    "        \n",
    "        df_meas.columns = df_meas.columns.str.lower()\n",
    "        df_smp.columns = df_smp.columns.str.lower()\n",
    "        \n",
    "        merged_df = pd.merge(df_meas, df_smp, on='key', how='left')\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Downloaded data for {file_prefix}01.csv and {file_prefix}02.csv in {time.time() - start_time:.2f} seconds.\")\n",
    "            \n",
    "        if save_to_cache:\n",
    "            dir = cache_path()\n",
    "            df_smp.to_csv(f'{dir}/{file_prefix}01.csv', index=False)\n",
    "            df_meas.to_csv(f'{dir}/{file_prefix}02.csv', index=False)\n",
    "            if verbose:\n",
    "                print(f\"Saved downloaded data to cache at {dir}/{file_prefix}01.csv and {dir}/{file_prefix}02.csv\")\n",
    "\n",
    "        return merged_df\n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `src_dir`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data for BIO01.csv and BIO02.csv in 1.28 seconds.\n",
      "Saved downloaded data to cache at /home/niallmurphy93/.marisco/cache/BIO01.csv and /home/niallmurphy93/.marisco/cache/BIO02.csv\n",
      "Downloaded data for SEA01.csv and SEA02.csv in 1.38 seconds.\n",
      "Saved downloaded data to cache at /home/niallmurphy93/.marisco/cache/SEA01.csv and /home/niallmurphy93/.marisco/cache/SEA02.csv\n",
      "Downloaded data for SED01.csv and SED02.csv in 1.88 seconds.\n",
      "Saved downloaded data to cache at /home/niallmurphy93/.marisco/cache/SED01.csv and /home/niallmurphy93/.marisco/cache/SED02.csv\n",
      "keys/sample types:  dict_keys(['BIOTA', 'SEAWATER', 'SEDIMENT'])\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, verbose=True, save_to_cache=True)\n",
    "print('keys/sample types: ', dfs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875cbd8",
   "metadata": {},
   "source": [
    "Lets take a look at each DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b> BIOTA DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/kg</th>\n",
       "      <th>value_bq/kg</th>\n",
       "      <th>basis</th>\n",
       "      <th>error%</th>\n",
       "      <th>number</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude ddmmmm</th>\n",
       "      <th>latitude dddddd</th>\n",
       "      <th>longitude ddmmmm</th>\n",
       "      <th>longitude dddddd</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>rubin</th>\n",
       "      <th>biotatype</th>\n",
       "      <th>tissue</th>\n",
       "      <th>no</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>dw%</th>\n",
       "      <th>loi%</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012041</td>\n",
       "      <td>09/23/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SD24</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.316667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BVTIG2012041</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td></td>\n",
       "      <td>135.30000</td>\n",
       "      <td>W</td>\n",
       "      <td>3.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012041</td>\n",
       "      <td>09/23/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SD24</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.316667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>948.0</td>\n",
       "      <td>18.453</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>02/27/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key   nuclide  method < value_bq/kg  value_bq/kg basis  error%  \\\n",
       "0  BVTIG2012041  CS134     VTIG01             <      0.01014     W     NaN   \n",
       "1  BVTIG2012041  K40       VTIG01                  135.30000     W    3.57   \n",
       "\n",
       "   number    date_of_entry_x  country laboratory  sequence               date  \\\n",
       "0     NaN  02/27/14 00:00:00      6.0       VTIG   2012041  09/23/12 00:00:00   \n",
       "1     NaN  02/27/14 00:00:00      6.0       VTIG   2012041  09/23/12 00:00:00   \n",
       "\n",
       "   year  month   day station  latitude ddmmmm  latitude dddddd  \\\n",
       "0  2012    9.0  23.0    SD24            54.17        54.283333   \n",
       "1  2012    9.0  23.0    SD24            54.17        54.283333   \n",
       "\n",
       "   longitude ddmmmm  longitude dddddd  sdepth     rubin biotatype  tissue  \\\n",
       "0             12.19         12.316667     NaN  GADU MOR         F       5   \n",
       "1             12.19         12.316667     NaN  GADU MOR         F       5   \n",
       "\n",
       "     no  length  weight     dw%  loi%  mors_subbasin  helcom_subbasin  \\\n",
       "0  16.0    45.7   948.0  18.453  92.9            2.0               16   \n",
       "1  16.0    45.7   948.0  18.453  92.9            2.0               16   \n",
       "\n",
       "     date_of_entry_y  \n",
       "0  02/27/14 00:00:00  \n",
       "1  02/27/14 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b> SEAWATER DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude (ddmmmm)</th>\n",
       "      <th>latitude (dddddd)</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003.0</td>\n",
       "      <td>05/23/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RU10</td>\n",
       "      <td>60.05</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004.0</td>\n",
       "      <td>05/23/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RU10</td>\n",
       "      <td>60.05</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key nuclide method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "\n",
       "     date_of_entry_x  country laboratory   sequence               date  \\\n",
       "0  08/20/14 00:00:00     90.0       KRIL  2012003.0  05/23/12 00:00:00   \n",
       "1  08/20/14 00:00:00     90.0       KRIL  2012004.0  05/23/12 00:00:00   \n",
       "\n",
       "     year  month   day station  latitude (ddmmmm)  latitude (dddddd)  \\\n",
       "0  2012.0    5.0  23.0    RU10              60.05            60.0833   \n",
       "1  2012.0    5.0  23.0    RU10              60.05            60.0833   \n",
       "\n",
       "   longitude (ddmmmm)  longitude (dddddd)  tdepth  sdepth  salin  ttemp filt  \\\n",
       "0                29.2             29.3333     NaN     0.0    NaN    NaN  NaN   \n",
       "1                29.2             29.3333     NaN    29.0    NaN    NaN  NaN   \n",
       "\n",
       "   mors_subbasin  helcom_subbasin    date_of_entry_y  \n",
       "0           11.0             11.0  08/20/14 00:00:00  \n",
       "1           11.0             11.0  08/20/14 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b> SEDIMENT DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/kg</th>\n",
       "      <th>value_bq/kg</th>\n",
       "      <th>error%_kg</th>\n",
       "      <th>&lt; value_bq/m²</th>\n",
       "      <th>value_bq/m²</th>\n",
       "      <th>error%_m²</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude (ddmmmm)</th>\n",
       "      <th>latitude (dddddd)</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>device</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>uppsli</th>\n",
       "      <th>lowsli</th>\n",
       "      <th>area</th>\n",
       "      <th>sedi</th>\n",
       "      <th>oxic</th>\n",
       "      <th>dw%</th>\n",
       "      <th>loi%</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>sum_link</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012116</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012116.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012117</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012117.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key nuclide method < value_bq/kg  value_bq/kg  error%_kg  \\\n",
       "0  SKRIL2012116   CS137    NaN           NaN       1200.0       20.0   \n",
       "1  SKRIL2012117   CS137    NaN           NaN        250.0       20.0   \n",
       "\n",
       "  < value_bq/m²  value_bq/m²  error%_m²    date_of_entry_x  country  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "\n",
       "  laboratory   sequence               date    year  month   day station  \\\n",
       "0       KRIL  2012116.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "1       KRIL  2012117.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "\n",
       "   latitude (ddmmmm) latitude (dddddd)  longitude (ddmmmm)  \\\n",
       "0              60.28           60,4667               27.48   \n",
       "1              60.28           60,4667               27.48   \n",
       "\n",
       "   longitude (dddddd)  device  tdepth  uppsli  lowsli   area  sedi oxic  dw%  \\\n",
       "0                27.8  KRIL01    25.0    15.0    20.0  0.006   NaN  NaN  NaN   \n",
       "1                27.8  KRIL01    25.0    20.0    25.0  0.006   NaN  NaN  NaN   \n",
       "\n",
       "   loi%  mors_subbasin  helcom_subbasin sum_link    date_of_entry_y  \n",
       "0   NaN           11.0             11.0      NaN  08/20/14 00:00:00  \n",
       "1   NaN           11.0             11.0      NaN  08/20/14 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "for key in dfs.keys():\n",
    "    display(Markdown(f\"<b> {key} DataFrame:</b>\"))\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        display(dfs[key].head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4ceb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d84ed7",
   "metadata": {},
   "source": [
    "This is demonstrated below for the `NUCLIDE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      value  n_chars  stripped_chars\n",
      "1       1   PU238           8               5\n",
      "9       9   CO60            8               4\n",
      "11     11  CS137            9               5\n",
      "26     26    SR90           7               4\n",
      "37     37   AM241           8               5\n",
      "44     44   CS134           8               5\n",
      "49     49     CS137         6               5\n",
      "51     51   SR90            8               4\n",
      "72     72   K40             8               3\n",
      "81     81    TC99           7               4\n",
      "83     83     SR90          6               4\n",
      "88     88      SR90         5               4\n",
      "90     90   CS137           8               5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(src_dir, use_cache=True), 'nuclide', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA Nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "SEAWATER Nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "SEDIMENT Nuclides: \n",
      "['cs137' 'ra226' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n",
      "[\"Convert 'nuclide' column values to lowercase, strip spaces, and store in 'NUCLIDE' column.\"]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE')])\n",
    "tfm()\n",
    "for key, df in tfm.dfs.items():\n",
    "    print(f'{key} Nuclides: ')\n",
    "    print(df['NUCLIDE'].unique())\n",
    "    \n",
    "print(tfm.logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58baf14",
   "metadata": {},
   "source": [
    "Below, we map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures to MARIS standards is a recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "We will refer to this process as **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31bc",
   "metadata": {},
   "source": [
    "The `get_unique_across_dfs` function is a utility in MARISCO that retrieves unique values from a specified column across all DataFrames. \n",
    "Note that there is one DataFrame for each sample type, such as biota, sediment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ee8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>bi214</td>\n",
       "      <td>ag110m</td>\n",
       "      <td>cm242</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>np237</td>\n",
       "      <td>sn113</td>\n",
       "      <td>nb95</td>\n",
       "      <td>co60</td>\n",
       "      <td>tl208</td>\n",
       "      <td>u234</td>\n",
       "      <td>...</td>\n",
       "      <td>eu155</td>\n",
       "      <td>cs146</td>\n",
       "      <td>th234</td>\n",
       "      <td>pb212</td>\n",
       "      <td>i131</td>\n",
       "      <td>cs138</td>\n",
       "      <td>mn54</td>\n",
       "      <td>sn117m</td>\n",
       "      <td>cs143</td>\n",
       "      <td>th232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1      2         3      4      5     6     7      8     9   \\\n",
       "index      0       1      2         3      4      5     6     7      8     9   \n",
       "value  bi214  ag110m  cm242  cm243244  np237  sn113  nb95  co60  tl208  u234   \n",
       "\n",
       "       ...     67     68     69     70    71     72    73      74     75  \\\n",
       "index  ...     67     68     69     70    71     72    73      74     75   \n",
       "value  ...  eu155  cs146  th234  pb212  i131  cs138  mn54  sn117m  cs143   \n",
       "\n",
       "          76  \n",
       "index     76  \n",
       "value  th232  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE')])\n",
    "\n",
    "dfs_output = tfm()\n",
    "\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1bdf",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the nuclide names of the HELCOM dataset to the MARIS standard nuclide names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0ea0c",
   "metadata": {},
   "source": [
    "Lets try to match HELCOM nuclide names to MARIS standard nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:01<00:00, 41.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 entries matched the criteria, while 14 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cm243244</th>\n",
       "      <td>cm242</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs134137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs134137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu239240</th>\n",
       "      <td>pu239</td>\n",
       "      <td>pu239240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu238240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu238240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs145</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs142</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs143</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs139</th>\n",
       "      <td>ce139</td>\n",
       "      <td>cs139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs144</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-40</th>\n",
       "      <td>k40</td>\n",
       "      <td>k-40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs140</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs141</th>\n",
       "      <td>ce141</td>\n",
       "      <td>cs141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs146</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs138</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "cm243244                cm242    cm243244            3\n",
       "cs134137                cs137    cs134137            3\n",
       "pu239240                pu239    pu239240            3\n",
       "pu238240                pu240    pu238240            3\n",
       "cs145                   ce140       cs145            2\n",
       "cs142                   ce140       cs142            2\n",
       "cs143                   ce140       cs143            2\n",
       "cs139                   ce139       cs139            1\n",
       "cs144                   cs134       cs144            1\n",
       "k-40                      k40        k-40            1\n",
       "cs140                   ce140       cs140            1\n",
       "cs141                   ce141       cs141            1\n",
       "cs146                   cs136       cs146            1\n",
       "cs138                   cs134       cs138            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cb838",
   "metadata": {},
   "source": [
    "We can now manually inspect the unmatched nuclide names and create a table to correct them to the MARIS standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs143': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'k-40': 'k40',\n",
    "    'cs140': 'cs137',\n",
    "    'cs146': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs138': 'cs137'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575e7e",
   "metadata": {},
   "source": [
    "We now include the table `fixes_nuclide_names`, which applies manual corrections to the nuclide names before the remapping process. \n",
    "The `generate_lookup_table` function has an `overwrite` parameter (default is `True`), which, when set to `True`, creates a pickle file cache of the lookup table. We can now test the remapping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:01<00:00, 42.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 entries matched the criteria, while 0 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1, verbose=True)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1276f",
   "metadata": {},
   "source": [
    "Test passes! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a189ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_helcom.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0281b22",
   "metadata": {},
   "source": [
    "The callback `RemapNuclideNameCB` is now created to remap the nuclide names using the `lut_nuclides` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    \"Remap data provider nuclide names to standardized MARIS nuclide names.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable, # Function that returns the lookup table dictionary\n",
    "                 col_name: str # Column name to remap\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name=self.col_name, as_df=True)\n",
    "        #lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        lut = {k: v.matched_id for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k][self.col_name].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce649d7a",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `LowerStripNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA NUCLIDE unique:  [31  4  9 33 12 21  6  8 22 10 24 77 17  2 37 41 47 23 11 13 25 16 14 36\n",
      " 35 29 34 67 63 46 43 42 94 55 50 40 53 87 92 86 15  7 93 85 91 90 51 59\n",
      " 76 72 54 57]\n",
      "SEAWATER NUCLIDE unique:  [33 12  1 31 67 77 72 73 75 15  4 16 11 24 14 17 13 22 80 34 37 62 64  9\n",
      " 68 41 47 65 69  6]\n",
      "SEDIMENT NUCLIDE unique:  [ 33  53  54   4  12  76  31  77  67   9  16  17  24  22  37  72   2  57\n",
      "  41   8   6  13  34  47  51  14  89  70  68  40  88  59  84  23  10  60\n",
      "  94  42  43  46  55  50  63 130]\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21634     40744\n",
      "Rows removed from original (tfm.dfs_removed)       0         0         0\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='NUCLIDE'),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "for key in dfs_out.keys():\n",
    "    print(f'{key} NUCLIDE unique: ', dfs_out[key]['NUCLIDE'].unique())\n",
    "    \n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24856dc5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Time/date is provide in the `DATE`, `YEAR`\n",
    ", `MONTH`, `DAY` columns. Note that the `DATE` contains missing values as indicated below. When missing, we fallback on the `YEAR`, `MONTH`, `DAY` columns. Note that sometimes `DAY` and `MONTH` contain 0. In this case we systematically set them to 1.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612873e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA DATE null values:  88\n",
      "SEAWATER DATE null values:  554\n",
      "SEDIMENT DATE null values:  830\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} DATE null values: ', dfs[key]['date'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Standardize time format across all dataframes.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._process_dates(df)\n",
    "\n",
    "    def _process_dates(self, df: pd.DataFrame) -> None:\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['TIME'] = self._parse_date(df)\n",
    "        self._handle_missing_dates(df)\n",
    "        self._fill_missing_time(df)\n",
    "\n",
    "    def _parse_date(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"Parse the DATE column if present.\"\n",
    "        return pd.to_datetime(df['date'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "\n",
    "    def _handle_missing_dates(self, df: pd.DataFrame):\n",
    "        \"Handle cases where DAY or MONTH is 0 or missing.\"\n",
    "        df.loc[df[\"day\"] == 0, \"day\"] = 1\n",
    "        df.loc[df[\"month\"] == 0, \"month\"] = 1\n",
    "        \n",
    "        missing_day_month = (df[\"day\"].isna()) & (df[\"month\"].isna()) & (df[\"year\"].notna())\n",
    "        df.loc[missing_day_month, [\"day\", \"month\"]] = 1\n",
    "\n",
    "    def _fill_missing_time(self, df: pd.DataFrame) -> None:\n",
    "        \"Fill missing time values using year, month, and day columns.\"\n",
    "        missing_time = df['TIME'].isna()\n",
    "        df.loc[missing_time, 'TIME'] = pd.to_datetime(\n",
    "            df.loc[missing_time, ['year', 'month', 'day']], \n",
    "            format='%Y%m%d', \n",
    "            errors='coerce'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the `TIME` data for `seawater`. Passing the `CompareDfsAndTfmCB` callback allows us to compare the original dataframes with the transformed dataframes using the `compare_stats` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21634     40744\n",
      "Rows removed from original (tfm.dfs_removed)       0         0         0\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n",
      "            TIME\n",
      "0     2012-05-23\n",
      "1     2012-05-23\n",
      "2     2012-06-17\n",
      "3     2012-05-24\n",
      "4     2012-05-24\n",
      "...          ...\n",
      "21629 2023-06-11\n",
      "21630 2023-06-11\n",
      "21631 2023-06-13\n",
      "21632 2023-06-13\n",
      "21633 2023-06-13\n",
      "\n",
      "[21634 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['SEAWATER'][['TIME']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "The NetCDF time format requires that time be encoded as the number of milliseconds since a specified origin. In our case, the origin is `1970-01-01`, as indicated in the `cdl.toml` file under the `[vars.defaults.time.attrs]` section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 8 missing time value(s) in SEAWATER\n",
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21626     40743\n",
      "Rows removed from original (tfm.dfs_removed)       0         8         1\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "#print(tfm.logs)                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b52103",
   "metadata": {},
   "source": [
    "## Split Sediment Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51dae5",
   "metadata": {},
   "source": [
    "Helcom reports two values for the SEDIMENT sample type: `VALUE_Bq/kg` and `VALUE_Bq/m³`. We need to split this and use a single column `VALUE` for the MARIS standard. We will use the `UNIT` column to identify the reported values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102849f",
   "metadata": {},
   "source": [
    "Lets take a look at the unit lookup table for MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bbf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "      <th>ordlist</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bq/m&lt;sup&gt;3&lt;/sup&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized  ordlist Unnamed: 4  Unnamed: 5  \\\n",
       "0        -1  Not applicable  Not applicable      NaN        NaN         NaN   \n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE      0.0        NaN         NaN   \n",
       "2         1           Bq/m3       Bq per m3      1.0      Bq/m3         NaN   \n",
       "3         2           Bq/m2       Bq per m2      2.0        NaN         NaN   \n",
       "4         3           Bq/kg       Bq per kg      3.0        NaN         NaN   \n",
       "5         4          Bq/kgd      Bq per kgd      4.0        NaN         NaN   \n",
       "6         5          Bq/kgw      Bq per kgw      5.0        NaN         NaN   \n",
       "7         6           kg/kg       kg per kg      6.0        NaN         NaN   \n",
       "8         7              TU              TU      7.0        NaN         NaN   \n",
       "9         8      DELTA/mill  DELTA per mill      8.0        NaN         NaN   \n",
       "10        9         atom/kg     atom per kg      9.0        NaN         NaN   \n",
       "11       10        atom/kgd    atom per kgd     10.0        NaN         NaN   \n",
       "12       11        atom/kgw    atom per kgw     11.0        NaN         NaN   \n",
       "13       12          atom/l      atom per l     12.0        NaN         NaN   \n",
       "14       13          Bq/kgC      Bq per kgC     13.0        NaN         NaN   \n",
       "\n",
       "          Unnamed: 6  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2   Bq/m<sup>3</sup>  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "5                NaN  \n",
       "6                NaN  \n",
       "7                NaN  \n",
       "8                NaN  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "11               NaN  \n",
       "12               NaN  \n",
       "13               NaN  \n",
       "14               NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83ec0d",
   "metadata": {},
   "source": [
    "We will define the columns of interest for the SEDIMENT measurement types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df02329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_sediment = {\n",
    "    'kg_type': {\n",
    "        'VALUE': 'value_bq/kg',\n",
    "        'UNC': 'error%_kg',\n",
    "        'DL': '< value_bq/kg',\n",
    "        'UNIT': 3,  # Unit ID for Bq/kg\n",
    "    },\n",
    "    'm2_type': {\n",
    "        'VALUE': 'value_bq/m²',\n",
    "        'UNC': 'error%_m²',\n",
    "        'DL': '< value_bq/m²',\n",
    "        'UNIT': 2,  # Unit ID for Bq/m²\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11202714",
   "metadata": {},
   "source": [
    "We define the `SplitSedimentValuesCB` callback to split the sediment entries into separate rows for `Bq/kg` and `Bq/m²`. We use underscore to denote the columns are temporary columns created during the splitting process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SplitSedimentValuesCB(Callback):\n",
    "    \"Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, Any]] # Columns of interest with value, uncertainty, DL columns and units\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        if 'SEDIMENT' not in tfm.dfs:\n",
    "            return\n",
    "            \n",
    "        df = tfm.dfs['SEDIMENT']\n",
    "        dfs_to_concat = []\n",
    "        \n",
    "        # For each measurement type (kg and m2)\n",
    "        for measure_type, cols in self.coi.items():\n",
    "            # If any of value/uncertainty/DL exists, keep the row\n",
    "            has_data = (\n",
    "                df[cols['VALUE']].notna() | \n",
    "                df[cols['UNC']].notna() | \n",
    "                df[cols['DL']].notna()\n",
    "            )\n",
    "            \n",
    "            if has_data.any():\n",
    "                df_measure = df[has_data].copy()\n",
    "                \n",
    "                # Copy columns to standardized names\n",
    "                df_measure['_VALUE'] = df_measure[cols['VALUE']]\n",
    "                df_measure['_UNC'] = df_measure[cols['UNC']]\n",
    "                df_measure['_DL'] = df_measure[cols['DL']]\n",
    "                df_measure['_UNIT'] = cols['UNIT']\n",
    "                \n",
    "                dfs_to_concat.append(df_measure)\n",
    "        \n",
    "        # Combine all measurement type dataframes\n",
    "        if dfs_to_concat:\n",
    "            tfm.dfs['SEDIMENT'] = pd.concat(dfs_to_concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ee701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21634     70697\n",
      "Rows removed from original (tfm.dfs_removed)       0         0         0\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29953 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/kg</th>\n",
       "      <th>value_bq/kg</th>\n",
       "      <th>error%_kg</th>\n",
       "      <th>&lt; value_bq/m²</th>\n",
       "      <th>value_bq/m²</th>\n",
       "      <th>error%_m²</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude (ddmmmm)</th>\n",
       "      <th>latitude (dddddd)</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>device</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>uppsli</th>\n",
       "      <th>lowsli</th>\n",
       "      <th>area</th>\n",
       "      <th>sedi</th>\n",
       "      <th>oxic</th>\n",
       "      <th>dw%</th>\n",
       "      <th>loi%</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>sum_link</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "      <th>_VALUE</th>\n",
       "      <th>_UNC</th>\n",
       "      <th>_DL</th>\n",
       "      <th>_UNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012116</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012116.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012117</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012117.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012118</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012118.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012119</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012119.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012120</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012120.0</td>\n",
       "      <td>05/25/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RU99</td>\n",
       "      <td>60.28</td>\n",
       "      <td>60,4667</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.8</td>\n",
       "      <td>KRIL01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key nuclide method < value_bq/kg  value_bq/kg  error%_kg  \\\n",
       "0  SKRIL2012116   CS137    NaN           NaN       1200.0       20.0   \n",
       "1  SKRIL2012117   CS137    NaN           NaN        250.0       20.0   \n",
       "2  SKRIL2012118   CS137    NaN           NaN        140.0       21.0   \n",
       "3  SKRIL2012119   CS137    NaN           NaN         79.0       20.0   \n",
       "4  SKRIL2012120   CS137    NaN           NaN         29.0       24.0   \n",
       "\n",
       "  < value_bq/m²  value_bq/m²  error%_m²    date_of_entry_x  country  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00     90.0   \n",
       "\n",
       "  laboratory   sequence               date    year  month   day station  \\\n",
       "0       KRIL  2012116.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "1       KRIL  2012117.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "2       KRIL  2012118.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "3       KRIL  2012119.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "4       KRIL  2012120.0  05/25/12 00:00:00  2012.0    5.0  25.0    RU99   \n",
       "\n",
       "   latitude (ddmmmm) latitude (dddddd)  longitude (ddmmmm)  \\\n",
       "0              60.28           60,4667               27.48   \n",
       "1              60.28           60,4667               27.48   \n",
       "2              60.28           60,4667               27.48   \n",
       "3              60.28           60,4667               27.48   \n",
       "4              60.28           60,4667               27.48   \n",
       "\n",
       "   longitude (dddddd)  device  tdepth  uppsli  lowsli   area  sedi oxic  dw%  \\\n",
       "0                27.8  KRIL01    25.0    15.0    20.0  0.006   NaN  NaN  NaN   \n",
       "1                27.8  KRIL01    25.0    20.0    25.0  0.006   NaN  NaN  NaN   \n",
       "2                27.8  KRIL01    25.0    25.0    30.0  0.006   NaN  NaN  NaN   \n",
       "3                27.8  KRIL01    25.0    30.0    35.0  0.006   NaN  NaN  NaN   \n",
       "4                27.8  KRIL01    25.0    35.0    40.0  0.006   NaN  NaN  NaN   \n",
       "\n",
       "   loi%  mors_subbasin  helcom_subbasin sum_link    date_of_entry_y  _VALUE  \\\n",
       "0   NaN           11.0             11.0      NaN  08/20/14 00:00:00  1200.0   \n",
       "1   NaN           11.0             11.0      NaN  08/20/14 00:00:00   250.0   \n",
       "2   NaN           11.0             11.0      NaN  08/20/14 00:00:00   140.0   \n",
       "3   NaN           11.0             11.0      NaN  08/20/14 00:00:00    79.0   \n",
       "4   NaN           11.0             11.0      NaN  08/20/14 00:00:00    29.0   \n",
       "\n",
       "   _UNC  _DL  _UNIT  \n",
       "0  20.0  NaN      3  \n",
       "1  20.0  NaN      3  \n",
       "2  21.0  NaN      3  \n",
       "3  20.0  NaN      3  \n",
       "4  24.0  NaN      3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(tfm.dfs['SEDIMENT'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807cbbe4",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some of the HELCOM datasets contain missing values in the `VALUE` column, see output after applying the `SanitizeValueCB` callback.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de49e39",
   "metadata": {},
   "source": [
    "We allocate each column containing measurement values (named differently across sample types) into a single column `VALUE` and remove `NA` where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_val = {'SEAWATER' : {'VALUE': 'value_bq/m³'},\n",
    "           'BIOTA':  {'VALUE': 'value_bq/kg'},\n",
    "           'SEDIMENT': {'VALUE': '_VALUE'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d74eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SanitizeValueCB(Callback):\n",
    "    \"Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, str]], # Columns of interest. Format: {group_name: {'val': 'column_name'}}\n",
    "                 verbose: bool=False\n",
    "                 ): \n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        tfm.dfs_dropped = {}\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            value_col = self.coi[grp]['VALUE']\n",
    "            # Count NaN values before dropping\n",
    "            initial_nan_count = df[value_col].isna().sum()\n",
    "                        \n",
    "            # define a dataframe with the rows that were dropped    \n",
    "            tfm.dfs_dropped[grp] = df[df[value_col].isna()]\n",
    "            \n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "\n",
    "            # Count NaN values after dropping\n",
    "            final_nan_count = df[value_col].isna().sum()\n",
    "            dropped_nan_count = initial_nan_count - final_nan_count\n",
    "            \n",
    "            # Print the number of dropped NaN values\n",
    "            if dropped_nan_count > 0 and self.verbose:\n",
    "                print(f\"Warning: {dropped_nan_count} missing value(s) in {value_col} for group {grp}.\")\n",
    "            \n",
    "            \n",
    "            df['VALUE'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 30 missing value(s) in value_bq/kg for group BIOTA.\n",
      "Warning: 153 missing value(s) in value_bq/m³ for group SEAWATER.\n",
      "Warning: 246 missing value(s) in _VALUE for group SEDIMENT.\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16094     21481     70451\n",
      "Rows removed from original (tfm.dfs_removed)      30       153       144\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29851 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val, verbose=True),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df: pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col: str, # Name of the column with measurement values\n",
    "    unc_col: str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the `UNC` is provided as a relative uncertainty. The column names for both the `VALUE` and the `UNC` vary by sample type. The `coi_units_unc` dictionary defines the column names for the `VALUE` and `UNC` for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('SEAWATER', 'value_bq/m³', 'error%_m³'),\n",
    "                 ('BIOTA', 'value_bq/kg', 'error%'),\n",
    "                 ('SEDIMENT', '_VALUE', '_UNC')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the ``UNC`` by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"Convert from relative error to standard uncertainty.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc: Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi: List[Tuple[str, str, str]]=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['UNC'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback ``NormalizeUncCB``. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALUE    UNC\n",
      "0    5.3  1.696\n",
      "1   19.9  3.980\n",
      "       VALUE      UNC\n",
      "0    0.01014      NaN\n",
      "1  135.30000  4.83021\n",
      "    VALUE    UNC\n",
      "0  1200.0  240.0\n",
      "1   250.0   50.0\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16094     21481     70451\n",
      "Rows removed from original (tfm.dfs_removed)      30       153       144\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29851 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "\n",
    "print(tfm.dfs['SEAWATER'][['VALUE', 'UNC']][:2])\n",
    "print(tfm.dfs['BIOTA'][['VALUE', 'UNC']][:2])\n",
    "print(tfm.dfs['SEDIMENT'][['VALUE', 'UNC']][:2])\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2c077",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c862aa2",
   "metadata": {},
   "source": [
    "HELCOM incorporates the unit directly into the column name. For the `SEDIMENT` sample type, the units are accounted for when Splitting the sediment values (i.e. `SplitSedimentValuesCB`). Let's examine the units associated with the other sample types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d102c9",
   "metadata": {},
   "source": [
    "For the `BIOTA` sample type, the base unit is `Bq/kg`, as indicated in the `value_bq/kg` column. The distinction between wet (W) and dry weight (D) is specified in the basis column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea27b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_bq/kg</th>\n",
       "      <th>basis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01014</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value_bq/kg basis\n",
       "0      0.01014     W"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA'][['value_bq/kg', 'basis']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a583f32",
   "metadata": {},
   "source": [
    "For the `SEAWATER` sample type, the unit is `Bq/m³` as indicated in the `value_bq/m³` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ed8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_bq/m³</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value_bq/m³\n",
       "0          5.3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEAWATER'][['value_bq/m³']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e264aa",
   "metadata": {},
   "source": [
    "We can now review the units that are available in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e594cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized\n",
       "0        -1  Not applicable  Not applicable\n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE\n",
       "2         1           Bq/m3       Bq per m3\n",
       "3         2           Bq/m2       Bq per m2\n",
       "4         3           Bq/kg       Bq per kg\n",
       "5         4          Bq/kgd      Bq per kgd\n",
       "6         5          Bq/kgw      Bq per kgw\n",
       "7         6           kg/kg       kg per kg\n",
       "8         7              TU              TU\n",
       "9         8      DELTA/mill  DELTA per mill\n",
       "10        9         atom/kg     atom per kg\n",
       "11       10        atom/kgd    atom per kgd\n",
       "12       11        atom/kgw    atom per kgw\n",
       "13       12          atom/l      atom per l\n",
       "14       13          Bq/kgC      Bq per kgC"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())[['unit_id', 'unit', 'unit_sanitized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d34fe",
   "metadata": {},
   "source": [
    "We define unit renaming rules for HELCOM in an **ad hoc** way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_units = {\n",
    "    'SEAWATER': 1,  # 'Bq/m3'\n",
    "    'SEDIMENT': '_UNIT', # account for in SplitSedimentValuesCB.\n",
    "    'BIOTA': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07e170",
   "metadata": {},
   "source": [
    "We define the `RemapUnitCB` callback to set the `UNIT` column in the DataFrames based on the lookup table `lut_units`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapUnitCB(Callback):\n",
    "    \"Set the `unit` id column in the DataFrames based on a lookup table.\"\n",
    "    def __init__(self, \n",
    "                 lut_units: dict=lut_units # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp == 'SEAWATER':\n",
    "                tfm.dfs[grp]['UNIT'] = self.lut_units[grp]\n",
    "            elif grp == 'BIOTA':\n",
    "                tfm.dfs[grp]['UNIT'] = tfm.dfs[grp]['basis'].apply(lambda x: lut_units[grp].get(x, 0))\n",
    "            elif grp == 'SEDIMENT':\n",
    "                tfm.dfs[grp]['UNIT'] = tfm.dfs[grp]['_UNIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e7771",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `RemapUnitCB()`. Then, print the unique `UNIT` for the `SEAWATER` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d546d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16094     21481     70451\n",
      "Rows removed from original (tfm.dfs_removed)      30       153       144\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29851 \n",
      "\n",
      "BIOTA: [5 0 4]\n",
      "SEDIMENT: [3 2]\n",
      "SEAWATER: [1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['UNIT'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa950b",
   "metadata": {},
   "source": [
    "## Remap detection limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fe0fa",
   "metadata": {},
   "source": [
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcce61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77091197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c37e8f",
   "metadata": {},
   "source": [
    "Based on columns of interest for each sample type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'SEAWATER' : {'VALUE' : 'value_bq/m³',\n",
    "                       'UNC' : 'error%_m³',\n",
    "                       'DL' : '< value_bq/m³'},\n",
    "          'BIOTA':  {'VALUE' : 'value_bq/kg',\n",
    "                     'UNC' : 'error%',\n",
    "                     'DL' : '< value_bq/kg'},\n",
    "          'SEDIMENT': {\n",
    "              'VALUE' : '_VALUE',\n",
    "              'UNC' : '_UNC',\n",
    "              'DL' : '_DL'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce2004",
   "metadata": {},
   "source": [
    "In some cases the detection limit is not provided in the HELCOM dataset. To handle this, we define the `RemapDetectionLimitCB` callback to process the detection limit (`DL`) column by applying the following logic:\n",
    "- Lookup Mapping: Maps existing detection limit values using a lookup table provided by fn_lut. This table translates specific detection limit indicators to standardized values.\n",
    "- Equal Condition Assignment: If both the activity value and its uncertainty are present, and the detection limit is not already defined in the lookup table, the detection limit is set to '=' (indicating a detected value).\n",
    "- Handling Unmatched Values: Any detection limit values not found in the lookup table are set to 'Not Available', ensuring all entries are accounted for in the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 coi: dict,  # Configuration options for column names\n",
    "                 fn_lut: Callable  # Function that returns a lookup table\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        lut = self.fn_lut()\n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "\n",
    "    def _update_detection_limit(self, df: pd.DataFrame, grp: str, lut: dict) -> None:\n",
    "        if grp not in coi_dl:\n",
    "            raise ValueError(f\"Group '{grp}' not found in coi_dl configuration.\")\n",
    "        \n",
    "        value_col, uncertainty_col, detection_col = self._get_column_names(grp)\n",
    "        df['DL'] = df[detection_col]\n",
    "        self._set_detection_limits(df, value_col, uncertainty_col, lut)\n",
    "\n",
    "    def _get_column_names(self, grp: str) -> tuple:\n",
    "        \"Retrieve column names for the group.\"\n",
    "        return coi_dl[grp]['VALUE'], coi_dl[grp]['UNC'], coi_dl[grp]['DL']\n",
    "\n",
    "    def _set_detection_limits(self, df: pd.DataFrame, value_col: str, uncertainty_col: str, lut: dict) -> None:\n",
    "        self._apply_equal_condition(df, value_col, uncertainty_col, lut)\n",
    "        self._set_unmatched_to_not_available(df, lut)\n",
    "        self._map_detection_limits(df, lut)\n",
    "\n",
    "    def _apply_equal_condition(self, df: pd.DataFrame, value_col: str, uncertainty_col: str, lut: dict) -> None:\n",
    "        \"Apply condition to set detection limits to '='.\"\n",
    "        # Set detection limits to '=' if there is a value and uncertainty and 'DL' value is not \n",
    "        # in the lookup table.\n",
    "        condition_eq = (df[value_col].notna() & df[uncertainty_col].notna() & ~df['DL'].isin(lut.keys()))\n",
    "        df.loc[condition_eq, 'DL'] = '='\n",
    "\n",
    "    def _set_unmatched_to_not_available(self, df: pd.DataFrame, lut: dict) -> None:\n",
    "        \"Set unmatched detection limits to 'Not Available'.\"\n",
    "        # Set detection limits to 'Not Available' if 'DL' value is not in the lookup table.\n",
    "        df.loc[~df['DL'].isin(lut.keys()), 'DL'] = 'Not Available'\n",
    "\n",
    "    def _map_detection_limits(self, df: pd.DataFrame, lut: dict) -> None:\n",
    "        \"Map detection limits using the lookup table.\"\n",
    "        df['DL'] = df['DL'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16094     21481     70451\n",
      "Rows removed from original (tfm.dfs_removed)      30       153       144\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29851 \n",
      "\n",
      "Unique DL values for BIOTA: [2 1 0]\n",
      "Unique DL values for SEDIMENT: [1 2 0]\n",
      "Unique DL values for SEAWATER: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB(),                  \n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f'Unique DL values for {grp}: {tfm.dfs[grp][\"DL\"].unique()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda9f9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**Feedback to Data Provider**: Discrepancies have been identified between some `rubin` codes in the HELCOM Biota dataset and the entries in the `RUBIN_NAME` lookup table. These discrepancies include typographical errors and trailing spaces, as illustrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c66608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CHAR BALT', 'FUCU SPP', 'FUCU VES ', 'FURC LUMB', 'GADU MOR  ', 'STUC PECT'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "set(dfs['BIOTA']['rubin']) - set(read_csv('RUBIN_NAME.csv')['RUBIN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a307ea",
   "metadata": {},
   "source": [
    "Lets review the data that includes inconsistent entries for the `rubin` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent entries for the `rubin` column: 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/kg</th>\n",
       "      <th>value_bq/kg</th>\n",
       "      <th>basis</th>\n",
       "      <th>error%</th>\n",
       "      <th>number</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude ddmmmm</th>\n",
       "      <th>latitude dddddd</th>\n",
       "      <th>longitude ddmmmm</th>\n",
       "      <th>longitude dddddd</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>rubin</th>\n",
       "      <th>biotatype</th>\n",
       "      <th>tissue</th>\n",
       "      <th>no</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>dw%</th>\n",
       "      <th>loi%</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13585</th>\n",
       "      <td>BVTIG2012042</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>W</td>\n",
       "      <td>6.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012042</td>\n",
       "      <td>12/15/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BARC11</td>\n",
       "      <td>54.4717</td>\n",
       "      <td>54.7862</td>\n",
       "      <td>13.5096</td>\n",
       "      <td>13.8493</td>\n",
       "      <td>37.0</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.79</td>\n",
       "      <td>1414.29</td>\n",
       "      <td>19.2</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13586</th>\n",
       "      <td>BVTIG2012042</td>\n",
       "      <td>CS137</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.17000</td>\n",
       "      <td>W</td>\n",
       "      <td>6.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012042</td>\n",
       "      <td>12/15/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BARC11</td>\n",
       "      <td>54.4717</td>\n",
       "      <td>54.7862</td>\n",
       "      <td>13.5096</td>\n",
       "      <td>13.8493</td>\n",
       "      <td>37.0</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.79</td>\n",
       "      <td>1414.29</td>\n",
       "      <td>19.2</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13587</th>\n",
       "      <td>BVTIG2012042</td>\n",
       "      <td>CS134</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.02366</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012042</td>\n",
       "      <td>12/15/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BARC11</td>\n",
       "      <td>54.4717</td>\n",
       "      <td>54.7862</td>\n",
       "      <td>13.5096</td>\n",
       "      <td>13.8493</td>\n",
       "      <td>37.0</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.79</td>\n",
       "      <td>1414.29</td>\n",
       "      <td>19.2</td>\n",
       "      <td>92.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13594</th>\n",
       "      <td>BVTIG2012045</td>\n",
       "      <td>K40</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.00000</td>\n",
       "      <td>W</td>\n",
       "      <td>6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012045</td>\n",
       "      <td>12/16/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>54.1385</td>\n",
       "      <td>54.2308</td>\n",
       "      <td>11.4691</td>\n",
       "      <td>11.7818</td>\n",
       "      <td>21.0</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38.87</td>\n",
       "      <td>1128.67</td>\n",
       "      <td>18.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13595</th>\n",
       "      <td>BVTIG2012045</td>\n",
       "      <td>CS137</td>\n",
       "      <td>VTIG01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.77000</td>\n",
       "      <td>W</td>\n",
       "      <td>6.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>2012045</td>\n",
       "      <td>12/16/12 00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>54.1385</td>\n",
       "      <td>54.2308</td>\n",
       "      <td>11.4691</td>\n",
       "      <td>11.7818</td>\n",
       "      <td>21.0</td>\n",
       "      <td>GADU MOR</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38.87</td>\n",
       "      <td>1128.67</td>\n",
       "      <td>18.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>04/07/16 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                key nuclide  method < value_bq/kg  value_bq/kg basis  error%  \\\n",
       "13585  BVTIG2012042     K40  VTIG01           NaN    144.00000     W    6.63   \n",
       "13586  BVTIG2012042   CS137  VTIG01           NaN      6.17000     W    6.03   \n",
       "13587  BVTIG2012042   CS134  VTIG01             <      0.02366     W     NaN   \n",
       "13594  BVTIG2012045     K40  VTIG01           NaN    131.00000     W    6.62   \n",
       "13595  BVTIG2012045   CS137  VTIG01           NaN      5.77000     W    6.03   \n",
       "\n",
       "       number    date_of_entry_x  country laboratory  sequence  \\\n",
       "13585     NaN  04/07/16 00:00:00      6.0       VTIG   2012042   \n",
       "13586     NaN  04/07/16 00:00:00      6.0       VTIG   2012042   \n",
       "13587     NaN  04/07/16 00:00:00      6.0       VTIG   2012042   \n",
       "13594     NaN  04/07/16 00:00:00      6.0       VTIG   2012045   \n",
       "13595     NaN  04/07/16 00:00:00      6.0       VTIG   2012045   \n",
       "\n",
       "                    date  year  month   day station  latitude ddmmmm  \\\n",
       "13585  12/15/12 00:00:00  2012   12.0  15.0  BARC11          54.4717   \n",
       "13586  12/15/12 00:00:00  2012   12.0  15.0  BARC11          54.4717   \n",
       "13587  12/15/12 00:00:00  2012   12.0  15.0  BARC11          54.4717   \n",
       "13594  12/16/12 00:00:00  2012   12.0  16.0     B12          54.1385   \n",
       "13595  12/16/12 00:00:00  2012   12.0  16.0     B12          54.1385   \n",
       "\n",
       "       latitude dddddd  longitude ddmmmm  longitude dddddd  sdepth  \\\n",
       "13585          54.7862           13.5096           13.8493    37.0   \n",
       "13586          54.7862           13.5096           13.8493    37.0   \n",
       "13587          54.7862           13.5096           13.8493    37.0   \n",
       "13594          54.2308           11.4691           11.7818    21.0   \n",
       "13595          54.2308           11.4691           11.7818    21.0   \n",
       "\n",
       "            rubin biotatype  tissue    no  length   weight   dw%  loi%  \\\n",
       "13585  GADU MOR           F       5  14.0   48.79  1414.29  19.2  92.9   \n",
       "13586  GADU MOR           F       5  14.0   48.79  1414.29  19.2  92.9   \n",
       "13587  GADU MOR           F       5  14.0   48.79  1414.29  19.2  92.9   \n",
       "13594  GADU MOR           F       5  15.0   38.87  1128.67  18.7  92.7   \n",
       "13595  GADU MOR           F       5  15.0   38.87  1128.67  18.7  92.7   \n",
       "\n",
       "       mors_subbasin  helcom_subbasin    date_of_entry_y  \n",
       "13585            2.0                2  04/07/16 00:00:00  \n",
       "13586            2.0                2  04/07/16 00:00:00  \n",
       "13587            2.0                2  04/07/16 00:00:00  \n",
       "13594            5.0               16  04/07/16 00:00:00  \n",
       "13595            5.0               16  04/07/16 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "rows_to_show = 5 \n",
    "df = dfs['BIOTA'][dfs['BIOTA']['rubin'].isin(set(dfs['BIOTA']['rubin']) - set(read_csv('RUBIN_NAME.csv')['RUBIN']))]\n",
    "print (f\"Number of inconsistent entries for the `rubin` column: {len(df)}\")\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head(rows_to_show))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7129a",
   "metadata": {},
   "source": [
    "We will remap the HELCOM `RUBIN` column to the MARIS `SPECIES` column using the **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply) pattern. First lets **inspect** the `RUBIN_NAME.csv` file provided by HELCOM, which describes the nomenclature of `BIOTA` species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "read_csv('RUBIN_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1858121",
   "metadata": {},
   "source": [
    "Now we try to **match** the `SCIENTIFIC NAME` column of ``HELCOM`` ``BIOTA`` dataset to the `species` column of the MARIS species lookup table, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 46/46 [00:07<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMI SAC</th>\n",
       "      <td>Laminaria japonica</td>\n",
       "      <td>LAMINARIA SACCHARINA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD EDU</th>\n",
       "      <td>Cardiidae</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH HI;BA</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>CHARA BALTICA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSET MAX</th>\n",
       "      <td>Pinctada maxima</td>\n",
       "      <td>PSETTA MAXIMA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA           10\n",
       "LAMI SAC     Laminaria japonica     LAMINARIA SACCHARINA            7\n",
       "CARD EDU              Cardiidae            CARDIUM EDULE            6\n",
       "CH HI;BA        Macoma balthica            CHARA BALTICA            6\n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "PSET MAX        Pinctada maxima            PSETTA MAXIMA            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=read_csv('RUBIN_NAME.csv'),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='SCIENTIFIC NAME',\n",
    "                    provider_col_key='RUBIN',\n",
    "                    fname_cache='species_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3b8aa",
   "metadata": {},
   "source": [
    "Below, we will correct the entries that were not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_species = {\n",
    "    'STIZOSTEDION LUCIOPERCA': 'Sander luciopercas',\n",
    "    'LAMINARIA SACCHARINA': 'Saccharina latissima',\n",
    "    'CARDIUM EDULE': 'Cerastoderma edule',\n",
    "    'CHARA BALTICA': NA,\n",
    "    'PSETTA MAXIMA': 'Scophthalmus maximus'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781f210",
   "metadata": {},
   "source": [
    "And give the ``remapper`` another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb07a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 46/46 [00:07<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a5",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `RUBIN` column to the `species` column after having defined the lookup table `lut_biota`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=read_csv('RUBIN_NAME.csv'),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='SCIENTIFIC NAME',\n",
    "                             provider_col_key='RUBIN',\n",
    "                             fname_cache='species_helcom.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321b5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  99,  243,   50,  139,  270,  192,  191,  284,   84,  269,  122,\n",
       "         96,  287,  279,  278,  288,  286,  244,  129,  275,  271,  285,\n",
       "        283,  247,  120,   59,  280,  274,  273,  290,  289,  272,  277,\n",
       "        276,   21,  282,  110,  281,  245,  704, 1524,  703,    0,  621,\n",
       "         60])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA')\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "tfm.dfs['BIOTA']['SPECIES'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "## Remap Body Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae2880",
   "metadata": {},
   "source": [
    "Let's inspect the `TISSUE.csv` file provided by HELCOM describing the tissue nomenclature. Biota tissue is known as `body part` in the MARIS data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 94.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>SKIN/EPIDERMIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brain</td>\n",
       "      <td>ENTRAILS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                           source_name  \\\n",
       "source_key                                                                \n",
       "3             Flesh without bones  WHOLE FISH WITHOUT HEAD AND ENTRAILS   \n",
       "2             Flesh without bones           WHOLE FISH WITHOUT ENTRAILS   \n",
       "8                      Soft parts                        SKIN/EPIDERMIS   \n",
       "5             Flesh without bones          FLESH WITHOUT BONES (FILETS)   \n",
       "1                    Whole animal                            WHOLE FISH   \n",
       "12                          Brain                              ENTRAILS   \n",
       "15          Stomach and intestine                   STOMACH + INTESTINE   \n",
       "41                   Whole animal                         WHOLE ANIMALS   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "3                    20  \n",
       "2                    13  \n",
       "8                    10  \n",
       "5                     9  \n",
       "1                     5  \n",
       "12                    5  \n",
       "15                    3  \n",
       "41                    1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=read_csv('TISSUE.csv'),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                    provider_col_key='TISSUE',\n",
    "                    fname_cache='tissues_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1bb9",
   "metadata": {},
   "source": [
    "We address several entries that were not correctly matched by the Remapper object, as detailed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_tissues = {\n",
    "    'WHOLE FISH WITHOUT HEAD AND ENTRAILS': 'Whole animal eviscerated without head',\n",
    "    'WHOLE FISH WITHOUT ENTRAILS': 'Whole animal eviscerated',\n",
    "    'SKIN/EPIDERMIS': 'Skin',\n",
    "    'ENTRAILS': 'Viscera'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 100.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                   source_name  match_score\n",
       "source_key                                                                  \n",
       "5             Flesh without bones  FLESH WITHOUT BONES (FILETS)            9\n",
       "1                    Whole animal                    WHOLE FISH            5\n",
       "15          Stomach and intestine           STOMACH + INTESTINE            3\n",
       "41                   Whole animal                 WHOLE ANIMALS            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef75cb1",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `TISSUE` column to the `BODY_PART` column after having defined the lookup table `lut_tissues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=read_csv('TISSUE.csv'),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                               provider_col_key='TISSUE',\n",
    "                               fname_cache='tissues_helcom.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1887c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tissue  BODY_PART\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='tissue', dest_grps='BIOTA'),\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA'][['tissue', 'BODY_PART']][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "## Remap Biological Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`lut_biogroup_from_biota` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biogroup_from_biota = lambda: get_lut(src_dir=species_lut_path().parent, fname=species_lut_path().name, \n",
    "                               key='species_id', value='biogroup_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a37157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3  0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='tissue', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA')\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA']['BIO_GROUP'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "## Remap Sediment Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938d40",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `SEDI` values `56` and `73` are not found in the `SEDIMENT_TYPE.csv` lookup table provided. Note there are many `nan` values. We reassign them to `-99` for now but should be clarified/fixed. This is demonstrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sediment type values in HELCOM lookup table: {56.0, nan, 73.0}\n",
      "Number of `56.0` values: 12\n",
      "Number of `73.0` values: 3\n",
      "Number of `NA` values: 1239\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Load the sediment type lookup table\n",
    "df_sed_lut = read_csv('SEDIMENT_TYPE.csv')\n",
    "\n",
    "# Load data with caching enabled\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "\n",
    "# Extract unique sediment types from the dataset and lookup table\n",
    "sediment_sedi = set(dfs['SEDIMENT']['sedi'].unique())\n",
    "lookup_sedi = set(df_sed_lut['SEDI'])\n",
    "\n",
    "# Identify missing sediment types\n",
    "missing = sediment_sedi - lookup_sedi\n",
    "\n",
    "# Output results\n",
    "print(f\"Missing sediment type values in HELCOM lookup table: {missing if missing else 'None'}\")\n",
    "print(f\"Number of `56.0` values: {(dfs['SEDIMENT']['sedi']== 56.0).sum()}\")\n",
    "print(f\"Number of `73.0` values: {(dfs['SEDIMENT']['sedi']== 73.0).sum()}\")\n",
    "print(f\"Number of `NA` values: {(dfs['SEDIMENT']['sedi'].isna()).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffefc5",
   "metadata": {},
   "source": [
    "Once again, we employ the **IMFA** (Inspect, Match, Fix, Apply) pattern to remap the HELCOM sediment types. Let's inspect the `SEDIMENT_TYPE.csv` file provided by HELCOM describing the sediment type nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SEDI</th>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <td>NO DATA</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>SAND</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>SILT</td>\n",
       "      <td>CLAY</td>\n",
       "      <td>MUD</td>\n",
       "      <td>GLACIAL</td>\n",
       "      <td>SOFT</td>\n",
       "      <td>SULPHIDIC</td>\n",
       "      <td>Fe-Mg CONCRETIONS</td>\n",
       "      <td>SAND AND GRAVEL</td>\n",
       "      <td>PURE SAND</td>\n",
       "      <td>SAND AND FINE SAND</td>\n",
       "      <td>SAND AND SILT</td>\n",
       "      <td>SAND AND CLAY</td>\n",
       "      <td>SAND AND MUD</td>\n",
       "      <td>FINE SAND AND GRAVEL</td>\n",
       "      <td>FINE SAND AND SAND</td>\n",
       "      <td>PURE FINE SAND</td>\n",
       "      <td>FINE SAND AND SILT</td>\n",
       "      <td>FINE SAND AND CLAY</td>\n",
       "      <td>FINE SAND AND MUD</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>SILT AND SAND</td>\n",
       "      <td>SILT AND FINE SAND</td>\n",
       "      <td>PURE SILT</td>\n",
       "      <td>SILT AND CLAY</td>\n",
       "      <td>SILT AND MUD</td>\n",
       "      <td>CLAY AND GRAVEL</td>\n",
       "      <td>CLAY AND SAND</td>\n",
       "      <td>CLAY AND FINE SAND</td>\n",
       "      <td>CLAY AND SILT</td>\n",
       "      <td>PURE CLAY</td>\n",
       "      <td>CLAY AND MUD</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>SOFT CLAY</td>\n",
       "      <td>SULPHIDIC CLAY</td>\n",
       "      <td>CLAY AND Fe-Mg CONCRETIONS</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>MUD AND SAND</td>\n",
       "      <td>MUD AND FINE SAND</td>\n",
       "      <td>MUD AND CLAY</td>\n",
       "      <td>PURE MUD</td>\n",
       "      <td>SOFT MUD</td>\n",
       "      <td>SULPHIDIC MUD</td>\n",
       "      <td>MUD AND Fe-Mg CONCRETIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO (ONLY TO USE AS ADJECTIVE)</td>\n",
       "      <td>NO (ONLY TO USE AS ADJECTIVE)</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0       1     2          3     4     5    6   \\\n",
       "SEDI                        -99       0     1          2     3     4    5   \n",
       "SEDIMENT TYPE           NO DATA  GRAVEL  SAND  FINE SAND  SILT  CLAY  MUD   \n",
       "RECOMMENDED TO BE USED      NaN     YES   YES         NO   YES   YES  YES   \n",
       "\n",
       "                             7     8                              9   \\\n",
       "SEDI                          6     7                              8   \n",
       "SEDIMENT TYPE           GLACIAL  SOFT                      SULPHIDIC   \n",
       "RECOMMENDED TO BE USED       NO    NO  NO (ONLY TO USE AS ADJECTIVE)   \n",
       "\n",
       "                                                   10               11  \\\n",
       "SEDI                                                9               10   \n",
       "SEDIMENT TYPE                       Fe-Mg CONCRETIONS  SAND AND GRAVEL   \n",
       "RECOMMENDED TO BE USED  NO (ONLY TO USE AS ADJECTIVE)              YES   \n",
       "\n",
       "                               12                  13             14  \\\n",
       "SEDI                           11                  12             13   \n",
       "SEDIMENT TYPE           PURE SAND  SAND AND FINE SAND  SAND AND SILT   \n",
       "RECOMMENDED TO BE USED         NO                  NO            YES   \n",
       "\n",
       "                                   15            16                    17  \\\n",
       "SEDI                               14            15                    20   \n",
       "SEDIMENT TYPE           SAND AND CLAY  SAND AND MUD  FINE SAND AND GRAVEL   \n",
       "RECOMMENDED TO BE USED            YES           YES                    NO   \n",
       "\n",
       "                                        18              19  \\\n",
       "SEDI                                    21              22   \n",
       "SEDIMENT TYPE           FINE SAND AND SAND  PURE FINE SAND   \n",
       "RECOMMENDED TO BE USED                  NO              NO   \n",
       "\n",
       "                                        20                  21  \\\n",
       "SEDI                                    23                  24   \n",
       "SEDIMENT TYPE           FINE SAND AND SILT  FINE SAND AND CLAY   \n",
       "RECOMMENDED TO BE USED                  NO                  NO   \n",
       "\n",
       "                                       22               23             24  \\\n",
       "SEDI                                   25               30             31   \n",
       "SEDIMENT TYPE           FINE SAND AND MUD  SILT AND GRAVEL  SILT AND SAND   \n",
       "RECOMMENDED TO BE USED                 NO              YES            YES   \n",
       "\n",
       "                                        25         26             27  \\\n",
       "SEDI                                    32         33             34   \n",
       "SEDIMENT TYPE           SILT AND FINE SAND  PURE SILT  SILT AND CLAY   \n",
       "RECOMMENDED TO BE USED                  NO         NO            YES   \n",
       "\n",
       "                                  28               29             30  \\\n",
       "SEDI                              35               40             41   \n",
       "SEDIMENT TYPE           SILT AND MUD  CLAY AND GRAVEL  CLAY AND SAND   \n",
       "RECOMMENDED TO BE USED           YES              YES            YES   \n",
       "\n",
       "                                        31             32         33  \\\n",
       "SEDI                                    42             43         44   \n",
       "SEDIMENT TYPE           CLAY AND FINE SAND  CLAY AND SILT  PURE CLAY   \n",
       "RECOMMENDED TO BE USED                  NO            YES         NO   \n",
       "\n",
       "                                  34            35         36              37  \\\n",
       "SEDI                              45            46         47              48   \n",
       "SEDIMENT TYPE           CLAY AND MUD  CLACIAL CLAY  SOFT CLAY  SULPHIDIC CLAY   \n",
       "RECOMMENDED TO BE USED           YES            NO         NO             YES   \n",
       "\n",
       "                                                38              39  \\\n",
       "SEDI                                            49              50   \n",
       "SEDIMENT TYPE           CLAY AND Fe-Mg CONCRETIONS  MUD AND GARVEL   \n",
       "RECOMMENDED TO BE USED                         YES             YES   \n",
       "\n",
       "                                  40                 41            42  \\\n",
       "SEDI                              51                 52            54   \n",
       "SEDIMENT TYPE           MUD AND SAND  MUD AND FINE SAND  MUD AND CLAY   \n",
       "RECOMMENDED TO BE USED           YES                 NO           YES   \n",
       "\n",
       "                              43        44             45  \\\n",
       "SEDI                          55        57             58   \n",
       "SEDIMENT TYPE           PURE MUD  SOFT MUD  SULPHIDIC MUD   \n",
       "RECOMMENDED TO BE USED        NO        NO            YES   \n",
       "\n",
       "                                               46  \n",
       "SEDI                                           59  \n",
       "SEDIMENT TYPE           MUD AND Fe-Mg CONCRETIONS  \n",
       "RECOMMENDED TO BE USED                        YES  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(read_csv('SEDIMENT_TYPE.csv').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e669f",
   "metadata": {},
   "source": [
    "Let's try to match as many as possible of the HELCOM sediment types to the MARIS standard sediment types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 95.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 entries matched the criteria, while 3 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>Soft</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99                      Soft         NO DATA            5\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=read_csv('SEDIMENT_TYPE.csv'),\n",
    "                    maris_lut_fn=sediments_lut_path,\n",
    "                    maris_col_id='sedtype_id',\n",
    "                    maris_col_name='sedtype',\n",
    "                    provider_col_to_match='SEDIMENT TYPE',\n",
    "                    provider_col_key='SEDI',\n",
    "                    fname_cache='sediments_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a92e4",
   "metadata": {},
   "source": [
    "We address the remaining unmatched values by adding fixes_sediments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_sediments = {\n",
    "    'NO DATA': NA\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05728a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 82.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 entries matched the criteria, while 3 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>(Not available)</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99           (Not available)         NO DATA            2\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_sediments)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152c8c7",
   "metadata": {},
   "source": [
    "Upon visual inspection, the remaining values are deemed acceptable for further processing. We will now implement a callback to remap the SEDI values to their corresponding MARIS standard sediment types, designated as SED_TYPE. The HELCOM SEDIMENT dataset contains SEDI values that are absent from the HELCOM lookup table. These values will be reassigned to `-99`, indicating 'Not Available' as per the HELCOM standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8afbb",
   "metadata": {},
   "source": [
    "Reassign the `SEDI` values of `56`, `73`, and `nan` to `-99` (Not available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052dda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "sed_replace_lut = {\n",
    "    56: -99,\n",
    "    73: -99,\n",
    "    NA: -99\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d99eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedimentCB(Callback):\n",
    "    \"Lookup sediment id using lookup table.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable,  # Function that returns the lookup table dictionary\n",
    "                 sed_grp_name: str = 'SEDIMENT',  # The name of the sediment group\n",
    "                 sed_col_name: str = 'sedi',  # The name of the sediment column\n",
    "                 replace_lut: dict = None  # Dictionary for replacing SEDI values\n",
    "                 ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap sediment types using lookup table.\"\n",
    "        df = tfm.dfs[self.sed_grp_name]\n",
    "        self._fix_inconsistent_values(df)\n",
    "        self._map_sediment_types(df)\n",
    "\n",
    "    def _fix_inconsistent_values(self, df: pd.DataFrame) -> None:\n",
    "        \"Fix inconsistent values using the replace lookup table.\"\n",
    "        if self.replace_lut:\n",
    "            df[self.sed_col_name] = df[self.sed_col_name].replace(self.replace_lut)\n",
    "            if NA in self.replace_lut:\n",
    "                df[self.sed_col_name] = df[self.sed_col_name].fillna(self.replace_lut[NA])\n",
    "\n",
    "    def _map_sediment_types(self, df: pd.DataFrame) -> None:\n",
    "        \"Map sediment types using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        df['SED_TYPE'] = df[self.sed_col_name].map(\n",
    "            lambda x: lut.get(x, Match(0, None, None, None)).matched_id\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_sediments = lambda: Remapper(provider_lut_df=read_csv('SEDIMENT_TYPE.csv'),\n",
    "                                 maris_lut_fn=sediments_lut_path,\n",
    "                                 maris_col_id='sedtype_id',\n",
    "                                 maris_col_name='sedtype',\n",
    "                                 provider_col_to_match='SEDIMENT TYPE',\n",
    "                                 provider_col_key='SEDI',\n",
    "                                 fname_cache='sediments_helcom.pkl'\n",
    "                                 ).generate_lookup_table(fixes=fixes_sediments, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d334ac",
   "metadata": {},
   "source": [
    "Utilize the `RemapSedimentCB` callback to remap the `SEDI` values in the HELCOM dataset to the corresponding MARIS standard sediment type, referred to as `SED_TYPE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25495b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 58, 30, 59, 55, 56, 36, 29, 47,  4, 54, 33,  6, 44, 42, 48,\n",
       "       61, 57, 28, 49, 32, 45, 39, 46, 38, 31, 60, 62, 26, 53, 52,  1, 51,\n",
       "       37, 34, 50,  7, 10, 41, 43, 35])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut)\n",
    "    ])\n",
    "\n",
    "tfm()\n",
    "tfm.dfs['SEDIMENT']['SED_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "## Remap Filtering Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea63f3",
   "metadata": {},
   "source": [
    "HELCOM filtered status is encoded as follows in the `FILT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index value\n",
       "0      0     F\n",
       "1      1     n\n",
       "2      2     N\n",
       "3      3   NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "get_unique_across_dfs(dfs, col_name='filt', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee067",
   "metadata": {},
   "source": [
    "MARIS uses a different encoding for filtered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(filtered_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf457",
   "metadata": {},
   "source": [
    "For only four categories to remap, the `Remapper` is an overkill. We can use a simple dictionary to map the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_filtered = {\n",
    "    'N': 2, # No\n",
    "    'n': 2, # No\n",
    "    'F': 1 # Yes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`RemapFiltCB` converts the HELCOM `filt` data to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapFiltCB(Callback):\n",
    "    \"Lookup filt value in dataframe using the lookup table.\"\n",
    "    def __init__(self,\n",
    "                 lut_filtered: dict=lut_filtered, # Dictionary mapping filt codes to their corresponding names\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'filt' in df.columns:\n",
    "                df['FILT'] = df['filt'].map(lambda x: self.lut_filtered.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719feb2c",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[RemapFiltCB(lut_filtered)])\n",
    "\n",
    "print(tfm()['SEAWATER']['FILT'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "## Add Sample ID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abac4d",
   "metadata": {},
   "source": [
    "The `AddSampleIDCB` callback generates a sample ID, `SMP_ID`, from the HELCOM `KEY`. The `custom_enums` attribute of the `Transformer` stores dictionaries of custom enums. In this context, `custom_enums` maps the HELCOM `KEY` to an integer, which is then used to create the `SMP_ID`. Custom enums are created for each group and included in the output NetCDF file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41078e33",
   "metadata": {},
   "source": [
    "Need to santise the sample id values for the enum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class AddSampleIDCB(Callback):\n",
    "    \"Generate a SMP_ID from the KEY values in the HELCOM dataset. Each KEY is mapped to a unique integer, with the mapping stored in an enumeration (i.e., smp_id).\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            # Generate and store the SMP_ID map\n",
    "            smp_id_map = self._generate_sample_id_map(df)\n",
    "            tfm.custom_maps[grp]['SMP_ID'] = smp_id_map\n",
    "            # Create SMP_ID column in the DataFrame\n",
    "            self._create_smp_id(df, smp_id_map)\n",
    "        \n",
    "    def _generate_sample_id_map(self, df: pd.DataFrame) -> dict:\n",
    "        \"\"\"Enumerate unique 'key' values and map them to integers.\"\"\"\n",
    "        return {key: idx for idx, key in enumerate(df['key'].unique())}\n",
    "\n",
    "    def _create_smp_id(self, df: pd.DataFrame, smp_id_map: dict) -> None:\n",
    "        \"\"\"Map 'key' values to 'SMP_ID' using the provided enum.\"\"\"\n",
    "        df['SMP_ID'] = df['key'].map(smp_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sample ids in SEAWATER: 9784\n",
      "Number of unique sample ids in BIOTA: 4792\n",
      "Number of unique sample ids in SEDIMENT: 14234\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21634     40744\n",
      "Rows removed from original (tfm.dfs_removed)       0         0         0\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                        AddSampleIDCB(),\n",
    "                        CompareDfsAndTfmCB(dfs)\n",
    "                        ])\n",
    "tfm()\n",
    "\n",
    "print(f'Number of unique sample ids in SEAWATER: {tfm.dfs[\"SEAWATER\"][\"SMP_ID\"].unique().size}')\n",
    "print(f'Number of unique sample ids in BIOTA: {tfm.dfs[\"BIOTA\"][\"SMP_ID\"].unique().size}')\n",
    "print(f'Number of unique sample ids in SEDIMENT: {tfm.dfs[\"SEDIMENT\"][\"SMP_ID\"].unique().size}')\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adeeee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude (ddmmmm)</th>\n",
       "      <th>latitude (dddddd)</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "      <th>SMP_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003.0</td>\n",
       "      <td>05/23/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RU10</td>\n",
       "      <td>60.05</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004.0</td>\n",
       "      <td>05/23/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RU10</td>\n",
       "      <td>60.05</td>\n",
       "      <td>60.0833</td>\n",
       "      <td>29.20</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005.0</td>\n",
       "      <td>06/17/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>RU11</td>\n",
       "      <td>59.26</td>\n",
       "      <td>59.4333</td>\n",
       "      <td>23.09</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006.0</td>\n",
       "      <td>05/24/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>RU19</td>\n",
       "      <td>60.15</td>\n",
       "      <td>60.2500</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007.0</td>\n",
       "      <td>05/24/12 00:00:00</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>RU19</td>\n",
       "      <td>60.15</td>\n",
       "      <td>60.2500</td>\n",
       "      <td>27.59</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key nuclide method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     date_of_entry_x  country laboratory   sequence               date  \\\n",
       "0  08/20/14 00:00:00     90.0       KRIL  2012003.0  05/23/12 00:00:00   \n",
       "1  08/20/14 00:00:00     90.0       KRIL  2012004.0  05/23/12 00:00:00   \n",
       "2  08/20/14 00:00:00     90.0       KRIL  2012005.0  06/17/12 00:00:00   \n",
       "3  08/20/14 00:00:00     90.0       KRIL  2012006.0  05/24/12 00:00:00   \n",
       "4  08/20/14 00:00:00     90.0       KRIL  2012007.0  05/24/12 00:00:00   \n",
       "\n",
       "     year  month   day station  latitude (ddmmmm)  latitude (dddddd)  \\\n",
       "0  2012.0    5.0  23.0    RU10              60.05            60.0833   \n",
       "1  2012.0    5.0  23.0    RU10              60.05            60.0833   \n",
       "2  2012.0    6.0  17.0    RU11              59.26            59.4333   \n",
       "3  2012.0    5.0  24.0    RU19              60.15            60.2500   \n",
       "4  2012.0    5.0  24.0    RU19              60.15            60.2500   \n",
       "\n",
       "   longitude (ddmmmm)  longitude (dddddd)  tdepth  sdepth  salin  ttemp filt  \\\n",
       "0               29.20             29.3333     NaN     0.0    NaN    NaN  NaN   \n",
       "1               29.20             29.3333     NaN    29.0    NaN    NaN  NaN   \n",
       "2               23.09             23.1500     NaN     0.0    NaN    NaN  NaN   \n",
       "3               27.59             27.9833     NaN     0.0    NaN    NaN  NaN   \n",
       "4               27.59             27.9833     NaN    39.0    NaN    NaN  NaN   \n",
       "\n",
       "   mors_subbasin  helcom_subbasin    date_of_entry_y  SMP_ID  \n",
       "0           11.0             11.0  08/20/14 00:00:00       0  \n",
       "1           11.0             11.0  08/20/14 00:00:00       1  \n",
       "2           11.0              3.0  08/20/14 00:00:00       2  \n",
       "3           11.0             11.0  08/20/14 00:00:00       3  \n",
       "4           11.0             11.0  08/20/14 00:00:00       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(tfm.dfs['SEAWATER'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac551",
   "metadata": {},
   "source": [
    "## Add depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7940b",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a column for the sampling depth (`SDEPTH`) for the `SEAWATER` and `BIOTA` datasets. Additionally, it contains a column for the total depth (`TDEPTH`) applicable to both the `SEDIMENT` and `SEAWATER` datasets. In this section, we will create a callback to incorporate both the sampling depth (`smp_depth`) and total depth (`tot_depth`) into the MARIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f14b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddDepthCB(Callback):\n",
    "    \"Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'sdepth' in df.columns:\n",
    "                df['SMP_DEPTH'] = df['sdepth'].astype(float)\n",
    "            if 'tdepth' in df.columns:\n",
    "                df['TOT_DEPTH'] = df['tdepth'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96264ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA:        SMP_DEPTH\n",
      "0            NaN\n",
      "78         22.00\n",
      "88         39.00\n",
      "96         40.00\n",
      "183        65.00\n",
      "...          ...\n",
      "15874      43.10\n",
      "15921      30.43\n",
      "15984       7.60\n",
      "15985       5.50\n",
      "15988      11.20\n",
      "\n",
      "[301 rows x 1 columns]\n",
      "SEAWATER:        SMP_DEPTH  TOT_DEPTH\n",
      "0            0.0        NaN\n",
      "1           29.0        NaN\n",
      "4           39.0        NaN\n",
      "6           62.0        NaN\n",
      "10          71.0        NaN\n",
      "...          ...        ...\n",
      "21059       15.0       15.0\n",
      "21217        7.0       16.0\n",
      "21235       19.2       21.0\n",
      "21312        1.0        5.5\n",
      "21521        0.5        NaN\n",
      "\n",
      "[1686 rows x 2 columns]\n",
      "SEDIMENT:        TOT_DEPTH\n",
      "0           25.0\n",
      "6           61.0\n",
      "19          31.0\n",
      "33          39.0\n",
      "42          36.0\n",
      "...          ...\n",
      "35882        3.9\n",
      "36086      103.0\n",
      "36449      108.9\n",
      "36498        4.5\n",
      "36899      125.0\n",
      "\n",
      "[195 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[AddDepthCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'SMP_DEPTH' in tfm.dfs[grp].columns and 'TOT_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SMP_DEPTH','TOT_DEPTH']].drop_duplicates())\n",
    "    elif 'SMP_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SMP_DEPTH']].drop_duplicates())\n",
    "    elif 'TOT_DEPTH' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['TOT_DEPTH']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e169c8",
   "metadata": {},
   "source": [
    "## Add Salinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e599987",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**\n",
    "\n",
    "The HELCOM dataset includes a column for the salinity of the water (`SALIN`). According to the HELCOM documentation, the `SALIN` column represents \"Salinity of water in PSU units\".\n",
    "\n",
    "In the SEAWATER dataset, three entries have salinity values greater than 50 PSU. While salinity values greater than 50 PSU are possible, these entries may require further verification. Notably, these three entries have a salinity value of 99.99 PSU, which suggests potential data entry errors.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e7a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12288</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>CS137</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>CS134</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12290</th>\n",
       "      <td>WDHIG1998072</td>\n",
       "      <td>SR90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1998072.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                key nuclide method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "12288  WDHIG1998072   CS137      3           NaN         40.1        1.6   \n",
       "12289  WDHIG1998072   CS134      3           NaN          1.1       23.6   \n",
       "12290  WDHIG1998072    SR90      2           NaN          8.5        1.9   \n",
       "\n",
       "      date_of_entry_x  country laboratory   sequence  ... tdepth  sdepth  \\\n",
       "12288             NaN      6.0       DHIG  1998072.0  ...   25.0     0.0   \n",
       "12289             NaN      6.0       DHIG  1998072.0  ...   25.0     0.0   \n",
       "12290             NaN      6.0       DHIG  1998072.0  ...   25.0     0.0   \n",
       "\n",
       "       salin  ttemp filt  mors_subbasin  helcom_subbasin  date_of_entry_y  \\\n",
       "12288  99.99    5.0    F            5.0             15.0              NaN   \n",
       "12289  99.99    5.0    F            5.0             15.0              NaN   \n",
       "12290  99.99    5.0    F            5.0             15.0              NaN   \n",
       "\n",
       "       SMP_DEPTH  TOT_DEPTH  \n",
       "12288        0.0       25.0  \n",
       "12289        0.0       25.0  \n",
       "12290        0.0       25.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "tfm.dfs['SEAWATER'][tfm.dfs['SEAWATER']['salin'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fd696",
   "metadata": {},
   "source": [
    "Lets add the salinity values to the SEAWATER DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddSalinityCB(Callback):\n",
    "    def __init__(self, salinity_col: str = 'salin'):\n",
    "        self.salinity_col = salinity_col\n",
    "    \"Add salinity to the SEAWATER DataFrame.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if self.salinity_col in df.columns:\n",
    "                df['SALINITY'] = df[self.salinity_col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER:        SALINITY\n",
      "0           NaN\n",
      "97        7.570\n",
      "98        7.210\n",
      "101       7.280\n",
      "104       7.470\n",
      "...         ...\n",
      "21449    11.244\n",
      "21450     7.426\n",
      "21451     9.895\n",
      "21452     2.805\n",
      "21453     7.341\n",
      "\n",
      "[2766 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[AddSalinityCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'SALINITY' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['SALINITY']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31cc1d5",
   "metadata": {},
   "source": [
    "## Add Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6b981",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**\n",
    "\n",
    "The HELCOM dataset includes a column for the temperature of the water (`TTEMP`). According to the HELCOM documentation, the `TTEMP` column represents:\n",
    "> 'Water temperature in Celsius (ºC) degrees of sampled water'\n",
    "\n",
    "In the SEAWATER dataset, several entries have temperature values greater than 50ºC. These entries may require further verification. Notably, these entries have a temperature value of 99.99ºC, which suggests potential data entry errors, see below.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e1b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with temperature greater than 50ºC:  92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "      <th>SALINITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>WDHIG1995559</td>\n",
       "      <td>CS134</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1995559.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2033</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>99.9</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>WDHIG1995559</td>\n",
       "      <td>CS137</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1995559.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2033</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>99.9</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>WDHIG1995569</td>\n",
       "      <td>CS134</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1995569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2777</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>99.9</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>WDHIG1995569</td>\n",
       "      <td>CS137</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1995569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2777</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>99.9</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>WDHIG1995571</td>\n",
       "      <td>CS134</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>1995571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.59</td>\n",
       "      <td>99.9</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               key nuclide method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "5954  WDHIG1995559   CS134      4           NaN          1.7       15.0   \n",
       "5955  WDHIG1995559   CS137      4           NaN         58.7        2.0   \n",
       "5960  WDHIG1995569   CS134      4           NaN          1.4       12.0   \n",
       "5961  WDHIG1995569   CS137      4           NaN         62.8        1.0   \n",
       "5964  WDHIG1995571   CS134      4           NaN          1.5       17.0   \n",
       "\n",
       "     date_of_entry_x  country laboratory   sequence  ... longitude (dddddd)  \\\n",
       "5954             NaN      6.0       DHIG  1995559.0  ...            10.2033   \n",
       "5955             NaN      6.0       DHIG  1995559.0  ...            10.2033   \n",
       "5960             NaN      6.0       DHIG  1995569.0  ...            10.2777   \n",
       "5961             NaN      6.0       DHIG  1995569.0  ...            10.2777   \n",
       "5964             NaN      6.0       DHIG  1995571.0  ...            10.2000   \n",
       "\n",
       "      tdepth  sdepth  salin ttemp  filt  mors_subbasin  helcom_subbasin  \\\n",
       "5954    13.0    11.0  14.81  99.9     N            5.0             15.0   \n",
       "5955    13.0    11.0  14.81  99.9     N            5.0             15.0   \n",
       "5960    14.0    12.0  14.80  99.9     N            5.0             15.0   \n",
       "5961    14.0    12.0  14.80  99.9     N            5.0             15.0   \n",
       "5964    19.0    17.0  14.59  99.9     N            5.0             15.0   \n",
       "\n",
       "      date_of_entry_y  SALINITY  \n",
       "5954              NaN     14.81  \n",
       "5955              NaN     14.81  \n",
       "5960              NaN     14.80  \n",
       "5961              NaN     14.80  \n",
       "5964              NaN     14.59  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "t_df= tfm.dfs['SEAWATER'][tfm.dfs['SEAWATER']['ttemp'] > 50]\n",
    "print('Number of entries with temperature greater than 50ºC: ', t_df.shape[0])\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd942d",
   "metadata": {},
   "source": [
    "Lets add the temperature values to the SEAWATER DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047afa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AddTemperatureCB(Callback):\n",
    "    def __init__(self, temperature_col: str = 'ttemp'):\n",
    "        self.temperature_col = temperature_col\n",
    "    \"Add temperature to the SEAWATER DataFrame.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            if self.temperature_col in df.columns:\n",
    "                df['TEMPERATURE'] = df[self.temperature_col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER:        TEMPERATURE\n",
      "0              NaN\n",
      "987           7.80\n",
      "990           6.50\n",
      "993           4.10\n",
      "996           4.80\n",
      "...            ...\n",
      "21521         0.57\n",
      "21523        18.27\n",
      "21525        21.54\n",
      "21529         4.94\n",
      "21537         2.35\n",
      "\n",
      "[1086 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[AddTemperatureCB()])\n",
    "tfm()\n",
    "for grp in tfm.dfs.keys():  \n",
    "    if 'TEMPERATURE' in tfm.dfs[grp].columns:\n",
    "        print(f'{grp}:', tfm.dfs[grp][['TEMPERATURE']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "## Add slice position (TOP and BOTTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['uppsli']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['lowsli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOP  BOTTOM\n",
      "0  15.0    20.0\n",
      "1  20.0    25.0\n",
      "2  25.0    30.0\n",
      "3  30.0    35.0\n",
      "4  35.0    40.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedSliceTopBottomCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEDIMENT'][['TOP','BOTTOM']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "## Add dry weight, wet weight and percentage weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d2796",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Entries for the ``BASIS`` value of the ``BIOTA`` dataset report a value of `F` which is not consistent with the HELCOM description provided in the metadata. The `GUIDELINES FOR MONITORING OF RADIOACTIVE SUBSTANCES` was obtained from [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2b08",
   "metadata": {},
   "source": [
    "Lets take a look at the BIOTA BASIS values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcfc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['basis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafeff5",
   "metadata": {},
   "source": [
    "Number of entries for each ``BASIS`` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d37b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basis\n",
       "W    12164\n",
       "D     3868\n",
       "F       25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['basis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc763755",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some entries for ``DW%`` (Dry weight as percentage (%) of fresh weight) are much higher than 100%. Additionally, ``DW%`` is repoted as 0% in some cases.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f3249",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc7826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['dw%'][dfs['BIOTA']['dw%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b30b6b",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f386973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['dw%'][dfs['BIOTA']['dw%'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b1201",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['dw%'][dfs['SEDIMENT']['dw%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f48f6",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44234014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['dw%'][dfs['SEDIMENT']['dw%'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00833c1f",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Several SEDIMENT entries have `DW%` (Dry weight as percentage of fresh weight) values less than 1%. While technically possible, this would indicate samples contained more than 99% water content.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fb178",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` less than 1% but greater than 0.001%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c78c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "percent=1\n",
    "dfs['SEDIMENT']['dw%'][(dfs['SEDIMENT']['dw%'] < percent) & (dfs['SEDIMENT']['dw%'] > 0.001)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c2a",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS description of the `percentwt`, `drywt` and `wetwt` variables:\n",
    "\n",
    "- `percentwt`: Dry weight as ratio of fresh weight, expressed as a decimal .\n",
    "- `drywt`: Dry weight in grams.\n",
    "- `wetwt`: Fresh weight in grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92f75f",
   "metadata": {},
   "source": [
    "Lets take a look at the HELCOM dataset, the weight of the sample is not reported for ``SEDIMENT``. However, the percentage dry weight is reported as `DW%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92c9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'nuclide', 'method', '< value_bq/kg', 'value_bq/kg', 'error%_kg',\n",
       "       '< value_bq/m²', 'value_bq/m²', 'error%_m²', 'date_of_entry_x',\n",
       "       'country', 'laboratory', 'sequence', 'date', 'year', 'month', 'day',\n",
       "       'station', 'latitude (ddmmmm)', 'latitude (dddddd)',\n",
       "       'longitude (ddmmmm)', 'longitude (dddddd)', 'device', 'tdepth',\n",
       "       'uppsli', 'lowsli', 'area', 'sedi', 'oxic', 'dw%', 'loi%',\n",
       "       'mors_subbasin', 'helcom_subbasin', 'sum_link', 'date_of_entry_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1037bff",
   "metadata": {},
   "source": [
    "The BIOTA dataset reports the weight of the sample as `WEIGHT` and the percentage dry weight as `DW%`. The `BASIS` column describes the basis of the value reported. Lets create a callback to include the `PERCENTWT`, `DRYWT` and `WETWT` columns in the MARIS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetPercentWeightCB(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'dw%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "            if 'weight' in tfm.dfs[grp].columns and 'basis' in tfm.dfs[grp].columns:\n",
    "                self._correct_basis(tfm.dfs[grp])\n",
    "                self._apply_weight(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['PERCENTWT'] = df['dw%'] / 100  # Convert percentage to fraction\n",
    "        df.loc[df['PERCENTWT'] == 0, 'PERCENTWT'] = np.NaN  # Convert 0% to NaN\n",
    "\n",
    "    def _correct_basis(self, df: pd.DataFrame) -> None:\n",
    "        \"Correct BASIS values. Assuming F = Fresh weight, so F = W\"\n",
    "        df.loc[df['basis'] == 'F', 'basis'] = 'W'\n",
    "\n",
    "    def _apply_weight(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply weight conversion and formatting to the given DataFrame.\"\n",
    "        dry_condition = df['basis'] == 'D'\n",
    "        wet_condition = df['basis'] == 'W'\n",
    "        \n",
    "        df.loc[dry_condition, 'DRYWT'] = df['weight']\n",
    "        df.loc[dry_condition & df['PERCENTWT'].notna(), 'WETWT'] = df['weight'] / df['PERCENTWT']\n",
    "        \n",
    "        df.loc[wet_condition, 'WETWT'] = df['weight']\n",
    "        df.loc[wet_condition & df['PERCENTWT'].notna(), 'DRYWT'] = df['weight'] * df['PERCENTWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21634     40744\n",
      "Rows removed from original (tfm.dfs_removed)       0         0         0\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n",
      "BIOTA:    PERCENTWT      DRYWT  WETWT\n",
      "0    0.18453  174.93444  948.0\n",
      "1    0.18453  174.93444  948.0\n",
      "2    0.18453  174.93444  948.0\n",
      "3    0.18453  174.93444  948.0\n",
      "4    0.18458  177.93512  964.0 \n",
      "\n",
      "SEDIMENT: [       nan 0.1        0.13       ... 0.24418605 0.25764192 0.26396495]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('BIOTA:', tfm.dfs['BIOTA'][['PERCENTWT','DRYWT','WETWT']].head(), '\\n')\n",
    "print('SEDIMENT:', tfm.dfs['SEDIMENT']['PERCENTWT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68925d7c",
   "metadata": {},
   "source": [
    "Note that the dry weight is greater than the wet weight for some entries in the BIOTA dataset due to the DW% being greater than 100%, see above. Lets take a look at the number of entries where this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRYWT    20\n",
       "WETWT    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['BIOTA'][['DRYWT','WETWT']][tfm.dfs['BIOTA']['DRYWT'] > tfm.dfs['BIOTA']['WETWT']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af4d77",
   "metadata": {},
   "source": [
    "## Standardize Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203cb3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Column names for geographical coordinates are inconsistent across sample types (biota, sediment, seawater). Sometimes using parentheses, sometimes not.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c04fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: ['latitude ddmmmm', 'latitude dddddd', 'longitude ddmmmm', 'longitude dddddd']\n",
      "SEAWATER: ['latitude (ddmmmm)', 'latitude (dddddd)', 'longitude (ddmmmm)', 'longitude (dddddd)']\n",
      "SEDIMENT: ['latitude (ddmmmm)', 'latitude (dddddd)', 'longitude (ddmmmm)', 'longitude (dddddd)']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "for grp in dfs.keys():\n",
    "    print(f'{grp}: {[col for col in dfs[grp].columns if \"lon\" in col or \"lat\" in col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83c2e1",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: HELCOM SEAWATER data includes values of 0 or nan for both latitude and longitude. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82edeb9",
   "metadata": {},
   "source": [
    "Lets create a callback to parse the coordinates of the HELCOM dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseCoordinates(Callback):\n",
    "    \"Get geographical coordinates from columns expressed in degrees decimal format or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_cor: Callable # Function that converts coordinates from degree-minute to decimal degree format\n",
    "                 ):\n",
    "        self.fn_convert_cor = fn_convert_cor\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._format_coordinates(df)\n",
    "\n",
    "    def _format_coordinates(self, df:pd.DataFrame) -> None:\n",
    "        coord_cols = self._get_coord_columns(df.columns)\n",
    "        \n",
    "        \n",
    "        for coord in ['lat', 'lon']:\n",
    "            decimal_col, minute_col = coord_cols[f'{coord}_d'], coord_cols[f'{coord}_m']\n",
    "            # Attempt to convert columns to numeric, coercing errors to NaN.\n",
    "            df[decimal_col] = pd.to_numeric(df[decimal_col], errors='coerce')\n",
    "            df[minute_col] = pd.to_numeric(df[minute_col], errors='coerce')\n",
    "            condition = df[decimal_col].isna() | (df[decimal_col] == 0)\n",
    "            df[coord.upper()] = np.where(condition,\n",
    "                                 df[minute_col].apply(self._safe_convert),\n",
    "                                 df[decimal_col])\n",
    "        \n",
    "        df.dropna(subset=['LAT', 'LON'], inplace=True)\n",
    "\n",
    "    def _get_coord_columns(self, columns) -> dict:\n",
    "        return {\n",
    "            'lon_d': self._find_coord_column(columns, 'lon', 'dddddd'),\n",
    "            'lat_d': self._find_coord_column(columns, 'lat', 'dddddd'),\n",
    "            'lon_m': self._find_coord_column(columns, 'lon', 'ddmmmm'),\n",
    "            'lat_m': self._find_coord_column(columns, 'lat', 'ddmmmm')\n",
    "        }\n",
    "\n",
    "    def _find_coord_column(self, columns, coord_type, coord_format) -> str:\n",
    "        pattern = re.compile(f'{coord_type}.*{coord_format}', re.IGNORECASE)\n",
    "        matching_columns = [col for col in columns if pattern.search(col)]\n",
    "        return matching_columns[0] if matching_columns else None\n",
    "\n",
    "    def _safe_convert(self, value) -> str:\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21626     40743\n",
      "Rows removed from original (tfm.dfs_removed)       0         8         1\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "16119  61.241500  21.395000\n",
      "16120  61.241500  21.395000\n",
      "16121  61.343333  21.385000\n",
      "16122  61.343333  21.385000\n",
      "16123  61.343333  21.385000\n",
      "\n",
      "[16124 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51392c",
   "metadata": {},
   "source": [
    "Lets review the rows removed from SEAWATER dataset during the parsing of coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude (ddmmmm)</th>\n",
       "      <th>latitude (dddddd)</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>WSSSM2015009</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20557</th>\n",
       "      <td>WSSSM2015010</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>29.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>WSSSM2015011</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>WSSSM2015012</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>41.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20560</th>\n",
       "      <td>WSSSM2015013</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>43.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20561</th>\n",
       "      <td>WSSSM2015014</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20562</th>\n",
       "      <td>WSSSM2015015</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20563</th>\n",
       "      <td>WSSSM2015016</td>\n",
       "      <td>H3</td>\n",
       "      <td>STYR201</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                key nuclide   method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "20556  WSSSM2015009      H3  STYR201             <       2450.0        NaN   \n",
       "20557  WSSSM2015010      H3  STYR201           NaN       2510.0      29.17   \n",
       "20558  WSSSM2015011      H3  STYR201             <       2450.0        NaN   \n",
       "20559  WSSSM2015012      H3  STYR201           NaN       1740.0      41.26   \n",
       "20560  WSSSM2015013      H3  STYR201           NaN       1650.0      43.53   \n",
       "20561  WSSSM2015014      H3  STYR201             <       2277.0        NaN   \n",
       "20562  WSSSM2015015      H3  STYR201             <       2277.0        NaN   \n",
       "20563  WSSSM2015016      H3  STYR201             <       2277.0        NaN   \n",
       "\n",
       "      date_of_entry_x  country laboratory  sequence date  year  month  day  \\\n",
       "20556             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20557             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20558             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20559             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20560             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20561             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20562             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "20563             NaN      NaN        NaN       NaN  NaN   NaN    NaN  NaN   \n",
       "\n",
       "      station  latitude (ddmmmm)  latitude (dddddd)  longitude (ddmmmm)  \\\n",
       "20556     NaN                NaN                NaN                 NaN   \n",
       "20557     NaN                NaN                NaN                 NaN   \n",
       "20558     NaN                NaN                NaN                 NaN   \n",
       "20559     NaN                NaN                NaN                 NaN   \n",
       "20560     NaN                NaN                NaN                 NaN   \n",
       "20561     NaN                NaN                NaN                 NaN   \n",
       "20562     NaN                NaN                NaN                 NaN   \n",
       "20563     NaN                NaN                NaN                 NaN   \n",
       "\n",
       "       longitude (dddddd)  tdepth  sdepth  salin  ttemp filt  mors_subbasin  \\\n",
       "20556                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20557                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20558                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20559                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20560                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20561                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20562                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "20563                 NaN     NaN     NaN    NaN    NaN  NaN            NaN   \n",
       "\n",
       "       helcom_subbasin date_of_entry_y  \n",
       "20556              NaN             NaN  \n",
       "20557              NaN             NaN  \n",
       "20558              NaN             NaN  \n",
       "20559              NaN             NaN  \n",
       "20560              NaN             NaN  \n",
       "20561              NaN             NaN  \n",
       "20562              NaN             NaN  \n",
       "20563              NaN             NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "with pd.option_context('display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(tfm.dfs_removed['SEAWATER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates by dropping rows where both longitude and latitude are zero or contain unrealistic values. Convert the , separator in longitude and latitude to a . separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16124     21626     40743\n",
      "Rows removed from original (tfm.dfs_removed)       0         8         1\n",
      "Rows created in transformed (tfm.dfs_created)      0         0         0 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "16119  61.241500  21.395000\n",
      "16120  61.241500  21.395000\n",
      "16121  61.343333  21.385000\n",
      "16122  61.343333  21.385000\n",
      "16123  61.343333  21.385000\n",
      "\n",
      "[16124 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir,  use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 8 missing time value(s) in SEAWATER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "                                               BIOTA  SEAWATER  SEDIMENT\n",
      "Original row count (dfs)                       16124     21634     40744\n",
      "Transformed row count (tfm.dfs)                16094     21473     70449\n",
      "Rows removed from original (tfm.dfs_removed)      30       161       144\n",
      "Rows created in transformed (tfm.dfs_created)      0         0     29849 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='tissue', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleIDCB(),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c7a2",
   "metadata": {},
   "source": [
    "Lets inspect the rows that are removed for the SEAWATER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ad4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER, number of dropped rows: 161.\n",
      "Viewing dropped rows for SEAWATER:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>method</th>\n",
       "      <th>&lt; value_bq/m³</th>\n",
       "      <th>value_bq/m³</th>\n",
       "      <th>error%_m³</th>\n",
       "      <th>date_of_entry_x</th>\n",
       "      <th>country</th>\n",
       "      <th>laboratory</th>\n",
       "      <th>sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude (ddmmmm)</th>\n",
       "      <th>longitude (dddddd)</th>\n",
       "      <th>tdepth</th>\n",
       "      <th>sdepth</th>\n",
       "      <th>salin</th>\n",
       "      <th>ttemp</th>\n",
       "      <th>filt</th>\n",
       "      <th>mors_subbasin</th>\n",
       "      <th>helcom_subbasin</th>\n",
       "      <th>date_of_entry_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>WRISO2001025</td>\n",
       "      <td>CS137</td>\n",
       "      <td>RISO02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>RISO</td>\n",
       "      <td>2001025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.500</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>WLEPA2002001</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.030</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>14.40</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>WLEPA2002002</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.574</td>\n",
       "      <td>20.956667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.57</td>\n",
       "      <td>11.95</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>WLEPA2002003</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.236</td>\n",
       "      <td>19.393333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>WLEPA2002004</td>\n",
       "      <td>CS134</td>\n",
       "      <td>LEPA02</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>2002010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.205</td>\n",
       "      <td>20.341700</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.06</td>\n",
       "      <td>8.65</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21542</th>\n",
       "      <td>WLRPC2023011</td>\n",
       "      <td>SR90</td>\n",
       "      <td>LRPC02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LRPC</td>\n",
       "      <td>2023011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.480</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>19.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21543</th>\n",
       "      <td>WLRPC2023012</td>\n",
       "      <td>CS137</td>\n",
       "      <td>LRPC01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LRPC</td>\n",
       "      <td>2023012.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.480</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>8.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21544</th>\n",
       "      <td>WLRPC2023012</td>\n",
       "      <td>SR90</td>\n",
       "      <td>LRPC02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LRPC</td>\n",
       "      <td>2023012.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.480</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>8.80</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21545</th>\n",
       "      <td>WLRPC2023013</td>\n",
       "      <td>CS137</td>\n",
       "      <td>LRPC01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LRPC</td>\n",
       "      <td>2023013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.427</td>\n",
       "      <td>20.711700</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21546</th>\n",
       "      <td>WLRPC2023013</td>\n",
       "      <td>SR90</td>\n",
       "      <td>LRPC02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>LRPC</td>\n",
       "      <td>2023013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.427</td>\n",
       "      <td>20.711700</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>05/03/24 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                key nuclide  method < value_bq/m³  value_bq/m³  error%_m³  \\\n",
       "13439  WRISO2001025   CS137  RISO02           NaN          NaN       10.0   \n",
       "14017  WLEPA2002001   CS134  LEPA02             <          NaN        NaN   \n",
       "14020  WLEPA2002002   CS134  LEPA02             <          NaN        NaN   \n",
       "14023  WLEPA2002003   CS134  LEPA02             <          NaN        NaN   \n",
       "14026  WLEPA2002004   CS134  LEPA02             <          NaN        NaN   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "21542  WLRPC2023011    SR90  LRPC02           NaN          NaN        NaN   \n",
       "21543  WLRPC2023012   CS137  LRPC01           NaN          NaN        NaN   \n",
       "21544  WLRPC2023012    SR90  LRPC02           NaN          NaN        NaN   \n",
       "21545  WLRPC2023013   CS137  LRPC01           NaN          NaN        NaN   \n",
       "21546  WLRPC2023013    SR90  LRPC02           NaN          NaN        NaN   \n",
       "\n",
       "         date_of_entry_x  country laboratory   sequence  ...  \\\n",
       "13439                NaN     26.0       RISO  2001025.0  ...   \n",
       "14017                NaN     93.0       LEPA  2002001.0  ...   \n",
       "14020                NaN     93.0       LEPA  2002004.0  ...   \n",
       "14023                NaN     93.0       LEPA  2002007.0  ...   \n",
       "14026                NaN     93.0       LEPA  2002010.0  ...   \n",
       "...                  ...      ...        ...        ...  ...   \n",
       "21542  05/03/24 00:00:00     93.0       LRPC  2023011.0  ...   \n",
       "21543  05/03/24 00:00:00     93.0       LRPC  2023012.0  ...   \n",
       "21544  05/03/24 00:00:00     93.0       LRPC  2023012.0  ...   \n",
       "21545  05/03/24 00:00:00     93.0       LRPC  2023013.0  ...   \n",
       "21546  05/03/24 00:00:00     93.0       LRPC  2023013.0  ...   \n",
       "\n",
       "      longitude (ddmmmm)  longitude (dddddd)  tdepth  sdepth salin  ttemp  \\\n",
       "13439             10.500           10.833333    22.0    20.0  0.00    NaN   \n",
       "14017             21.030           21.050000    16.0     0.0  3.77  14.40   \n",
       "14020             20.574           20.956667    14.0     0.0  6.57  11.95   \n",
       "14023             19.236           19.393333    73.0     0.0  7.00   9.19   \n",
       "14026             20.205           20.341700    47.0     0.0  7.06   8.65   \n",
       "...                  ...                 ...     ...     ...   ...    ...   \n",
       "21542             20.480           20.800000    45.0     1.0  7.22  19.80   \n",
       "21543             20.480           20.800000    45.0     1.0  7.23   8.80   \n",
       "21544             20.480           20.800000    45.0     1.0  7.23   8.80   \n",
       "21545             20.427           20.711700    41.0     1.0  7.23  19.30   \n",
       "21546             20.427           20.711700    41.0     1.0  7.23  19.30   \n",
       "\n",
       "       filt  mors_subbasin  helcom_subbasin    date_of_entry_y  \n",
       "13439     N            5.0              5.0                NaN  \n",
       "14017     N            4.0              9.0                NaN  \n",
       "14020     N            4.0              9.0                NaN  \n",
       "14023     N            4.0              9.0                NaN  \n",
       "14026     N            4.0              9.0                NaN  \n",
       "...     ...            ...              ...                ...  \n",
       "21542     N            4.0              9.0  05/03/24 00:00:00  \n",
       "21543     N            4.0              9.0  05/03/24 00:00:00  \n",
       "21544     N            4.0              9.0  05/03/24 00:00:00  \n",
       "21545     N            4.0              9.0  05/03/24 00:00:00  \n",
       "21546     N            4.0              9.0  05/03/24 00:00:00  \n",
       "\n",
       "[161 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "grp='SEAWATER' # 'SEAWATER', 'BIOTA' or 'SEDIMENT'\n",
    "print(f'{grp}, number of dropped rows: {tfm.dfs_removed[grp].shape[0]}.')\n",
    "print(f'Viewing dropped rows for {grp}:')\n",
    "tfm.dfs_removed[grp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 8 missing time value(s) in SEAWATER\n",
      "Warning: 1 missing time value(s) in SEDIMENT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Convert 'nuclide' column values to lowercase, strip spaces, and store in 'NUCLIDE' column.\",\n",
       " 'Remap data provider nuclide names to standardized MARIS nuclide names.',\n",
       " 'Standardize time format across all dataframes.',\n",
       " 'Encode time as seconds since epoch.',\n",
       " 'Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements.',\n",
       " 'Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column.',\n",
       " 'Convert from relative error to standard uncertainty.',\n",
       " 'Set the `unit` id column in the DataFrames based on a lookup table.',\n",
       " 'Remap value type to MARIS format.',\n",
       " \"Remap values from 'rubin' to 'SPECIES' for groups: BIOTA.\",\n",
       " \"Remap values from 'tissue' to 'BODY_PART' for groups: BIOTA.\",\n",
       " \"Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA.\",\n",
       " 'Lookup sediment id using lookup table.',\n",
       " 'Lookup filt value in dataframe using the lookup table.',\n",
       " 'Generate a SMP_ID from the KEY values in the HELCOM dataset. Each KEY is mapped to a unique integer, with the mapping stored in an enumeration (i.e., smp_id).',\n",
       " \"Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns.\",\n",
       " 'Remap Sediment slice top and bottom to MARIS format.',\n",
       " 'Lookup dry-wet ratio and format for MARIS.',\n",
       " 'Get geographical coordinates from columns expressed in degrees decimal format or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.',\n",
       " 'Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(src_dir, use_cache=True)\n",
    "\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='tissue', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleIDCB(),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109b5b1",
   "metadata": {},
   "source": [
    "## Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c293bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(\n",
    "    tfm: Transformer, # Transformer object\n",
    "    zotero_key: str, # Zotero dataset record key\n",
    "    kw: list = kw # List of keywords\n",
    "    ) -> dict: # Global attributes\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'geospatial_vertical_max': '437.0',\n",
       " 'geospatial_vertical_min': '0.0',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2023-11-30T00:00:00',\n",
       " 'id': '26VMZZ2Q',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert 'nuclide' column values to lowercase, strip spaces, and store in 'NUCLIDE' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'rubin' to 'SPECIES' for groups: BIOTA., Remap values from 'tissue' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Lookup sediment id using lookup table., Lookup filt value in dataframe using the lookup table., Generate a SMP_ID from the KEY values in the HELCOM dataset. Each KEY is mapped to a unique integer, with the mapping stored in an enumeration (i.e., smp_id)., Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "## <a name=\"encoding-netcdf\"></a>Encoding NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(\n",
    "    src_dir: str, # Input file name\n",
    "    fname_out_nc: str, # Output file name\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Encode data to NetCDF.\"\n",
    "    dfs = load_data(src_dir)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='nuclide', col_dst='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides, col_name='NUCLIDE'),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),                           \n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='rubin', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='tissue', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            AddSampleIDCB(),\n",
    "                            AddDepthCB(),\n",
    "                            AddSalinityCB(),\n",
    "                            AddTemperatureCB(),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            custom_maps=tfm.custom_maps,\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec225f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 8 missing time value(s) in SEAWATER\n",
      "Warning: 1 missing time value(s) in SEDIMENT\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "encode(src_dir, fname_out_nc, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7e258",
   "metadata": {},
   "source": [
    "## NetCDF Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e5e7",
   "metadata": {},
   "source": [
    "First lets review the global attributes of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '26VMZZ2Q', 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances', 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.', 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)', 'history': 'TBD', 'keywords_vocabulary': 'GCMD Science Keywords', 'keywords_vocabulary_url': 'https://gcmd.earthdata.nasa.gov/static/kms/', 'record': 'TBD', 'featureType': 'TBD', 'cdm_data_type': 'TBD', 'Conventions': 'CF-1.10 ACDD-1.3', 'publisher_name': 'Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI', 'publisher_email': 'p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org', 'publisher_url': 'https://maris.iaea.org', 'publisher_institution': 'International Atomic Energy Agency - IAEA', 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]', 'institution': 'TBD', 'metadata_link': 'TBD', 'creator_email': 'TBD', 'creator_url': 'TBD', 'references': 'TBD', 'license': 'Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).', 'comment': 'TBD', 'geospatial_lat_min': '31.17', 'geospatial_lon_min': '9.6333', 'geospatial_lat_max': '65.75', 'geospatial_lon_max': '53.5', 'geospatial_vertical_min': '0.0', 'geospatial_vertical_max': '437.0', 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))', 'geospatial_bounds_crs': 'EPSG:4326', 'time_coverage_start': '1984-01-10T00:00:00', 'time_coverage_end': '2023-11-30T00:00:00', 'local_time_zone': 'TBD', 'date_created': 'TBD', 'date_modified': 'TBD', 'publisher_postprocess_logs': \"Convert 'nuclide' column values to lowercase, strip spaces, and store in 'NUCLIDE' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'rubin' to 'SPECIES' for groups: BIOTA., Remap values from 'tissue' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Lookup sediment id using lookup table., Lookup filt value in dataframe using the lookup table., Generate a SMP_ID from the KEY values in the HELCOM dataset. Each KEY is mapped to a unique integer, with the mapping stored in an enumeration (i.e., smp_id)., Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\"}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "contents = ExtractNetcdfContents(fname_out_nc)\n",
    "print(contents.global_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cc5bc",
   "metadata": {},
   "source": [
    "Review the publisher_postprocess_logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert 'nuclide' column values to lowercase, strip spaces, and store in 'NUCLIDE' column., Remap data provider nuclide names to standardized MARIS nuclide names., Standardize time format across all dataframes., Encode time as seconds since epoch., Separate sediment entries into distinct rows for Bq/kg and Bq/m² measurements., Sanitize measurement values by removing blanks and standardizing to use the `VALUE` column., Convert from relative error to standard uncertainty., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Remap values from 'rubin' to 'SPECIES' for groups: BIOTA., Remap values from 'tissue' to 'BODY_PART' for groups: BIOTA., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: BIOTA., Lookup sediment id using lookup table., Lookup filt value in dataframe using the lookup table., Generate a SMP_ID from the KEY values in the HELCOM dataset. Each KEY is mapped to a unique integer, with the mapping stored in an enumeration (i.e., smp_id)., Ensure depth values are floats and add 'SMP_DEPTH' and 'TOT_DEPTH' columns., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., Get geographical coordinates from columns expressed in degrees decimal format or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero., Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(contents.global_attrs['publisher_postprocess_logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b00241",
   "metadata": {},
   "source": [
    "Now lets review the enums of the groups in the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of enum_dicts:\n",
      "{'Not applicable': '-1', 'Not available': '0', 'Birds': '1', 'Crustaceans': '2', 'Echinoderms': '3', 'Fish': '4', 'Mammals': '5', 'Molluscs': '6', 'Others': '7', 'Plankton': '8', 'Polychaete worms': '9', 'Reptile': '10', 'Seaweeds and plants': '11', 'Cephalopods': '12', 'Gastropods': '13', 'Bivalves': '14'}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print('Example of enum_dicts:')\n",
    "print(contents.enum_dicts['BIOTA']['bio_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be69a09",
   "metadata": {},
   "source": [
    "Lets review the custom maps of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of custom_maps, first 10 key-value pairs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WKRIL2012003': 0,\n",
       " 'WKRIL2012004': 1,\n",
       " 'WKRIL2012005': 2,\n",
       " 'WKRIL2012006': 3,\n",
       " 'WKRIL2012007': 4,\n",
       " 'WKRIL2012008': 5,\n",
       " 'WKRIL2012009': 6,\n",
       " 'WKRIL2012010': 7,\n",
       " 'WKRIL2012011': 8,\n",
       " 'WKRIL2012012': 9}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "print('Example of custom_maps, first 10 key-value pairs:')\n",
    "dict(list(contents.custom_maps['SEAWATER']['SMP_ID'].items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c543039",
   "metadata": {},
   "source": [
    "Lets return the data contained in the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df252c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dfs = contents.dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750b936",
   "metadata": {},
   "source": [
    "Lets review the biota data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>BIO_GROUP</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>BODY_PART</th>\n",
       "      <th>DRYWT</th>\n",
       "      <th>WETWT</th>\n",
       "      <th>PERCENTWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>5</td>\n",
       "      <td>4.830210</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4.338000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.150962</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.18453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348358400</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>177.935120</td>\n",
       "      <td>964.0</td>\n",
       "      <td>0.18458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>21.395000</td>\n",
       "      <td>61.241501</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1652140800</td>\n",
       "      <td>4789</td>\n",
       "      <td>33</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.520600</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16090</th>\n",
       "      <td>21.395000</td>\n",
       "      <td>61.241501</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1652140800</td>\n",
       "      <td>4789</td>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16091</th>\n",
       "      <td>21.385000</td>\n",
       "      <td>61.343334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1663200000</td>\n",
       "      <td>4790</td>\n",
       "      <td>4</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>4.106700</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16092</th>\n",
       "      <td>21.385000</td>\n",
       "      <td>61.343334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1663200000</td>\n",
       "      <td>4790</td>\n",
       "      <td>33</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16093</th>\n",
       "      <td>21.385000</td>\n",
       "      <td>61.343334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1663200000</td>\n",
       "      <td>4790</td>\n",
       "      <td>12</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16094 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LON        LAT  SMP_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       "0      12.316667  54.283333        NaN  1348358400       0       31   \n",
       "1      12.316667  54.283333        NaN  1348358400       0        4   \n",
       "2      12.316667  54.283333        NaN  1348358400       0        9   \n",
       "3      12.316667  54.283333        NaN  1348358400       0       33   \n",
       "4      12.316667  54.283333        NaN  1348358400       1       31   \n",
       "...          ...        ...        ...         ...     ...      ...   \n",
       "16089  21.395000  61.241501        2.0  1652140800    4789       33   \n",
       "16090  21.395000  61.241501        2.0  1652140800    4789        9   \n",
       "16091  21.385000  61.343334        NaN  1663200000    4790        4   \n",
       "16092  21.385000  61.343334        NaN  1663200000    4790       33   \n",
       "16093  21.385000  61.343334        NaN  1663200000    4790       12   \n",
       "\n",
       "            VALUE  UNIT       UNC  DL  BIO_GROUP  SPECIES  BODY_PART  \\\n",
       "0        0.010140     5       NaN   2          4       99         52   \n",
       "1      135.300003     5  4.830210   1          4       99         52   \n",
       "2        0.013980     5       NaN   2          4       99         52   \n",
       "3        4.338000     5  0.150962   1          4       99         52   \n",
       "4        0.009614     5       NaN   2          4       99         52   \n",
       "...           ...   ...       ...  ..        ...      ...        ...   \n",
       "16089   13.700000     4  0.520600   1         11       96         55   \n",
       "16090    0.500000     4  0.045500   1         11       96         55   \n",
       "16091   50.700001     4  4.106700   1         14      129          1   \n",
       "16092    0.880000     4  0.140800   1         14      129          1   \n",
       "16093    6.600000     4  0.349800   1         14      129          1   \n",
       "\n",
       "            DRYWT  WETWT  PERCENTWT  \n",
       "0      174.934433  948.0    0.18453  \n",
       "1      174.934433  948.0    0.18453  \n",
       "2      174.934433  948.0    0.18453  \n",
       "3      174.934433  948.0    0.18453  \n",
       "4      177.935120  964.0    0.18458  \n",
       "...           ...    ...        ...  \n",
       "16089         NaN    NaN        NaN  \n",
       "16090         NaN    NaN        NaN  \n",
       "16091         NaN    NaN        NaN  \n",
       "16092         NaN    NaN        NaN  \n",
       "16093         NaN    NaN        NaN  \n",
       "\n",
       "[16094 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_biota=dfs['BIOTA']\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(nc_dfs_biota)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef71cc",
   "metadata": {},
   "source": [
    "Lets review the sediment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e068f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>SED_TYPE</th>\n",
       "      <th>TOP</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>PERCENTWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.799999</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.799999</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.799999</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.799999</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.799999</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1337904000</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.960000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70444</th>\n",
       "      <td>15.537800</td>\n",
       "      <td>54.617832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1654646400</td>\n",
       "      <td>14121</td>\n",
       "      <td>67</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.257642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70445</th>\n",
       "      <td>15.537800</td>\n",
       "      <td>54.617832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1654646400</td>\n",
       "      <td>14121</td>\n",
       "      <td>77</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.257642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70446</th>\n",
       "      <td>15.537800</td>\n",
       "      <td>54.617832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1654646400</td>\n",
       "      <td>14122</td>\n",
       "      <td>4</td>\n",
       "      <td>5873.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>164.444000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.263965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70447</th>\n",
       "      <td>15.537800</td>\n",
       "      <td>54.617832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1654646400</td>\n",
       "      <td>14122</td>\n",
       "      <td>33</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>2</td>\n",
       "      <td>2.162400</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.263965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70448</th>\n",
       "      <td>15.537800</td>\n",
       "      <td>54.617832</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1654646400</td>\n",
       "      <td>14122</td>\n",
       "      <td>77</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.263965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70449 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LON        LAT  TOT_DEPTH        TIME  SMP_ID  NUCLIDE  \\\n",
       "0      27.799999  60.466667       25.0  1337904000       0       33   \n",
       "1      27.799999  60.466667       25.0  1337904000       1       33   \n",
       "2      27.799999  60.466667       25.0  1337904000       2       33   \n",
       "3      27.799999  60.466667       25.0  1337904000       3       33   \n",
       "4      27.799999  60.466667       25.0  1337904000       4       33   \n",
       "...          ...        ...        ...         ...     ...      ...   \n",
       "70444  15.537800  54.617832       62.0  1654646400   14121       67   \n",
       "70445  15.537800  54.617832       62.0  1654646400   14121       77   \n",
       "70446  15.537800  54.617832       62.0  1654646400   14122        4   \n",
       "70447  15.537800  54.617832       62.0  1654646400   14122       33   \n",
       "70448  15.537800  54.617832       62.0  1654646400   14122       77   \n",
       "\n",
       "             VALUE  UNIT         UNC  DL  SED_TYPE   TOP  BOTTOM  PERCENTWT  \n",
       "0      1200.000000     3  240.000000   1         0  15.0    20.0        NaN  \n",
       "1       250.000000     3   50.000000   1         0  20.0    25.0        NaN  \n",
       "2       140.000000     3   29.400000   1         0  25.0    30.0        NaN  \n",
       "3        79.000000     3   15.800000   1         0  30.0    35.0        NaN  \n",
       "4        29.000000     3    6.960000   1         0  35.0    40.0        NaN  \n",
       "...            ...   ...         ...  ..       ...   ...     ...        ...  \n",
       "70444     0.044000     2    0.015312   1        10  15.0    17.0   0.257642  \n",
       "70445     2.500000     2    0.185000   1        10  15.0    17.0   0.257642  \n",
       "70446  5873.000000     2  164.444000   1        10  17.0    19.0   0.263965  \n",
       "70447    21.200001     2    2.162400   1        10  17.0    19.0   0.263965  \n",
       "70448     0.370000     2    0.048100   1        10  17.0    19.0   0.263965  \n",
       "\n",
       "[70449 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_sediment = dfs['SEDIMENT']\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(nc_dfs_sediment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d6fc",
   "metadata": {},
   "source": [
    "Lets review the seawater data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>SMP_DEPTH</th>\n",
       "      <th>TOT_DEPTH</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SMP_ID</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNC</th>\n",
       "      <th>DL</th>\n",
       "      <th>FILT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337731200</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.696000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337731200</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339891200</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337817600</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1337817600</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>3.996000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>13.499833</td>\n",
       "      <td>54.600334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1686441600</td>\n",
       "      <td>9724</td>\n",
       "      <td>1</td>\n",
       "      <td>702.838074</td>\n",
       "      <td>1</td>\n",
       "      <td>51.276207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>13.499833</td>\n",
       "      <td>54.600334</td>\n",
       "      <td>45.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1686441600</td>\n",
       "      <td>9725</td>\n",
       "      <td>1</td>\n",
       "      <td>725.855713</td>\n",
       "      <td>1</td>\n",
       "      <td>52.686260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>14.200833</td>\n",
       "      <td>54.600334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1686614400</td>\n",
       "      <td>9731</td>\n",
       "      <td>1</td>\n",
       "      <td>648.992920</td>\n",
       "      <td>1</td>\n",
       "      <td>48.154419</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>14.665500</td>\n",
       "      <td>54.600334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1686614400</td>\n",
       "      <td>9732</td>\n",
       "      <td>1</td>\n",
       "      <td>627.178406</td>\n",
       "      <td>1</td>\n",
       "      <td>46.245316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>14.330000</td>\n",
       "      <td>54.600334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1686614400</td>\n",
       "      <td>9734</td>\n",
       "      <td>1</td>\n",
       "      <td>605.715088</td>\n",
       "      <td>1</td>\n",
       "      <td>45.691143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21473 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LON        LAT  SMP_DEPTH  TOT_DEPTH        TIME  SMP_ID  \\\n",
       "0      29.333300  60.083302        0.0        NaN  1337731200       0   \n",
       "1      29.333300  60.083302       29.0        NaN  1337731200       1   \n",
       "2      23.150000  59.433300        0.0        NaN  1339891200       2   \n",
       "3      27.983299  60.250000        0.0        NaN  1337817600       3   \n",
       "4      27.983299  60.250000       39.0        NaN  1337817600       4   \n",
       "...          ...        ...        ...        ...         ...     ...   \n",
       "21468  13.499833  54.600334        0.0       47.0  1686441600    9724   \n",
       "21469  13.499833  54.600334       45.0       47.0  1686441600    9725   \n",
       "21470  14.200833  54.600334        0.0       11.0  1686614400    9731   \n",
       "21471  14.665500  54.600334        0.0       20.0  1686614400    9732   \n",
       "21472  14.330000  54.600334        0.0       17.0  1686614400    9734   \n",
       "\n",
       "       NUCLIDE       VALUE  UNIT        UNC  DL  FILT  \n",
       "0           33    5.300000     1   1.696000   1     0  \n",
       "1           33   19.900000     1   3.980000   1     0  \n",
       "2           33   25.500000     1   5.100000   1     0  \n",
       "3           33   17.000000     1   4.930000   1     0  \n",
       "4           33   22.200001     1   3.996000   1     0  \n",
       "...        ...         ...   ...        ...  ..   ...  \n",
       "21468        1  702.838074     1  51.276207   1     0  \n",
       "21469        1  725.855713     1  52.686260   1     0  \n",
       "21470        1  648.992920     1  48.154419   1     0  \n",
       "21471        1  627.178406     1  46.245316   1     0  \n",
       "21472        1  605.715088     1  45.691143   1     0  \n",
       "\n",
       "[21473 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_seawater = dfs['SEAWATER']\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(nc_dfs_seawater)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d380cb",
   "metadata": {},
   "source": [
    "## Data Format Conversion \n",
    "\n",
    "The MARIS data processing workflow involves two key steps:\n",
    "\n",
    "1. **NetCDF to Standardized CSV Compatible with OpenRefine Pipeline**\n",
    "   - Convert standardized NetCDF files to CSV formats compatible with OpenRefine using the `NetCDFDecoder`.\n",
    "   - Preserve data integrity and variable relationships.\n",
    "   - Maintain standardized nomenclature and units.\n",
    "\n",
    "2. **Database Integration**\n",
    "   - Process the converted CSV files using OpenRefine.\n",
    "   - Apply data cleaning and standardization rules.\n",
    "   - Export validated data to the MARIS master database.\n",
    "\n",
    "This section focuses on the first step: converting NetCDF files to a format suitable for OpenRefine processing using the `NetCDFDecoder` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BIOTA to ../../_data/output/100-HELCOM-MORS-2024_BIOTA.csv\n",
      "Saved SEAWATER to ../../_data/output/100-HELCOM-MORS-2024_SEAWATER.csv\n",
      "Saved SEDIMENT to ../../_data/output/100-HELCOM-MORS-2024_SEDIMENT.csv\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "decode(fname_in=fname_out_nc, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.helcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a6a41",
   "metadata": {},
   "source": [
    "# HELCOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709cfb6",
   "metadata": {},
   "source": [
    "> This data pipeline, known as a \"handler\" in Marisco terminology, is designed to clean, standardize, and encode [HELCOM data](https://helcom.fi/about-us) into `NetCDF` format. The handler processes raw HELCOM data, applying various transformations and lookups to align it with `MARIS` data standards.\n",
    "\n",
    "Key functions of this handler:\n",
    "\n",
    "- **Cleans** and **normalizes** raw HELCOM data\n",
    "- **Applies standardized nomenclature** and units\n",
    "- **Encodes the processed data** into `NetCDF` format compatible with MARIS requirements\n",
    "\n",
    "This handler is a crucial component in the Marisco data processing workflow, ensuring HELCOM data is properly integrated into the MARIS database.\n",
    "\n",
    "\n",
    "Note: *Additionally, an optional encoder (pipeline) is provided below to process data into a `.csv` format compatible with the MARIS master database. This feature is maintained for legacy purposes, as data ingestion was previously performed using OpenRefine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801c877",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "For new MARIS users, please refer to [Understanding MARIS Data Formats (NetCDF and Open Refine)](https://github.com/franckalbinet/marisco/blob/main/nbs/metadata/field-definition.ipynb) for detailed information.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121843",
   "metadata": {},
   "source": [
    "The present notebook pretends to be an instance of [Literate Programming](https://www.wikiwand.com/en/articles/Literate_programming) in the sense that it is a narrative that includes code snippets that are interspersed with explanations. When a function or a class needs to be exported in a dedicated python module (in our case `marisco/handlers/helcom.py`) the code snippet is added to the module using `#| exports` as provided by the wonderful [nbdev](https://nbdev.readthedocs.io/en/latest/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#from functools import partial \n",
    "import fastcore.all as fc \n",
    "from pathlib import Path \n",
    "#from dataclasses import asdict\n",
    "from typing import List, Dict, Callable, Tuple, Any \n",
    "from collections import OrderedDict, defaultdict\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "from marisco.utils import (\n",
    "    Remapper, \n",
    "    ddmm_to_dd,\n",
    "    Match, \n",
    "    get_unique_across_dfs\n",
    ")\n",
    "\n",
    "from marisco.callbacks import (\n",
    "    Callback, \n",
    "    Transformer, \n",
    "    EncodeTimeCB, \n",
    "    AddSampleTypeIdColumnCB,\n",
    "    AddNuclideIdColumnCB, \n",
    "    LowerStripNameCB, \n",
    "    SanitizeLonLatCB, \n",
    "    CompareDfsAndTfmCB, \n",
    "    RemapCB\n",
    ")\n",
    "\n",
    "from marisco.metadata import (\n",
    "    GlobAttrsFeeder, \n",
    "    BboxCB, \n",
    "    DepthRangeCB, \n",
    "    TimeRangeCB, \n",
    "    ZoteroCB, \n",
    "    KeyValuePairCB\n",
    ")\n",
    "\n",
    "from marisco.configs import (\n",
    "    nuc_lut_path, \n",
    "    nc_tpl_path, \n",
    "    cfg, \n",
    "    species_lut_path, \n",
    "    sediments_lut_path, \n",
    "    bodyparts_lut_path, \n",
    "    detection_limit_lut_path, \n",
    "    filtered_lut_path, \n",
    "    get_lut, \n",
    "    unit_lut_path,\n",
    "    prepmet_lut_path,\n",
    "    sampmet_lut_path,\n",
    "    counmet_lut_path, \n",
    "    lab_lut_path,\n",
    "    NC_VARS\n",
    ")\n",
    "\n",
    "from marisco.encoders import (\n",
    "    NetCDFEncoder, \n",
    ")\n",
    "\n",
    "from marisco.decoders import (\n",
    "    nc_to_dfs,\n",
    "    get_netcdf_properties, \n",
    "    get_netcdf_group_properties,\n",
    "    get_netcdf_variable_properties\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5519e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045eeae",
   "metadata": {},
   "source": [
    "## Configuration & file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b476d",
   "metadata": {},
   "source": [
    "- **fname_in**: path to the folder containing the HELCOM data in CSV format. The path can be defined as a relative path. \n",
    "\n",
    "- **fname_out_nc**: path and filename for the NetCDF output.The path can be defined as a relative path. \n",
    "\n",
    "- **Zotero key**: used to retrieve attributes related to the dataset from [Zotero](https://www.zotero.org/). The MARIS datasets include a [library](https://maris.iaea.org/datasets) available on [Zotero](https://www.zotero.org/groups/2432820/maris/library). \n",
    "\n",
    "- **ref_id**: refers to the location in Archive of the Zotero library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034b0a9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**:  Review NetCDF file name format, see (https://trello.com/c/RlB7mM8N#comment-6747489a3ef094e3520a4272)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fname_in = '../../_data/accdb/mors/csv'\n",
    "fname_out_nc = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "zotero_key ='26VMZZ2Q' # HELCOM MORS zotero key\n",
    "ref_id = 100 # HELCOM MORS reference id as defined by MARIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88d99c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbc83f",
   "metadata": {},
   "source": [
    "[Helcom MORS (Monitoring of Radioactive Substances in the Baltic Sea) data](https://helcom.fi/about-us) is provided as a Microsoft Access database. \n",
    "[`Mdbtools`](https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "Metadata for the HELCOM MORS dataset is available [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    "**Example steps**:\n",
    "\n",
    "\n",
    "1. [Download data](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24)\n",
    "\n",
    "2. Install mdbtools via VScode Terminal: \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ```\n",
    "\n",
    "3. Install unzip via VScode Terminal:\n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ```\n",
    "\n",
    "4. In `VS Code` terminal (for instance), navigate to the marisco data folder:\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip `MORS_ENVIRONMENT.zip`:\n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run `preprocess.sh` to generate the required data files:\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ```\n",
    "\n",
    "7. Content of `preprocess.sh` script:\n",
    "\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "    dbname=$(ls *.accdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n",
    "\n",
    "Once converted to `.csv` files, the data is ready to be loaded into a dictionary of dataframes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_smp_types = {  \n",
    "    'BIO': 'BIOTA', \n",
    "    'SEA': 'SEAWATER', \n",
    "    'SED': 'SEDIMENT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_data(src_dir: str|Path, \n",
    "              smp_types: dict = default_smp_types \n",
    "             ) -> Dict[str, pd.DataFrame]: \n",
    "    \"Load HELCOM data and return the data in a dictionary of dataframes with the dictionary key as the sample type.\"\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    def load_and_merge(file_prefix: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df_meas = pd.read_csv(src_path / f'{file_prefix}02.csv')\n",
    "            df_smp = pd.read_csv(src_path / f'{file_prefix}01.csv')\n",
    "            return pd.merge(df_meas, df_smp, on='KEY', how='left')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files for {file_prefix}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if files are not found\n",
    "    \n",
    "    return {smp_type: load_and_merge(file_prefix) for file_prefix, smp_type in smp_types.items()}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e48dc6",
   "metadata": {},
   "source": [
    "`dfs` is a dictionary of dataframes created from the Helcom dataset located at the path `fname_in`. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys/sample types:  dict_keys(['BIOTA', 'SEAWATER', 'SEDIMENT'])\n",
      "BIOTA columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEAWATER columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/m³', 'VALUE_Bq/m³', 'ERROR%_m³',\n",
      "       'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR',\n",
      "       'MONTH', 'DAY', 'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'TDEPTH', 'SDEPTH', 'SALIN',\n",
      "       'TTEMP', 'FILT', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n",
      "SEDIMENT columns:  Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
      "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
      "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
      "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
      "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
      "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
      "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "print('keys/sample types: ', dfs.keys())\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} columns: ', dfs[key].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e76547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "## Normalize nuclide names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "### Lower & strip nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4ceb",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some nuclide names contain one or multiple trailing spaces.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d84ed7",
   "metadata": {},
   "source": [
    "This is demonstrated below for the `NUCLIDE` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      value  n_chars  stripped_chars\n",
      "5       5    SR90           7               4\n",
      "7       7     CS137         6               5\n",
      "12     12   K40             8               3\n",
      "13     13   AM241           8               5\n",
      "15     15   CO60            8               4\n",
      "21     21  CS137            9               5\n",
      "25     25     SR90          6               4\n",
      "42     42   SR90            8               4\n",
      "43     43   CS137           8               5\n",
      "49     49    TC99           7               4\n",
      "50     50   CS134           8               5\n",
      "91     91      SR90         5               4\n",
      "93     93   PU238           8               5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = get_unique_across_dfs(load_data(fname_in), 'NUCLIDE', as_df=True, include_nchars=True)\n",
    "df['stripped_chars'] = df['value'].str.strip().str.replace(' ', '').str.len()\n",
    "print(df[df['n_chars'] != df['stripped_chars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518174ba",
   "metadata": {},
   "source": [
    "To fix this issue, we use the `LowerStripNameCB` callback. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA nuclides: \n",
      "['cs134' 'k40' 'co60' 'cs137' 'sr90' 'ag108m' 'mn54' 'co58' 'ag110m'\n",
      " 'zn65' 'sb125' 'pu239240' 'ru106' 'be7' 'ce144' 'pb210' 'po210' 'sb124'\n",
      " 'sr89' 'zr95' 'te129m' 'ru103' 'nb95' 'ce141' 'la140' 'i131' 'ba140'\n",
      " 'pu238' 'u235' 'bi214' 'pb214' 'pb212' 'tl208' 'ac228' 'ra223' 'eu155'\n",
      " 'ra226' 'gd153' 'sn113' 'fe59' 'tc99' 'co57' 'sn117m' 'eu152' 'sc46'\n",
      " 'rb86' 'ra224' 'th232' 'cs134137' 'am241' 'ra228' 'th228' 'k-40' 'cs138'\n",
      " 'cs139' 'cs140' 'cs141' 'cs142' 'cs143' 'cs144' 'cs145' 'cs146']\n",
      "SEAWATER nuclides: \n",
      "['cs137' 'sr90' 'h3' 'cs134' 'pu238' 'pu239240' 'am241' 'cm242' 'cm244'\n",
      " 'tc99' 'k40' 'ru103' 'sr89' 'sb125' 'nb95' 'ru106' 'zr95' 'ag110m'\n",
      " 'cm243244' 'ba140' 'ce144' 'u234' 'u238' 'co60' 'pu239' 'pb210' 'po210'\n",
      " 'np237' 'pu240' 'mn54']\n",
      "SEDIMENT nuclides: \n",
      "['ra226' 'cs137' 'ra228' 'k40' 'sr90' 'cs134137' 'cs134' 'pu239240'\n",
      " 'pu238' 'co60' 'ru103' 'ru106' 'sb125' 'ag110m' 'ce144' 'am241' 'be7'\n",
      " 'th228' 'pb210' 'co58' 'mn54' 'zr95' 'ba140' 'po210' 'ra224' 'nb95'\n",
      " 'pu238240' 'pu241' 'pu239' 'eu155' 'ir192' 'th232' 'cd109' 'sb124' 'zn65'\n",
      " 'th234' 'tl208' 'pb212' 'pb214' 'bi214' 'ac228' 'ra223' 'u235' 'bi212']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "for key in tfm().keys():\n",
    "    print(f'{key} nuclides: ')\n",
    "    print(tfm()[key]['NUCLIDE'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "### Remap nuclide names to MARIS data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58baf14",
   "metadata": {},
   "source": [
    "Below, we map nuclide names used by HELCOM to the MARIS standard nuclide names. \n",
    "\n",
    "Remapping data provider nomenclatures to MARIS standards is a recurrent operation and is done in a semi-automated manner according to the following pattern:\n",
    "\n",
    "1. **Inspect** data provider nomenclature:\n",
    "2. **Match** automatically against MARIS nomenclature (using a fuzzy matching algorithm); \n",
    "3. **Fix** potential mismatches; \n",
    "4. **Apply** the lookup table to the dataframe.\n",
    "\n",
    "We will refer to this process as **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31bc",
   "metadata": {},
   "source": [
    "The `get_unique_across_dfs` function is a utility in MARISCO that retrieves unique values from a specified column across all DataFrames. \n",
    "Note that there is one DataFrame for each sample type, such as biota, sediment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32ee8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>ru103</td>\n",
       "      <td>cs146</td>\n",
       "      <td>co60</td>\n",
       "      <td>fe59</td>\n",
       "      <td>u235</td>\n",
       "      <td>sr90</td>\n",
       "      <td>po210</td>\n",
       "      <td>pb210</td>\n",
       "      <td>am241</td>\n",
       "      <td>mn54</td>\n",
       "      <td>...</td>\n",
       "      <td>u234</td>\n",
       "      <td>ba140</td>\n",
       "      <td>sr89</td>\n",
       "      <td>cs143</td>\n",
       "      <td>pu241</td>\n",
       "      <td>cs145</td>\n",
       "      <td>cm242</td>\n",
       "      <td>pu239</td>\n",
       "      <td>pu238</td>\n",
       "      <td>cs139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1     2     3     4     5      6      7      8     9   ...  \\\n",
       "index      0      1     2     3     4     5      6      7      8     9  ...   \n",
       "value  ru103  cs146  co60  fe59  u235  sr90  po210  pb210  am241  mn54  ...   \n",
       "\n",
       "         67     68    69     70     71     72     73     74     75     76  \n",
       "index    67     68    69     70     71     72     73     74     75     76  \n",
       "value  u234  ba140  sr89  cs143  pu241  cs145  cm242  pu239  pu238  cs139  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE')])\n",
    "\n",
    "dfs_output = tfm()\n",
    "\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c1bdf",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the nuclide names of the HELCOM dataset to the MARIS standard nuclide names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcdbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=get_unique_across_dfs(dfs_output, col_name='NUCLIDE', as_df=True),\n",
    "                    maris_lut_fn=nuc_lut_path,\n",
    "                    maris_col_id='nuclide_id',\n",
    "                    maris_col_name='nc_name',\n",
    "                    provider_col_to_match='value',\n",
    "                    provider_col_key='value',\n",
    "                    fname_cache='nuclides_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0ea0c",
   "metadata": {},
   "source": [
    "Lets try to match HELCOM nuclide names to MARIS standard nuclide names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb645c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 31.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 entries matched the criteria, while 14 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pu239240</th>\n",
       "      <td>pu239</td>\n",
       "      <td>pu239240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pu238240</th>\n",
       "      <td>pu240</td>\n",
       "      <td>pu238240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cm243244</th>\n",
       "      <td>cm242</td>\n",
       "      <td>cm243244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs134137</th>\n",
       "      <td>cs137</td>\n",
       "      <td>cs134137</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs142</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs143</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs145</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs146</th>\n",
       "      <td>cs136</td>\n",
       "      <td>cs146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs140</th>\n",
       "      <td>ce140</td>\n",
       "      <td>cs140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-40</th>\n",
       "      <td>k40</td>\n",
       "      <td>k-40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs141</th>\n",
       "      <td>ce141</td>\n",
       "      <td>cs141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs144</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs138</th>\n",
       "      <td>cs134</td>\n",
       "      <td>cs138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs139</th>\n",
       "      <td>ce139</td>\n",
       "      <td>cs139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name source_name  match_score\n",
       "source_key                                            \n",
       "pu239240                pu239    pu239240            3\n",
       "pu238240                pu240    pu238240            3\n",
       "cm243244                cm242    cm243244            3\n",
       "cs134137                cs137    cs134137            3\n",
       "cs142                   ce140       cs142            2\n",
       "cs143                   ce140       cs143            2\n",
       "cs145                   ce140       cs145            2\n",
       "cs146                   cs136       cs146            1\n",
       "cs140                   ce140       cs140            1\n",
       "k-40                      k40        k-40            1\n",
       "cs141                   ce141       cs141            1\n",
       "cs144                   cs134       cs144            1\n",
       "cs138                   cs134       cs138            1\n",
       "cs139                   ce139       cs139            1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cb838",
   "metadata": {},
   "source": [
    "We can now manually inspect the unmatched nuclide names and create a table to correct them to the MARIS standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cf885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_nuclide_names = {\n",
    "    'cs134137': 'cs134_137_tot',\n",
    "    'cm243244': 'cm243_244_tot',\n",
    "    'pu239240': 'pu239_240_tot',\n",
    "    'pu238240': 'pu238_240_tot',\n",
    "    'cs143': 'cs137',\n",
    "    'cs145': 'cs137',\n",
    "    'cs142': 'cs137',\n",
    "    'cs141': 'cs137',\n",
    "    'cs144': 'cs137',\n",
    "    'k-40': 'k40',\n",
    "    'cs140': 'cs137',\n",
    "    'cs146': 'cs137',\n",
    "    'cs139': 'cs137',\n",
    "    'cs138': 'cs137'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575e7e",
   "metadata": {},
   "source": [
    "We now include the table `fixes_nuclide_names`, which applies manual corrections to the nuclide names before the remapping process. \n",
    "The `generate_lookup_table` function has an `overwrite` parameter (default is `True`), which, when set to `True`, creates a pickle file cache of the lookup table. We can now test the remapping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73410b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 77/77 [00:02<00:00, 33.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 entries matched the criteria, while 0 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_nuclide_names)\n",
    "fc.test_eq(len(remapper.select_match(match_score_threshold=1, verbose=True)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1276f",
   "metadata": {},
   "source": [
    "Test passes! We can now create a callback `RemapNuclideNameCB` to remap the nuclide names. Note that we pass `overwrite=False` to the `Remapper` constructor to now use the cached version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a189ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for nuclide names\n",
    "lut_nuclides = lambda df: Remapper(provider_lut_df=df,\n",
    "                                   maris_lut_fn=nuc_lut_path,\n",
    "                                   maris_col_id='nuclide_id',\n",
    "                                   maris_col_name='nc_name',\n",
    "                                   provider_col_to_match='value',\n",
    "                                   provider_col_key='value',\n",
    "                                   fname_cache='nuclides_helcom.pkl').generate_lookup_table(fixes=fixes_nuclide_names, \n",
    "                                                                                            as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0281b22",
   "metadata": {},
   "source": [
    "We now create the callback `RemapNuclideNameCB`, which will remap the nuclide names using the `lut_nuclides` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d47237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapNuclideNameCB(Callback):\n",
    "    \"Remap data provider nuclide names to MARIS nuclide names.\"\n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable # Function that returns the lookup table dictionary\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        df_uniques = get_unique_across_dfs(tfm.dfs, col_name='NUCLIDE', as_df=True)\n",
    "        #lut = {k: v.matched_maris_name for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        lut = {k: v.matched_id for k, v in self.fn_lut(df_uniques).items()}    \n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['NUCLIDE'] = tfm.dfs[k]['NUCLIDE'].replace(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce649d7a",
   "metadata": {},
   "source": [
    "Let's see it in action, along with the `RemapRdnNameCB` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9a9ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31,  4,  9, 33, 12, 21,  6,  8, 22, 10, 24, 77, 17,  2, 37, 41, 47,\n",
       "       23, 11, 13, 25, 16, 14, 36, 35, 29, 34, 67, 63, 46, 43, 42, 94, 55,\n",
       "       50, 40, 53, 87, 92, 86, 15,  7, 93, 85, 91, 90, 51, 59, 76, 72, 54,\n",
       "       57])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides)\n",
    "                            ])\n",
    "dfs_out = tfm()\n",
    "\n",
    "# For instance\n",
    "dfs_out['BIOTA'].NUCLIDE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9e1f4",
   "metadata": {},
   "source": [
    "## Standardize Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24856dc5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Time/date is provide in the `DATE`, `YEAR`\n",
    ", `MONTH`, `DAY` columns. Note that the `DATE` contains missing values as indicated below. When missing, we fallback on the `YEAR`, `MONTH`, `DAY` columns. Note also that sometimes `DAY` and `MONTH` contain 0. In this case we systematically set them to 1.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612873e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA DATE null values:  84\n",
      "SEAWATER DATE null values:  494\n",
      "SEDIMENT DATE null values:  741\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for key in dfs.keys():\n",
    "    print(f'{key} DATE null values: ', dfs[key]['DATE'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae547a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseTimeCB(Callback):\n",
    "    \"Parse and standardize time information in the dataframe.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._process_dates(df)\n",
    "\n",
    "    def _process_dates(self, df: pd.DataFrame) -> None:\n",
    "        \"Process and correct date and time information in the DataFrame.\"\n",
    "        df['TIME'] = self._parse_date(df)\n",
    "        self._handle_missing_dates(df)\n",
    "        self._fill_missing_time(df)\n",
    "\n",
    "    def _parse_date(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"Parse the DATE column if present.\"\n",
    "        return pd.to_datetime(df['DATE'], format='%m/%d/%y %H:%M:%S', errors='coerce')\n",
    "\n",
    "    def _handle_missing_dates(self, df: pd.DataFrame):\n",
    "        \"Handle cases where DAY or MONTH is 0 or missing.\"\n",
    "        df.loc[df[\"DAY\"] == 0, \"DAY\"] = 1\n",
    "        df.loc[df[\"MONTH\"] == 0, \"MONTH\"] = 1\n",
    "        \n",
    "        missing_day_month = (df[\"DAY\"].isna()) & (df[\"MONTH\"].isna()) & (df[\"YEAR\"].notna())\n",
    "        df.loc[missing_day_month, [\"DAY\", \"MONTH\"]] = 1\n",
    "\n",
    "    def _fill_missing_time(self, df: pd.DataFrame) -> None:\n",
    "        \"Fill missing time values using YEAR, MONTH, and DAY columns.\"\n",
    "        missing_time = df['TIME'].isna()\n",
    "        df.loc[missing_time, 'TIME'] = pd.to_datetime(\n",
    "            df.loc[missing_time, ['YEAR', 'MONTH', 'DAY']], \n",
    "            format='%Y%m%d', \n",
    "            errors='coerce'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34819",
   "metadata": {},
   "source": [
    "Apply the transformer for callbacks `ParseTimeCB`. Then, print the `TIME` data for `seawater`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "            TIME\n",
      "0     2012-05-23\n",
      "1     2012-05-23\n",
      "2     2012-06-17\n",
      "3     2012-05-24\n",
      "4     2012-05-24\n",
      "...          ...\n",
      "20313 2015-06-22\n",
      "20314 2015-06-23\n",
      "20315 2015-06-23\n",
      "20316 2015-06-24\n",
      "20317 2015-06-24\n",
      "\n",
      "[20318 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['SEAWATER'][['TIME']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd488a",
   "metadata": {},
   "source": [
    "The NetCDF time format requires that time be encoded as the number of milliseconds since a specified origin. In our case, the origin is `1970-01-01`, as indicated in the `cdl.toml` file under the `[vars.defaults.time.attrs]` section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2966",
   "metadata": {},
   "source": [
    "`EncodeTimeCB` converts the HELCOM `time` format to the MARIS NetCDF `time` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8edc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d24a9aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/m³</th>\n",
       "      <th>VALUE_Bq/m³</th>\n",
       "      <th>ERROR%_m³</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>SEQUENCE</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE (dddddd)</th>\n",
       "      <th>TDEPTH</th>\n",
       "      <th>SDEPTH</th>\n",
       "      <th>SALIN</th>\n",
       "      <th>TTEMP</th>\n",
       "      <th>FILT</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WKRIL2012003</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012003</td>\n",
       "      <td>...</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKRIL2012004</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012004</td>\n",
       "      <td>...</td>\n",
       "      <td>29.3333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WKRIL2012005</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012005</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1339891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKRIL2012006</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012006</td>\n",
       "      <td>...</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKRIL2012007</td>\n",
       "      <td>CS137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>2012007</td>\n",
       "      <td>...</td>\n",
       "      <td>27.9833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>1337817600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
       "0  WKRIL2012003   CS137    NaN           NaN          5.3       32.0   \n",
       "1  WKRIL2012004   CS137    NaN           NaN         19.9       20.0   \n",
       "2  WKRIL2012005   CS137    NaN           NaN         25.5       20.0   \n",
       "3  WKRIL2012006   CS137    NaN           NaN         17.0       29.0   \n",
       "4  WKRIL2012007   CS137    NaN           NaN         22.2       18.0   \n",
       "\n",
       "     DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ... LONGITUDE (dddddd)  \\\n",
       "0  08/20/14 00:00:00       90       KRIL   2012003  ...            29.3333   \n",
       "1  08/20/14 00:00:00       90       KRIL   2012004  ...            29.3333   \n",
       "2  08/20/14 00:00:00       90       KRIL   2012005  ...            23.1500   \n",
       "3  08/20/14 00:00:00       90       KRIL   2012006  ...            27.9833   \n",
       "4  08/20/14 00:00:00       90       KRIL   2012007  ...            27.9833   \n",
       "\n",
       "   TDEPTH  SDEPTH  SALIN TTEMP  FILT  MORS_SUBBASIN  HELCOM_SUBBASIN  \\\n",
       "0     NaN     0.0    NaN   NaN   NaN             11               11   \n",
       "1     NaN    29.0    NaN   NaN   NaN             11               11   \n",
       "2     NaN     0.0    NaN   NaN   NaN             11                3   \n",
       "3     NaN     0.0    NaN   NaN   NaN             11               11   \n",
       "4     NaN    39.0    NaN   NaN   NaN             11               11   \n",
       "\n",
       "     DATE_OF_ENTRY_y        TIME  \n",
       "0  08/20/14 00:00:00  1337731200  \n",
       "1  08/20/14 00:00:00  1337731200  \n",
       "2  08/20/14 00:00:00  1339891200  \n",
       "3  08/20/14 00:00:00  1337817600  \n",
       "4  08/20/14 00:00:00  1337817600  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['SEAWATER'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b776775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y',\n",
       "       'TIME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['SEDIMENT'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b52103",
   "metadata": {},
   "source": [
    "## Split Sediment Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51dae5",
   "metadata": {},
   "source": [
    "Helcom reports two values for the SEDIMENT sample type: `VALUE_Bq/kg` and `VALUE_Bq/m³`. We need to split this and use a single column `VALUE` for the MARIS standard. We will use the `UNIT` column to identify the reported values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102849f",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS unit lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d14bbf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "      <th>ordlist</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bq/m&lt;sup&gt;3&lt;/sup&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized  ordlist Unnamed: 4  Unnamed: 5  \\\n",
       "0        -1  Not applicable  Not applicable      NaN        NaN         NaN   \n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE      0.0        NaN         NaN   \n",
       "2         1           Bq/m3       Bq per m3      1.0      Bq/m3         NaN   \n",
       "3         2           Bq/m2       Bq per m2      2.0        NaN         NaN   \n",
       "4         3           Bq/kg       Bq per kg      3.0        NaN         NaN   \n",
       "5         4          Bq/kgd      Bq per kgd      4.0        NaN         NaN   \n",
       "6         5          Bq/kgw      Bq per kgw      5.0        NaN         NaN   \n",
       "7         6           kg/kg       kg per kg      6.0        NaN         NaN   \n",
       "8         7              TU              TU      7.0        NaN         NaN   \n",
       "9         8      DELTA/mill  DELTA per mill      8.0        NaN         NaN   \n",
       "10        9         atom/kg     atom per kg      9.0        NaN         NaN   \n",
       "11       10        atom/kgd    atom per kgd     10.0        NaN         NaN   \n",
       "12       11        atom/kgw    atom per kgw     11.0        NaN         NaN   \n",
       "13       12          atom/l      atom per l     12.0        NaN         NaN   \n",
       "14       13          Bq/kgC      Bq per kgC     13.0        NaN         NaN   \n",
       "\n",
       "          Unnamed: 6  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2   Bq/m<sup>3</sup>  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "5                NaN  \n",
       "6                NaN  \n",
       "7                NaN  \n",
       "8                NaN  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "11               NaN  \n",
       "12               NaN  \n",
       "13               NaN  \n",
       "14               NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel(unit_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83ec0d",
   "metadata": {},
   "source": [
    "We will define the columns of interest for the SEDIMENT measurement types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df02329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_sediment = {\n",
    "    'kg_type': {\n",
    "        'VALUE': 'VALUE_Bq/kg',\n",
    "        'UNCERTAINTY': 'ERROR%_kg',\n",
    "        'DL': '< VALUE_Bq/kg',\n",
    "        'UNIT': 3,  # Unit ID for Bq/kg\n",
    "    },\n",
    "    'm2_type': {\n",
    "        'VALUE': 'VALUE_Bq/m²',\n",
    "        'UNCERTAINTY': 'ERROR%_m²',\n",
    "        'DL': '< VALUE_Bq/m²',\n",
    "        'UNIT': 2,  # Unit ID for Bq/m²\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11202714",
   "metadata": {},
   "source": [
    "We define the `SplitSedimentValuesCB` callback to split the sediment entries into separate rows for Bq/kg and Bq/m² values. We use underscore to denote the columns are temporary columns created during the splitting process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13fb2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SplitSedimentValuesCB(Callback):\n",
    "    \"Split sediment entries into separate rows for Bq/kg and Bq/m² values\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, Any]] # Columns of interest with value, uncertainty, DL columns and units\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        if 'SEDIMENT' not in tfm.dfs:\n",
    "            return\n",
    "            \n",
    "        df = tfm.dfs['SEDIMENT']\n",
    "        dfs_to_concat = []\n",
    "        \n",
    "        # For each measurement type (kg and m2)\n",
    "        for measure_type, cols in self.coi.items():\n",
    "            # If any of value/uncertainty/DL exists, keep the row\n",
    "            has_data = (\n",
    "                df[cols['VALUE']].notna() | \n",
    "                df[cols['UNCERTAINTY']].notna() | \n",
    "                df[cols['DL']].notna()\n",
    "            )\n",
    "            \n",
    "            if has_data.any():\n",
    "                df_measure = df[has_data].copy()\n",
    "                \n",
    "                # Copy columns to standardized names\n",
    "                df_measure['_VALUE'] = df_measure[cols['VALUE']]\n",
    "                df_measure['_UNCERTAINTY'] = df_measure[cols['UNCERTAINTY']]\n",
    "                df_measure['_DL'] = df_measure[cols['DL']]\n",
    "                df_measure['_UNIT'] = cols['UNIT']\n",
    "                \n",
    "                dfs_to_concat.append(df_measure)\n",
    "        \n",
    "        # Combine all measurement type dataframes\n",
    "        if dfs_to_concat:\n",
    "            tfm.dfs['SEDIMENT'] = pd.concat(dfs_to_concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c53ee701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     64074\n",
      "Number of rows removed         0         0         0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>_VALUE</th>\n",
       "      <th>_UNCERTAINTY</th>\n",
       "      <th>_DL</th>\n",
       "      <th>_UNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0  SKRIL2012048   RA226    NaN           NaN         35.0       26.0   \n",
       "1  SKRIL2012049   RA226    NaN           NaN         36.0       22.0   \n",
       "2  SKRIL2012050   RA226    NaN           NaN         38.0       24.0   \n",
       "3  SKRIL2012051   RA226    NaN           NaN         36.0       25.0   \n",
       "4  SKRIL2012052   RA226    NaN           NaN         30.0       23.0   \n",
       "\n",
       "  < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  DW% LOI%  \\\n",
       "0           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "1           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "2           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "3           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "4           NaN          NaN        NaN  08/20/14 00:00:00  ...  NaN  NaN   \n",
       "\n",
       "   MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK    DATE_OF_ENTRY_y  _VALUE  \\\n",
       "0           11.0            11.0       NaN  08/20/14 00:00:00    35.0   \n",
       "1           11.0            11.0       NaN  08/20/14 00:00:00    36.0   \n",
       "2           11.0            11.0       NaN  08/20/14 00:00:00    38.0   \n",
       "3           11.0            11.0       NaN  08/20/14 00:00:00    36.0   \n",
       "4           11.0            11.0       NaN  08/20/14 00:00:00    30.0   \n",
       "\n",
       "  _UNCERTAINTY  _DL  _UNIT  \n",
       "0         26.0  NaN      3  \n",
       "1         22.0  NaN      3  \n",
       "2         24.0  NaN      3  \n",
       "3         25.0  NaN      3  \n",
       "4         23.0  NaN      3  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "\n",
    "tfm.dfs['SEDIMENT'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4f4b",
   "metadata": {},
   "source": [
    "## Sanitize value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de49e39",
   "metadata": {},
   "source": [
    "We allocate each column containing measurement values (named differently across sample types) into a single column `VALUE` and remove NA where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8580f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_val = {'SEAWATER' : {'VALUE': 'VALUE_Bq/m³'},\n",
    "           'BIOTA':  {'VALUE': 'VALUE_Bq/kg'},\n",
    "           'SEDIMENT': {'VALUE': '_VALUE'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d74eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SanitizeValueCB(Callback):\n",
    "    \"Sanitize value/measurement by removing blank entries and populating `value` column.\"\n",
    "    def __init__(self, \n",
    "                 coi: Dict[str, Dict[str, str]] # Columns of interest. Format: {group_name: {'val': 'column_name'}}\n",
    "                 ): \n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, df in tfm.dfs.items():\n",
    "            value_col = self.coi[grp]['VALUE']\n",
    "            df.dropna(subset=[value_col], inplace=True)\n",
    "            df['VALUE'] = df[value_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bccb7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14873     20242     63870\n",
      "Number of rows removed        20        76       112 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7264387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "      <th>_VALUE</th>\n",
       "      <th>_UNCERTAINTY</th>\n",
       "      <th>_DL</th>\n",
       "      <th>_UNIT</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKRIL2012048</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKRIL2012049</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKRIL2012050</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKRIL2012051</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKRIL2012052</td>\n",
       "      <td>RA226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/20/14 00:00:00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64069</th>\n",
       "      <td>SSTUK2016044</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.916443</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.916443</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8.916443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64070</th>\n",
       "      <td>SSTUK2016045</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.992930</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.992930</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.992930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64071</th>\n",
       "      <td>SSTUK2016050</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2164.945699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2164.945699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2164.945699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64072</th>\n",
       "      <td>SSTUK2016051</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2523.279045</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2523.279045</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2523.279045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64073</th>\n",
       "      <td>SSTUK2016052</td>\n",
       "      <td>CS137</td>\n",
       "      <td>STUK01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3929.780107</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3929.780107</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3929.780107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63870 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "0      SKRIL2012048   RA226     NaN           NaN        35.00       26.0   \n",
       "1      SKRIL2012049   RA226     NaN           NaN        36.00       22.0   \n",
       "2      SKRIL2012050   RA226     NaN           NaN        38.00       24.0   \n",
       "3      SKRIL2012051   RA226     NaN           NaN        36.00       25.0   \n",
       "4      SKRIL2012052   RA226     NaN           NaN        30.00       23.0   \n",
       "...             ...     ...     ...           ...          ...        ...   \n",
       "64069  SSTUK2016044   CS137  STUK01           NaN         1.20       12.0   \n",
       "64070  SSTUK2016045   CS137  STUK01           NaN         0.79       20.0   \n",
       "64071  SSTUK2016050   CS137  STUK01           NaN       512.00       11.0   \n",
       "64072  SSTUK2016051   CS137  STUK01           NaN       527.00        6.3   \n",
       "64073  SSTUK2016052   CS137  STUK01           NaN       684.00        5.0   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOI%  \\\n",
       "0               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "1               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "2               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "3               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "4               NaN          NaN        NaN  08/20/14 00:00:00  ...   NaN   \n",
       "...             ...          ...        ...                ...  ...   ...   \n",
       "64069           NaN     8.916443       15.0                NaN  ...   NaN   \n",
       "64070           NaN     5.992930       23.0                NaN  ...   NaN   \n",
       "64071           NaN  2164.945699       14.0                NaN  ...   NaN   \n",
       "64072           NaN  2523.279045        9.3                NaN  ...   NaN   \n",
       "64073           NaN  3929.780107        8.0                NaN  ...   NaN   \n",
       "\n",
       "      MORS_SUBBASIN  HELCOM_SUBBASIN SUM_LINK    DATE_OF_ENTRY_y       _VALUE  \\\n",
       "0              11.0             11.0      NaN  08/20/14 00:00:00    35.000000   \n",
       "1              11.0             11.0      NaN  08/20/14 00:00:00    36.000000   \n",
       "2              11.0             11.0      NaN  08/20/14 00:00:00    38.000000   \n",
       "3              11.0             11.0      NaN  08/20/14 00:00:00    36.000000   \n",
       "4              11.0             11.0      NaN  08/20/14 00:00:00    30.000000   \n",
       "...             ...              ...      ...                ...          ...   \n",
       "64069           3.0              3.0      NaN                NaN     8.916443   \n",
       "64070           3.0              3.0      NaN                NaN     5.992930   \n",
       "64071           8.0              8.0      NaN                NaN  2164.945699   \n",
       "64072           8.0              8.0      NaN                NaN  2523.279045   \n",
       "64073           8.0              8.0      NaN                NaN  3929.780107   \n",
       "\n",
       "       _UNCERTAINTY  _DL  _UNIT        VALUE  \n",
       "0              26.0  NaN      3    35.000000  \n",
       "1              22.0  NaN      3    36.000000  \n",
       "2              24.0  NaN      3    38.000000  \n",
       "3              25.0  NaN      3    36.000000  \n",
       "4              23.0  NaN      3    30.000000  \n",
       "...             ...  ...    ...          ...  \n",
       "64069          15.0  NaN      2     8.916443  \n",
       "64070          23.0  NaN      2     5.992930  \n",
       "64071          14.0  NaN      2  2164.945699  \n",
       "64072           9.3  NaN      2  2523.279045  \n",
       "64073           8.0  NaN      2  3929.780107  \n",
       "\n",
       "[63870 rows x 40 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_sed=tfm.dfs['SEDIMENT']\n",
    "rev_sed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be199c49",
   "metadata": {},
   "source": [
    "## Normalize uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515714b",
   "metadata": {},
   "source": [
    "Function `unc_rel2stan` converts uncertainty from relative uncertainty to standard uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76077d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def unc_rel2stan(\n",
    "    df: pd.DataFrame, # DataFrame containing measurement and uncertainty columns\n",
    "    meas_col: str, # Name of the column with measurement values\n",
    "    unc_col: str # Name of the column with relative uncertainty values (percentages)\n",
    ") -> pd.Series: # Series with calculated absolute uncertainties\n",
    "    \"Convert relative uncertainty to absolute uncertainty.\"\n",
    "    return df.apply(lambda row: row[unc_col] * row[meas_col] / 100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917d107",
   "metadata": {},
   "source": [
    "For each sample type in the Helcom dataset, the `UNCERTAINTY` is provided as a relative uncertainty. The column names for both the `VALUE` and the `UNCERTAINTY` vary by sample type. The `coi_units_unc` dictionary defines the column names for the `VALUE` and `UNCERTAINTY` for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b231b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Columns of interest\n",
    "coi_units_unc = [('SEAWATER', 'VALUE_Bq/m³', 'ERROR%_m³'),\n",
    "                 ('BIOTA', 'VALUE_Bq/kg', 'ERROR%'),\n",
    "                 ('SEDIMENT', '_VALUE', '_UNCERTAINTY')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c9a4b",
   "metadata": {},
   "source": [
    "NormalizeUncCB callback normalizes the ``UNCERTAINTY`` by converting from relative uncertainty to standard uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cf262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class NormalizeUncCB(Callback):\n",
    "    \"Convert from relative error % to standard uncertainty.\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_unc: Callable=unc_rel2stan, # Function converting relative uncertainty to absolute uncertainty\n",
    "                 coi: List[Tuple[str, str, str]]=coi_units_unc # List of columns of interest\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp, val, unc in self.coi:\n",
    "            if grp in tfm.dfs:\n",
    "                df = tfm.dfs[grp]\n",
    "                df['UNCERTAINTY'] = self.fn_convert_unc(df, val, unc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b262",
   "metadata": {},
   "source": [
    "Apply the transformer for callback ``NormalizeUncCB``. Then, print the value (i.e. activity per unit ) and standard uncertainty for each sample type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd9e14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VALUE  UNCERTAINTY\n",
      "0    5.3        1.696\n",
      "1   19.9        3.980\n",
      "2   25.5        5.100\n",
      "3   17.0        4.930\n",
      "4   22.2        3.996\n",
      "        VALUE  UNCERTAINTY\n",
      "0    0.010140          NaN\n",
      "1  135.300000     4.830210\n",
      "2    0.013980          NaN\n",
      "3    4.338000     0.150962\n",
      "4    0.009614          NaN\n",
      "   VALUE  UNCERTAINTY\n",
      "0   35.0         9.10\n",
      "1   36.0         7.92\n",
      "2   38.0         9.12\n",
      "3   36.0         9.00\n",
      "4   30.0         6.90\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[SplitSedimentValuesCB(coi_sediment),\n",
    "                            SanitizeValueCB(coi_val),\n",
    "                            NormalizeUncCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEAWATER'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['BIOTA'][['VALUE', 'UNCERTAINTY']][:5])\n",
    "print(tfm.dfs['SEDIMENT'][['VALUE', 'UNCERTAINTY']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392b0cb",
   "metadata": {},
   "source": [
    "## Remap Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfda9f9",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: RUBIN contains codes that are not found in the HELCOM biota dataset. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe37ba",
   "metadata": {},
   "source": [
    "For example, 'CH HI;BA', its not in the HELCOM biota dataset. Lets return the uniue RUBIN of the HELCOM biota dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33953cd",
   "metadata": {},
   "source": [
    "Other unused RUBIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70e11297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unused RUBIN names: ['CH HI;BA', 'SOLE SOL']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "unique_rubin = dfs['BIOTA']['RUBIN'].unique()\n",
    "unique_rubin_set = set(unique_rubin)\n",
    "rubin_lut = list(pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv')['RUBIN'])\n",
    "unused_rubins = [rune for rune in rubin_lut if rune not in unique_rubin_set]\n",
    "print(\"Unused RUBIN names:\", unused_rubins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7129a",
   "metadata": {},
   "source": [
    "We will remap the HELCOM `RUBIN` column to the MARIS `SPECIES` column using the **IMFA** (**I**nspect, **M**atch, **F**ix, **A**pply) pattern. First lets **inspect** the `RUBIN_NAME.csv` file provided by HELCOM, which describes the nomenclature of biota species.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "023d3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUBIN_ID</th>\n",
       "      <th>RUBIN</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>ENGLISH NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ABRA BRA</td>\n",
       "      <td>ABRAMIS BRAMA</td>\n",
       "      <td>BREAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>ANGU ANG</td>\n",
       "      <td>ANGUILLA ANGUILLA</td>\n",
       "      <td>EEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>ARCT ISL</td>\n",
       "      <td>ARCTICA ISLANDICA</td>\n",
       "      <td>ISLAND CYPRINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>ASTE RUB</td>\n",
       "      <td>ASTERIAS RUBENS</td>\n",
       "      <td>COMMON STARFISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>CARD EDU</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>COCKLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUBIN_ID     RUBIN    SCIENTIFIC NAME     ENGLISH NAME\n",
       "0        11  ABRA BRA      ABRAMIS BRAMA            BREAM\n",
       "1        12  ANGU ANG  ANGUILLA ANGUILLA              EEL\n",
       "2        13  ARCT ISL  ARCTICA ISLANDICA   ISLAND CYPRINE\n",
       "3        14  ASTE RUB    ASTERIAS RUBENS  COMMON STARFISH\n",
       "4        15  CARD EDU      CARDIUM EDULE           COCKLE"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08d23db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/marisco/.marisco/lut/dbo_species_2024_11_19.xlsx')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "species_lut_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1858121",
   "metadata": {},
   "source": [
    "Now we try to **MATCH** the `SCIENTIFIC NAME` column of HELCOM biota dataset to the `species` column of the MARIS species lookup table, again using a `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a45da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:09<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMI SAC</th>\n",
       "      <td>Laminaria japonica</td>\n",
       "      <td>LAMINARIA SACCHARINA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARD EDU</th>\n",
       "      <td>Cardiidae</td>\n",
       "      <td>CARDIUM EDULE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH HI;BA</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>CHARA BALTICA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSET MAX</th>\n",
       "      <td>Pinctada maxima</td>\n",
       "      <td>PSETTA MAXIMA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA           10\n",
       "LAMI SAC     Laminaria japonica     LAMINARIA SACCHARINA            7\n",
       "CARD EDU              Cardiidae            CARDIUM EDULE            6\n",
       "CH HI;BA        Macoma balthica            CHARA BALTICA            6\n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "PSET MAX        Pinctada maxima            PSETTA MAXIMA            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                    maris_lut_fn=species_lut_path,\n",
    "                    maris_col_id='species_id',\n",
    "                    maris_col_name='species',\n",
    "                    provider_col_to_match='SCIENTIFIC NAME',\n",
    "                    provider_col_key='RUBIN',\n",
    "                    fname_cache='species_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3b8aa",
   "metadata": {},
   "source": [
    "Below, we will correct the entries that were not properly matched by the `Remapper` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8290222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_species = {\n",
    "    'CHARA BALTICA': 'NOT AVAILABLE', # CHARA BALTICA (RUBIN: CH HI;BA) is not listed in the biota data. \n",
    "    'CARDIUM EDULE': 'Cerastoderma edule',\n",
    "    'LAMINARIA SACCHARINA': 'Saccharina latissima',\n",
    "    'PSETTA MAXIMA': 'Scophthalmus maximus',\n",
    "    'STIZOSTEDION LUCIOPERCA': 'Sander luciopercas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781f210",
   "metadata": {},
   "source": [
    "And give the ``remapper`` another try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdb07a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 43/43 [00:06<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 entries matched the criteria, while 4 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENCH CIM</th>\n",
       "      <td>Echinodermata</td>\n",
       "      <td>ENCHINODERMATA CIM</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACO BAL</th>\n",
       "      <td>Macoma balthica</td>\n",
       "      <td>MACOMA BALTICA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STIZ LUC</th>\n",
       "      <td>Sander lucioperca</td>\n",
       "      <td>STIZOSTEDION LUCIOPERCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUC PEC</th>\n",
       "      <td>Stuckenia pectinata</td>\n",
       "      <td>STUCKENIA PECTINATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             matched_maris_name              source_name  match_score\n",
       "source_key                                                           \n",
       "ENCH CIM          Echinodermata       ENCHINODERMATA CIM            5\n",
       "MACO BAL        Macoma balthica           MACOMA BALTICA            1\n",
       "STIZ LUC      Sander lucioperca  STIZOSTEDION LUCIOPERCA            1\n",
       "STUC PEC    Stuckenia pectinata      STUCKENIA PECTINATE            1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(fixes=fixes_biota_species)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a5",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `RUBIN` column to the `species` column after having defined the lookup table `lut_biota`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e316ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biota = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'RUBIN_NAME.csv'),\n",
    "                             maris_lut_fn=species_lut_path,\n",
    "                             maris_col_id='species_id',\n",
    "                             maris_col_name='species',\n",
    "                             provider_col_to_match='SCIENTIFIC NAME',\n",
    "                             provider_col_key='RUBIN',\n",
    "                             fname_cache='species_helcom.pkl'\n",
    "                             ).generate_lookup_table(fixes=fixes_biota_species, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7321b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  99  243   50  139  270  192  191  284   84  269  122   96  287  279\n",
      "  278  288  286  244  129  275  271  285  283  247  120   59  280  274\n",
      "  273  290  289  272  277  276   21  282  110  281  245  704 1524]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA')\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "print(tfm.dfs['BIOTA']['SPECIES'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c74e492",
   "metadata": {},
   "source": [
    "## Remap Biota tissues\n",
    "Let's inspect the `TISSUE.csv` file provided by HELCOM describing the tissue nomenclature. Biota tissue is known as `body part` in the maris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a38df50b-46a9-4a2d-9379-e670eb0d0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE</th>\n",
       "      <th>TISSUE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FLESH WITH BONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TISSUE                    TISSUE_DESCRIPTION\n",
       "0       1                            WHOLE FISH\n",
       "1       2           WHOLE FISH WITHOUT ENTRAILS\n",
       "2       3  WHOLE FISH WITHOUT HEAD AND ENTRAILS\n",
       "3       4                      FLESH WITH BONES\n",
       "4       5          FLESH WITHOUT BONES (FILETS)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2613f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 81.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 entries matched the criteria, while 8 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT HEAD AND ENTRAILS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soft parts</td>\n",
       "      <td>SKIN/EPIDERMIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brain</td>\n",
       "      <td>ENTRAILS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                           source_name  \\\n",
       "source_key                                                                \n",
       "3             Flesh without bones  WHOLE FISH WITHOUT HEAD AND ENTRAILS   \n",
       "2             Flesh without bones           WHOLE FISH WITHOUT ENTRAILS   \n",
       "8                      Soft parts                        SKIN/EPIDERMIS   \n",
       "5             Flesh without bones          FLESH WITHOUT BONES (FILETS)   \n",
       "1                    Whole animal                            WHOLE FISH   \n",
       "12                          Brain                              ENTRAILS   \n",
       "15          Stomach and intestine                   STOMACH + INTESTINE   \n",
       "41                   Whole animal                         WHOLE ANIMALS   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "3                    20  \n",
       "2                    13  \n",
       "8                    10  \n",
       "5                     9  \n",
       "1                     5  \n",
       "12                    5  \n",
       "15                    3  \n",
       "41                    1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                    maris_lut_fn=bodyparts_lut_path,\n",
    "                    maris_col_id='bodypar_id',\n",
    "                    maris_col_name='bodypar',\n",
    "                    provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                    provider_col_key='TISSUE',\n",
    "                    fname_cache='tissues_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee1bb9",
   "metadata": {},
   "source": [
    "We address several entries that were not correctly matched by the Remapper object, as detailed below:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6e2b06f-5eb1-4708-8087-75c836f08112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_biota_tissues = {\n",
    "    'WHOLE FISH WITHOUT HEAD AND ENTRAILS': 'Whole animal eviscerated without head',\n",
    "    'ENTRAILS': 'Viscera',\n",
    "    'SKIN/EPIDERMIS': 'Skin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c07fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 29/29 [00:00<00:00, 72.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 entries matched the criteria, while 5 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>WHOLE FISH WITHOUT ENTRAILS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flesh without bones</td>\n",
       "      <td>FLESH WITHOUT BONES (FILETS)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE FISH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stomach and intestine</td>\n",
       "      <td>STOMACH + INTESTINE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whole animal</td>\n",
       "      <td>WHOLE ANIMALS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               matched_maris_name                   source_name  match_score\n",
       "source_key                                                                  \n",
       "2             Flesh without bones   WHOLE FISH WITHOUT ENTRAILS           13\n",
       "5             Flesh without bones  FLESH WITHOUT BONES (FILETS)            9\n",
       "1                    Whole animal                    WHOLE FISH            5\n",
       "15          Stomach and intestine           STOMACH + INTESTINE            3\n",
       "41                   Whole animal                 WHOLE ANIMALS            1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_biota_tissues)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef75cb1",
   "metadata": {},
   "source": [
    "Visual inspection of the remaining unperfectly matched entries seem acceptable to proceed. \n",
    "\n",
    "We can now use the generic `RemapCB` callback to perform the remapping of the `TISSUE` column to the `body_part` column after having defined the lookup table `lut_tissues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c42eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_tissues = lambda: Remapper(provider_lut_df=pd.read_csv('../../_data/accdb/mors/csv/TISSUE.csv'),\n",
    "                               maris_lut_fn=bodyparts_lut_path,\n",
    "                               maris_col_id='bodypar_id',\n",
    "                               maris_col_name='bodypar',\n",
    "                               provider_col_to_match='TISSUE_DESCRIPTION',\n",
    "                               provider_col_key='TISSUE',\n",
    "                               fname_cache='tissues_helcom.pkl'\n",
    "                               ).generate_lookup_table(fixes=fixes_biota_tissues, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d1887c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TISSUE  BODY_PART\n",
      "0       5         52\n",
      "1       5         52\n",
      "2       5         52\n",
      "3       5         52\n",
      "4       5         52\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA'][['TISSUE', 'BODY_PART']][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc596011",
   "metadata": {},
   "source": [
    "## Remap biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f111f2",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "\n",
    "1) Is this needed in NETCDF? Can enum include the species and biogroup LUT?\n",
    "\n",
    "2) Include the `lut_biogroup_from_biota` callback in utils.ipynb. \n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ebe6",
   "metadata": {},
   "source": [
    "`lut_biogroup_from_biota` reads the file at `species_lut_path()` and from the contents of this file creates a dictionary linking `species_id` to `biogroup_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_biogroup_from_biota = lambda: get_lut(src_dir=species_lut_path().parent, fname=species_lut_path().name, \n",
    "                               key='species_id', value='biogroup_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2a37157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 14 11  8  3]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "    RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA')\n",
    "    ])\n",
    "\n",
    "print(tfm()['BIOTA']['BIO_GROUP'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf607d",
   "metadata": {},
   "source": [
    "## Remap Sediment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938d40",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The `SEDI` values `56` and `73` are not found in the `SEDIMENT_TYPE.csv` lookup table provided. Note also there are many `nan` values in the `SEDIMENT_TYPE.csv` file.\n",
    "\n",
    "We reassign them to `-99` for now but should be clarified/fixed. This is demonstrated below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beb4547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SEDI values: {56.0, nan, 73.0}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_sed_lut = pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv')\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "sediment_sedi = set(dfs['SEDIMENT'].SEDI.unique())\n",
    "lookup_sedi = set(df_sed_lut['SEDI'])\n",
    "missing = sediment_sedi - lookup_sedi\n",
    "print(f\"Missing SEDI values: {missing if missing else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1b5c5",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    " ``SedRepName`` is used by OpenRefine. ``SedRepName`` is not included in the NetCDF encoding. Description of the `SedRepName` from [MARIS Data Formats\n",
    "](https://github.com/franckalbinet/marisco/tree/main/install_configure_guide); 'Name of the sediment as reported by the data provider. The sediment name should be stored exactly as provided, without any modifications'. \n",
    "\n",
    "This information will be lost with the latest workflow (creating netcdf and decoding to csv) if we do not include strings in the netcdf encoding. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffefc5",
   "metadata": {},
   "source": [
    "Once again, we employ the **IMFA** (Inspect, Match, Fix, Apply) pattern to remap the HELCOM sediment types. Let's inspect the `SEDIMENT_TYPE.csv` file provided by HELCOM describing the sediment type nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5f6b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEDI</th>\n",
       "      <th>SEDIMENT TYPE</th>\n",
       "      <th>RECOMMENDED TO BE USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>SILT AND GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAVEL</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SAND</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>FINE SAND</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEDI    SEDIMENT TYPE RECOMMENDED TO BE USED\n",
       "0   -99          NO DATA                    NaN\n",
       "1    30  SILT AND GRAVEL                    YES\n",
       "2     0           GRAVEL                    YES\n",
       "3     1             SAND                    YES\n",
       "4     2        FINE SAND                     NO"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e669f",
   "metadata": {},
   "source": [
    "Let's try to match as many as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ce8fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 71.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 entries matched the criteria, while 3 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-99</th>\n",
       "      <td>Soft</td>\n",
       "      <td>NO DATA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "-99                      Soft         NO DATA            5\n",
       " 50            Mud and gravel  MUD AND GARVEL            2\n",
       " 46              Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in)/'SEDIMENT_TYPE.csv'),\n",
    "                    maris_lut_fn=sediments_lut_path,\n",
    "                    maris_col_id='sedtype_id',\n",
    "                    maris_col_name='sedtype',\n",
    "                    provider_col_to_match='SEDIMENT TYPE',\n",
    "                    provider_col_key='SEDI',\n",
    "                    fname_cache='sediments_helcom.pkl'\n",
    "                    )\n",
    "\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a92e4",
   "metadata": {},
   "source": [
    "We address the remaining unmatched values by adding fixes_sediments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ea46125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_sediments = {\n",
    "    'NO DATA': '(Not available)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05728a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 47/47 [00:00<00:00, 88.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 entries matched the criteria, while 2 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mud and gravel</td>\n",
       "      <td>MUD AND GARVEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Glacial clay</td>\n",
       "      <td>CLACIAL CLAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           matched_maris_name     source_name  match_score\n",
       "source_key                                                \n",
       "50             Mud and gravel  MUD AND GARVEL            2\n",
       "46               Glacial clay    CLACIAL CLAY            1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_sediments)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152c8c7",
   "metadata": {},
   "source": [
    "A visual inspection of the remaining values shows that they are acceptable to proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d16ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedimentCB(Callback):\n",
    "    \"Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fn_lut: Callable,  # Function that returns the lookup table dictionary\n",
    "                 sed_grp_name: str = 'SEDIMENT',  # The name of the sediment group\n",
    "                 replace_lut: dict = None  # Dictionary for replacing SEDI values\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap sediment types in the DataFrame using the lookup table and handle specific replacements.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        # Fix inconsistent SEDI values\n",
    "        tfm.dfs[self.sed_grp_name] = self._fix_inconsistent_sedi(tfm.dfs[self.sed_grp_name], self.replace_lut)\n",
    "        \n",
    "        # Get unique SEDI values\n",
    "        unique_sedi = tfm.dfs[self.sed_grp_name]['SEDI'].unique()\n",
    "        \n",
    "        # Get sediment types for unique SEDI values\n",
    "        sediment_mapping = self._get_sediment_types(unique_sedi, lut)\n",
    "        \n",
    "        # Replace SEDI values in the DataFrame using the mapping\n",
    "        tfm.dfs[self.sed_grp_name]['SED_TYPE'] = tfm.dfs[self.sed_grp_name]['SEDI'].map(sediment_mapping)\n",
    "\n",
    "    def _fix_inconsistent_sedi(self, df: pd.DataFrame, replace_lut: dict) -> pd.DataFrame:\n",
    "        \"Temporary fix for inconsistent SEDI values. Data provider to confirm and clarify.\"\n",
    "        df['SEDI'] = df['SEDI'].replace(replace_lut)\n",
    "        return df\n",
    "\n",
    "    def _get_sediment_types(self, unique_sedi: np.ndarray, lut: dict) -> dict:\n",
    "        \"Get sediment types for unique SEDI values and return a mapping dictionary.\"\n",
    "        sediment_mapping = {}\n",
    "        \n",
    "        for sedi_value in unique_sedi:\n",
    "            match = lut.get(sedi_value, Match(0, None, None, None))\n",
    "            if match.matched_id == 0:\n",
    "                self._print_unmatched_sedi(sedi_value)\n",
    "            sediment_mapping[sedi_value] = match.matched_id\n",
    "        \n",
    "        return sediment_mapping\n",
    "\n",
    "    def _print_unmatched_sedi(self, \n",
    "                              sedi_value: int,  # The `SEDI` value from the DataFrame\n",
    "                             ) -> None:\n",
    "        \"Print the SEDI value if the matched_id is 0 (i.e. Not available).\"\n",
    "        print(f\"Unmatched SEDI: {sedi_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23fe1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_sediments = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'SEDIMENT_TYPE.csv'),\n",
    "                                 maris_lut_fn=sediments_lut_path,\n",
    "                                 maris_col_id='sedtype_id',\n",
    "                                 maris_col_name='sedtype',\n",
    "                                 provider_col_to_match='SEDIMENT TYPE',\n",
    "                                 provider_col_key='SEDI',\n",
    "                                 fname_cache='sediments_helcom.pkl'\n",
    "                                 ).generate_lookup_table(fixes=fixes_sediments, as_df=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e7e02",
   "metadata": {},
   "source": [
    "Reassign the `SEDI` values of `56`, `73`, and `nan` to `-99`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63482233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "sed_replace_lut = {\n",
    "    56: -99,\n",
    "    73: -99,\n",
    "    np.nan: -99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d334ac",
   "metadata": {},
   "source": [
    "Utilize the RemapSedimentCB callback to remap the SEDI values in the HELCOM dataset to the corresponding MARIS standard sediment type, referred to as SED_TYPE. After the remapping process, display the SEDI and SED_TYPE columns from the SEDIMENT DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25495b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 58, 30, 59, 55, 56, 36, 29, 47,  4, 54, 33,  6, 44, 42, 48,\n",
       "       61, 57, 28, 49, 32, 45, 39, 46, 38, 31, 60, 62, 26, 53, 52,  1, 51,\n",
       "       37, 34, 50,  7, 10, 41, 43, 35])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut)])\n",
    "\n",
    "tfm()\n",
    "\n",
    "tfm.dfs['SEDIMENT']['SED_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0add1",
   "metadata": {},
   "source": [
    "## Remap units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4064ed",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: The handling of unit types varies between `biota` and `sediment` sample types. For consistency and ease of use, it would be beneficial to have dedicated unit columns for all sample types.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a682ac",
   "metadata": {},
   "source": [
    "Given the inconsistent handling of units across sample types, we need to define custom mapping rules for standardizing the units. The units available in MARIS are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cab93970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Bq/m3</td>\n",
       "      <td>Bq per m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bq/m2</td>\n",
       "      <td>Bq per m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bq/kg</td>\n",
       "      <td>Bq per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Bq/kgd</td>\n",
       "      <td>Bq per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Bq/kgw</td>\n",
       "      <td>Bq per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>kg/kg</td>\n",
       "      <td>kg per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>TU</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>DELTA/mill</td>\n",
       "      <td>DELTA per mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>atom/kg</td>\n",
       "      <td>atom per kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>atom/kgd</td>\n",
       "      <td>atom per kgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>atom/kgw</td>\n",
       "      <td>atom per kgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>atom/l</td>\n",
       "      <td>atom per l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>Bq/kgC</td>\n",
       "      <td>Bq per kgC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_id            unit  unit_sanitized\n",
       "0        -1  Not applicable  Not applicable\n",
       "1         0   NOT AVAILABLE   NOT AVAILABLE\n",
       "2         1           Bq/m3       Bq per m3\n",
       "3         2           Bq/m2       Bq per m2\n",
       "4         3           Bq/kg       Bq per kg\n",
       "5         4          Bq/kgd      Bq per kgd\n",
       "6         5          Bq/kgw      Bq per kgw\n",
       "7         6           kg/kg       kg per kg\n",
       "8         7              TU              TU\n",
       "9         8      DELTA/mill  DELTA per mill\n",
       "10        9         atom/kg     atom per kg\n",
       "11       10        atom/kgd    atom per kgd\n",
       "12       11        atom/kgw    atom per kgw\n",
       "13       12          atom/l      atom per l\n",
       "14       13          Bq/kgC      Bq per kgC"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(unit_lut_path())[['unit_id', 'unit', 'unit_sanitized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbefe4",
   "metadata": {},
   "source": [
    "We define unit renaming rules for HELCOM in an **ad hoc** way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12a86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_units = {\n",
    "    'SEAWATER': 1,  # 'Bq/m3'\n",
    "    'SEDIMENT': 4,  # 'Bq/kgd' for sediment\n",
    "    'BIOTA': {\n",
    "        'D': 4,  # 'Bq/kgd'\n",
    "        'W': 5,  # 'Bq/kgw'\n",
    "        'F': 5   # 'Bq/kgw' (assumed to be 'Fresh', so set to wet)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e404d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapUnitCB(Callback):\n",
    "    \"Set the `unit` id column in the DataFrames based on a lookup table.\"\n",
    "    def __init__(self, \n",
    "                 lut_units: dict=lut_units # Dictionary containing renaming rules for different unit categories\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if grp in ['SEAWATER', 'SEDIMENT']:\n",
    "                tfm.dfs[grp]['UNIT'] = self.lut_units[grp]\n",
    "            else:\n",
    "                tfm.dfs[grp]['UNIT'] = tfm.dfs[grp]['BASIS'].apply(lambda x: lut_units[grp].get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03fcc9",
   "metadata": {},
   "source": [
    "Apply the transformer for callback `RemapUnitCB()`. Then, print the unique `UNIT` for the `SEAWATER` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa0f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [5 0 4]\n",
      "SEDIMENT: [4]\n",
      "SEAWATER: [1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapUnitCB()])\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['UNIT'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d978c67",
   "metadata": {},
   "source": [
    "## Remap detection limit\n",
    "Detection limits are encoded as follows in MARIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1b07268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Detected value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>Detection limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>Not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>Derived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name   name_sanitized\n",
       "0  -1  Not applicable   Not applicable\n",
       "1   0   Not Available    Not available\n",
       "2   1               =   Detected value\n",
       "3   2               <  Detection limit\n",
       "4   3              ND     Not detected\n",
       "5   4              DE          Derived"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(detection_limit_lut_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7083b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_dl = lambda: pd.read_excel(detection_limit_lut_path(), usecols=['name','id']).set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023ddb4",
   "metadata": {},
   "source": [
    "Based on columns of interest for each sample type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dc43c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "coi_dl = {'SEAWATER' : {'VALUE' : 'VALUE_Bq/m³',\n",
    "                       'UNCERTAINTY' : 'ERROR%_m³',\n",
    "                       'DL' : '< VALUE_Bq/m³'},\n",
    "          'BIOTA':  {'VALUE' : 'VALUE_Bq/kg',\n",
    "                     'UNCERTAINTY' : 'ERROR%',\n",
    "                     'DL' : '< VALUE_Bq/kg'},\n",
    "          'SEDIMENT': {\n",
    "              'VALUE' : 'VALUE_Bq/kg',\n",
    "              'UNCERTAINTY' : 'ERROR%_kg',\n",
    "              'DL' : '< VALUE_Bq/kg'}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ac6a6",
   "metadata": {},
   "source": [
    "We follow the following business logic to encode the detection limit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4784b",
   "metadata": {},
   "source": [
    "`RemapDetectionLimitCB` creates a `detection_limit` column with values determined as follows:\n",
    "1. Perform a lookup with the appropriate columns value type (or DL) columns (`< VALUE_Bq/m³` or `< VALUE_Bq/kg`) against the table returned from the function `get_detectionlimit_lut`.\n",
    "2. If `< VALUE_Bq/m³` or `< VALUE_Bq/kg` is NaN but both activity values (`VALUE_Bq/m³` or `VALUE_Bq/kg`) and standard uncertainty (`ERROR%_m³`, `ERROR%`, or `ERROR%_kg`) are provided, then assign the ID of `1` (i.e. \"Detected value\").\n",
    "3. For other NaN values in the `detection_limit` column, set them to `0` (i.e. `Not Available`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a72f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class RemapDetectionLimitCB(Callback):\n",
    "    \"Remap value type to MARIS format.\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 coi: dict,  # Configuration options for column names\n",
    "                 fn_lut: Callable  # Function that returns a lookup table\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Remap detection limits in the DataFrames using the lookup table.\"\n",
    "        lut = self.fn_lut()\n",
    "        \n",
    "        for grp in tfm.dfs:\n",
    "            df = tfm.dfs[grp]\n",
    "            self._update_detection_limit(df, grp, lut)\n",
    "\n",
    "    def _update_detection_limit(self, \n",
    "                                df: pd.DataFrame,  # The DataFrame to modify\n",
    "                                grp: str,  # The group name to get the column configuration\n",
    "                                lut: dict  # The lookup table dictionary\n",
    "                               ) -> None:\n",
    "        \"Update detection limit column in the DataFrame based on lookup table and rules.\"\n",
    "        \n",
    "        # Check if the group exists in coi_dl\n",
    "        if grp not in coi_dl:\n",
    "            raise ValueError(f\"Group '{grp}' not found in coi_dl configuration.\")\n",
    "        \n",
    "        # Access column names from coi_dl\n",
    "        value_col = coi_dl[grp]['VALUE']\n",
    "        uncertainty_col = coi_dl[grp]['UNCERTAINTY']\n",
    "        detection_col = coi_dl[grp]['DL']\n",
    "\n",
    "        # Initialize detection limit column\n",
    "        df['DL'] = df[detection_col]\n",
    "        \n",
    "        # Set detection limits based on conditions\n",
    "        self._set_detection_limits(df, value_col, uncertainty_col, lut)\n",
    "\n",
    "    def _set_detection_limits(self, df: pd.DataFrame, value_col: str, uncertainty_col: str, lut: dict) -> None:\n",
    "        \"Set detection limits based on value and uncertainty columns.\"\n",
    "        \n",
    "        # Condition for setting '='\n",
    "        # 'DL' defaults to equal (i.e. '=') if there is a value and uncertainty and 'DL' value is not \n",
    "        # in the lookup table.\n",
    "        \n",
    "        condition_eq =(df[value_col].notna() & \n",
    "                       df[uncertainty_col].notna() & \n",
    "                       ~df['DL'].isin(lut.keys())\n",
    "        )\n",
    "        \n",
    "        df.loc[condition_eq, 'DL'] = '='\n",
    "\n",
    "        # Set 'Not Available' for unmatched detection limits\n",
    "        df.loc[~df['DL'].isin(lut.keys()), 'DL'] = 'Not Available'\n",
    "        \n",
    "        # Perform lookup to map detection limits\n",
    "        df['DL'] = df['DL'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ba3694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: [2 1 0]\n",
      "SEDIMENT: [1 2 0]\n",
      "SEAWATER: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            SplitSedimentValuesCB(coi_sediment),\n",
    "                            NormalizeUncCB(),\n",
    "                            SanitizeValueCB(coi_val),                       \n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl)])\n",
    "\n",
    "\n",
    "for grp in ['BIOTA', 'SEDIMENT', 'SEAWATER']:\n",
    "    print(f\"{grp}: {tfm()[grp]['DL'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026620e",
   "metadata": {},
   "source": [
    "## Remap filtering status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea63f3",
   "metadata": {},
   "source": [
    "HELCOM filtered status is encoded as follows in the `FILT` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5eacd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index value\n",
       "0      0   NaN\n",
       "1      1     F\n",
       "2      2     N\n",
       "3      3     n"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "get_unique_across_dfs(dfs, col_name='FILT', as_df=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee067",
   "metadata": {},
   "source": [
    "MARIS uses a different encoding for filtered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34e737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            name\n",
       "0  -1  Not applicable\n",
       "1   0   Not available\n",
       "2   1             Yes\n",
       "3   2              No"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_excel(filtered_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf457",
   "metadata": {},
   "source": [
    "For only four categories to remap, the `Remapper` is an overkill. We can use a simple dictionary to map the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d2b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_filtered = {\n",
    "    'N': 2, # No\n",
    "    'n': 2, # No\n",
    "    'F': 1 # Yes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ea425",
   "metadata": {},
   "source": [
    "`RemapFiltCB` converts the HELCOM `FILT` format to the MARIS `FILT` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8f58336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapFiltCB(Callback):\n",
    "    \"Lookup FILT value in dataframe using the lookup table.\"\n",
    "    def __init__(self,\n",
    "                 lut_filtered: dict=lut_filtered, # Dictionary mapping FILT codes to their corresponding names\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for df in tfm.dfs.values():\n",
    "            if 'FILT' in df.columns:\n",
    "                df['FILT'] = df['FILT'].map(lambda x: self.lut_filtered.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719feb2c",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2d13536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapFiltCB(lut_filtered)])\n",
    "\n",
    "print(tfm()['SEAWATER']['FILT'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1762e",
   "metadata": {},
   "source": [
    "## Add Laboratory ID (REVIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa8601",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**:  Review the inclusion of LAB in the NetCDF output, note with minor updates to dbo_lab.xlsx it would offer a way to obtain a `SMP_ID`\n",
    "\n",
    "This section could be simplified by including all Helcom 'LABORATORY' names in the MARIS standard laboratory names lookup table (dbo_lab.xlsx). For example STUK, KRIL, RISO, etc. are absent from the MARIS standard laboratory names lookup table lab_abb column.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fd6c2",
   "metadata": {},
   "source": [
    "Lets use the utility `get_unique_across_dfs` function to review the unique laboratory IDs in the HELCOM dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f669ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAAS</td>\n",
       "      <td>SSSI</td>\n",
       "      <td>STUK</td>\n",
       "      <td>VTIG</td>\n",
       "      <td>IMGW</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>JORC</td>\n",
       "      <td>CLOR</td>\n",
       "      <td>EBRS</td>\n",
       "      <td>LREB</td>\n",
       "      <td>RISO</td>\n",
       "      <td>LVDC</td>\n",
       "      <td>KRIL</td>\n",
       "      <td>NCRS</td>\n",
       "      <td>SSSM</td>\n",
       "      <td>BFFG</td>\n",
       "      <td>LVEA</td>\n",
       "      <td>DHIG</td>\n",
       "      <td>ERPC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     10    11  \\\n",
       "index    0     1     2     3     4     5     6     7     8     9    10    11   \n",
       "value  NaN  SAAS  SSSI  STUK  VTIG  IMGW  LEPA  JORC  CLOR  EBRS  LREB  RISO   \n",
       "\n",
       "         12    13    14    15    16    17    18    19  \n",
       "index    12    13    14    15    16    17    18    19  \n",
       "value  LVDC  KRIL  NCRS  SSSM  BFFG  LVEA  DHIG  ERPC  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Transpose to display the dataframe horizontally\n",
    "get_unique_across_dfs(tfm.dfs, col_name='LABORATORY', as_df=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20d826",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a lookup table `LABORATORY_NAME.csv` which captures the laboratory names and codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c476eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABORATORY</th>\n",
       "      <th>LABORATORY_NAME</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG</td>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY</td>\n",
       "      <td>01/01/86 00:00:00</td>\n",
       "      <td>12/31/07 00:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLOR</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>01/01/84 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DHIG</td>\n",
       "      <td>FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY</td>\n",
       "      <td>01/01/84 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBRS</td>\n",
       "      <td>RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA</td>\n",
       "      <td>01/01/10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMHI</td>\n",
       "      <td>ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABORATORY                                              LABORATORY_NAME  \\\n",
       "0       BFFG                BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY   \n",
       "1       CLOR    CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "2       DHIG            FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY   \n",
       "3       EBRS     RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA   \n",
       "4       EMHI  ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA   \n",
       "\n",
       "          START_DATE           END_DATE  COUNTRY  \n",
       "0  01/01/86 00:00:00  12/31/07 00:00:00        6  \n",
       "1  01/01/84 00:00:00                NaN       67  \n",
       "2  01/01/84 00:00:00                NaN        6  \n",
       "3  01/01/10 00:00:00                NaN       91  \n",
       "4                NaN                NaN       91  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af592d43",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS standard laboratory names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7f95bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_abb</th>\n",
       "      <th>lab</th>\n",
       "      <th>addr_1</th>\n",
       "      <th>addr_2</th>\n",
       "      <th>twn_zip</th>\n",
       "      <th>country</th>\n",
       "      <th>tel</th>\n",
       "      <th>e_mail</th>\n",
       "      <th>fax</th>\n",
       "      <th>note</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IAEA-EL</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P.O. Box No. 800</td>\n",
       "      <td>MC-98012 Monaco Cedex</td>\n",
       "      <td>Principality of Monaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab = 'International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)', country = '' where lab_id = 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>INPAS</td>\n",
       "      <td>Institute of Nuclear Physics - Academy of Sciences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab = 'Institute of Nuclear Physics - Academy of Sciences', country = '' where lab_id = 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_id         lab_abb  \\\n",
       "0      -1  Not applicable   \n",
       "1       0   Not available   \n",
       "2       1         IAEA-EL   \n",
       "3       2           INPAS   \n",
       "\n",
       "                                                                                                  lab  \\\n",
       "0                                                                                                 NaN   \n",
       "1                                                                                       Not available   \n",
       "2  International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)   \n",
       "3                                                  Institute of Nuclear Physics - Academy of Sciences   \n",
       "\n",
       "  addr_1            addr_2                twn_zip                 country  \\\n",
       "0    NaN               NaN                    NaN                     NaN   \n",
       "1    NaN               NaN                    NaN           Not available   \n",
       "2    NaN  P.O. Box No. 800  MC-98012 Monaco Cedex  Principality of Monaco   \n",
       "3    NaN               NaN                 Tirana                 Albania   \n",
       "\n",
       "   tel e_mail  fax note  Unnamed: 11  Unnamed: 12  \\\n",
       "0  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "1  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "2  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "3  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "\n",
       "                                                                                                                                                Unnamed: 13  \n",
       "0                                                                                                                                                       NaN  \n",
       "1                                                                                                                                                       NaN  \n",
       "2  update lab set lab = 'International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)', country = '' where lab_id = 1  \n",
       "3                                                  update lab set lab = 'Institute of Nuclear Physics - Academy of Sciences', country = '' where lab_id = 2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "maris_lab_lut=pd.read_excel(lab_lut_path())\n",
    "maris_lab_lut.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e993fd1",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR DATA PROVIDER**: \n",
    "One entry for the `LABORATORY` column includes a 'NaN', see below.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fa2ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with NaN in the `LABORATORY` column:\n",
      "SEDIMENT: \n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "def find_nan_entries(dfs, columns=None):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of DataFrames, each containing the complete rows where any of the specified columns have NaN values from the original DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "        dfs (dict): A dictionary where keys are dataset names and values are pandas DataFrames.\n",
    "        columns (list, optional): A list of column names to check for NaN values. If None, all columns are checked.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where each key is the dataset name and the value is a DataFrame of complete rows that have NaN entries in the specified columns.\n",
    "    \"\"\"\n",
    "    nan_entries = {}\n",
    "    for key, df in dfs.items():\n",
    "        # If columns are specified, check these columns for NaN values\n",
    "        if columns is not None:\n",
    "            # Find rows with NaN values in the specified columns\n",
    "            nan_rows = df[columns].isnull().any(axis=1)\n",
    "        else:\n",
    "            # Find rows with any NaN values across all columns\n",
    "            nan_rows = df.isnull().any(axis=1)\n",
    "        \n",
    "        # Use the boolean index to select the complete rows from the original DataFrame\n",
    "        complete_nan_rows = df[nan_rows]\n",
    "        \n",
    "        if not complete_nan_rows.empty:\n",
    "            nan_entries[key] = complete_nan_rows\n",
    "    return nan_entries\n",
    "\n",
    "nan_lab_df = find_nan_entries(dfs, columns=['LABORATORY'])\n",
    "\n",
    "print ('Entries with NaN in the `LABORATORY` column:')\n",
    "for key, df in nan_lab_df.items():\n",
    "    print(f\"{key}: \\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cedd8",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Consider integrating combine_lut_columns into utils.ipynb. I've updated the remapper and match_maris_lut functions to accept either a lut_path or a DataFrame. This code could be further simplified by handling the file opening (e.g., pd.read_excel) directly within the remapper function, thereby always passing a DataFrame to match_maris_lut. Refer to the implementation in utils.ipynb for details.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8717d2",
   "metadata": {},
   "source": [
    "The HELCOM description of laboratory includes both the laboratory name and country. Lets update the ``maris_lab_lut`` to include the laboratory name and country in the same column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55c3703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def combine_lut_columns(lut_path: Callable, combine_cols: List[str] = []):\n",
    "    if lut_path:\n",
    "        df_lut = pd.read_excel(lut_path()) \n",
    "        if combine_cols:\n",
    "            # Combine the specified columns into a single column with space as separator\n",
    "            df_lut['combined'] = df_lut[combine_cols].astype(str).agg(' '.join, axis=1)\n",
    "            # Create a column name by joining column names with '_'\n",
    "            combined_col_name = '_'.join(combine_cols)\n",
    "            df_lut.rename(columns={'combined': combined_col_name}, inplace=True)\n",
    "        return df_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10b9418a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>lab_abb</th>\n",
       "      <th>lab</th>\n",
       "      <th>addr_1</th>\n",
       "      <th>addr_2</th>\n",
       "      <th>twn_zip</th>\n",
       "      <th>country</th>\n",
       "      <th>tel</th>\n",
       "      <th>e_mail</th>\n",
       "      <th>fax</th>\n",
       "      <th>note</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>lab_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IAEA-EL</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P.O. Box No. 800</td>\n",
       "      <td>MC-98012 Monaco Cedex</td>\n",
       "      <td>Principality of Monaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update lab set lab = 'International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)', country = '' where lab_id = 1</td>\n",
       "      <td>International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory) Principality of Monaco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab_id         lab_abb  \\\n",
       "0      -1  Not applicable   \n",
       "1       0   Not available   \n",
       "2       1         IAEA-EL   \n",
       "\n",
       "                                                                                                  lab  \\\n",
       "0                                                                                                 NaN   \n",
       "1                                                                                       Not available   \n",
       "2  International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)   \n",
       "\n",
       "  addr_1            addr_2                twn_zip                 country  \\\n",
       "0    NaN               NaN                    NaN                     NaN   \n",
       "1    NaN               NaN                    NaN           Not available   \n",
       "2    NaN  P.O. Box No. 800  MC-98012 Monaco Cedex  Principality of Monaco   \n",
       "\n",
       "   tel e_mail  fax note  Unnamed: 11  Unnamed: 12  \\\n",
       "0  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "1  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "2  NaN    NaN  NaN  NaN          NaN          NaN   \n",
       "\n",
       "                                                                                                                                                Unnamed: 13  \\\n",
       "0                                                                                                                                                       NaN   \n",
       "1                                                                                                                                                       NaN   \n",
       "2  update lab set lab = 'International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory)', country = '' where lab_id = 1   \n",
       "\n",
       "                                                                                                                 lab_country  \n",
       "0                                                                                                                    nan nan  \n",
       "1                                                                                                Not available Not available  \n",
       "2  International Atomic Energy Agency - Environment Laboratory (former Marine Environment Laboratory) Principality of Monaco  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_lut=combine_lut_columns(lab_lut_path, ['lab','country'])\n",
    "df_lut.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913278b",
   "metadata": {},
   "source": [
    "Let's now create an instance of a [fuzzy matching algorithm](https://www.wikiwand.com/en/articles/Approximate_string_matching) `Remapper`. This instance will match the ``LABORATORY`` column of the HELCOM dataset to the MARIS standard laboratory names using both `lab` and `country` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c40f9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "remapper = Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv'),\n",
    "                    maris_lut_fn= combine_lut_columns(lut_path=lab_lut_path, combine_cols=['lab','country']),\n",
    "                    maris_col_id='lab_id',\n",
    "                    maris_col_name='lab_country',\n",
    "                    provider_col_to_match='LABORATORY_NAME',\n",
    "                    provider_col_key='LABORATORY',\n",
    "                    fname_cache='lab_helcom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1528926",
   "metadata": {},
   "source": [
    "Lets try to match ``LABORATORY`` names to MARIS standard laboratory names as automatically as possible. The `match_score` column allows to assess the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b00ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [00:00<00:00, 64.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entries matched the criteria, while 20 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSSI</th>\n",
       "      <td>Nuclear Research Institute Vietnam</td>\n",
       "      <td>STATENS STRÅLSKYDDSINSTITUT, SWEDEN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRIL</th>\n",
       "      <td>Polytechnic Institute Romania</td>\n",
       "      <td>V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STUK</th>\n",
       "      <td>Radiation and Nuclear Safety Authority Finland</td>\n",
       "      <td>SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAAS</th>\n",
       "      <td>National Board of Nuclear Safety and Radiation Protection Germany</td>\n",
       "      <td>NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISO</th>\n",
       "      <td>Risø National Laboratory - The Radiation Research Department Denmark</td>\n",
       "      <td>RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEPA</th>\n",
       "      <td>Environmental Protection Agency Ireland</td>\n",
       "      <td>ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCRS</th>\n",
       "      <td>The Swedish University of Agricultural Sciences Sweden</td>\n",
       "      <td>SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOR</th>\n",
       "      <td>Central Laboratory for Radiological Protection Poland</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTIG</th>\n",
       "      <td>JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany</td>\n",
       "      <td>JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBRS</th>\n",
       "      <td>Radiation Safety Department, Environmental Board Estonia</td>\n",
       "      <td>RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSSM</th>\n",
       "      <td>SVERIGE'S  STRÅL SÄKERHETS MYNDIGHETEN Sweden</td>\n",
       "      <td>SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVEA</th>\n",
       "      <td>Latvian Environment Agency Latvia</td>\n",
       "      <td>LATVIAN ENVIRONMENT AGENCY, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFFG</th>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany</td>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVDC</th>\n",
       "      <td>Environmental Data Center of Latvia Latvia</td>\n",
       "      <td>ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JORC</th>\n",
       "      <td>Joint Research Center Lithuania</td>\n",
       "      <td>JOINT RESEARCH CENTER, LITHUANIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMGW</th>\n",
       "      <td>Institute of Meteorology and Water Management Poland</td>\n",
       "      <td>INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERPC</th>\n",
       "      <td>Estonian Radiation Protection Centre Estonia</td>\n",
       "      <td>ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMHI</th>\n",
       "      <td>Estonian Meteorological and Hydrological Institute Estonia</td>\n",
       "      <td>ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHIG</th>\n",
       "      <td>Federal Maritime and Hydrographic Agency Germany</td>\n",
       "      <td>FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LREB</th>\n",
       "      <td>Lielriga Regional Environmental Board Latvia</td>\n",
       "      <td>LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              matched_maris_name  \\\n",
       "source_key                                                                         \n",
       "SSSI                                          Nuclear Research Institute Vietnam   \n",
       "KRIL                                               Polytechnic Institute Romania   \n",
       "STUK                              Radiation and Nuclear Safety Authority Finland   \n",
       "SAAS           National Board of Nuclear Safety and Radiation Protection Germany   \n",
       "RISO        Risø National Laboratory - The Radiation Research Department Denmark   \n",
       "LEPA                                     Environmental Protection Agency Ireland   \n",
       "NCRS                      The Swedish University of Agricultural Sciences Sweden   \n",
       "CLOR                       Central Laboratory for Radiological Protection Poland   \n",
       "VTIG                                 JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany   \n",
       "EBRS                    Radiation Safety Department, Environmental Board Estonia   \n",
       "SSSM                               SVERIGE'S  STRÅL SÄKERHETS MYNDIGHETEN Sweden   \n",
       "LVEA                                           Latvian Environment Agency Latvia   \n",
       "BFFG                                BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany   \n",
       "LVDC                                  Environmental Data Center of Latvia Latvia   \n",
       "JORC                                             Joint Research Center Lithuania   \n",
       "IMGW                        Institute of Meteorology and Water Management Poland   \n",
       "ERPC                                Estonian Radiation Protection Centre Estonia   \n",
       "EMHI                  Estonian Meteorological and Hydrological Institute Estonia   \n",
       "DHIG                            Federal Maritime and Hydrographic Agency Germany   \n",
       "LREB                                Lielriga Regional Environmental Board Latvia   \n",
       "\n",
       "                                                                    source_name  \\\n",
       "source_key                                                                        \n",
       "SSSI                                        STATENS STRÅLSKYDDSINSTITUT, SWEDEN   \n",
       "KRIL                                     V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA   \n",
       "STUK        SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND   \n",
       "SAAS         NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY   \n",
       "RISO           RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK   \n",
       "LEPA                                 ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA   \n",
       "NCRS                        SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN   \n",
       "CLOR                  CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "VTIG                              JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY   \n",
       "EBRS                   RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA   \n",
       "SSSM                              SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN   \n",
       "LVEA                                         LATVIAN ENVIRONMENT AGENCY, LATVIA   \n",
       "BFFG                              BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY   \n",
       "LVDC                                ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA   \n",
       "JORC                                           JOINT RESEARCH CENTER, LITHUANIA   \n",
       "IMGW                      INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND   \n",
       "ERPC                              ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA   \n",
       "EMHI                ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA   \n",
       "DHIG                          FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY   \n",
       "LREB                              LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "SSSI                 23  \n",
       "KRIL                 22  \n",
       "STUK                 21  \n",
       "SAAS                 10  \n",
       "RISO                  8  \n",
       "LEPA                  7  \n",
       "NCRS                  5  \n",
       "CLOR                  4  \n",
       "VTIG                  2  \n",
       "EBRS                  2  \n",
       "SSSM                  2  \n",
       "LVEA                  1  \n",
       "BFFG                  1  \n",
       "LVDC                  1  \n",
       "JORC                  1  \n",
       "IMGW                  1  \n",
       "ERPC                  1  \n",
       "EMHI                  1  \n",
       "DHIG                  1  \n",
       "LREB                  1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ba2b",
   "metadata": {},
   "source": [
    "Although the match score is 1 or greater for all entries, many are still matched appropriately. Let's manually correct any unmatched values. Here, we are manually aligning the data providers' laboratory names with those used by the MARIS LUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0cc653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "fixes_lab_names = {\n",
    "    'STATENS STRÅLSKYDDSINSTITUT, SWEDEN': 'Swedish Radiation Safety Authority Sweden',\n",
    "    'V. G. KHLOPIN RADIUM INSTITUTE, RUSSIA': 'V.G. Khlopin Radium Institute - Lab. of Environmental Radioactive Contamination Monitoring Russian Federation',\n",
    "    'ENVIRONMENTAL PROTECTION AGENCY, LITHUANIA': 'Lithuanian Environmental Protection Agency Lithuania',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d8f3d",
   "metadata": {},
   "source": [
    "Now, lets apply the manual corrections, `fixes_lab_names` and try again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "795d6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [00:00<00:00, 54.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 entries matched the criteria, while 17 entries had a match score of 1 or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_maris_name</th>\n",
       "      <th>source_name</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STUK</th>\n",
       "      <td>Radiation and Nuclear Safety Authority Finland</td>\n",
       "      <td>SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAAS</th>\n",
       "      <td>National Board of Nuclear Safety and Radiation Protection Germany</td>\n",
       "      <td>NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISO</th>\n",
       "      <td>Risø National Laboratory - The Radiation Research Department Denmark</td>\n",
       "      <td>RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCRS</th>\n",
       "      <td>The Swedish University of Agricultural Sciences Sweden</td>\n",
       "      <td>SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOR</th>\n",
       "      <td>Central Laboratory for Radiological Protection Poland</td>\n",
       "      <td>CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTIG</th>\n",
       "      <td>JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany</td>\n",
       "      <td>JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBRS</th>\n",
       "      <td>Radiation Safety Department, Environmental Board Estonia</td>\n",
       "      <td>RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSSM</th>\n",
       "      <td>SVERIGE'S  STRÅL SÄKERHETS MYNDIGHETEN Sweden</td>\n",
       "      <td>SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVEA</th>\n",
       "      <td>Latvian Environment Agency Latvia</td>\n",
       "      <td>LATVIAN ENVIRONMENT AGENCY, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFFG</th>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany</td>\n",
       "      <td>BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVDC</th>\n",
       "      <td>Environmental Data Center of Latvia Latvia</td>\n",
       "      <td>ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JORC</th>\n",
       "      <td>Joint Research Center Lithuania</td>\n",
       "      <td>JOINT RESEARCH CENTER, LITHUANIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMGW</th>\n",
       "      <td>Institute of Meteorology and Water Management Poland</td>\n",
       "      <td>INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERPC</th>\n",
       "      <td>Estonian Radiation Protection Centre Estonia</td>\n",
       "      <td>ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMHI</th>\n",
       "      <td>Estonian Meteorological and Hydrological Institute Estonia</td>\n",
       "      <td>ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHIG</th>\n",
       "      <td>Federal Maritime and Hydrographic Agency Germany</td>\n",
       "      <td>FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LREB</th>\n",
       "      <td>Lielriga Regional Environmental Board Latvia</td>\n",
       "      <td>LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              matched_maris_name  \\\n",
       "source_key                                                                         \n",
       "STUK                              Radiation and Nuclear Safety Authority Finland   \n",
       "SAAS           National Board of Nuclear Safety and Radiation Protection Germany   \n",
       "RISO        Risø National Laboratory - The Radiation Research Department Denmark   \n",
       "NCRS                      The Swedish University of Agricultural Sciences Sweden   \n",
       "CLOR                       Central Laboratory for Radiological Protection Poland   \n",
       "VTIG                                 JOHAN HEINRICH VON THÜNEN-INSTITUTE Germany   \n",
       "EBRS                    Radiation Safety Department, Environmental Board Estonia   \n",
       "SSSM                               SVERIGE'S  STRÅL SÄKERHETS MYNDIGHETEN Sweden   \n",
       "LVEA                                           Latvian Environment Agency Latvia   \n",
       "BFFG                                BUNDESFORSCHUNGANSTALT FÜR FISCHEREI Germany   \n",
       "LVDC                                  Environmental Data Center of Latvia Latvia   \n",
       "JORC                                             Joint Research Center Lithuania   \n",
       "IMGW                        Institute of Meteorology and Water Management Poland   \n",
       "ERPC                                Estonian Radiation Protection Centre Estonia   \n",
       "EMHI                  Estonian Meteorological and Hydrological Institute Estonia   \n",
       "DHIG                            Federal Maritime and Hydrographic Agency Germany   \n",
       "LREB                                Lielriga Regional Environmental Board Latvia   \n",
       "\n",
       "                                                                    source_name  \\\n",
       "source_key                                                                        \n",
       "STUK        SÄTEILYTURVAKESKUS, RADIATION AND NUCLEAR SAFETY AUTHORITY, FINLAND   \n",
       "SAAS         NATIONAL BOARD FOR ATOMIC SAFETY AND RADIATION PROTECTION, GERMANY   \n",
       "RISO           RISÖ NATIONAL LABORATORY, RADIATION RESEARCH DEPARTMENT, DENMARK   \n",
       "NCRS                        SWEDISH UNIVERSITY OF AGRICULTURAL SCIENCES, SWEDEN   \n",
       "CLOR                  CENTRAL  LABORATORY  FOR  RADIOLOGICAL PROTECTION, POLAND   \n",
       "VTIG                              JOHANN HEINRICH VON THÜNEN-INSTITUTE, GERMANY   \n",
       "EBRS                   RADIATION SAFETY DEPARTMENT ENVIRONMENTAL BOARD, ESTONIA   \n",
       "SSSM                              SVERIGE'S  STRÅLSÄKERHETS MYNDIGHETEN, SWEDEN   \n",
       "LVEA                                         LATVIAN ENVIRONMENT AGENCY, LATVIA   \n",
       "BFFG                              BUNDESFORSCHUNGANSTALT FÜR FISCHEREI, GERMANY   \n",
       "LVDC                                ENVIRONMENTAL DATA CENTER OF LATVIA, LATVIA   \n",
       "JORC                                           JOINT RESEARCH CENTER, LITHUANIA   \n",
       "IMGW                      INSTITUTE OF METEOROLOGY AND WATER MANAGEMENT, POLAND   \n",
       "ERPC                              ESTONIAN RADIATION PROTECTION CENTRE, ESTONIA   \n",
       "EMHI                ESTONIAN METEOROLOGICAL AND HYDROLOGICAL INSTITUTE, ESTONIA   \n",
       "DHIG                          FEDERAL MARITIME AND HYDROGRAPHIC AGENCY, GERMANY   \n",
       "LREB                              LIELRIGA REGIONAL ENVIRONMENTAL BOARD, LATVIA   \n",
       "\n",
       "            match_score  \n",
       "source_key               \n",
       "STUK                 21  \n",
       "SAAS                 10  \n",
       "RISO                  8  \n",
       "NCRS                  5  \n",
       "CLOR                  4  \n",
       "VTIG                  2  \n",
       "EBRS                  2  \n",
       "SSSM                  2  \n",
       "LVEA                  1  \n",
       "BFFG                  1  \n",
       "LVDC                  1  \n",
       "JORC                  1  \n",
       "IMGW                  1  \n",
       "ERPC                  1  \n",
       "EMHI                  1  \n",
       "DHIG                  1  \n",
       "LREB                  1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "remapper.generate_lookup_table(as_df=True, fixes=fixes_lab_names)\n",
    "remapper.select_match(match_score_threshold=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b35a2",
   "metadata": {},
   "source": [
    "We have successfully matched the laboratory names to the MARIS standard laboratory names. We can now create a lookup table for the laboratory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce61019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "# Create a lookup table for laboratory names\n",
    "lut_lab = lambda: Remapper(provider_lut_df=pd.read_csv(Path(fname_in) / 'LABORATORY_NAME.csv'),\n",
    "                    maris_lut_fn= combine_lut_columns(lut_path=lab_lut_path, combine_cols=['lab','country']),\n",
    "                    maris_col_id='lab_id',\n",
    "                    maris_col_name='lab_country',\n",
    "                    provider_col_to_match='LABORATORY_NAME',\n",
    "                    provider_col_key='LABORATORY',\n",
    "                    fname_cache='lab_helcom.pkl').generate_lookup_table(fixes=fixes_lab_names,as_df=False, overwrite=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58648646",
   "metadata": {},
   "source": [
    "We now create the callback `RemapLabCB`, which will remap the nuclide names using the `lut_lab` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b640027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched value: nan\n",
      "Example of unique laboratory names: \n",
      "       LABORATORY  LAB\n",
      "0           VTIG  342\n",
      "547         STUK  301\n",
      "2855        SSSM  340\n",
      "3095        SSSI  381\n",
      "3611        SAAS  118\n",
      "4249        RISO  329\n",
      "5109        NCRS  238\n",
      "5828        LVEA  325\n",
      "5850        LVDC  326\n",
      "5866        LREB  327\n",
      "5875        LEPA  324\n",
      "5916        JORC  323\n",
      "5940        ERPC  322\n",
      "5977        EBRS  350\n",
      "5999        CLOR  188\n",
      "8103        BFFG  341\n",
      "14055       IMGW  191\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER'])\n",
    "    ])\n",
    "tfm()\n",
    "tfm.dfs['BIOTA'].columns\n",
    "# For instance:\n",
    "unique_labs = tfm.dfs['BIOTA'][['LABORATORY', 'LAB']].drop_duplicates()\n",
    "print('Example of unique laboratory names: \\n', unique_labs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5ef74",
   "metadata": {},
   "source": [
    "## Add Sample ID (REVIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3625631",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Enhancing traceability of NetCDF entries to original samples in the datasource using a standardized `SMP_ID`.\n",
    "\n",
    "*Context*:\n",
    "\n",
    "Previously, the NetCDF output did not include a sample laboratory code (or `SMP_ID`), limiting our ability to trace data back to its source. \n",
    "\n",
    "*Issue Identified*:\n",
    "The `KEY` column in the HELCOM dataset, which combines a sample type, a laboratory code, and an integer sequence offers a way trace data back to the HELCOM source. The `KEY` is of type string which is not included in our NetCDF output. To include a way to trace data back to the HELCOM source, we propose to include a `SMP_ID` in the NetCDF output which is of type integer.\n",
    "\n",
    "*Proposed Solution*:\n",
    "For the HELCOM dataset, where the `KEY` column includes unique codes like `WDHIG1996246` (comprising sample type, lab code, and sequence), we propose encoding this into a structured `SMP_ID`. This `SMP_ID` will use standardized MARIS Lookup Tables (LUTs) to convert both the sample type and laboratory code into integers.\n",
    "\n",
    "*Implementation Details*:\n",
    "- The `SMP_ID` will be formatted such that:\n",
    "  - The first digit indicates the sample type (e.g., 1 for Seawater).\n",
    "  - The next three digits represent the laboratory code (e.g., 313 for DHIG as standardized in dbo_lab.xlsx).\n",
    "  - The remaining digits reflect the integer sequence from the HELCOM KEY.\n",
    "- Example: `WDHIG1996246` becomes `SMP_ID` `13131996246`.\n",
    "\n",
    "*Action Required*:\n",
    "To adopt this approach, a review and update of the laboratory codes in the LUT (dbo_lab.xlsx) are necessary to ensure consistency and accuracy. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af75adc",
   "metadata": {},
   "source": [
    "First we wil use ``check_unique_key_int`` to show the non unique integer part of the `KEY` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0988fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def check_unique_key_int(tfm):\n",
    "    \"\"\"\n",
    "    Extracts unique 'KEY' values from specified DataFrames, separates them into string and integer components,\n",
    "    and groups keys by their integer components.\n",
    "\n",
    "    Parameters:\n",
    "    tfm (Transformer): The transformer object containing DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with the unique keys, their string and integer components, and grouped keys by integer component.\n",
    "    \"\"\"\n",
    "    # Define the groups to extract keys from\n",
    "    groups = ['SEAWATER', 'BIOTA', 'SEDIMENT']\n",
    "    \n",
    "    # Initialize a set to store unique keys\n",
    "    unique_keys = set()\n",
    "    \n",
    "    # Collect unique keys from each DataFrame\n",
    "    for grp in groups:\n",
    "        unique_keys.update(tfm.dfs[grp]['KEY'].unique())\n",
    "    \n",
    "    # Initialize a dictionary to group keys by their integer components\n",
    "    int_key_map = {}\n",
    "    \n",
    "    for key in unique_keys:\n",
    "        # Assuming the integer part starts after the first 5 characters\n",
    "        int_part = int(key[5:]) if key[5:].isdigit() else None  # Remaining part as integer\n",
    "        \n",
    "        if int_part is not None:\n",
    "            if int_part not in int_key_map:\n",
    "                int_key_map[int_part] = []  # Initialize list for this integer part\n",
    "            int_key_map[int_part].append(key)  # Append the complete key to the list\n",
    "    \n",
    "    return {\n",
    "        'int_key_map': int_key_map  # Return the mapping of integer parts to complete keys\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64748dbf",
   "metadata": {},
   "source": [
    "Below, we will generate a DataFrame where the index (labeled 'INT COMPONENT OF `KEY`') represents the integer portion extracted from the Helcom `KEY`. The 'KEYS' column lists all the `KEY` values that include this integer component. Originally, the plan was to use the integer part of the `KEY` column to create the `SMP_ID`. However, as demonstrated below, the integer part is not unique, which complicates this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f6b7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEYS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT COMPONENT OF `KEY`</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006012</th>\n",
       "      <td>[SRISO2006012, BSSSI2006012, SCLOR2006012, WSTUK2006012, WKRIL2006012, BSTUK2006012, BCLOR2006012, BRISO2006012, BBFFG2006012, WIMGW2006012, WLEPA2006012, SKRIL2006012, WRISO2006012, SSTUK2006012, SSSSI2006012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010003</th>\n",
       "      <td>[BVTIG2010003, BRISO2010003, WSSSI2010003, SLEPA2010003, WLVEA2010003, WEBRS2010003, BSSSM2010003, WKRIL2010003, SLVEA2010003, WRISO2010003, WLEPA2010003, SSTUK2010003, BCLOR2010003, SSSSI2010003, SRISO2010003, BSTUK2010003, WSTUK2010003, WIMGW2010003, SKRIL2010003, SCLOR2010003, BEBRS2010003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012014</th>\n",
       "      <td>[WKRIL2012014, WRISO2012014, SCLOR2012014, BCLOR2012014, WSTUK2012014, SSSSM2012014, SEBRS2012014, SSTUK2012014, BSSSM2012014, SLVEA2012014, SKRIL2012014, WIMGW2012014, BVTIG2012014, BSTUK2012014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007033</th>\n",
       "      <td>[SSTUK2007033, WRISO2007033, SCLOR2007033, WIMGW2007033, SKRIL2007033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002125</th>\n",
       "      <td>[SSTUK2002125, SDHIG2002125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                          KEYS\n",
       "INT COMPONENT OF `KEY`                                                                                                                                                                                                                                                                                                        \n",
       "2006012                                                                                                     [SRISO2006012, BSSSI2006012, SCLOR2006012, WSTUK2006012, WKRIL2006012, BSTUK2006012, BCLOR2006012, BRISO2006012, BBFFG2006012, WIMGW2006012, WLEPA2006012, SKRIL2006012, WRISO2006012, SSTUK2006012, SSSSI2006012]\n",
       "2010003                 [BVTIG2010003, BRISO2010003, WSSSI2010003, SLEPA2010003, WLVEA2010003, WEBRS2010003, BSSSM2010003, WKRIL2010003, SLVEA2010003, WRISO2010003, WLEPA2010003, SSTUK2010003, BCLOR2010003, SSSSI2010003, SRISO2010003, BSTUK2010003, WSTUK2010003, WIMGW2010003, SKRIL2010003, SCLOR2010003, BEBRS2010003]\n",
       "2012014                                                                                                                   [WKRIL2012014, WRISO2012014, SCLOR2012014, BCLOR2012014, WSTUK2012014, SSSSM2012014, SEBRS2012014, SSTUK2012014, BSSSM2012014, SLVEA2012014, SKRIL2012014, WIMGW2012014, BVTIG2012014, BSTUK2012014]\n",
       "2007033                                                                                                                                                                                                                                                 [SSTUK2007033, WRISO2007033, SCLOR2007033, WIMGW2007033, SKRIL2007033]\n",
       "2002125                                                                                                                                                                                                                                                                                           [SSTUK2002125, SDHIG2002125]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Create DataFrame from dictionary and set index name and column name\n",
    "unique_key_df = pd.DataFrame.from_dict(check_unique_key_int(tfm)).rename_axis('INT COMPONENT OF `KEY`')\n",
    "unique_key_df=unique_key_df.rename(columns={unique_key_df.columns[0]: 'KEYS'})\n",
    "unique_key_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc7e07",
   "metadata": {},
   "source": [
    "Below we will create a callback `AddSampleIDCB` to remap the `KEY` column to the `SMP_ID` column in each DataFrame.\n",
    "\n",
    "Remeber that in HELCOM, the `KEY` column has the sample type (S=Sediment, W=Seawater, B=Biota), the laboratory code (e.g., DHIG), followed by an integer sequence. \n",
    "\n",
    "If we update the MARIS LUT (dbo_lab.xlsx), to include laboratory codes (i.e. update the ``lab_abb`` column), then the remapping of the  `LAB` and the `AddSampleIDCB` can be much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4090d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "smp_type_lut = {\n",
    "    'SEAWATER': 1,\n",
    "    'BIOTA': 2,\n",
    "    'SEDIMENT': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f29d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "class AddSampleIDCB(Callback):\n",
    "    \"Remap `KEY` column to `SMP_ID` in each DataFrame.\"\n",
    "    def __init__(self, lut_type: Dict[str, int]):\n",
    "        self.lut_type = lut_type\n",
    "        \n",
    "    def __call__(self, tfm: Transformer):\n",
    "        for grp in tfm.dfs:\n",
    "            self._remap_sample_id(tfm.dfs[grp], grp)\n",
    "    \n",
    "    def _remap_sample_id(self, df: pd.DataFrame, grp: str):\n",
    "        \"\"\"\n",
    "        Remaps the 'KEY' column to 'SMP_ID' using the provided lookup table.\n",
    "        Sets 'SMP_ID' to -1 if 'LAB' or 'SEQUENCE' is NaN.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The DataFrame to process.\n",
    "            grp (str): The group key from the DataFrame dictionary, used to access specific LUT values.\n",
    "        \"\"\"\n",
    "        # Check for NaNs in 'LAB' or 'SEQUENCE' and compute 'SMP_ID' conditionally\n",
    "        df['SMP_ID'] = np.where(\n",
    "            df['LAB'].isna() | df['SEQUENCE'].isna(),\n",
    "            -1,\n",
    "            str(self.lut_type[grp]) + df['LAB'].astype(str).str.zfill(3) + df['SEQUENCE'].astype(str).str.zfill(7)\n",
    "        )\n",
    "\n",
    "        # Convert 'SMP_ID' to integer, handling floating point representations\n",
    "        df['SMP_ID'] = df['SMP_ID'].apply(lambda x: int(float(x)) if isinstance(x, str) and '.' in x else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a13ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched value: nan\n",
      "[12112012003 12112012004 12112012005 ... 13400201806 13400201807\n",
      " 13400201808]\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                        RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                        AddSampleIDCB(lut_type=smp_type_lut),\n",
    "                        CompareDfsAndTfmCB(dfs)\n",
    "                        ])\n",
    "\n",
    "print(tfm()['SEAWATER']['SMP_ID'].unique())\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05383c",
   "metadata": {},
   "source": [
    "## Add Methods (FOR NEXT VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7dcdb",
   "metadata": {},
   "source": [
    "lut_method = lambda: pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307c018",
   "metadata": {},
   "source": [
    "The HELCOM dataset includes a look-up table `ANALYSIS_METHOD.csv` which captures the methods used by HELCOM in a description field (free text). Lets review the ANALYSIS METHOD descriptions of HELCOM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFFG01</td>\n",
       "      <td>6</td>\n",
       "      <td>Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFFG02</td>\n",
       "      <td>6</td>\n",
       "      <td>Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLOR02</td>\n",
       "      <td>67</td>\n",
       "      <td>Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   METHOD  COUNTRY  \\\n",
       "0  BFFG01        6   \n",
       "1  BFFG02        6   \n",
       "2  CLOR02       67   \n",
       "\n",
       "                                                                                                                                                                                                                                               DESCRIPTION  \n",
       "0                                                            Gammaspectrometric analysis with Germanium detectors (p-type HGeLi's and HPGe's and 1 n-type HPGe), with efficiency 20-48% Energy resolution 1.8-2.3 keV at 1.33 MeV (not to in use any more)  \n",
       "1                                                    Sr-90, a) Y-90 extraction method dried ash and added Y-90 + HCl, Ph adjustment and Y-90 extraction with HDEHP in n-heptane b) Modified version of classic nitric acid method (not to in use any more)  \n",
       "2  Radiochemical method Radiocaesium separation from seawater samples.134+137Cs was adsorbed on AMP mat,  dissolved with NaOH and after purification precipitated as chloroplatinate (Cs2PtCl6).Counting with low background anticoincidence beta counter.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "analsis_method_df=pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv')\n",
    "analsis_method_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39ead8",
   "metadata": {},
   "source": [
    "Number of unique ANALYSIS_METHOD DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28536ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "len(analsis_method_df['DESCRIPTION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9976e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "lut_method = lambda: pd.read_csv(Path(fname_in) / 'ANALYSIS_METHOD.csv').set_index('METHOD').to_dict()['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a7232",
   "metadata": {},
   "source": [
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['UPPSLI']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef89d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "prepmet_lut = pd.read_excel(prepmet_lut_path())\n",
    "sampmet_lut = pd.read_excel(sampmet_lut_path())\n",
    "counmet_lut = pd.read_excel(counmet_lut_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d625717",
   "metadata": {},
   "source": [
    "**DISCUSS** repition of counting method in `counmet_lut`. When should we use each of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counmet_id</th>\n",
       "      <th>counmet</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Atomic absorption</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>ALP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Alpha ionization chamber spectrometry</td>\n",
       "      <td>ALPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Alpha liquid scintillation spectrometry</td>\n",
       "      <td>ALPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Alpha semiconductor spectrometry</td>\n",
       "      <td>ALPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Alpha total</td>\n",
       "      <td>ALPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Accelerator mass spectrometry</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>Beta</td>\n",
       "      <td>BET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counmet_id                                  counmet  code\n",
       "0          -1                           Not applicable   NaN\n",
       "1           0                            Not available     0\n",
       "2           1                        Atomic absorption    AA\n",
       "3           2                                    Alpha   ALP\n",
       "4           3    Alpha ionization chamber spectrometry  ALPI\n",
       "5           4  Alpha liquid scintillation spectrometry  ALPL\n",
       "6           5         Alpha semiconductor spectrometry  ALPS\n",
       "7           6                              Alpha total  ALPT\n",
       "8           7            Accelerator mass spectrometry   AMS\n",
       "9           8                                     Beta   BET"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "counmet_lut.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff696fec",
   "metadata": {},
   "source": [
    "## Add slice position (TOP and BOTTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf398df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class RemapSedSliceTopBottomCB(Callback):\n",
    "    \"Remap Sediment slice top and bottom to MARIS format.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and remap sediment slice top and bottom.\"\n",
    "        tfm.dfs['SEDIMENT']['TOP'] = tfm.dfs['SEDIMENT']['UPPSLI']\n",
    "        tfm.dfs['SEDIMENT']['BOTTOM'] = tfm.dfs['SEDIMENT']['LOWSLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOP  BOTTOM\n",
      "0  15.0    20.0\n",
      "1  20.0    27.0\n",
      "2   0.0     2.0\n",
      "3   2.0     4.0\n",
      "4   4.0     6.0\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[RemapSedSliceTopBottomCB()])\n",
    "tfm()\n",
    "print(tfm.dfs['SEDIMENT'][['TOP','BOTTOM']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbf53",
   "metadata": {},
   "source": [
    "## Add dry weight, wet weight and percentage weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d2796",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Entries for the ``BASIS`` value of the ``BIOTA`` dataset report a value of `F` which is not consistent with the HELCOM description provided in the metadata. The `GUIDELINES FOR MONITORING OF RADIOACTIVE SUBSTANCES` was obtained from [here](https://metadata.helcom.fi/geonetwork/srv/fin/catalog.search#/metadata/2fdd2d46-0329-40e3-bf96-cb08c7206a24).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2b08",
   "metadata": {},
   "source": [
    "Lets take a look at the BIOTA BASIS values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcfc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', nan, 'D', 'F'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafeff5",
   "metadata": {},
   "source": [
    "Number of entries for each ``BASIS`` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d37b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASIS\n",
       "W    11167\n",
       "D     3634\n",
       "F       25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['BASIS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc763755",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Some entries for ``DW%`` (Dry weight as percentage (%) of fresh weight) are much higher than 100%. Additionally, ``DW%`` is repoted as 0% in some cases.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f3249",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc7826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b30b6b",
   "metadata": {},
   "source": [
    "For BIOTA, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f386973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA']['DW%'][dfs['BIOTA']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b1201",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` higher than 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37493d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] > 100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f48f6",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` equal to 0%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44234014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT']['DW%'][dfs['SEDIMENT']['DW%'] == 0].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00833c1f",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Several SEDIMENT entries have `DW%` (Dry weight as percentage of fresh weight) values less than 1%. While technically possible, this would indicate samples contained more than 99% water content.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fb178",
   "metadata": {},
   "source": [
    "For SEDIMENT, the number of entries for ``DW%`` less than 1% but greater than 0.001%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c78c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "percent=1\n",
    "dfs['SEDIMENT']['DW%'][(dfs['SEDIMENT']['DW%'] < percent) & (dfs['SEDIMENT']['DW%'] > 0.001)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71231c2a",
   "metadata": {},
   "source": [
    "Lets take a look at the MARIS description of the `percentwt`, `drywt` and `wetwt` variables:\n",
    "\n",
    "- `percentwt`: Dry weight as ratio of fresh weight, expressed as a decimal .\n",
    "- `drywt`: Dry weight in grams.\n",
    "- `wetwt`: Fresh weight in grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92f75f",
   "metadata": {},
   "source": [
    "Lets take a look at the HELCOM dataset, the weight of the sample is not reported for ``SEDIMENT``. However, the percentage dry weight is reported as `DW%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92c9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'ERROR%_kg',\n",
       "       '< VALUE_Bq/m²', 'VALUE_Bq/m²', 'ERROR%_m²', 'DATE_OF_ENTRY_x',\n",
       "       'COUNTRY', 'LABORATORY', 'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY',\n",
       "       'STATION', 'LATITUDE (ddmmmm)', 'LATITUDE (dddddd)',\n",
       "       'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)', 'DEVICE', 'TDEPTH',\n",
       "       'UPPSLI', 'LOWSLI', 'AREA', 'SEDI', 'OXIC', 'DW%', 'LOI%',\n",
       "       'MORS_SUBBASIN', 'HELCOM_SUBBASIN', 'SUM_LINK', 'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['SEDIMENT'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1037bff",
   "metadata": {},
   "source": [
    "The BIOTA dataset reports the weight of the sample as `WEIGHT` and the percentage dry weight as `DW%`. The `BASIS` column describes the basis the value reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
       "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
       "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
       "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
       "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
       "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
       "       'DATE_OF_ENTRY_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs['BIOTA'].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class LookupDryWetPercentWeightCB(Callback):\n",
    "    \"Lookup dry-wet ratio and format for MARIS.\"\n",
    "    def __call__(self, tfm: Transformer):\n",
    "        \"Iterate through all DataFrames in the transformer object and apply the dry-wet ratio lookup.\"\n",
    "        for grp in tfm.dfs.keys():\n",
    "            if 'DW%' in tfm.dfs[grp].columns:\n",
    "                self._apply_dry_wet_ratio(tfm.dfs[grp])\n",
    "            if 'WEIGHT' in tfm.dfs[grp].columns and 'BASIS' in tfm.dfs[grp].columns:\n",
    "                self._correct_basis(tfm.dfs[grp])\n",
    "                self._apply_weight(tfm.dfs[grp])\n",
    "\n",
    "    def _apply_dry_wet_ratio(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply dry-wet ratio conversion and formatting to the given DataFrame.\"\n",
    "        df['PERCENTWT'] = df['DW%'] / 100  # Convert percentage to fraction\n",
    "        df.loc[df['PERCENTWT'] == 0, 'PERCENTWT'] = np.NaN  # Convert 0% to NaN\n",
    "\n",
    "    def _correct_basis(self, df: pd.DataFrame) -> None:\n",
    "        \"Correct BASIS values. Assuming F = Fresh weight, so F = W\"\n",
    "        df.loc[df['BASIS'] == 'F', 'BASIS'] = 'W'\n",
    "\n",
    "    def _apply_weight(self, df: pd.DataFrame) -> None:\n",
    "        \"Apply weight conversion and formatting to the given DataFrame.\"\n",
    "        dry_condition = df['BASIS'] == 'D'\n",
    "        wet_condition = df['BASIS'] == 'W'\n",
    "        \n",
    "        df.loc[dry_condition, 'DRYWT'] = df['WEIGHT']\n",
    "        df.loc[dry_condition & df['PERCENTWT'].notna(), 'WETWT'] = df['WEIGHT'] / df['PERCENTWT']\n",
    "        \n",
    "        df.loc[wet_condition, 'WETWT'] = df['WEIGHT']\n",
    "        df.loc[wet_condition & df['PERCENTWT'].notna(), 'DRYWT'] = df['WEIGHT'] * df['PERCENTWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d714bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37347\n",
      "Number of rows removed         0         0         0 \n",
      "\n",
      "BIOTA:    PERCENTWT      DRYWT  WETWT\n",
      "0    0.18453  174.93444  948.0\n",
      "1    0.18453  174.93444  948.0\n",
      "2    0.18453  174.93444  948.0\n",
      "3    0.18453  174.93444  948.0\n",
      "4    0.18458  177.93512  964.0\n",
      "SEDIMENT: 0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: PERCENTWT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print('BIOTA:', tfm.dfs['BIOTA'][['PERCENTWT','DRYWT','WETWT']].head())\n",
    "print('SEDIMENT:', tfm.dfs['SEDIMENT']['PERCENTWT'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68925d7c",
   "metadata": {},
   "source": [
    "Note that the dry weight is greater than the wet weight for some entries in the BIOTA dataset due to the DW% being greater than 100%, see above. Lets take a look at the number of entries where this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRYWT    20\n",
       "WETWT    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.dfs['BIOTA'][['DRYWT','WETWT']][tfm.dfs['BIOTA']['DRYWT'] > tfm.dfs['BIOTA']['WETWT']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b9aa0",
   "metadata": {},
   "source": [
    "class ParseCoordinates(Callback):\n",
    "    \"\"\"\n",
    "    Get geographical coordinates from columns expressed in degrees decimal format \n",
    "    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_cor: Callable # Function that converts coordinates from degree-minute to decimal degree format\n",
    "                 ):\n",
    "        self.fn_convert_cor = fn_convert_cor\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._format_coordinates(df)\n",
    "\n",
    "    def _format_coordinates(self, df:pd.DataFrame) -> None:\n",
    "        coord_cols = self._get_coord_columns(df.columns)\n",
    "        \n",
    "        for coord in ['lat', 'lon']:\n",
    "            decimal_col, minute_col = coord_cols[f'{coord}_d'], coord_cols[f'{coord}_m']\n",
    "            \n",
    "            condition = df[decimal_col].isna() | (df[decimal_col] == 0)\n",
    "            df[coord.upper()] = np.where(condition,\n",
    "                                 df[minute_col].apply(self._safe_convert),\n",
    "                                 df[decimal_col])\n",
    "        \n",
    "        df.dropna(subset=['LAT', 'LON'], inplace=True)\n",
    "\n",
    "    def _get_coord_columns(self, columns) -> dict:\n",
    "        return {\n",
    "            'lon_d': self._find_coord_column(columns, 'LON', 'dddddd'),\n",
    "            'lat_d': self._find_coord_column(columns, 'LAT', 'dddddd'),\n",
    "            'lon_m': self._find_coord_column(columns, 'LON', 'ddmmmm'),\n",
    "            'lat_m': self._find_coord_column(columns, 'LAT', 'ddmmmm')\n",
    "        }\n",
    "\n",
    "    def _find_coord_column(self, columns, coord_type, coord_format) -> str:\n",
    "        pattern = re.compile(f'{coord_type}.*{coord_format}', re.IGNORECASE)\n",
    "        matching_columns = [col for col in columns if pattern.search(col)]\n",
    "        return matching_columns[0] if matching_columns else None\n",
    "\n",
    "    def _safe_convert(self, value) -> str:\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203cb3",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: Column names for geographical coordinates are inconsistent across sample types (biota, sediment, seawater). Sometimes using parentheses, sometimes not.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c04fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA: ['LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
      "SEAWATER: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
      "SEDIMENT: ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)', 'LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "for grp in dfs.keys():\n",
    "    print(f'{grp}: {[col for col in dfs[grp].columns if \"LON\" in col or \"LAT\" in col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83c2e1",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK TO DATA PROVIDER**: HELCOM SEAWATER datase includes values of 0 for both latitude and longitude. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAWATER invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/m³  VALUE_Bq/m³  ERROR%_m³  \\\n",
      "19238  WSTUK2015001      H3  STUK04             <        920.0        0.0   \n",
      "19239  WSTUK2015002      H3  STUK04             <        920.0        0.0   \n",
      "19240  WSTUK2015003      H3  STUK04             <        920.0        0.0   \n",
      "19241  WSTUK2015004      H3  STUK04             <        920.0        0.0   \n",
      "19242  WSTUK2015005      H3  STUK04             <        920.0        0.0   \n",
      "\n",
      "         DATE_OF_ENTRY_x  COUNTRY LABORATORY  SEQUENCE  ...  \\\n",
      "19238  12/07/16 00:00:00       34       STUK   2015001  ...   \n",
      "19239  12/07/16 00:00:00       34       STUK   2015002  ...   \n",
      "19240  12/07/16 00:00:00       34       STUK   2015003  ...   \n",
      "19241  12/07/16 00:00:00       34       STUK   2015004  ...   \n",
      "19242  12/07/16 00:00:00       34       STUK   2015005  ...   \n",
      "\n",
      "      LONGITUDE (ddmmmm)  LONGITUDE (dddddd)  TDEPTH  SDEPTH SALIN  TTEMP  \\\n",
      "19238            23.3761                 0.0    81.0     1.0   NaN    NaN   \n",
      "19239            23.3761                 0.0    81.0    80.0   NaN    NaN   \n",
      "19240            26.2080                 0.0    69.0     1.0   NaN    NaN   \n",
      "19241            26.2080                 0.0    69.0    68.0   NaN    NaN   \n",
      "19242            21.0477                 0.0   173.0     1.0   NaN    NaN   \n",
      "\n",
      "       FILT  MORS_SUBBASIN  HELCOM_SUBBASIN    DATE_OF_ENTRY_y  \n",
      "19238     N             11               11  12/07/16 00:00:00  \n",
      "19239     N             11               11  12/07/16 00:00:00  \n",
      "19240     N             11               11  12/07/16 00:00:00  \n",
      "19241     N             11               11  12/07/16 00:00:00  \n",
      "19242     N              3                3  12/07/16 00:00:00  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (ddmmmm)_LONGITUDE (ddmmmm):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n",
      "SEDIMENT invalid coordinates for LATITUDE (dddddd)_LONGITUDE (dddddd):\n",
      "                KEY NUCLIDE  METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
      "35783  SDHIG2016236   CS137  DHIG03           NaN       8.2952      2.351   \n",
      "\n",
      "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m²    DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
      "35783           NaN   237.500899        NaN  05/13/19 00:00:00  ...     NaN   \n",
      "\n",
      "      AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
      "35783  NaN   NaN  NaN  NaN   NaN            NaN             NaN       NaN   \n",
      "\n",
      "       DATE_OF_ENTRY_y  \n",
      "35783              NaN  \n",
      "\n",
      "[1 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "def get_invalid_coordinate_df(df, lat_cols, lon_cols):\n",
    "    invalid_dfs = {}\n",
    "    \n",
    "    for lat_col, lon_col in zip(lat_cols, lon_cols):\n",
    "        # Filter rows where latitude or longitude is NaN or zero\n",
    "        invalid_df = df[(df[lat_col].isna() | df[lon_col].isna()) | \n",
    "                        (df[lat_col] == 0) | (df[lon_col] == 0)]\n",
    "        \n",
    "        # Store the invalid DataFrame in the dictionary\n",
    "        if not invalid_df.empty:\n",
    "            invalid_dfs[f'{lat_col}_{lon_col}'] = invalid_df\n",
    "\n",
    "    return invalid_dfs\n",
    "\n",
    "def print_invalid_coordinates(invalid_dfs, dataset_name):\n",
    "    for key, invalid_df in invalid_dfs.items():\n",
    "        print(f'{dataset_name} invalid coordinates for {key}:')\n",
    "        print(invalid_df.head())\n",
    "\n",
    "# Define the columns for each dataset\n",
    "biota_lat_cols = ['LATITUDE ddmmmm', 'LATITUDE dddddd']\n",
    "biota_lon_cols = ['LONGITUDE ddmmmm', 'LONGITUDE dddddd']\n",
    "\n",
    "seawater_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "seawater_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "sediment_lat_cols = ['LATITUDE (ddmmmm)', 'LATITUDE (dddddd)']\n",
    "sediment_lon_cols = ['LONGITUDE (ddmmmm)', 'LONGITUDE (dddddd)']\n",
    "\n",
    "# Get invalid coordinate DataFrames for each dataset\n",
    "biota_invalid_dfs = get_invalid_coordinate_df(dfs['BIOTA'], biota_lat_cols, biota_lon_cols)\n",
    "seawater_invalid_dfs = get_invalid_coordinate_df(dfs['SEAWATER'], seawater_lat_cols, seawater_lon_cols)\n",
    "sediment_invalid_dfs = get_invalid_coordinate_df(dfs['SEDIMENT'], sediment_lat_cols, sediment_lon_cols)\n",
    "\n",
    "# Print only non-empty invalid DataFrames\n",
    "print_invalid_coordinates(biota_invalid_dfs, 'BIOTA')\n",
    "print_invalid_coordinates(seawater_invalid_dfs, 'SEAWATER')\n",
    "print_invalid_coordinates(sediment_invalid_dfs, 'SEDIMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class ParseCoordinates(Callback):\n",
    "    \"\"\"\n",
    "    Get geographical coordinates from columns expressed in degrees decimal format \n",
    "    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 fn_convert_cor: Callable # Function that converts coordinates from degree-minute to decimal degree format\n",
    "                 ):\n",
    "        self.fn_convert_cor = fn_convert_cor\n",
    "\n",
    "    def __call__(self, tfm:Transformer):\n",
    "        for df in tfm.dfs.values():\n",
    "            self._format_coordinates(df)\n",
    "\n",
    "    def _format_coordinates(self, df:pd.DataFrame) -> None:\n",
    "        coord_cols = self._get_coord_columns(df.columns)\n",
    "        \n",
    "        for coord in ['lat', 'lon']:\n",
    "            decimal_col, minute_col = coord_cols[f'{coord}_d'], coord_cols[f'{coord}_m']\n",
    "            \n",
    "            condition = df[decimal_col].isna() | (df[decimal_col] == 0)\n",
    "            df[coord.upper()] = np.where(condition,\n",
    "                                 df[minute_col].apply(self._safe_convert),\n",
    "                                 df[decimal_col])\n",
    "        \n",
    "        df.dropna(subset=['LAT', 'LON'], inplace=True)\n",
    "\n",
    "    def _get_coord_columns(self, columns) -> dict:\n",
    "        return {\n",
    "            'lon_d': self._find_coord_column(columns, 'LON', 'dddddd'),\n",
    "            'lat_d': self._find_coord_column(columns, 'LAT', 'dddddd'),\n",
    "            'lon_m': self._find_coord_column(columns, 'LON', 'ddmmmm'),\n",
    "            'lat_m': self._find_coord_column(columns, 'LAT', 'ddmmmm')\n",
    "        }\n",
    "\n",
    "    def _find_coord_column(self, columns, coord_type, coord_format) -> str:\n",
    "        pattern = re.compile(f'{coord_type}.*{coord_format}', re.IGNORECASE)\n",
    "        matching_columns = [col for col in columns if pattern.search(col)]\n",
    "        return matching_columns[0] if matching_columns else None\n",
    "\n",
    "    def _safe_convert(self, value) -> str:\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "        try:\n",
    "            return self.fn_convert_cor(value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting value {value}: {e}\")\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[                    \n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055628",
   "metadata": {},
   "source": [
    "Sanitize coordinates drops a row when both longitude & latitude equal 0 or data contains unrealistic longitude & latitude values. Converts longitude & latitude `,` separator to `.` separator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14893     20318     37346\n",
      "Number of rows removed         0         0         1 \n",
      "\n",
      "             LAT        LON\n",
      "0      54.283333  12.316667\n",
      "1      54.283333  12.316667\n",
      "2      54.283333  12.316667\n",
      "3      54.283333  12.316667\n",
      "4      54.283333  12.316667\n",
      "...          ...        ...\n",
      "14888  54.583300  19.000000\n",
      "14889  54.333300  15.500000\n",
      "14890  54.333300  15.500000\n",
      "14891  54.333300  15.500000\n",
      "14892  54.363900  19.433300\n",
      "\n",
      "[14893 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n",
    "print(tfm.dfs['BIOTA'][['LAT','LON']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716bff",
   "metadata": {},
   "source": [
    "## Review all callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8a07959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n",
      "                           BIOTA  SEAWATER  SEDIMENT\n",
      "Number of rows in dfs      14893     20318     37347\n",
      "Number of rows in tfm.dfs  14873     20242     37089\n",
      "Number of rows removed        20        76       258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "print(pd.DataFrame.from_dict(tfm.compare_stats) , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bfb3a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOTA columns:\n",
      "Index(['KEY', 'NUCLIDE', 'METHOD', '< VALUE_Bq/kg', 'VALUE_Bq/kg', 'BASIS',\n",
      "       'ERROR%', 'NUMBER', 'DATE_OF_ENTRY_x', 'COUNTRY', 'LABORATORY',\n",
      "       'SEQUENCE', 'DATE', 'YEAR', 'MONTH', 'DAY', 'STATION',\n",
      "       'LATITUDE ddmmmm', 'LATITUDE dddddd', 'LONGITUDE ddmmmm',\n",
      "       'LONGITUDE dddddd', 'SDEPTH', 'RUBIN', 'BIOTATYPE', 'TISSUE', 'NO',\n",
      "       'LENGTH', 'WEIGHT', 'DW%', 'LOI%', 'MORS_SUBBASIN', 'HELCOM_SUBBASIN',\n",
      "       'DATE_OF_ENTRY_y', 'TIME', 'VALUE', 'UNCERTAINTY', 'SPECIES',\n",
      "       'BODY_PART', 'BIO_GROUP', 'UNIT', 'DL', 'LAB', 'PERCENTWT', 'DRYWT',\n",
      "       'WETWT', 'LAT', 'LON'],\n",
      "      dtype='object')\n",
      "[31  4  9 33 12 21  6  8 22 10 24 77 17  2 37 41 47 23 11 13 25 16 14 36\n",
      " 35 29 34 67 63 46 43 42 94 55 50 40 53 87 92 86 15  7 93 85 91 90 51 59\n",
      " 76 72 54 57]\n"
     ]
    }
   ],
   "source": [
    "grp = 'BIOTA'\n",
    "print(f'{grp} columns:')\n",
    "print(tfm.dfs[grp].columns)\n",
    "print(tfm.dfs[grp].NUCLIDE.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c7a2",
   "metadata": {},
   "source": [
    "For instance, lets inspect dropped rows for SEDIMENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a64ad4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEDIMENT, no of dropped rows: 258\n",
      "Viewing 5 dropped rows for SEDIMENT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>NUCLIDE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>&lt; VALUE_Bq/kg</th>\n",
       "      <th>VALUE_Bq/kg</th>\n",
       "      <th>ERROR%_kg</th>\n",
       "      <th>&lt; VALUE_Bq/m²</th>\n",
       "      <th>VALUE_Bq/m²</th>\n",
       "      <th>ERROR%_m²</th>\n",
       "      <th>DATE_OF_ENTRY_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LOWSLI</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SEDI</th>\n",
       "      <th>OXIC</th>\n",
       "      <th>DW%</th>\n",
       "      <th>LOI%</th>\n",
       "      <th>MORS_SUBBASIN</th>\n",
       "      <th>HELCOM_SUBBASIN</th>\n",
       "      <th>SUM_LINK</th>\n",
       "      <th>DATE_OF_ENTRY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>SLREB1998021</td>\n",
       "      <td>SR90</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11824</th>\n",
       "      <td>SLVDC1997023</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>SLVDC1997031</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>SLVDC1997040</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>SLVDC1998011</td>\n",
       "      <td>CS137</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>55.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                KEY NUCLIDE METHOD < VALUE_Bq/kg  VALUE_Bq/kg  ERROR%_kg  \\\n",
       "11784  SLREB1998021    SR90      2           NaN          NaN        NaN   \n",
       "11824  SLVDC1997023   CS137      1           NaN          NaN        NaN   \n",
       "11832  SLVDC1997031   CS137      1           NaN          NaN        NaN   \n",
       "11841  SLVDC1997040   CS137      1           NaN          NaN        NaN   \n",
       "11849  SLVDC1998011   CS137      1           NaN          NaN        NaN   \n",
       "\n",
       "      < VALUE_Bq/m²  VALUE_Bq/m²  ERROR%_m² DATE_OF_ENTRY_x  ...  LOWSLI  \\\n",
       "11784           NaN          NaN        NaN             NaN  ...    12.0   \n",
       "11824           NaN          NaN        NaN             NaN  ...    14.0   \n",
       "11832           NaN          NaN        NaN             NaN  ...    14.0   \n",
       "11841           NaN          NaN        NaN             NaN  ...    16.0   \n",
       "11849           NaN          NaN        NaN             NaN  ...    16.0   \n",
       "\n",
       "        AREA  SEDI OXIC  DW%  LOI%  MORS_SUBBASIN HELCOM_SUBBASIN  SUM_LINK  \\\n",
       "11784  0.021  55.0    O  NaN   NaN           14.0            14.0         a   \n",
       "11824  0.021  55.0    O  NaN   NaN            9.0             9.0         a   \n",
       "11832  0.021  55.0    O  NaN   NaN            9.0             9.0         a   \n",
       "11841  0.021  55.0    O  NaN   NaN            9.0             9.0         a   \n",
       "11849  0.021  55.0    O  NaN   NaN           14.0            14.0         a   \n",
       "\n",
       "       DATE_OF_ENTRY_y  \n",
       "11784              NaN  \n",
       "11824              NaN  \n",
       "11832              NaN  \n",
       "11841              NaN  \n",
       "11849              NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grp='SEDIMENT' # 'SEAWATER', 'BIOTA' or 'SEDIMENT'\n",
    "print(f'{grp}, no of dropped rows: {tfm.dfs_dropped[grp].shape[0]}')\n",
    "view_number=5\n",
    "print(f'Viewing {view_number} dropped rows for {grp}:')\n",
    "tfm.dfs_dropped[grp].head(view_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af7a47-0760-45bd-97f7-033bb7aa886e",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "75d1968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'.\",\n",
       " 'Remap data provider nuclide names to MARIS nuclide names.',\n",
       " 'Parse and standardize time information in the dataframe.',\n",
       " 'Encode time as seconds since epoch.',\n",
       " 'Sanitize value/measurement by removing blank entries and populating `value` column.',\n",
       " 'Convert from relative error % to standard uncertainty.',\n",
       " \"Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A.\",\n",
       " \"Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A.\",\n",
       " \"Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A.\",\n",
       " 'Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx).',\n",
       " 'Set the `unit` id column in the DataFrames based on a lookup table.',\n",
       " 'Remap value type to MARIS format.',\n",
       " 'Lookup FILT value in dataframe using the lookup table.',\n",
       " \"Remap values from 'LABORATORY' to 'LAB' for groups: BIOTA, SEDIMENT, SEAWATER.\",\n",
       " 'Remap Sediment slice top and bottom to MARIS format.',\n",
       " 'Lookup dry-wet ratio and format for MARIS.',\n",
       " '\\n    Get geographical coordinates from columns expressed in degrees decimal format \\n    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\\n    ',\n",
       " 'Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.',\n",
       " 'Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dfs = load_data(fname_in)\n",
    "\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapCB(fn_lut=lut_lab, col_remap='LAB', col_src='LABORATORY', dest_grps=['BIOTA','SEDIMENT','SEAWATER']),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            CompareDfsAndTfmCB(dfs)\n",
    "                            ])\n",
    "\n",
    "tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_attrs(\n",
    "    tfm: Transformer, # Transformer object\n",
    "    zotero_key: str, # Zotero dataset record key\n",
    "    kw: list = kw # List of keywords\n",
    "    ) -> dict: # Global attributes\n",
    "    \"Retrieve all global attributes.\"\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geospatial_lat_min': '31.17',\n",
       " 'geospatial_lat_max': '65.75',\n",
       " 'geospatial_lon_min': '9.6333',\n",
       " 'geospatial_lon_max': '53.5',\n",
       " 'geospatial_bounds': 'POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))',\n",
       " 'time_coverage_start': '1984-01-10T00:00:00',\n",
       " 'time_coverage_end': '2018-12-14T00:00:00',\n",
       " 'title': 'Environmental database - Helsinki Commission Monitoring of Radioactive Substances',\n",
       " 'summary': 'MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\\n\\nThe database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\\n\\nThe database is updated and quality assured annually by HELCOM MORS EG.',\n",
       " 'creator_name': '[{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]',\n",
       " 'keywords': 'oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)',\n",
       " 'publisher_postprocess_logs': \"Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \\n    Get geographical coordinates from columns expressed in degrees decimal format \\n    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\\n    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator., Create a dataframe of dropped data. Data included in the `dfs` not in the `tfm`.\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_attrs(tfm, zotero_key=zotero_key, kw=kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e109f56",
   "metadata": {},
   "source": [
    "### <a name=\"encoding-netcdf\"></a>Encoding NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923236b-db58-4173-93ea-c416f5343eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def encode(\n",
    "    fname_in: str, # Input file name\n",
    "    fname_out_nc: str, # Output file name\n",
    "    **kwargs # Additional arguments\n",
    "    ) -> None:\n",
    "    \"Encode data to NetCDF.\"\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[\n",
    "                            LowerStripNameCB(col_src='NUCLIDE'),\n",
    "                            RemapNuclideNameCB(lut_nuclides),\n",
    "                            ParseTimeCB(),\n",
    "                            EncodeTimeCB(),\n",
    "                            SanitizeValueCB(coi_val),       \n",
    "                            NormalizeUncCB(),\n",
    "                            RemapCB(fn_lut=lut_biota, col_remap='SPECIES', col_src='RUBIN', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_tissues, col_remap='BODY_PART', col_src='TISSUE', dest_grps='BIOTA'),\n",
    "                            RemapCB(fn_lut=lut_biogroup_from_biota, col_remap='BIO_GROUP', col_src='SPECIES', dest_grps='BIOTA'),\n",
    "                            RemapSedimentCB(fn_lut=lut_sediments, replace_lut=sed_replace_lut),\n",
    "                            RemapUnitCB(),\n",
    "                            RemapDetectionLimitCB(coi_dl, lut_dl),\n",
    "                            RemapFiltCB(lut_filtered),\n",
    "                            RemapSedSliceTopBottomCB(),\n",
    "                            LookupDryWetPercentWeightCB(),\n",
    "                            ParseCoordinates(ddmm_to_dd),\n",
    "                            SanitizeLonLatCB(),\n",
    "                            ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            dest_fname=fname_out_nc, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key=zotero_key, kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd973e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 missing time value(s) in SEDIMENT\n",
      "Unmatched SEDI: -99.0\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: bio_group\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: species\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: body_part\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: drywt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: biota, Variable: wetwt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: seawater, Variable: filt\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lon\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: lat\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: time\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: area\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: nuclide\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: value\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: unit\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: dl\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: sed_type\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: top\n",
      "--------------------------------------------------------------------------------\n",
      "Group: sediment, Variable: bottom\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "encode(fname_in, fname_out_nc, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7e258",
   "metadata": {},
   "source": [
    "## NetCDF QA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271e5e7",
   "metadata": {},
   "source": [
    "First lets review the general properties of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_size_bytes: 669457\n",
      "file_format: NETCDF4\n",
      "groups: ['biota', 'seawater', 'sediment']\n",
      "global_attributes:\n",
      "  id: TBD\n",
      "  title: Environmental database - Helsinki Commission Monitoring of Radioactive Substances\n",
      "  summary: MORS Environment database has been used to collate data resulting from monitoring of environmental radioactivity in the Baltic Sea based on HELCOM Recommendation 26/3.\n",
      "\n",
      "The database is structured according to HELCOM Guidelines on Monitoring of Radioactive Substances (https://www.helcom.fi/wp-content/uploads/2019/08/Guidelines-for-Monitoring-of-Radioactive-Substances.pdf), which specifies reporting format, database structure, data types and obligatory parameters used for reporting data under Recommendation 26/3.\n",
      "\n",
      "The database is updated and quality assured annually by HELCOM MORS EG.\n",
      "  keywords: oceanography, Earth Science > Oceans > Ocean Chemistry> Radionuclides, Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure, Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments, Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes, Earth Science > Oceans > Water Quality > Ocean Contaminants, Earth Science > Biological Classification > Animals/Vertebrates > Fish, Earth Science > Biosphere > Ecosystems > Marine Ecosystems, Earth Science > Biological Classification > Animals/Invertebrates > Mollusks, Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans, Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)\n",
      "  history: TBD\n",
      "  keywords_vocabulary: GCMD Science Keywords\n",
      "  keywords_vocabulary_url: https://gcmd.earthdata.nasa.gov/static/kms/\n",
      "  record: TBD\n",
      "  featureType: TBD\n",
      "  cdm_data_type: TBD\n",
      "  Conventions: CF-1.10 ACDD-1.3\n",
      "  publisher_name: Paul MCGINNITY, Iolanda OSVATH, Florence DESCROIX-COMANDUCCI\n",
      "  publisher_email: p.mc-ginnity@iaea.org, i.osvath@iaea.org, F.Descroix-Comanducci@iaea.org\n",
      "  publisher_url: https://maris.iaea.org\n",
      "  publisher_institution: International Atomic Energy Agency - IAEA\n",
      "  creator_name: [{\"creatorType\": \"author\", \"name\": \"HELCOM MORS\"}]\n",
      "  institution: TBD\n",
      "  metadata_link: TBD\n",
      "  creator_email: TBD\n",
      "  creator_url: TBD\n",
      "  references: TBD\n",
      "  license: Without prejudice to the applicable Terms and Conditions (https://nucleus.iaea.org/Pages/Others/Disclaimer.aspx), I hereby agree that any use of the data will contain appropriate acknowledgement of the data source(s) and the IAEA Marine Radioactivity Information System (MARIS).\n",
      "  comment: TBD\n",
      "  geospatial_lat_min: 31.17\n",
      "  geospatial_lon_min: 9.6333\n",
      "  geospatial_lat_max: 65.75\n",
      "  geospatial_lon_max: 53.5\n",
      "  geospatial_vertical_min: TBD\n",
      "  geospatial_vertical_max: TBD\n",
      "  geospatial_bounds: POLYGON ((9.6333 53.5, 31.17 53.5, 31.17 65.75, 9.6333 65.75, 9.6333 53.5))\n",
      "  geospatial_bounds_crs: EPSG:4326\n",
      "  time_coverage_start: 1984-01-10T00:00:00\n",
      "  time_coverage_end: 2018-12-14T00:00:00\n",
      "  local_time_zone: TBD\n",
      "  date_created: TBD\n",
      "  date_modified: TBD\n",
      "  publisher_postprocess_logs: Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \n",
      "    Get geographical coordinates from columns expressed in degrees decimal format \n",
      "    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\n",
      "    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties=get_netcdf_properties(fname_out_nc)\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c821d",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Update TBD values. \n",
    "The publisher_postprocess_logs may include ',' in the string. Can we review how the publisher_postprocess_logs are encoded? Would a dictionary be better?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b8243",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "**FEEDBACK FOR NEXT VERSION**: \n",
    "Enums (LUTS) should be encoded in the NetCDF file. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cc5bc",
   "metadata": {},
   "source": [
    "Review the publisher_postprocess_logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert values from 'NUCLIDE' to lowercase, strip spaces, and store in 'None'., Remap data provider nuclide names to MARIS nuclide names., Parse and standardize time information in the dataframe., Encode time as seconds since epoch., Sanitize value/measurement by removing blank entries and populating `value` column., Convert from relative error % to standard uncertainty., Remap values from 'RUBIN' to 'SPECIES' for groups: B, I, O, T, A., Remap values from 'TISSUE' to 'BODY_PART' for groups: B, I, O, T, A., Remap values from 'SPECIES' to 'BIO_GROUP' for groups: B, I, O, T, A., Update sediment id based on MARIS species LUT (dbo_sedtype.xlsx)., Set the `unit` id column in the DataFrames based on a lookup table., Remap value type to MARIS format., Lookup FILT value in dataframe using the lookup table., Remap Sediment slice top and bottom to MARIS format., Lookup dry-wet ratio and format for MARIS., \n",
      "    Get geographical coordinates from columns expressed in degrees decimal format \n",
      "    or from columns in degrees/minutes decimal format where degrees decimal format is missing or zero.\n",
      "    , Drop rows with invalid longitude & latitude values. Convert `,` separator to `.` separator.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(properties['global_attributes']['publisher_postprocess_logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b00241",
   "metadata": {},
   "source": [
    "Now lets review the properties of the groups in the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biota:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'bio_group', 'species', 'body_part', 'drywt', 'wetwt']\n",
      "  dimensions: {'id': 14873}\n",
      "  attributes: {}\n",
      "seawater:\n",
      "  variables: ['lon', 'lat', 'time', 'nuclide', 'value', 'unit', 'dl', 'filt']\n",
      "  dimensions: {'id': 20242}\n",
      "  attributes: {}\n",
      "sediment:\n",
      "  variables: ['lon', 'lat', 'time', 'area', 'nuclide', 'value', 'unit', 'dl', 'sed_type', 'top', 'bottom']\n",
      "  dimensions: {'id': 37089}\n",
      "  attributes: {}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "properties = get_netcdf_group_properties(fname_out_nc)\n",
    "\n",
    "for key, val in properties.items():\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(f\"  {sub_key}: {sub_val}\")\n",
    "    else:\n",
    "        print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09981ba",
   "metadata": {},
   "source": [
    "Lets review all variable attributes for the groups of the NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff21c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>biota</td>\n",
       "      <td>...</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "      <td>sediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>lon</td>\n",
       "      <td>lat</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>bio_group</td>\n",
       "      <td>species</td>\n",
       "      <td>body_part</td>\n",
       "      <td>...</td>\n",
       "      <td>lat</td>\n",
       "      <td>time</td>\n",
       "      <td>area</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>value</td>\n",
       "      <td>unit</td>\n",
       "      <td>dl</td>\n",
       "      <td>sed_type</td>\n",
       "      <td>top</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_id</th>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>...</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "      <td>('id',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions_size</th>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>(14873,)</td>\n",
       "      <td>...</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "      <td>(37089,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;u8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;i8</td>\n",
       "      <td>&lt;f4</td>\n",
       "      <td>&lt;f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_long_name</th>\n",
       "      <td>Measurement longitude</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Biota group</td>\n",
       "      <td>Species</td>\n",
       "      <td>Body part</td>\n",
       "      <td>...</td>\n",
       "      <td>Measurement latitude</td>\n",
       "      <td>Time of measurement</td>\n",
       "      <td>Marine area/region id</td>\n",
       "      <td>Nuclide</td>\n",
       "      <td>Activity</td>\n",
       "      <td>Unit</td>\n",
       "      <td>Detection limit</td>\n",
       "      <td>Sediment type</td>\n",
       "      <td>Top depth of sediment layer</td>\n",
       "      <td>Bottom depth of sediment layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_standard_name</th>\n",
       "      <td>longitude</td>\n",
       "      <td>latitude</td>\n",
       "      <td>time</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>biota_group_tbd</td>\n",
       "      <td>species</td>\n",
       "      <td>body_part_tbd</td>\n",
       "      <td>...</td>\n",
       "      <td>latitude</td>\n",
       "      <td>time</td>\n",
       "      <td>area_id</td>\n",
       "      <td>nuclide</td>\n",
       "      <td>activity</td>\n",
       "      <td>unit</td>\n",
       "      <td>detection_limit</td>\n",
       "      <td>sediment_type_tbd</td>\n",
       "      <td>top_depth_of_sediment_layer_tbd</td>\n",
       "      <td>bottom_depth_of_sediment_layer_tbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_units</th>\n",
       "      <td>degrees_east</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>seconds since 1970-01-01 00:00:00.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_origin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_time_zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_abbreviation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_axis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_calendar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gregorian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0                     1   \\\n",
       "group                               biota                 biota   \n",
       "variable                              lon                   lat   \n",
       "dimensions_id                     ('id',)               ('id',)   \n",
       "dimensions_size                  (14873,)              (14873,)   \n",
       "data_type                             <f4                   <f4   \n",
       "attr_long_name      Measurement longitude  Measurement latitude   \n",
       "attr_standard_name              longitude              latitude   \n",
       "attr_units                   degrees_east         degrees_north   \n",
       "attr_time_origin                      NaN                   NaN   \n",
       "attr_time_zone                        NaN                   NaN   \n",
       "attr_abbreviation                     NaN                   NaN   \n",
       "attr_axis                             NaN                   NaN   \n",
       "attr_calendar                         NaN                   NaN   \n",
       "\n",
       "                                                     2         3         4   \\\n",
       "group                                             biota     biota     biota   \n",
       "variable                                           time   nuclide     value   \n",
       "dimensions_id                                   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                                (14873,)  (14873,)  (14873,)   \n",
       "data_type                                           <u8       <i8       <f4   \n",
       "attr_long_name                      Time of measurement   Nuclide  Activity   \n",
       "attr_standard_name                                 time   nuclide  activity   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0       NaN       NaN   \n",
       "attr_time_origin                    1970-01-01 00:00:00       NaN       NaN   \n",
       "attr_time_zone                                      UTC       NaN       NaN   \n",
       "attr_abbreviation                             Date/Time       NaN       NaN   \n",
       "attr_axis                                             T       NaN       NaN   \n",
       "attr_calendar                                 gregorian       NaN       NaN   \n",
       "\n",
       "                          5                6                7         8   \\\n",
       "group                  biota            biota            biota     biota   \n",
       "variable                unit               dl        bio_group   species   \n",
       "dimensions_id        ('id',)          ('id',)          ('id',)   ('id',)   \n",
       "dimensions_size     (14873,)         (14873,)         (14873,)  (14873,)   \n",
       "data_type                <i8              <i8              <i8       <i8   \n",
       "attr_long_name          Unit  Detection limit      Biota group   Species   \n",
       "attr_standard_name      unit  detection_limit  biota_group_tbd   species   \n",
       "attr_units               NaN              NaN              NaN       NaN   \n",
       "attr_time_origin         NaN              NaN              NaN       NaN   \n",
       "attr_time_zone           NaN              NaN              NaN       NaN   \n",
       "attr_abbreviation        NaN              NaN              NaN       NaN   \n",
       "attr_axis                NaN              NaN              NaN       NaN   \n",
       "attr_calendar            NaN              NaN              NaN       NaN   \n",
       "\n",
       "                               9   ...                    21  \\\n",
       "group                       biota  ...              sediment   \n",
       "variable                body_part  ...                   lat   \n",
       "dimensions_id             ('id',)  ...               ('id',)   \n",
       "dimensions_size          (14873,)  ...              (37089,)   \n",
       "data_type                     <i8  ...                   <f4   \n",
       "attr_long_name          Body part  ...  Measurement latitude   \n",
       "attr_standard_name  body_part_tbd  ...              latitude   \n",
       "attr_units                    NaN  ...         degrees_north   \n",
       "attr_time_origin              NaN  ...                   NaN   \n",
       "attr_time_zone                NaN  ...                   NaN   \n",
       "attr_abbreviation             NaN  ...                   NaN   \n",
       "attr_axis                     NaN  ...                   NaN   \n",
       "attr_calendar                 NaN  ...                   NaN   \n",
       "\n",
       "                                                     22  \\\n",
       "group                                          sediment   \n",
       "variable                                           time   \n",
       "dimensions_id                                   ('id',)   \n",
       "dimensions_size                                (37089,)   \n",
       "data_type                                           <u8   \n",
       "attr_long_name                      Time of measurement   \n",
       "attr_standard_name                                 time   \n",
       "attr_units          seconds since 1970-01-01 00:00:00.0   \n",
       "attr_time_origin                    1970-01-01 00:00:00   \n",
       "attr_time_zone                                      UTC   \n",
       "attr_abbreviation                             Date/Time   \n",
       "attr_axis                                             T   \n",
       "attr_calendar                                 gregorian   \n",
       "\n",
       "                                       23        24        25        26  \\\n",
       "group                            sediment  sediment  sediment  sediment   \n",
       "variable                             area   nuclide     value      unit   \n",
       "dimensions_id                     ('id',)   ('id',)   ('id',)   ('id',)   \n",
       "dimensions_size                  (37089,)  (37089,)  (37089,)  (37089,)   \n",
       "data_type                             <i8       <i8       <f4       <i8   \n",
       "attr_long_name      Marine area/region id   Nuclide  Activity      Unit   \n",
       "attr_standard_name                area_id   nuclide  activity      unit   \n",
       "attr_units                            NaN       NaN       NaN       NaN   \n",
       "attr_time_origin                      NaN       NaN       NaN       NaN   \n",
       "attr_time_zone                        NaN       NaN       NaN       NaN   \n",
       "attr_abbreviation                     NaN       NaN       NaN       NaN   \n",
       "attr_axis                             NaN       NaN       NaN       NaN   \n",
       "attr_calendar                         NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                 27                 28  \\\n",
       "group                      sediment           sediment   \n",
       "variable                         dl           sed_type   \n",
       "dimensions_id               ('id',)            ('id',)   \n",
       "dimensions_size            (37089,)           (37089,)   \n",
       "data_type                       <i8                <i8   \n",
       "attr_long_name      Detection limit      Sediment type   \n",
       "attr_standard_name  detection_limit  sediment_type_tbd   \n",
       "attr_units                      NaN                NaN   \n",
       "attr_time_origin                NaN                NaN   \n",
       "attr_time_zone                  NaN                NaN   \n",
       "attr_abbreviation               NaN                NaN   \n",
       "attr_axis                       NaN                NaN   \n",
       "attr_calendar                   NaN                NaN   \n",
       "\n",
       "                                                 29  \\\n",
       "group                                      sediment   \n",
       "variable                                        top   \n",
       "dimensions_id                               ('id',)   \n",
       "dimensions_size                            (37089,)   \n",
       "data_type                                       <f4   \n",
       "attr_long_name          Top depth of sediment layer   \n",
       "attr_standard_name  top_depth_of_sediment_layer_tbd   \n",
       "attr_units                                      NaN   \n",
       "attr_time_origin                                NaN   \n",
       "attr_time_zone                                  NaN   \n",
       "attr_abbreviation                               NaN   \n",
       "attr_axis                                       NaN   \n",
       "attr_calendar                                   NaN   \n",
       "\n",
       "                                                    30  \n",
       "group                                         sediment  \n",
       "variable                                        bottom  \n",
       "dimensions_id                                  ('id',)  \n",
       "dimensions_size                               (37089,)  \n",
       "data_type                                          <f4  \n",
       "attr_long_name          Bottom depth of sediment layer  \n",
       "attr_standard_name  bottom_depth_of_sediment_layer_tbd  \n",
       "attr_units                                         NaN  \n",
       "attr_time_origin                                   NaN  \n",
       "attr_time_zone                                     NaN  \n",
       "attr_abbreviation                                  NaN  \n",
       "attr_axis                                          NaN  \n",
       "attr_calendar                                      NaN  \n",
       "\n",
       "[13 rows x 31 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df_var_prop=get_netcdf_variable_properties(fname_out_nc, as_df=True).T\n",
    "df_var_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c543039",
   "metadata": {},
   "source": [
    "Lets convert the NetCDF file to a dictionary of DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df252c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dfs=nc_to_dfs(fname_out_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750b936",
   "metadata": {},
   "source": [
    "Lets review the biota data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>bio_group</th>\n",
       "      <th>species</th>\n",
       "      <th>body_part</th>\n",
       "      <th>drywt</th>\n",
       "      <th>wetwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>4</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>33</td>\n",
       "      <td>4.338000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>174.934433</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.316667</td>\n",
       "      <td>54.283333</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>52</td>\n",
       "      <td>177.935120</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>54.583302</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>53</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>3</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>4</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>33</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14871</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>54.333302</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>53</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>52</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14872</th>\n",
       "      <td>19.433300</td>\n",
       "      <td>54.363899</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>33</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14873 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide       value  unit  dl  \\\n",
       "0      12.316667  54.283333 2012-09-23       31    0.010140     5   2   \n",
       "1      12.316667  54.283333 2012-09-23        4  135.300003     5   1   \n",
       "2      12.316667  54.283333 2012-09-23        9    0.013980     5   2   \n",
       "3      12.316667  54.283333 2012-09-23       33    4.338000     5   1   \n",
       "4      12.316667  54.283333 2012-09-23       31    0.009614     5   2   \n",
       "...          ...        ...        ...      ...         ...   ...  ..   \n",
       "14868  19.000000  54.583302 2018-02-26       53    0.043000     5   1   \n",
       "14869  15.500000  54.333302 2018-02-13        4   98.000000     5   1   \n",
       "14870  15.500000  54.333302 2018-02-13       33    3.690000     5   1   \n",
       "14871  15.500000  54.333302 2018-02-13       53    0.049000     5   1   \n",
       "14872  19.433300  54.363899 2018-10-03       33    0.830000     5   1   \n",
       "\n",
       "       bio_group  species  body_part       drywt  wetwt  \n",
       "0              4       99         52  174.934433  948.0  \n",
       "1              4       99         52  174.934433  948.0  \n",
       "2              4       99         52  174.934433  948.0  \n",
       "3              4       99         52  174.934433  948.0  \n",
       "4              4       99         52  177.935120  964.0  \n",
       "...          ...      ...        ...         ...    ...  \n",
       "14868          4      191          3  120.000000  500.0  \n",
       "14869          4      191         52  112.500000  500.0  \n",
       "14870          4      191         52  112.500000  500.0  \n",
       "14871          4      191         52  112.500000  500.0  \n",
       "14872          4      247         52         NaN  120.0  \n",
       "\n",
       "[14873 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_biota=dfs['BIOTA']\n",
    "nc_dfs_biota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef71cc",
   "metadata": {},
   "source": [
    "Lets review the sediment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e068f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>area</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>sed_type</th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0000</td>\n",
       "      <td>59.666698</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>38.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.8433</td>\n",
       "      <td>59.860001</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37084</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37085</th>\n",
       "      <td>21.0830</td>\n",
       "      <td>59.035999</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37086</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>512.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37087</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>527.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37088</th>\n",
       "      <td>19.7297</td>\n",
       "      <td>61.066700</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>684.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37089 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lon        lat       time  area  nuclide   value  unit  dl  \\\n",
       "0      24.0000  59.666698 2012-06-17     0       53   35.00     4   1   \n",
       "1      24.0000  59.666698 2012-06-17     0       53   36.00     4   1   \n",
       "2      28.8433  59.860001 2012-08-10     0       53   38.00     4   1   \n",
       "3      28.8433  59.860001 2012-08-10     0       53   36.00     4   1   \n",
       "4      28.8433  59.860001 2012-08-10     0       53   30.00     4   1   \n",
       "...        ...        ...        ...   ...      ...     ...   ...  ..   \n",
       "37084  21.0830  59.035999 2016-06-09     0       33    1.20     4   1   \n",
       "37085  21.0830  59.035999 2016-06-09     0       33    0.79     4   1   \n",
       "37086  19.7297  61.066700 2016-05-29     0       33  512.00     4   1   \n",
       "37087  19.7297  61.066700 2016-05-29     0       33  527.00     4   1   \n",
       "37088  19.7297  61.066700 2016-05-29     0       33  684.00     4   1   \n",
       "\n",
       "       sed_type   top  bottom  \n",
       "0             0  15.0    20.0  \n",
       "1             0  20.0    27.0  \n",
       "2             0   0.0     2.0  \n",
       "3             0   2.0     4.0  \n",
       "4             0   4.0     6.0  \n",
       "...         ...   ...     ...  \n",
       "37084        50  18.0    20.0  \n",
       "37085        50  20.0    22.0  \n",
       "37086        59   0.0     2.0  \n",
       "37087        51   2.0     4.0  \n",
       "37088        50   4.0     6.0  \n",
       "\n",
       "[37089 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_sediment=dfs['SEDIMENT']\n",
    "nc_dfs_sediment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d6fc",
   "metadata": {},
   "source": [
    "Lets review the seawater data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>nuclide</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>dl</th>\n",
       "      <th>filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.333300</td>\n",
       "      <td>60.083302</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>33</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.150000</td>\n",
       "      <td>59.433300</td>\n",
       "      <td>2012-06-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.983299</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>33</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20237</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>54.006802</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>12</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20238</th>\n",
       "      <td>14.667200</td>\n",
       "      <td>54.499500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20239</th>\n",
       "      <td>14.334200</td>\n",
       "      <td>54.750500</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>12</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>13.500200</td>\n",
       "      <td>54.916500</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20242 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       time  nuclide      value  unit  dl  filt\n",
       "0      29.333300  60.083302 2012-05-23       33   5.300000     1   1     0\n",
       "1      29.333300  60.083302 2012-05-23       33  19.900000     1   1     0\n",
       "2      23.150000  59.433300 2012-06-17       33  25.500000     1   1     0\n",
       "3      27.983299  60.250000 2012-05-24       33  17.000000     1   1     0\n",
       "4      27.983299  60.250000 2012-05-24       33  22.200001     1   1     0\n",
       "...          ...        ...        ...      ...        ...   ...  ..   ...\n",
       "20237  14.200000  54.006802 2015-06-22       12   6.600000     1   1     1\n",
       "20238  14.667200  54.499500 2015-06-23       12   6.900000     1   1     1\n",
       "20239  14.334200  54.750500 2015-06-23       12   6.800000     1   1     1\n",
       "20240  13.500200  54.916500 2015-06-24       12   7.300000     1   1     1\n",
       "20241  13.500200  54.916500 2015-06-24       12   5.500000     1   1     1\n",
       "\n",
       "[20242 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "nc_dfs_seawater=dfs['SEAWATER']\n",
    "nc_dfs_seawater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05beed7f",
   "metadata": {},
   "source": [
    "## Open Refine Decoder (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d380cb",
   "metadata": {},
   "source": [
    "Currently, the processing of MARIS data to the master dataset is done in OpenRefine. A standardised CSV is processed in OpenRefine and exported to the MARIS database. \n",
    "\n",
    "A decoder is needed to convert the NetCDF file format to the standardised CSV format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2c6f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

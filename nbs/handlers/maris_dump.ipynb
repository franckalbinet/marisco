{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.maris_dump"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "# MARIS dump\n",
    "> Data pipeline (handler) to convert global MARIS db dump into `NetCDF` format. It allows to encode as NetCDF all legacy datasets in one batch.\n",
    "\n",
    "The input data is a dump from already imported MARIS datasets.\n",
    "\n",
    "**Dev. board**: https://trello.com/b/IszgV1bj/marisco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a15f43-5d42-4a31-8e8a-0f988b82f08e",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "* filtering status? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import fastcore.all as fc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from marisco.callbacks import (Callback, Transformer, SanitizeLonLatCB, EncodeTimeCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB,\n",
    "                              DepthRangeCB, TimeRangeCB,\n",
    "                              ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import lut_path, cdl_cfg, cfg, nc_tpl_path, Enums\n",
    "from marisco.serializers import NetCDFEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ade1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02bf0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = Path().home() / 'pro/data/maris/MARIS_exportSample_20240313.txt'\n",
    "dir_dest = '../../_data/output/dump'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ab222",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_dump(fname): \n",
    "    return pd.read_csv(fname, sep='\\t', encoding='ISO-8859-1')   \n",
    "\n",
    "def load_data(df:pd.DataFrame, # MARIS global dump \n",
    "                 ref_id:int, # Reference id of interest\n",
    "                 ):\n",
    "    \"Load specific MARIS dataset through its ref_id\"\n",
    "    lut = {\n",
    "        'Sediment': 'sediment',\n",
    "        'Seawater': 'seawater',\n",
    "        'Suspended matter': 'suspended-matter',\n",
    "        'Biota': 'biota'}\n",
    "    dfs = {}\n",
    "    for name, grp in df[df.ref_id  == ref_id].groupby('samptype'): \n",
    "        dfs[lut[name]] = grp\n",
    "    return dfs\n",
    "\n",
    "def get_zotero_key(dfs):\n",
    "    return dfs[next(iter(dfs))][['zoterourl']].iloc[0].values[0].split('/')[-1]\n",
    "\n",
    "def get_fname(dfs):\n",
    "    id, name = dfs[next(iter(dfs))][['ref_id', 'displaytext']].iloc[0]\n",
    "    name = name.replace(',', '').replace('.', '').replace('-', ' ').split(' ')\n",
    "    return '-'.join(([str(id)] + name)) + '.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48f8fb",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "df = load_dump(fname_in)\n",
    "\n",
    "print('# of unique refs: ', len(df.ref_id.unique()))\n",
    "print('columns: ', df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# 52, 191 (OSPAR), 100 (HELCOM), 717 (only seawater)\n",
    "ref_id = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a71c0",
   "metadata": {},
   "source": [
    "## Data transformation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e58b33",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_varnames_lut():\n",
    "    fname = lut_path() / 'dbo_nuclide.xlsx'\n",
    "    df_nuclide = pd.read_excel(fname, usecols=['nuclide_id', 'nc_name'])\n",
    "    return df_nuclide.set_index('nuclide_id').to_dict()['nc_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapRdnNameCB(Callback):\n",
    "    \"Remap to MARIS radionuclide names.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_varnames_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['nuclide_id'] = tfm.dfs[k]['nuclide_id'].replace(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a45542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[RemapRdnNameCB()])\n",
    "\n",
    "print(tfm()['sediment']['nuclide_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb47cf",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef59c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['sediment'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525775d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# To be added: endperiod, lab\n",
    "def renaming_rules():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    # Define column names renaming rules\n",
    "    return {\n",
    "        'latitude': vars['defaults']['lat']['name'],\n",
    "        'longitude': vars['defaults']['lon']['name'],\n",
    "        'begperiod': vars['defaults']['time']['name'],\n",
    "        'sampdepth': vars['defaults']['smp_depth']['name'],\n",
    "        'totdepth': vars['defaults']['tot_depth']['name'],\n",
    "        'uncertaint': vars['suffixes']['uncertainty']['name'],\n",
    "        'unit_id': vars['suffixes']['unit']['name'],\n",
    "        'detection': vars['suffixes']['detection_limit']['name'],\n",
    "        'area_id': vars['defaults']['area']['name'], \n",
    "        'species_id': vars['bio']['species']['name'],\n",
    "        'biogroup_id': vars['bio']['bio_group']['name'],\n",
    "        'bodypar_id': vars['bio']['body_part']['name'],\n",
    "        'sedtype_id': vars['sed']['sed_type']['name'],\n",
    "        'volume': vars['suffixes']['volume']['name'],\n",
    "        'salinity': vars['suffixes']['salinity']['name'],\n",
    "        'temperatur': vars['suffixes']['temperature']['name'],\n",
    "        'sampmet_id': vars['suffixes']['sampling_method']['name'],\n",
    "        'prepmet_id': vars['suffixes']['preparation_method']['name'],\n",
    "        'counmet_id': vars['suffixes']['counting_method']['name'],\n",
    "        'activity': 'value',\n",
    "        'nuclide_id': 'nuclide'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RenameColumnCB(Callback):\n",
    "    \"Renaming variables to MARIS standard names.\"\n",
    "    def __init__(self, renaming_rules=renaming_rules): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = renaming_rules()\n",
    "        coi = lut.keys()\n",
    "        for k in tfm.dfs.keys():\n",
    "            # Select cols of interest\n",
    "            tfm.dfs[k] = tfm.dfs[k].loc[:, coi]\n",
    "            # Rename cols\n",
    "            tfm.dfs[k].rename(columns=lut, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB()\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2fbc4",
   "metadata": {},
   "source": [
    "### Drop NaN only columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819703e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DropNAColumnsCB(Callback):\n",
    "    \"Drop variable containing only NaN or 'Not available' (id=0 in MARIS lookup tables).\"\n",
    "    def __init__(self, na_value=0):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def isMarisNA(self, col): \n",
    "        return len(col.unique()) == 1 and col.iloc[0] == self.na_value\n",
    "    \n",
    "    def dropMarisNA(self, df):\n",
    "        na_cols = [col for col in df.columns if self.isMarisNA(df[col])]\n",
    "        return df.drop(labels=na_cols, axis=1)\n",
    "        \n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k] = tfm.dfs[k].dropna(axis=1, how='all')\n",
    "            tfm.dfs[k] = self.dropMarisNA(tfm.dfs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB()\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a51628",
   "metadata": {},
   "source": [
    "### Sanitize detection limit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dl_lut():\n",
    "    fname = lut_path() / 'dbo_detectlimit.xlsx'\n",
    "    df_nuclide = pd.read_excel(fname, usecols=['name', 'id'])\n",
    "    return df_nuclide.set_index('name').to_dict()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_dl_lut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SanitizeDetectionLimitCB(Callback):\n",
    "    \"Assign Detection Limit name to its id based on MARIS nomenclature.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_dl_lut):\n",
    "        fc.store_attr()\n",
    "        self.var_name = cdl_cfg()['vars']['suffixes']['detection_limit']['name']\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k][self.var_name] = tfm.dfs[k][self.var_name].replace(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71200b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB()\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment']['_dl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07b9e9",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434da9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParseTimeCB(Callback):\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['time'] = pd.to_datetime(tfm.dfs[k].time, format='ISO8601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB(),\n",
    "    ParseTimeCB()\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375be6e5",
   "metadata": {},
   "source": [
    "### Reshape: long to wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns='nuclide', values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        \n",
    "        df.reset_index(names='sample', inplace=True)\n",
    "        \n",
    "        idx = list(set(df.columns) - set([self.columns] + derived_coi + self.values))\n",
    "        return df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k] = self.pivot(tfm.dfs[k])\n",
    "            tfm.dfs[k].columns = self.renamed_cols(tfm.dfs[k].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10de0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# How do that work?\n",
    "#    In our case, unique idx is a composite index (lon, lat, time, depth)\n",
    "#    We want to transform:\n",
    "# idx , nuc, val\n",
    "# 1   , a  , 1\n",
    "# 1   , b  , 2\n",
    "# 2   , c  , 3\n",
    "\n",
    "# to: \n",
    "# idx, a,  b,   c\n",
    "# 1  , 1,  2,   nan\n",
    "# 2  ,nan, nan, 3 \n",
    "df_test = pd.DataFrame({\n",
    "    'idx': [1, 1, 2],\n",
    "    'nuclide': ['a', 'b', 'c'],\n",
    "    'value': [1, 2, 3]\n",
    "    })\n",
    "\n",
    "df_test.pivot_table(index='idx',\n",
    "                    columns='nuclide',\n",
    "                    values='value',\n",
    "                    fill_value=np.nan,\n",
    "                    # aggfunc=lambda x: x\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB(),\n",
    "    ParseTimeCB(),\n",
    "    ReshapeLongToWide()\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587a731",
   "metadata": {},
   "source": [
    "### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB(),\n",
    "    ParseTimeCB(),\n",
    "    ReshapeLongToWide(),\n",
    "    EncodeTimeCB(cfg())\n",
    "    ])\n",
    "\n",
    "print(tfm()['sediment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91144a",
   "metadata": {},
   "source": [
    "### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80141e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB(),\n",
    "    ParseTimeCB(),\n",
    "    ReshapeLongToWide(),\n",
    "    EncodeTimeCB(cfg()),\n",
    "    SanitizeLonLatCB()\n",
    "    ])\n",
    "\n",
    "# print(tfm()['sediment'])\n",
    "df_debug = tfm()['sediment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b6999",
   "metadata": {},
   "source": [
    "## Encode to NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(df, ref_id)\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "    RemapRdnNameCB(),\n",
    "    RenameColumnCB(),\n",
    "    DropNAColumnsCB(),\n",
    "    SanitizeDetectionLimitCB(),\n",
    "    ParseTimeCB(),\n",
    "    ReshapeLongToWide(),\n",
    "    EncodeTimeCB(cfg()),\n",
    "    SanitizeLonLatCB()\n",
    "    ])\n",
    "\n",
    "dfs_tfm = tfm()\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5357b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key='3W354SQG', kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce312588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63419143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out, nc_tpl_path, **kwargs):\n",
    "    df = load_dump(fname_in)\n",
    "    ref_ids = kwargs.get('ref_ids', df.ref_id.unique())\n",
    "    print('Encoding ...')\n",
    "    for ref_id in tqdm(ref_ids, leave=False):\n",
    "        dfs = load_data(df, ref_id)\n",
    "        print(get_fname(dfs))\n",
    "        tfm = Transformer(dfs, cbs=[\n",
    "            RemapRdnNameCB(),\n",
    "            RenameColumnCB(),\n",
    "            DropNAColumnsCB(),\n",
    "            SanitizeDetectionLimitCB(),\n",
    "            ParseTimeCB(),\n",
    "            ReshapeLongToWide(),\n",
    "            EncodeTimeCB(cfg()),\n",
    "            SanitizeLonLatCB(verbose=True)\n",
    "            ])\n",
    "       \n",
    "        tfm()\n",
    "        encoder = NetCDFEncoder(tfm.dfs, \n",
    "                                src_fname=nc_tpl_path,\n",
    "                                dest_fname=Path(fname_out) / get_fname(dfs), \n",
    "                                global_attrs=get_attrs(tfm, zotero_key=get_zotero_key(dfs), kw=kw),\n",
    "                                verbose=kwargs.get('verbose', False),\n",
    "                                enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                                )\n",
    "        encoder.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb5bfd",
   "metadata": {},
   "source": [
    "### Single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11578c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm = Transformer(dfs, cbs=[\n",
    "            RemapRdnNameCB(),\n",
    "            RenameColumnCB(),\n",
    "            DropNAColumnsCB(),\n",
    "            SanitizeDetectionLimitCB(),\n",
    "            ParseTimeCB(),\n",
    "            ReshapeLongToWide(),\n",
    "            EncodeTimeCB(cfg()),\n",
    "            SanitizeLonLatCB(verbose=True)\n",
    "            ])\n",
    "\n",
    "dfs_test = tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "ref_id = 100\n",
    "encode(fname_in, dir_dest, nc_tpl_path(), verbose=False, ref_ids=[ref_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da7ded",
   "metadata": {},
   "source": [
    "### All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, dir_dest, nc_tpl_path(), verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

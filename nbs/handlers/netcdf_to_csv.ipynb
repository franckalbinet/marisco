{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp netcdf_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF to Open Refine CSV (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path # This module offers classes representing filesystem paths\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from marisco.callbacks import (Callback, Transformer,\n",
    "                               EncodeTimeCB, SanitizeLonLatCB)\n",
    "import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.\n",
    "from cftime import num2pydate \n",
    "from marisco.configs import cfg, cdl_cfg, nuc_lut_path, unit_lut_path, detection_limit_lut_path, species_lut_path, bodyparts_lut_path, sediments_lut_path\n",
    "from marisco.serializers import OpenRefineCsvEncoder\n",
    "from functools import reduce,partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the current working directory (cwd). . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/output/100-HELCOM-MORS-2024.nc'\n",
    "fname_out = '../../_data/output/helcom_from_netcdf.csv'\n",
    "ref_id = 100 # OSPAR ref_id 191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NetCDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def netcdf4_to_df(fname_in):  \n",
    "    # Read nc file\n",
    "    with Dataset(fname_in, \"r\", format='NETCDF4' ) as nc:\n",
    "        # Read groups ('seawater', 'biota', 'sediment')\n",
    "        groups= nc.groups.keys()\n",
    "        # Read fill values \n",
    "        fill_value={}\n",
    "        for group in groups:\n",
    "            fill_value[group] = nc.groups[group].variables['sample'][:].fill_value\n",
    "    \n",
    "    # Create dictionary of dataframes\n",
    "    dfs={}\n",
    "    for group in groups:\n",
    "        # Read dataset\n",
    "        ds = xr.open_dataset(fname_in, group=group,  decode_times=False)\n",
    "        # Create Pandas dataframe \n",
    "        dfs[group]=ds.to_dataframe()\n",
    "        # If the index is not 'sample' then set the index to be 'sample'\n",
    "        if dfs[group].index.name != 'sample':\n",
    "            dfs[group].set_index(\"sample\", inplace=True)\n",
    "        # Drop the rows where 'sample' uses the fill_value.\n",
    "        dfs[group]=dfs[group].drop(fill_value[group], axis=0, errors='ignore') \n",
    "    return(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['seawater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['biota']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape: wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReshapeWideToLong(Callback):\n",
    "    \"Convert data from wide to long with renamed columns.\"\n",
    "    def __init__(self, columns='nuclide', values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible suffixes vars (e.g '_unc', '_dl', ...) from configs\n",
    "        suff_cfg = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "        # Retrieve all possible nuclides\n",
    "        nucs_cfg = pd.read_excel(nuc_lut_path())['nc_name'].to_list()\n",
    "        nucs_cfg = [x for x in nucs_cfg if str(x) != 'nan'] # remove 'nan' from nuclide list\n",
    "        # Retrieve all possible vars thats are not in vars suffixes\n",
    "        self.vars_cfg=[x['name'] for var_key in cdl_cfg()['vars'].keys() for x in cdl_cfg()['vars'][var_key].values() if var_key != 'suffixes']\n",
    "        # combine all possible nuclides with its suffixes.    \n",
    "        value_name='value'\n",
    "        derived_nucs_cols={value_name:nucs_cfg}     \n",
    "        for suf in suff_cfg:\n",
    "            derived_nucs_cols[suf]= [str(nuc)+str(suf) for nuc in nucs_cfg]\n",
    "        self.derived_nucs_cols=derived_nucs_cols\n",
    "           \n",
    "    def melt(self, df):\n",
    "        # Among all possible 'self.derived_nuc_cols' include the ones present in df.\n",
    "        derived_nucs_cols={}\n",
    "        for key,derived_nuc_cols in self.derived_nucs_cols.items():\n",
    "            derived_nuc_cols = [col for col in derived_nuc_cols if col in df.columns]\n",
    "            if derived_nuc_cols:\n",
    "                derived_nucs_cols[key] = derived_nuc_cols\n",
    "        \n",
    "        # Among all possible 'self.vars_cfg' include the ones present in df.\n",
    "        vars_cfg = [var for var in self.vars_cfg if var in df.columns]\n",
    "        \n",
    "        # Melt cols included in self.derived_nucs_cols        \n",
    "        df=df.reset_index()  # Reset the index so 'sample' can be used with id_vars\n",
    "        nuc_dfs={}\n",
    "\n",
    "        for key,val in derived_nucs_cols.items():\n",
    "            # Transpose nuclide_cols\n",
    "            df_t=pd.melt(frame=df, id_vars=vars_cfg+['sample'], value_vars=val, var_name='nuclide', value_name=key)\n",
    "            # Remove the key from thr nuclide columns (e.g '_unit', '_dl', etc.).\n",
    "            df_t['nuclide']=df_t['nuclide'].str.replace(key, '')\n",
    "            # Keep rows where 'key' value is not nan\n",
    "            df_t=df_t[df_t[key].notna()]\n",
    "            nuc_dfs[key]=df_t    \n",
    "            \n",
    "        # Merge dfs created from melt. \n",
    "        combine_on= vars_cfg + ['sample'] + ['nuclide']\n",
    "        merged_df=reduce(lambda df1, df2: pd.merge(df1, df2,  how='left', left_on= combine_on, right_on = combine_on), nuc_dfs.values())\n",
    "        \n",
    "        # Keep rows where either value_name (i.e.Activity or MDA ) is not 'nan'.\n",
    "        merged_df = merged_df[merged_df[['value']].notna().any(axis=1)]\n",
    "                \n",
    "        return (merged_df)\n",
    "    \n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp] = self.melt(tfm.dfs[grp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong()])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['sediment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format: Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupTimeFromEncodedTime(Callback):\n",
    "    def __init__(self, cfg): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['Sampling start date'] = tfm.dfs[grp]['time'].apply(lambda row: self.format_date(row)) \n",
    "            tfm.dfs[grp]['Sampling start time'] = tfm.dfs[grp]['time'].apply(lambda row: self.format_time(row))\n",
    "    \n",
    "    def format_date(self, x): \n",
    "        date_time = num2pydate(x, units=self.cfg['units']['time'])\n",
    "        date = date_time.strftime('%d-%b-%Y')\n",
    "        return date\n",
    "    \n",
    "    def format_time(self, x): \n",
    "        date_time = num2pydate(x, units=self.cfg['units']['time'])\n",
    "        time = date_time.strftime('%H:%M:%S') \n",
    "        return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg())])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm.dfs['seawater']['Sampling start date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup: Sample Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GetSampleTypeCB(Callback):\n",
    "    def __init__(self): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['Sample type'] = k.upper()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB()])\n",
    "tfm()['biota']['Sample type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Nuclide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nucnames_lut():\n",
    "    df = pd.read_excel(nuc_lut_path(), usecols=['nc_name','nusymbol'])\n",
    "    return df.set_index('nc_name').to_dict()['nusymbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupNuclideByIdCB(Callback):\n",
    "    \"Lookup MARIS nuclide_id.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_nucnames_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['Nuclide'] = tfm.dfs[k]['nuclide'].replace(lut)\n",
    "            tfm.dfs[k]['Nuclide']=tfm.dfs[k]['Nuclide'].str.strip()\n",
    "            tfm.dfs[k]['Nuclide']=tfm.dfs[k]['Nuclide'].str.replace(',','_')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['biota']['Nuclide'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format : Longitude and Latitude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from Longitude and Latitude DDD.DDDDD° to degrees, minutes, seconds and direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def deg_to_dms(deg, coordinate='lat'):\n",
    "    \"\"\"Convert from decimal degrees to degrees, minutes, seconds.\"\"\"\n",
    "    m, s = divmod(abs(deg)*3600, 60)\n",
    "    d, m = divmod(m, 60)\n",
    "    \n",
    "    if deg < 0:\n",
    "        if coordinate == 'lat':\n",
    "            cord = 'S'\n",
    "        elif coordinate == 'lon':\n",
    "            cord = 'W'\n",
    "    else:\n",
    "        if coordinate == 'lat':\n",
    "            cord = 'N' \n",
    "        elif coordinate == 'lon':\n",
    "            cord = 'E'                       \n",
    "        \n",
    "    d, m = int(d), int(m)\n",
    "    \n",
    "    return pd.Series([d, m, s, cord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ConvertLonLatCB(Callback):\n",
    "    \"Convert from Longitude and Latitude DDD.DDDDD° to degrees, minutes, seconds and direction.\"\n",
    "    def __init__(self, fn_convert=deg_to_dms):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp][['Latitude degrees','Latitude minutes','Latitude seconds','Latitude direction']] = tfm.dfs[grp]['lat'].apply(self.fn_convert, coordinate='lat')\n",
    "            tfm.dfs[grp][['Longitude degrees','Longitude minutes','Longitude seconds','Longitude direction']] = tfm.dfs[grp]['lon'].apply(self.fn_convert, coordinate='lon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['seawater'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unitnames_lut():\n",
    "    df = pd.read_excel(unit_lut_path(), usecols=['unit_id','unit'])\n",
    "    return df.set_index('unit_id').to_dict()['unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupUnitByIdCB(Callback):\n",
    "    \"Lookup MARIS unit by unit_id.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_unitnames_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['Unit'] = tfm.dfs[k]['_unit'].replace(lut)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['seawater'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Value type (_dl) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_detectionlimitnames_lut():\n",
    "    df = pd.read_excel(detection_limit_lut_path(), usecols=['id','name'])\n",
    "    return df.set_index('id').to_dict()['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupValueTypeByIdCB(Callback):\n",
    "    \"Lookup MARIS Value Type.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_detectionlimitnames_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['Value type'] = tfm.dfs[k]['_dl'].replace(lut)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biogroup is in netcdf but not in OPEN REfINE csv format.  Should we include this in Netcdf? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_species_lut():\n",
    "    df = pd.read_excel(species_lut_path(), usecols=['species_id','species'])\n",
    "    return df.set_index('species_id').to_dict()['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupSpeciesByIdCB(Callback):\n",
    "    \"Lookup MARIS species by species_id.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_species_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            if 'species' in tfm.dfs[k].columns: \n",
    "                tfm.dfs[k]['Species'] = tfm.dfs[k]['species'].replace(lut)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB(),\n",
    "                            LookupSpeciesByIdCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Body part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_bodypart_lut():\n",
    "    df = pd.read_excel(bodyparts_lut_path(), usecols=['bodypar_id','bodypar'])\n",
    "    return df.set_index('bodypar_id').to_dict()['bodypar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupBodypartByIdCB(Callback):\n",
    "    \"Lookup MARIS bodypart by bodypar_id.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_bodypart_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            if 'body_part' in tfm.dfs[k].columns: \n",
    "                tfm.dfs[k]['Body part'] = tfm.dfs[k]['body_part'].replace(lut)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB(),\n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup : Sediment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sediments_lut():\n",
    "    df = pd.read_excel(sediments_lut_path(), usecols=['sedtype_id','sedtype'])\n",
    "    return df.set_index('sedtype_id').to_dict()['sedtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupSedimentTypeByIdCB(Callback):\n",
    "    \"Lookup MARIS sedtype by sedtype_id.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=get_sediments_lut):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()\n",
    "        for k in tfm.dfs.keys():\n",
    "            if 'sed_type' in tfm.dfs[k].columns: \n",
    "                tfm.dfs[k]['Sediment type'] = tfm.dfs[k]['sed_type'].replace(lut)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB(),\n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB(),\n",
    "                            LookupSedimentTypeByIdCB()\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest (keys) and renaming rules (values).\n",
    "def get_renaming_rules_netcdf2OpenRefine():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    return {('seawater','biota', 'sediment') : {    \n",
    "                                                        ## DEFAULT\n",
    "                                                        'Sample type' : 'Sample type',\n",
    "                                                        'Latitude degrees' : 'Latitude degrees',\n",
    "                                                        'Latitude minutes' : 'Latitude minutes',\n",
    "                                                        'Latitude seconds' : 'Latitude seconds',\n",
    "                                                        'Latitude direction' : 'Latitude direction',\n",
    "                                                        'Longitude degrees' : 'Longitude degrees',\n",
    "                                                        'Longitude minutes' : 'Longitude minutes',\n",
    "                                                        'Longitude seconds' : 'Longitude seconds', \n",
    "                                                        'Longitude direction' : 'Longitude direction', \n",
    "                                                        vars['defaults']['lat']['name'] : 'Latitude decimal',\n",
    "                                                        vars['defaults']['lon']['name'] : 'Longitude decimal',\n",
    "                                                        'Sampling start date' : 'Sampling start date',\n",
    "                                                        'Sampling start time' : 'Sampling start time',\n",
    "                                                        'Nuclide' : 'Nuclide',\n",
    "                                                        'Value type': 'Value type',\n",
    "                                                        'Unit' : 'Unit',\n",
    "                                                        'value' : 'Activity or MDA',\n",
    "                                                        vars['suffixes']['uncertainty']['name'] : 'Uncertainty',\n",
    "                                                        #'data_provider_station_id' : 'Station ID',\n",
    "                                                        #vars['defaults']['data_provider_sample_id']['name'] :'Sample ID',\n",
    "                                                        #'profile_id' : 'Profile or transect ID',                                                        \n",
    "                                                        #'Sampling method' : 'sampling_method'\n",
    "                                                        #'Preparation method' : 'preparation_method'\n",
    "                                                        #'Counting method' : 'counting_method'\n",
    "                                                        #'Sample notes' : 'sample_notes'\n",
    "                                                        #'Measurement notes' : 'measurement_notes'\n",
    "                                                    },\n",
    "                  ('seawater',) : {\n",
    "                                ## SEAWATER\n",
    "                                vars['defaults']['tot_depth']['name'] : 'Total depth',\n",
    "                                vars['defaults']['smp_depth']['name'] : 'Sampling depth' ,\n",
    "                                vars['suffixes']['salinity']['name'] : 'Salinity',\n",
    "                                vars['suffixes']['temperature']['name'] : 'Temperature',\n",
    "                                #vars['suffixes']['filtered']['name'] : 'Filtered' TODO: Include in NetCDF encoder. \n",
    "                                },\n",
    "                  ('biota',) : { \n",
    "                                ## BIOTA\n",
    "                                'Species' : 'Species',\n",
    "                                'Body part' : 'Body part',\n",
    "                                'bio_group' : vars['bio']['bio_group']['name'],\n",
    "                                #'SDEPTH' : vars['defaults']['smp_depth']['name'],\n",
    "                                #'dry_wet_ratio' : 'Dry/wet ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                \n",
    "                                },\n",
    "                  ('sediment',) : {\n",
    "                                ## SEDIMENT\n",
    "                                vars['defaults']['tot_depth']['name'] : 'Total depth',\n",
    "                                'Sediment type' : 'Sediment type',\n",
    "                                #'top' : 'Top',\n",
    "                                #'bottom' : 'Bottom', \n",
    "                                #'dry_wet_ratio' : 'Dry/wet ratio'\n",
    "                                #'Drying Method' : drying_method\n",
    "                                }\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectAndRenameColumnCB(Callback):\n",
    "    def __init__(self,\n",
    "                 fn_renaming_rules,\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        renaming = self.fn_renaming_rules()\n",
    "        for grp in tfm.dfs.keys():            \n",
    "            # get columns related to the grp (e.g. 'biota').\n",
    "            coi = [v for k, v in renaming.items() if grp in k]\n",
    "            # Join cols of interest\n",
    "            coi_rename = {}\n",
    "            for d in coi:\n",
    "                for k, v in d.items(): \n",
    "                    coi_rename[k]=v\n",
    "            # list cols\n",
    "            cols = list(coi_rename.keys()) \n",
    "            # select cols in df \n",
    "            tfm.dfs[grp] = tfm.dfs[grp].loc[:, cols]\n",
    "            # Rename cols\n",
    "            tfm.dfs[grp].rename(columns=coi_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB(),\n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB(),\n",
    "                            LookupSedimentTypeByIdCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf2OpenRefine)\n",
    "                            ])\n",
    "tfm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out, ref_id=-1, **kwargs):\n",
    "    dfs = netcdf4_to_df(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[ReshapeWideToLong(),\n",
    "                            LookupTimeFromEncodedTime(cfg()),\n",
    "                            GetSampleTypeCB(),\n",
    "                            LookupNuclideByIdCB(),\n",
    "                            ConvertLonLatCB(), \n",
    "                            LookupUnitByIdCB(),\n",
    "                            LookupValueTypeByIdCB(),\n",
    "                            LookupSpeciesByIdCB(),\n",
    "                            LookupBodypartByIdCB(),\n",
    "                            LookupSedimentTypeByIdCB(),\n",
    "                            SelectAndRenameColumnCB(get_renaming_rules_netcdf2OpenRefine)\n",
    "                            ])\n",
    "    \n",
    "    encoder = OpenRefineCsvEncoder(tfm(), \n",
    "                            dest_fname=fname_out,\n",
    "                            ref_id = ref_id,\n",
    "                            **kwargs)\n",
    "    encoder.encode()\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(fname_in, fname_out, ref_id, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Review Maris Nuclides lut. Cs127?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Should the var be called 'detection limit'? Is 'value type' more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Biogroup not used in OPEN REfINE csv format. Confirm this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Ask about Species dbo. Paul said there is a larger one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Maintain sample (i.e. index) in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp handlers.ospar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712eab9d",
   "metadata": {},
   "source": [
    "# OSPAR \n",
    "> Data pipeline (handler) to convert OSPAR data ([source](https://odims.ospar.org/en/)) to `NetCDF` format.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f263111a",
   "metadata": {},
   "source": [
    "The OSPAR Environment [database](https://odims.ospar.org/en/) is provided as a Microsoft Access database. \n",
    "`Mdbtools` (https://github.com/mdbtools/mdbtools) can be used to convert the tables of the Microsoft Access database to `.csv` files on Unix-like OS.\n",
    "\n",
    "Example steps:\n",
    "1. Download data.\n",
    "2. Install mdbtools via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install mdbtools\n",
    "    ````\n",
    "\n",
    "3. Install unzip via VScode Terminal \n",
    "\n",
    "    ```\n",
    "    sudo apt-get -y install unzip\n",
    "    ````\n",
    "\n",
    "4. In VS code terminal, navigate to the marisco data folder\n",
    "\n",
    "    ```\n",
    "    cd /home/marisco/downloads/marisco/_data/accdb/mors_19840101_20211231\n",
    "    ```\n",
    "\n",
    "5. Unzip MORS_ENVIRONMENT.zip \n",
    "\n",
    "    ```\n",
    "    unzip MORS_ENVIRONMENT.zip \n",
    "    ```\n",
    "\n",
    "6. Run preprocess.sh to generate the required data files\n",
    "\n",
    "    ```\n",
    "    ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    ````\n",
    "7. Content of 'preprocess.sh' script.\n",
    "    ```\n",
    "    #!/bin/bash\n",
    "\n",
    "    # Example of use: ./preprocess.sh MORS_ENVIRONMENT.zip\n",
    "    unzip $1\n",
    "dbname=$(ls *.accdb *.mdb)\n",
    "    mkdir csv\n",
    "    for table in $(mdb-tables -1 \"$dbname\"); do\n",
    "        echo \"Export table $table\"\n",
    "        mdb-export \"$dbname\" \"$table\" > \"csv/$table.csv\"\n",
    "    done\n",
    "    ```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a5c33",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db45fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd # Python package that provides fast, flexible, and expressive data structures.\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Python Progress Bar Library\n",
    "from functools import partial # Function which Return a new partial object which when called will behave like func called with the positional arguments args and keyword arguments keywords\n",
    "import fastcore.all as fc # package that brings fastcore functionality, see https://fastcore.fast.ai/.\n",
    "from pathlib import Path # This module offers classes representing filesystem paths\n",
    "from dataclasses import asdict\n",
    "import re # provides regular expression matching operations\n",
    "\n",
    "from marisco.utils import (has_valid_varname, match_worms, match_maris_lut, Match)\n",
    "from marisco.callbacks import (Callback, Transformer, EncodeTimeCB, SanitizeLonLatCB)\n",
    "from marisco.metadata import (GlobAttrsFeeder, BboxCB, DepthRangeCB, TimeRangeCB, ZoteroCB, KeyValuePairCB)\n",
    "from marisco.configs import (nc_tpl_path, cfg, cache_path, cdl_cfg, Enums, lut_path,\n",
    "                             species_lut_path, bodyparts_lut_path, unit_lut_path, detection_limit_lut_path)\n",
    "from marisco.serializers import NetCDFEncoder\n",
    "\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df103c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615df566",
   "metadata": {},
   "source": [
    "Here we define the fname_in and fname_out variables. These variables are paths which are defined as relative paths. These paths are relative to \n",
    "the current working directory. Note that fname_in refers to the csv folder that contains the OSPAR data. fname_out defines the path and filename for the NetCDF output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "fname_in = '../../_data/accdb/ospar/csv'\n",
    "fname_out = '../../_data/output/ospar_19950103_2021214.nc'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd04abcd",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(src_dir):\n",
    "    \"Load OSPAR data and return them as an individual dataframe by sample type\"\n",
    "    '''\n",
    "    Load data from the measurement file found in the src_dir (i.e. fname_in).\n",
    "    Returns a dictionary of pandas' dataframes. The key to the dictionary is \n",
    "    the sample type (i.e lut_smp_type)\n",
    "    '''    \n",
    "    dfs = {}\n",
    "    lut_smp_type = {'Seawater data': 'seawater', 'Biota data': 'biota'}\n",
    "    for k, v in lut_smp_type.items():\n",
    "        fname_meas = k + '.csv' # measurement (i.e. radioactivity) information and sample information     \n",
    "        df = pd.read_csv(Path(src_dir)/fname_meas, encoding='unicode_escape')\n",
    "        dfs[v] = df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename_cols(cols):\n",
    "    \"Flatten multiindex columns\"\n",
    "    new_cols = []\n",
    "    for outer, inner in cols:\n",
    "        if not inner:\n",
    "            new_cols.append(outer)\n",
    "        else:\n",
    "            if outer == 'unit':\n",
    "                new_cols.append(inner + '_' + outer)\n",
    "            if outer == 'unc':\n",
    "                new_cols.append(inner + '_' + outer)\n",
    "            if outer == 'value':\n",
    "                new_cols.append(inner)\n",
    "    return new_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e534545",
   "metadata": {},
   "source": [
    "## Load tables (dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47e4d4",
   "metadata": {},
   "source": [
    "dfs includes a dictionary of tables (dataframes) that is created from the OSPAR dataset defined by fname_in. The data to be included in each dataframe is sorted by sample type. Each dictionary is defined with a key equal to the sample type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bf289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd206ec",
   "metadata": {},
   "source": [
    "List the keys for the dictionary of dataframes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b847925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "keys = dfs.keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e562422",
   "metadata": {},
   "source": [
    "Show the structure of the 'seawater' dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8ab40",
   "metadata": {},
   "source": [
    "Show the structure of the `biota` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac781a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs['biota'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d68abc3",
   "metadata": {},
   "source": [
    "## Data transformation pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142ddab3",
   "metadata": {},
   "source": [
    "### Normalize nuclide names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa12913-4b04-46cc-872c-3880935e3f5d",
   "metadata": {},
   "source": [
    "**Comment (FA)**\n",
    "\n",
    "Well there are not so many different nuclides. I would just create a lut right away to prevent using regexp, ...\n",
    "This is a naive wait but more transparent. Just a suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869822f-5772-4b9b-932d-016f98e2380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs['seawater'].Nuclide.unique())\n",
    "print(dfs['biota'].Nuclide.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2311cd",
   "metadata": {},
   "source": [
    "**Lower & strip** \n",
    "\n",
    "Creates a class `LowerStripRdnNameCB` that receives a dictionary of dataframes. For each dataframe in the dictionary of dataframes, it corrects the nuclide name by converting it lowercase, striping any leading or trailing whitespace(s) and ensuring the number comes before letters (e.g. 137cs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_rdn_format(var):\n",
    "    # lowercase, strip separators (e.g. `-`,`,`) and any white-space(s)\n",
    "    separators=\"-,\"\n",
    "    var= var.lower().translate({ord(x): '' for x in separators}).replace(\" \", \"\")\n",
    "    # Format nuclide name with number then letters (e.g. 137cs) to \n",
    "    # letters and then numbers (e.g. cs137).\n",
    "    reg_num_str=re.compile(\"([0-9]+)([a-zA-Z]+)\")\n",
    "    sol=reg_num_str.match(var)\n",
    "    if sol is not None:\n",
    "        reg_group=sol.groups()\n",
    "        var=reg_group[1]+reg_group[0]\n",
    "    return (var)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LowerStripRdnNameCB(Callback):\n",
    "    \"Drop NaN nuclide names, convert nuclide names to lowercase, strip separators (e.g. `-`,`,`) and any trailing space(s)\"\n",
    "    def __init__(self, fn_format_rdn): fc.store_attr()\n",
    "    def __call__(self, tfm):        \n",
    "        # Apply condition to Nuclide col. \n",
    "        for k in tfm.dfs.keys():\n",
    "            # drop nan values\n",
    "            tfm.dfs[k] = tfm.dfs[k][tfm.dfs[k]['Nuclide'].notna()]\n",
    "            # Apply condition\n",
    "            tfm.dfs[k]['nuclide'] = tfm.dfs[k]['Nuclide'].apply(lambda x: self.fn_format_rdn(x))\n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cdc845",
   "metadata": {},
   "source": [
    "Here we apply the transformer LowerStripRdnNameCB. Print the nuclide name that is unique from the column, 'nuclide', of each dataframe included in the dictionary of dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format)])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['nuclide'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['nuclide'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c9d0fe",
   "metadata": {},
   "source": [
    "\n",
    "#### Remap to MARIS nuclide names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bf954",
   "metadata": {},
   "source": [
    "The marisco package includes a template that defines the permitted structure of the data. This template is located at `nc_tpl_path` and is available in a `NetCDF` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c61b27",
   "metadata": {},
   "source": [
    "Path to maris-template.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3283de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "nc_tpl_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80538ec",
   "metadata": {},
   "source": [
    "*View the `maris-template.nc` with `ncdump` via Terminal as follows:*\n",
    "```\n",
    "cd /home/marisco/.marisco/\n",
    "ncdump -h maris-template.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d199d",
   "metadata": {},
   "source": [
    "The function, `get_unique_nuclides`, returns a list of unique nuclides from each dataframe that is included in the dictionary of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf213bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_unique_nuclides(dfs):\n",
    "    \"Get list of unique radionuclide types measured across samples.\"\n",
    "    nuclides = []\n",
    "    for k in dfs.keys():\n",
    "        nuclides += dfs[k]['nuclide'].unique().tolist()\n",
    "    return nuclides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807b34b",
   "metadata": {},
   "source": [
    "Function, has_valid_varname, checks if a variable defined in the dataframes (i.e. OSPAR dataset), in this case nuclide names, are consistent with the template defined by maris-template.nc. If the variable name is not valid it will print the variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68dacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de7b3c",
   "metadata": {},
   "source": [
    "Create a look up table, varnames_lut_updates, which will be used to correct the nuclide names in the dictionary of dataframes (i.e. dfs) that are not compatible with the template at nc_tpl_path(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "varnames_lut_updates = {\n",
    "    'pu239240': 'pu239_240_tot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c1c66",
   "metadata": {},
   "source": [
    "Create a function, get_varnames_lut, which returns a dictionary of nuclide names. This dictionary of nuclide names includes the 'Nuclide' names in the dictionary and the corrections included in varnames_lut_updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90557494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_varnames_lut(dfs, lut=varnames_lut_updates):\n",
    "    lut = {n: n for n in set(get_unique_nuclides(dfs))}\n",
    "    lut.update(varnames_lut_updates)\n",
    "    return lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a964b01",
   "metadata": {},
   "source": [
    "Create the varnames_lut variable, a dictionary of nuclide names including updates defined by varnames_lut_updates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c083a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "varnames_lut = partial(get_varnames_lut, lut=varnames_lut_updates)(tfm.dfs)\n",
    "varnames_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3455653",
   "metadata": {},
   "source": [
    "Create a class that remaps the nuclide names in the dfs to those in varnames_lut_updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RemapRdnNameCB(Callback):\n",
    "    \"Remap to MARIS radionuclide names.\"\n",
    "    def __init__(self,\n",
    "                 fn_lut=partial(get_varnames_lut, lut=varnames_lut_updates)):\n",
    "        fc.store_attr()\n",
    "        \n",
    "    def __call__(self, tfm):       \n",
    "        # Replace 'Nuclide' vars according to lut. \n",
    "        lut = self.fn_lut(tfm.dfs)\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k]['nuclide'].replace(lut, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7750d4d",
   "metadata": {},
   "source": [
    "Apply the transformers `LowerStripRdnNameCB` and `RemapRdnNameCB`. Print the unique nuclides for each dataframe included in the dictionary of dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c075d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB()])\n",
    "print('seawater nuclides: ')\n",
    "print(tfm()['seawater']['nuclide'].unique())\n",
    "print('biota nuclides: ')\n",
    "print(tfm()['biota']['nuclide'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c99c7e",
   "metadata": {},
   "source": [
    "Check that all nuclide varnames are valid. Returns True if all are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c644322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "has_valid_varname(get_unique_nuclides(tfm.dfs), nc_tpl_path())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aaaf96a",
   "metadata": {},
   "source": [
    "### Parse time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1c92a",
   "metadata": {},
   "source": [
    "Create a class that remaps the time format in the dictionary of dataframes (i.e. '%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParseTimeCB(Callback):\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            # drop nan values\n",
    "            tfm.dfs[k] = tfm.dfs[k][tfm.dfs[k]['Sampling date'].notna()]            \n",
    "            tfm.dfs[k]['time'] = pd.to_datetime(tfm.dfs[k]['Sampling date'], \n",
    "                                                format='%d/%m/%Y')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b90d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB()])\n",
    "\n",
    "print(tfm()['seawater']['time'][:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5868c16b",
   "metadata": {},
   "source": [
    "### Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3dd6c",
   "metadata": {},
   "source": [
    "#### Biota species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e711b8",
   "metadata": {},
   "source": [
    "Create a function `get_maris_lut` which completes a lookup of the OSPAR data against the data allowed in Maris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_maris_lut(df_biota,\n",
    "                  fname_cache, # For instance 'species_ospar.pkl'\n",
    "                  data_provider_name_col:str, # Data provider lookup column name of interest\n",
    "                  maris_lut:Callable, # Function retrieving MARIS source lookup table\n",
    "                  maris_id: str, # Id of MARIS lookup table nomenclature item to match\n",
    "                  maris_name: str, # Name of MARIS lookup table nomenclature item to match\n",
    "                  unmatched_fixes={},\n",
    "                  as_dataframe=False,\n",
    "                  overwrite=False\n",
    "                 ):\n",
    "    fname_cache = cache_path() / fname_cache\n",
    "    lut = {}\n",
    "    maris_lut = maris_lut()\n",
    "\n",
    "    if overwrite or (not fname_cache.exists()):        \n",
    "        df = pd.DataFrame({data_provider_name_col : df_biota[data_provider_name_col].unique()})\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            \n",
    "            # Fix if unmatched\n",
    "            has_to_be_fixed = row[data_provider_name_col] in unmatched_fixes       \n",
    "            name_to_match = unmatched_fixes[row[data_provider_name_col]] if has_to_be_fixed else row[data_provider_name_col]\n",
    "\n",
    "            # Match\n",
    "            result = match_maris_lut(maris_lut, name_to_match, maris_id, maris_name)\n",
    "            match = Match(result.iloc[0][maris_id], result.iloc[0][maris_name], \n",
    "                        row[data_provider_name_col], result.iloc[0]['score'])\n",
    "                    \n",
    "            lut[row[data_provider_name_col]] = match\n",
    "            \n",
    "        fc.save_pickle(fname_cache, lut)\n",
    "    else:\n",
    "        lut = fc.load_pickle(fname_cache)\n",
    "\n",
    "    if as_dataframe:\n",
    "        df_lut = pd.DataFrame({k: asdict(v) for k, v in lut.items()}).transpose()\n",
    "        df_lut.index.name = 'source_id'\n",
    "        return df_lut.sort_values(by='match_score', ascending=False)\n",
    "    else:\n",
    "        return lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# key equals name in dfs['biota']. \n",
    "# value equals replacement name to use in match_maris_lut (i.e. name_to_match)\n",
    "unmatched_fixes_biota_species = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "species_lut_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# drop nan values\n",
    "tfm.dfs['biota']=tfm.dfs['biota'][tfm.dfs['biota']['Species'].notna()]\n",
    "\n",
    "species_lut_df = get_maris_lut(df_biota=tfm.dfs['biota'], \n",
    "                                fname_cache='species_ospar.pkl', \n",
    "                                data_provider_name_col='Species',\n",
    "                                maris_lut=species_lut_path,\n",
    "                                maris_id='species_id',\n",
    "                                maris_name='species',\n",
    "                                unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                                as_dataframe=True,\n",
    "                                overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978307c4",
   "metadata": {},
   "source": [
    "**TODO:** Mixed species ID (e.g.RHODYMENIA PSEUDOPALAMATA & PALMARIA PALMATA ). Drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f8fe3-6633-4ec6-8f47-f6f7bcaef336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faea0c34",
   "metadata": {},
   "source": [
    "Show `maris_species_lut` where `match_type` is not a perfect match ( i.e. not equal 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29514b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "species_lut_df[species_lut_df['match_score'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411434f1",
   "metadata": {},
   "source": [
    "Match unmatched `biota_species`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# LookupBiotaSpeciesCB filters 'Not available'. \n",
    "unmatched_fixes_biota_species = {'RHODYMENIA PSEUDOPALAMATA & PALMARIA PALMATA': 'Not available', # mix\n",
    " 'Mixture of green, red and brown algae': 'Not available', #mix \n",
    " 'Solea solea (S.vulgaris)': 'Solea solea',\n",
    " 'SOLEA SOLEA (S.VULGARIS)': 'Solea solea',\n",
    " 'CERASTODERMA (CARDIUM) EDULE': 'Cerastoderma edule',\n",
    " 'Cerastoderma (Cardium) Edule': 'Cerastoderma edule',\n",
    " 'MONODONTA LINEATA': 'Phorcus lineatus',\n",
    " 'NUCELLA LAPILLUS': 'Not available', # Droped. In worms 'Nucella lapillus (Linnaeus, 1758)', \n",
    " 'DICENTRARCHUS (MORONE) LABRAX': 'Dicentrarchus labrax',\n",
    " 'Pleuronectiformes [order]': 'Pleuronectiformes',\n",
    " 'RAJIDAE/BATOIDEA': 'Not available', #mix \n",
    " 'PALMARIA PALMATA': 'Not available', # Dropped. In worms 'Palmaria palmata (Linnaeus) F.Weber & D.Mohr, 1805',\n",
    " 'Sepia spp.': 'Sepia',\n",
    " 'Rhodymenia spp.': 'Rhodymenia',\n",
    " 'unknown': 'Not available',\n",
    " 'RAJA DIPTURUS BATIS': 'Dipturus batis',\n",
    " 'Unknown': 'Not available',\n",
    " 'Flatfish': 'Not available',\n",
    " 'FUCUS SPP.': 'FUCUS',\n",
    " 'Patella sp.': 'Patella',\n",
    " 'Gadus sp.': 'Gadus',\n",
    " 'FUCUS spp': 'FUCUS',\n",
    " 'Tapes sp.': 'Tapes',\n",
    " 'Thunnus sp.': 'Thunnus',\n",
    " 'RHODYMENIA spp': 'RHODYMENIA',\n",
    " 'Fucus sp.': 'Fucus',\n",
    " 'PECTINIDAE': 'Not available', # Droped. In worms as PECTINIDAE is a family.\n",
    " 'PLUERONECTES PLATESSA': 'Pleuronectes platessa',\n",
    " 'Gaidropsarus argenteus': 'Gaidropsarus argentatus'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# Drop row in the dfs['biota] where the unmatched_fixes_biota_species value is 'Not available'. \n",
    "na_list = ['Not available']     \n",
    "na_biota_species = [k for k,v in unmatched_fixes_biota_species.items() if v in na_list]\n",
    "tfm.dfs['biota'] = tfm.dfs['biota'][~tfm.dfs['biota']['Species'].isin(na_biota_species)]\n",
    "# drop nan values\n",
    "tfm.dfs['biota']=tfm.dfs['biota'][tfm.dfs['biota']['Species'].notna()]\n",
    "species_lut_df = get_maris_lut(df_biota=tfm.dfs['biota'], \n",
    "                                fname_cache='species_ospar.pkl', \n",
    "                                data_provider_name_col='Species',\n",
    "                                maris_lut=species_lut_path,\n",
    "                                maris_id='species_id',\n",
    "                                maris_name='species',\n",
    "                                unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                                as_dataframe=True,\n",
    "                                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "species_lut_df[species_lut_df['match_score'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaSpeciesCB(Callback):\n",
    "    \"\"\"\n",
    "    Biota species remapped to MARIS db:\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut, unmatched_fixes_biota_species): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut(df_biota=tfm.dfs['biota'])      \n",
    "        # Drop rows where 'Species' are 'nan'\n",
    "        tfm.dfs['biota'] = tfm.dfs['biota'][tfm.dfs['biota']['Species'].notna()]\n",
    "        # Drop row in the dfs['biota] where the unmatched_fixes_biota_species value is 'Not available'. \n",
    "        na_list = ['Not available']     \n",
    "        na_biota_species = [k for k,v in self.unmatched_fixes_biota_species.items() if v in na_list]\n",
    "        tfm.dfs['biota'] = tfm.dfs['biota'][~tfm.dfs['biota']['Species'].isin(na_biota_species)]\n",
    "        # Perform lookup \n",
    "        tfm.dfs['biota']['species'] = tfm.dfs['biota']['Species'].apply(lambda x: lut[x].matched_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb41da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_maris_species = partial(get_maris_lut, \n",
    "                fname_cache='species_ospar.pkl', \n",
    "                data_provider_name_col='SCIENTIFIC NAME',\n",
    "                maris_lut=species_lut_path,\n",
    "                maris_id='species_id',\n",
    "                maris_name='species',\n",
    "                unmatched_fixes=unmatched_fixes_biota_species,\n",
    "                as_dataframe=False,\n",
    "                overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405eb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species)\n",
    "                            ])\n",
    "print(tfm()['biota'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748c98",
   "metadata": {},
   "source": [
    "#### Biota tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b4b20",
   "metadata": {},
   "source": [
    "##### Correct OSPAR `Body Part` labelled as `Whole`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ea7e6",
   "metadata": {},
   "source": [
    "The OSPAR data includes entries with the variable Body Part labelled as `whole`. The Maris data requires that the body `body_part` distinguishes between `Whole animal` and `Whole plant`. The OSPAR data defines the `Biological group` which allows for the Body Part labelled as whole to be defined as `Whole animal` and `Whole plant`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba75bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "whole_animal_plant = {'whole' : ['Whole','WHOLE', 'WHOLE FISH', 'Whole fisk', 'Whole fish'],\n",
    "                      'Whole animal' : ['Molluscs','Fish','FISH','molluscs','fish','MOLLUSCS'],\n",
    "                      'Whole plant' : ['Seaweed','seaweed','SEAWEED'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe388f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CorrectWholeBodyPartCB(Callback):\n",
    "    \"\"\"\n",
    "    Update bodypart labeled as 'whole' to either 'Whole animal' or 'Whole plant'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, wap=whole_animal_plant): fc.store_attr()\n",
    "    \n",
    "    def __call__(self, tfm):        \n",
    "        tfm.dfs['biota'] = self.correct_whole_body_part(tfm.dfs['biota'],self.wap)\n",
    "\n",
    "    def correct_whole_body_part(self, df, wap):\n",
    "        whole_list= wap['whole']\n",
    "        animal_list = wap['Whole animal']\n",
    "        plant_lst = wap['Whole plant']\n",
    "        df['body_part'] = df['Body Part']   \n",
    "        df['body_part'].loc[(df['body_part'].isin(whole_list)) & (df['Biological group'].isin(animal_list))] = 'Whole animal'\n",
    "        df['body_part'].loc[(df['body_part'].isin(whole_list)) & (df['Biological group'].isin(plant_lst))] = 'Whole plant'\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB()\n",
    "                            ])\n",
    "print(tfm()['biota']['body_part'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05061d66",
   "metadata": {},
   "source": [
    "Get a dataframe of matched OSPAR biota tissues with Maris Bodyparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eee5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df = get_maris_lut(df_biota=tfm.dfs['biota'], \n",
    "                                fname_cache='tissues_ospar.pkl', \n",
    "                                data_provider_name_col='body_part',\n",
    "                                maris_lut=bodyparts_lut_path,\n",
    "                                maris_id='bodypar_id',\n",
    "                                maris_name='bodypar',\n",
    "                                unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                                as_dataframe=True,\n",
    "                                overwrite=True)\n",
    "tissues_lut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fe2e1",
   "metadata": {},
   "source": [
    "List unmatched OSPAR tissues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb05e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df[tissues_lut_df['match_score'] >= 1]['source_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d91d0d",
   "metadata": {},
   "source": [
    "Read Maris tissue lut to correct unmatched tissues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "marisco_lut_df = pd.read_excel(bodyparts_lut_path())\n",
    "marisco_lut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c7d03",
   "metadata": {},
   "source": [
    "Create a dictionary of unmatched tissues to allow for  correctection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "unmatched_fixes_biota_tissues = {\n",
    "'Mix of muscle and whole fish without liver' : 'Not available', # Drop\n",
    " 'Whole without head' : 'Whole animal eviscerated without head', # Drop? eviscerated? ,\n",
    " 'Cod medallion' : 'Whole animal eviscerated without head',\n",
    " 'FLESH' : 'Flesh without bones', # Drop? with or without bones?\n",
    " 'Flesh' : 'Flesh without bones', # Drop? with or without bones?\n",
    " 'UNKNOWN' : 'Not available',\n",
    " 'FLESH WITHOUT BONE' : 'Flesh without bones'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6076a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# Drop row in the dfs['biota] where the unmatched_fixes_biota_species value is 'Not available'. \n",
    "na_list = ['Not available']     \n",
    "na_biota_tissues = [k for k,v in unmatched_fixes_biota_tissues.items() if v in na_list]\n",
    "tfm.dfs['biota'] = tfm.dfs['biota'][~tfm.dfs['biota']['body_part'].isin(na_biota_tissues)]\n",
    "\n",
    "tissues_lut_df = get_maris_lut(df_biota=tfm.dfs['biota'], \n",
    "                                fname_cache='tissues_ospar.pkl', \n",
    "                                data_provider_name_col='body_part',\n",
    "                                maris_lut=bodyparts_lut_path,\n",
    "                                maris_id='bodypar_id',\n",
    "                                maris_name='bodypar',\n",
    "                                unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                                as_dataframe=True,\n",
    "                                overwrite=True)\n",
    "tissues_lut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b66cf5",
   "metadata": {},
   "source": [
    "List unmatched OSPAR tissues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tissues_lut_df[tissues_lut_df['match_score'] >= 1]['source_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866927f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiotaBodyPartCB(Callback):\n",
    "    \"\"\"\n",
    "    Update bodypart id based on MARIS dbo_bodypar.xlsx:\n",
    "        - 3: 'Whole animal eviscerated without head',\n",
    "        - 12: 'Viscera',\n",
    "        - 8: 'Skin'\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut, unmatched_fixes_biota_tissues): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut(df_biota=tfm.dfs['biota'])      \n",
    "        # Drop rows where 'Species' are 'nan'\n",
    "        tfm.dfs['biota']=tfm.dfs['biota'][tfm.dfs['biota']['body_part'].notna()]\n",
    "        # Drop row in the dfs['biota] where the unmatched_fixes_biota_species value is 'Not available'. \n",
    "        na_list = ['Not available']     \n",
    "        na_biota_tissues = [k for k,v in self.unmatched_fixes_biota_tissues.items() if v in na_list]\n",
    "        tfm.dfs['biota'] = tfm.dfs['biota'][~tfm.dfs['biota']['body_part'].isin(na_biota_tissues)]\n",
    "        # Perform lookup         \n",
    "        tfm.dfs['biota']['body_part'] = tfm.dfs['biota']['body_part'].apply(lambda x: lut[x].matched_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_maris_bodypart=partial(get_maris_lut, \n",
    "                            fname_cache='tissues_ospar.pkl', \n",
    "                            data_provider_name_col='body_part',\n",
    "                            maris_lut=bodyparts_lut_path,\n",
    "                            maris_id='bodypar_id',\n",
    "                            maris_name='bodypar',\n",
    "                            unmatched_fixes=unmatched_fixes_biota_tissues,\n",
    "                            as_dataframe=False,\n",
    "                            overwrite=False)\n",
    "tissues_lut_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baf396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues)\n",
    "                            ])\n",
    "print(tfm()['biota'][['Body Part', 'body_part']][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c00f4",
   "metadata": {},
   "source": [
    "#### Biogroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c2023",
   "metadata": {},
   "source": [
    "Define `bio_group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08392de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_biogroup_lut(maris_lut):\n",
    "    species = pd.read_excel(maris_lut)\n",
    "    return species[['species_id', 'biogroup_id']].set_index('species_id').to_dict()['biogroup_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupBiogroupCB(Callback):\n",
    "    \"\"\"\n",
    "    Update biogroup id  based on MARIS dbo_species.xlsx\n",
    "    \"\"\"\n",
    "    def __init__(self, fn_lut): fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        lut = self.fn_lut()        \n",
    "        tfm.dfs['biota']['bio_group'] = tfm.dfs['biota']['species'].apply(lambda x: lut[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path()))\n",
    "                            ])\n",
    "print(tfm()['biota']['bio_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94ec20",
   "metadata": {},
   "source": [
    "### Capture Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb912f",
   "metadata": {},
   "source": [
    "View `units`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a77bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['seawater'][ 'Unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb93f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.dfs['biota'][ 'Unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc70b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "units_df = pd.read_excel(unit_lut_path())\n",
    "units_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define unit names renaming rules\n",
    "renaming_unit_rules = {'Bq/l': 1, #'Bq/m3'\n",
    "                       'Bq/L': 1,\n",
    "                       'BQ/L': 1,\n",
    "                       'Bq/kg f.w.': 5, # Bq/kgw\n",
    "                       'Bq/kg.fw' : 5,\n",
    "                       'Bq/kg fw' : 5,\n",
    "                       'Bq/kg f.w' : 5 \n",
    "                       } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LookupUnitCB(Callback):\n",
    "    def __init__(self,\n",
    "                 lut=renaming_unit_rules):\n",
    "        fc.store_attr()\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            # Drop rows where 'Species' are 'nan'\n",
    "            tfm.dfs[grp]=tfm.dfs[grp][tfm.dfs[grp]['Unit'].notna()]\n",
    "            # Perform lookup  \n",
    "            # TODO review the cdl.toml\n",
    "            # tfm.dfs[grp]['unit'] = tfm.dfs[grp]['Unit'].apply(lambda x: np.int64(self.lut[x]))\n",
    "            tfm.dfs[grp]['unit'] = tfm.dfs[grp]['Unit'].apply(lambda x: self.lut[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules)\n",
    "                            ])\n",
    "print(tfm()['biota']['unit'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fc3be",
   "metadata": {},
   "source": [
    "### Detection Limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5c837",
   "metadata": {},
   "source": [
    "**TODO:** Review OSPAR `\">\"`? See `tfm.dfs[grp]['Value type'].unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae826e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "grp='biota'\n",
    "tfm.dfs[grp]['Value type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e102f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class LookupDetectionLimitCB(Callback):\n",
    "    \"Remamp activity value, activity uncertainty and detection limit to MARIS format.\"\n",
    "    def __init__(self , lut_path):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        df = pd.read_excel(self.lut_path)\n",
    "        df = df.astype({'id': 'int'})\n",
    "        lut= dict((v,k) for k,v in df.to_dict('dict')['name'].items())\n",
    "\n",
    "        for grp in tfm.dfs.keys():\n",
    "            \n",
    "            \n",
    "            # Copy 'Value type' col \n",
    "            tfm.dfs[grp]['val_type'] = tfm.dfs[grp]['Value type']\n",
    "            \n",
    "            # Fill nan values with 'Not Available'\n",
    "            tfm.dfs[grp]['val_type'] = tfm.dfs[grp]['val_type'].fillna('Not Available')\n",
    "            \n",
    "            # Drop rows where 'Value type' is not included in lut\n",
    "            tfm.dfs[grp] = tfm.dfs[grp][tfm.dfs[grp]['val_type'].isin(list(lut.keys()))]\n",
    "            \n",
    "            # Perform lookup\n",
    "            tfm.dfs[grp]['detection_limit'] = tfm.dfs[grp]['val_type'].apply(lambda x: lut[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44862cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path())\n",
    "                            ])\n",
    "tfm()['seawater'][['detection_limit','Value type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618cca89",
   "metadata": {},
   "source": [
    "### Lon, Lat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ConvertLonLatCB(Callback):\n",
    "    \"Convert Longitude and Latitude values to DDD.DDDDDÂ°\"\n",
    "    def __init__(self):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for grp in tfm.dfs.keys():\n",
    "            tfm.dfs[grp]['latitude'] = np.where(tfm.dfs[grp]['LatDir'].isin(['S']), ((tfm.dfs[grp]['LatD'] + tfm.dfs[grp]['LatM']/60 + tfm.dfs[grp]['LatS'] /(60*60))* (-1)), (tfm.dfs[grp]['LatD'] + tfm.dfs[grp]['LatM']/60 + tfm.dfs[grp]['LatS'] /(60*60)))\n",
    "            tfm.dfs[grp]['longitude'] = np.where(tfm.dfs[grp]['LongDir'].isin(['W']), ((tfm.dfs[grp]['LongD'] + tfm.dfs[grp]['LongM']/60 + tfm.dfs[grp]['LongS'] /(60*60))* (-1)), (tfm.dfs[grp]['LongD'] + tfm.dfs[grp]['LongM']/60 + tfm.dfs[grp]['LongS'] /(60*60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72254c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB()\n",
    "                            ])\n",
    "tfm()['seawater'][['latitude','LatD', 'LatM', 'LatS', 'longitude', 'LatDir', 'LongD', 'LongM','LongS', 'LongDir']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac271f14",
   "metadata": {},
   "source": [
    "### Encode time (seconds since ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB(),\n",
    "                            EncodeTimeCB(cfg())\n",
    "                            ])\n",
    "tfm()['seawater']['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287c2dc",
   "metadata": {},
   "source": [
    "### Compare DFS and TFM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75edc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class CompareDfsAndTfm(Callback):\n",
    "    \"Create a dfs of dropped data. Data included in the DFS not in the TFM\"\n",
    "    def __init__(self, dfs_compare):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        tfm.dfs_dropped={}\n",
    "        tfm.compare_stats={}\n",
    "        for grp in tfm.dfs.keys():\n",
    "            dfs_all = self.dfs_compare[grp].merge(tfm.dfs[grp], on=self.dfs_compare[grp].columns.to_list(), how='left', indicator=True)\n",
    "            tfm.dfs_dropped[grp]=dfs_all[dfs_all['_merge'] == 'left_only']  \n",
    "            tfm.compare_stats[grp]= {'Number of rows dfs:' : len(self.dfs_compare[grp].index),\n",
    "                                     'Number of rows tfm.dfs:' : len(tfm.dfs[grp].index),\n",
    "                                     'Number of dropped rows:' : len(tfm.dfs_dropped[grp].index),\n",
    "                                     'Number of rows tfm.dfs + Number of dropped rows:' : len(tfm.dfs[grp].index) + len(tfm.dfs_dropped[grp].index)\n",
    "                                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            CompareDfsAndTfm(dfs)\n",
    "                            ])\n",
    "tfm()\n",
    "tfm.compare_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs_dropped_biota=tfm.dfs_dropped['biota']\n",
    "dfs_dropped_seawater=tfm.dfs_dropped['seawater']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be391a75",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Define columns of interest by sample type\n",
    "coi_grp = {'seawater': ['nuclide', 'Activity or MDA', 'Uncertainty','detection_limit','unit', 'time', 'Sampling depth',\n",
    "                        'latitude', 'longitude', 'Sample ID'],\n",
    "           'biota': ['nuclide', 'Activity or MDA', 'Uncertainty','detection_limit','unit', 'time', 'latitude', 'longitude', 'Sample ID',\n",
    "                     'species', 'body_part', 'bio_group']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_renaming_rules():\n",
    "    vars = cdl_cfg()['vars']\n",
    "    # Define column names renaming rules\n",
    "    return {\n",
    "        'Activity or MDA': 'value',\n",
    "        'Uncertainty': vars['suffixes']['uncertainty']['name'],\n",
    "        'Sampling depth': vars['defaults']['smp_depth']['name'],\n",
    "        'latitude': vars['defaults']['lat']['name'],\n",
    "        'longitude': vars['defaults']['lon']['name'],\n",
    "        'unit': vars['suffixes']['unit']['name'],\n",
    "        'detection_limit': vars['suffixes']['detection_limit']['name']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RenameColumnCB(Callback):\n",
    "    def __init__(self,\n",
    "                 coi,\n",
    "                 fn_renaming_rules,\n",
    "                ):\n",
    "        fc.store_attr()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            # Select cols of interest\n",
    "            tfm.dfs[k] = tfm.dfs[k].loc[:, self.coi[k]]\n",
    "\n",
    "            # Rename cols\n",
    "            tfm.dfs[k].rename(columns=self.fn_renaming_rules(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a695543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            #CompareDfsAndTfm(dfs),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules)\n",
    "                            ])                            \n",
    "                            \n",
    "tfm()['seawater']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb26ce8",
   "metadata": {},
   "source": [
    "### ReshapeLongToWide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReshapeLongToWide(Callback):\n",
    "    \"Convert data from long to wide with renamed columns.\"\n",
    "    def __init__(self, columns='nuclide', values=['value']):\n",
    "        fc.store_attr()\n",
    "        # Retrieve all possible derived vars (e.g 'unc', 'dl', ...) from configs\n",
    "        self.derived_cols = [value['name'] for value in cdl_cfg()['vars']['suffixes'].values()]\n",
    "    \n",
    "    def renamed_cols(self, cols):\n",
    "        \"Flatten columns name\"\n",
    "        return [inner if outer == \"value\" else f'{inner}{outer}'\n",
    "                if inner else outer\n",
    "                for outer, inner in cols]\n",
    "\n",
    "    def pivot(self, df):\n",
    "        # Among all possible 'derived cols' select the ones present in df\n",
    "        derived_coi = [col for col in self.derived_cols if col in df.columns]\n",
    "        \n",
    "        df.reset_index(names='sample', inplace=True)\n",
    "        \n",
    "        idx = list(set(df.columns) - set([self.columns] + derived_coi + self.values))\n",
    "        return df.pivot_table(index=idx,\n",
    "                              columns=self.columns,\n",
    "                              values=self.values + derived_coi,\n",
    "                              fill_value=np.nan,\n",
    "                              aggfunc=lambda x: x\n",
    "                              ).reset_index()\n",
    "\n",
    "    def __call__(self, tfm):\n",
    "        for k in tfm.dfs.keys():\n",
    "            tfm.dfs[k] = self.pivot(tfm.dfs[k])\n",
    "            tfm.dfs[k].columns = self.renamed_cols(tfm.dfs[k].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec05112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            #CompareDfsAndTfm(dfs),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                            ReshapeLongToWide()\n",
    "                            ])                            \n",
    "                            \n",
    "tfm()['seawater']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c043285",
   "metadata": {},
   "source": [
    "### Sanitize coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c743b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = load_data(fname_in)\n",
    "tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                            RemapRdnNameCB(),\n",
    "                            ParseTimeCB(),\n",
    "                            LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                            CorrectWholeBodyPartCB(),\n",
    "                            LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                            LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                            LookupUnitCB(renaming_unit_rules),\n",
    "                            LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                            ConvertLonLatCB(),\n",
    "                            EncodeTimeCB(cfg()),\n",
    "                            #CompareDfsAndTfm(dfs),\n",
    "                            RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                            ReshapeLongToWide(),\n",
    "                            SanitizeLonLatCB()\n",
    "                            ])                            \n",
    "                            \n",
    "tfm()['seawater'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7ab45",
   "metadata": {},
   "source": [
    "## NetCDF encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273ae24",
   "metadata": {},
   "source": [
    "### Example change logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122346be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "tfm.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb28615",
   "metadata": {},
   "source": [
    "### Feed global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ca014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "kw = ['oceanography', 'Earth Science > Oceans > Ocean Chemistry> Radionuclides',\n",
    "      'Earth Science > Human Dimensions > Environmental Impacts > Nuclear Radiation Exposure',\n",
    "      'Earth Science > Oceans > Ocean Chemistry > Ocean Tracers, Earth Science > Oceans > Marine Sediments',\n",
    "      'Earth Science > Oceans > Ocean Chemistry, Earth Science > Oceans > Sea Ice > Isotopes',\n",
    "      'Earth Science > Oceans > Water Quality > Ocean Contaminants',\n",
    "      'Earth Science > Biological Classification > Animals/Vertebrates > Fish',\n",
    "      'Earth Science > Biosphere > Ecosystems > Marine Ecosystems',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Mollusks',\n",
    "      'Earth Science > Biological Classification > Animals/Invertebrates > Arthropods > Crustaceans',\n",
    "      'Earth Science > Biological Classification > Plants > Macroalgae (Seaweeds)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a456ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attrs(tfm, zotero_key, kw=kw):\n",
    "    return GlobAttrsFeeder(tfm.dfs, cbs=[\n",
    "        BboxCB(),\n",
    "        DepthRangeCB(),\n",
    "        TimeRangeCB(cfg()),\n",
    "        ZoteroCB(zotero_key, cfg=cfg()),\n",
    "        KeyValuePairCB('keywords', ', '.join(kw)),\n",
    "        KeyValuePairCB('publisher_postprocess_logs', ', '.join(tfm.logs))\n",
    "        ])()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1a5d5",
   "metadata": {},
   "source": [
    "Attributes related to the dataset are retrieved from [zotero](https://www.zotero.org/) using a zotero_key. The [MARIS datasets](https://maris.iaea.org/datasets) include a library on [zotero](https://www.zotero.org/groups/2432820/maris/library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f782051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "get_attrs(tfm, zotero_key='LQRA4MMK', kw=kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38382d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def enums_xtra(tfm, vars):\n",
    "    \"Retrieve a subset of the lengthy enum as 'species_t' for instance\"\n",
    "    enums = Enums(lut_src_dir=lut_path(), cdl_enums=cdl_cfg()['enums'])\n",
    "    xtras = {}\n",
    "    for var in vars:\n",
    "        unique_vals = tfm.unique(var)\n",
    "        if unique_vals.any():\n",
    "            xtras[f'{var}_t'] = enums.filter(f'{var}_t', unique_vals)\n",
    "    return xtras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780bae8",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode(fname_in, fname_out, nc_tpl_path, **kwargs):\n",
    "    dfs = load_data(fname_in)\n",
    "    tfm = Transformer(dfs, cbs=[LowerStripRdnNameCB(get_rdn_format),\n",
    "                                RemapRdnNameCB(),\n",
    "                                ParseTimeCB(),\n",
    "                                LookupBiotaSpeciesCB(get_maris_species, unmatched_fixes_biota_species),\n",
    "                                CorrectWholeBodyPartCB(),\n",
    "                                LookupBiotaBodyPartCB(get_maris_bodypart, unmatched_fixes_biota_tissues),\n",
    "                                LookupBiogroupCB(partial(get_biogroup_lut, species_lut_path())),\n",
    "                                LookupUnitCB(renaming_unit_rules),\n",
    "                                LookupDetectionLimitCB(detection_limit_lut_path()),\n",
    "                                ConvertLonLatCB(),\n",
    "                                EncodeTimeCB(cfg()),\n",
    "                                #CompareDfsAndTfm(dfs),\n",
    "                                RenameColumnCB(coi_grp, get_renaming_rules),\n",
    "                                ReshapeLongToWide(),\n",
    "                                SanitizeLonLatCB()\n",
    "                                ])\n",
    "    tfm()\n",
    "    encoder = NetCDFEncoder(tfm.dfs, \n",
    "                            src_fname=nc_tpl_path,\n",
    "                            dest_fname=fname_out, \n",
    "                            global_attrs=get_attrs(tfm, zotero_key='LQRA4MMK', kw=kw),\n",
    "                            verbose=kwargs.get('verbose', False),\n",
    "                            enums_xtra=enums_xtra(tfm, vars=['species', 'body_part'])\n",
    "                           )\n",
    "    encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd30348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "encode(fname_in, fname_out, nc_tpl_path(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33cc90",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b261be-6e36-4c29-9ef8-42cba2b09985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e918332-4d89-47fb-8d46-7ef516a4f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "def netcdf4_to_df(fname_in):\n",
    "    # read nc file\n",
    "    netcdf4_data = Dataset(fname_in, \"r\")\n",
    "    # Create dictionary of dataframes\n",
    "    dfs={}\n",
    "    for group in (netcdf4_data.groups.keys()):\n",
    "        ds = xr.open_dataset(fname_in, group=group,  decode_times=False)\n",
    "        dfs[group]=ds.to_dataframe()\n",
    "    netcdf4_data.close()\n",
    "    return(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99769bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs = netcdf4_to_df(fname_out)\n",
    "dfs_biota=dfs['biota']\n",
    "dfs_seawater=dfs['seawater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e30a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs_biota.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e91914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs_biota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc688cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dfs_seawater"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
